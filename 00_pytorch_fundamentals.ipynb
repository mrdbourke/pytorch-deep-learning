{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "> **원본:** 이 노트북은 [Daniel Bourke](https://github.com/mrdbourke)의 [Learn PyTorch for Deep Learning](https://github.com/mrdbourke/pytorch-deep-learning) 자료를 한국어로 번역한 것입니다. 원본 저장소: https://github.com/mrdbourke/pytorch-deep-learning\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> \n",
    "\n",
    "[View Source Code](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb) | [View Slides](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/00_pytorch_and_deep_learning_fundamentals.pdf) | [Watch Video Walkthrough](https://youtu.be/Z_ikDlimN6A?t=76) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSNK7duj5SeU"
   },
   "source": [
    "# 00. PyTorch 기초\n",
    "\n",
    "## PyTorch란 무엇인가?\n",
    "\n",
    "[PyTorch](https://pytorch.org/)는 오픈 소스 머신러닝 및 딥러닝 프레임워크입니다.\n",
    "\n",
    "## PyTorch는 무엇에 사용될 수 있는가?\n",
    "\n",
    "PyTorch를 사용하면 Python 코드를 사용하여 데이터를 조작하고 처리하며 머신러닝 알고리즘을 작성할 수 있습니다.\n",
    "\n",
    "## PyTorch를 누가 사용하는가?\n",
    "\n",
    "[메타(Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), 테슬라, 마이크로소프트와 같은 세계 최대 기술 회사들과 [OpenAI가 PyTorch를 사용](https://openai.com/blog/openai-pytorch/)하는 것과 같은 인공지능 연구 회사들이 연구를 강화하고 제품에 머신러닝을 도입하기 위해 PyTorch를 사용합니다.\n",
    "\n",
    "![pytorch being used across industry and research](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
    "\n",
    "예를 들어, Andrej Karpathy(테슬라 AI 책임자)는 테슬라가 자율주행 컴퓨터 비전 모델을 구동하기 위해 PyTorch를 어떻게 사용하는지에 대해 여러 번의 강연([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904))을 했습니다.\n",
    "\n",
    "PyTorch는 또한 [트랙터에서 컴퓨터 비전을 구동](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1)하는 것과 같은 농업과 같은 다른 산업에서도 사용됩니다.\n",
    "\n",
    "## PyTorch를 사용하는 이유는?\n",
    "\n",
    "머신러닝 연구자들은 PyTorch 사용을 좋아합니다. 그리고 2022년 2월 기준으로, PyTorch는 머신러닝 연구 논문과 관련 코드 저장소를 추적하는 웹사이트인 [Papers With Code에서 가장 많이 사용되는 딥러닝 프레임워크](https://paperswithcode.com/trends)입니다.\n",
    "\n",
    "PyTorch는 또한 GPU 가속(코드를 더 빠르게 실행)과 같은 많은 것들을 뒤에서 처리해줍니다.\n",
    "\n",
    "따라서 데이터 조작과 알고리즘 작성에 집중할 수 있고, PyTorch가 빠르게 실행되도록 보장해줍니다.\n",
    "\n",
    "그리고 테슬라와 메타(Facebook)와 같은 회사들이 수백 개의 애플리케이션을 구동하고, 수천 대의 자동차를 운전하며, 수십억 명의 사람들에게 콘텐츠를 전달하는 모델을 구축하기 위해 사용한다면, 개발 측면에서도 명백히 능력이 있다는 것입니다.\n",
    "\n",
    "## 이 모듈에서 다룰 내용\n",
    "\n",
    "이 코스는 다른 섹션(노트북)으로 나뉘어져 있습니다.\n",
    "\n",
    "각 노트북은 PyTorch 내의 중요한 아이디어와 개념을 다룹니다.\n",
    "\n",
    "후속 노트북들은 이전 노트북의 지식을 바탕으로 구축됩니다(번호는 00, 01, 02로 시작하여 끝까지 진행됩니다).\n",
    "\n",
    "이 노트북은 머신러닝과 딥러닝의 기본 구성 요소인 텐서를 다룹니다.\n",
    "\n",
    "구체적으로, 다음을 다룰 예정입니다:\n",
    "\n",
    "| **주제** | **내용** |\n",
    "| ----- | ----- |\n",
    "| **텐서 소개** | 텐서는 모든 머신러닝과 딥러닝의 기본 구성 요소입니다. |\n",
    "| **텐서 생성** | 텐서는 거의 모든 종류의 데이터(이미지, 단어, 숫자 표)를 나타낼 수 있습니다. |\n",
    "| **텐서에서 정보 가져오기** | 텐서에 정보를 넣을 수 있다면, 그것을 꺼내고 싶을 것입니다. |\n",
    "| **텐서 조작** | 머신러닝 알고리즘(신경망과 같은)은 더하기, 곱하기, 결합과 같은 다양한 방법으로 텐서를 조작하는 것을 포함합니다. | \n",
    "| **텐서 형태 다루기** | 머신러닝에서 가장 일반적인 문제 중 하나는 형태 불일치를 다루는 것입니다(잘못된 형태의 텐서를 다른 텐서와 혼합하려고 시도). |\n",
    "| **텐서 인덱싱** | Python 리스트나 NumPy 배열에 인덱싱해봤다면, 텐서도 매우 유사하지만 훨씬 더 많은 차원을 가질 수 있습니다. |\n",
    "| **PyTorch 텐서와 NumPy 혼합** | PyTorch는 텐서([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html))를 사용하고, NumPy는 배열([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html))을 선호합니다. 때로는 이것들을 혼합하고 매칭하고 싶을 것입니다. | \n",
    "| **재현성** | 머신러닝은 매우 실험적이고 작동하기 위해 많은 *무작위성*을 사용하므로, 때로는 그 *무작위성*이 그렇게 무작위하지 않기를 원할 것입니다. |\n",
    "| **GPU에서 텐서 실행** | GPU(그래픽 처리 장치)는 코드를 더 빠르게 만들고, PyTorch는 GPU에서 코드를 쉽게 실행할 수 있게 해줍니다. |\n",
    "\n",
    "## 어디서 도움을 받을 수 있는가?\n",
    "\n",
    "이 코스의 모든 자료는 [GitHub에 있습니다](https://github.com/mrdbourke/pytorch-deep-learning).\n",
    "\n",
    "그리고 문제가 생기면 [Discussions 페이지](https://github.com/mrdbourke/pytorch-deep-learning/discussions)에서 질문할 수도 있습니다.\n",
    "\n",
    "[PyTorch 개발자 포럼](https://discuss.pytorch.org/)도 있으며, PyTorch 관련 모든 것에 대해 매우 도움이 되는 곳입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5v3iRCRUTGeu"
   },
   "source": [
    "## PyTorch 가져오기\n",
    "\n",
    "> **참고:** 이 노트북의 코드를 실행하기 전에 [PyTorch 설정 단계](https://pytorch.org/get-started/locally/)를 거쳐야 합니다.\n",
    ">\n",
    "> 하지만 **Google Colab에서 실행하는 경우**, 모든 것이 작동해야 합니다(Google Colab에는 PyTorch와 다른 라이브러리들이 설치되어 있습니다).\n",
    "\n",
    "PyTorch를 가져오고 사용하고 있는 버전을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1VxEOik46Y4i",
    "outputId": "f3141076-29bc-4600-c1c3-1586b1fe2292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu116'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SqvI4S9TGew"
   },
   "source": [
    "훌륭합니다, PyTorch 1.10.0+ 버전을 사용하고 있는 것 같습니다.\n",
    "\n",
    "이는 이 자료를 진행하면서 PyTorch 1.10.0+와의 대부분의 호환성을 볼 수 있다는 의미이지만, 버전 번호가 훨씬 높다면 일부 불일치를 발견할 수 있습니다.\n",
    "\n",
    "그리고 문제가 있다면 코스 [GitHub Discussions 페이지](https://github.com/mrdbourke/pytorch-deep-learning/discussions)에 게시해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-33BKR16iWc"
   },
   "source": [
    "## 텐서 소개\n",
    "\n",
    "이제 PyTorch를 가져왔으니, 텐서에 대해 배울 시간입니다.\n",
    "\n",
    "텐서는 머신러닝의 기본 구성 요소입니다.\n",
    "\n",
    "텐서의 역할은 데이터를 수치적인 방식으로 표현하는 것입니다.\n",
    "\n",
    "예를 들어, 이미지를 `[3, 224, 224]` 형태의 텐서로 표현할 수 있는데, 이는 `[색상_채널, 높이, 너비]`를 의미합니다. 즉, 이미지가 `3`개의 색상 채널(빨강, 초록, 파랑)과 `224` 픽셀의 높이, `224` 픽셀의 너비를 가진다는 것입니다.\n",
    "\n",
    "![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
    "\n",
    "텐서 용어(텐서를 설명하는 데 사용되는 언어)로 말하면, 텐서는 `색상_채널`, `높이`, `너비`에 대한 세 개의 차원을 가집니다.\n",
    "\n",
    "하지만 너무 앞서 나가고 있습니다.\n",
    "\n",
    "코딩을 통해 텐서에 대해 더 자세히 알아보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFF0N2TU7S7Q"
   },
   "source": [
    "### 텐서 생성\n",
    "\n",
    "PyTorch는 텐서를 좋아합니다. [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) 클래스에 전용 문서 페이지가 있을 정도입니다.\n",
    "\n",
    "첫 번째 숙제는 [`torch.Tensor` 문서](https://pytorch.org/docs/stable/tensors.html)를 10분간 읽어보는 것입니다. 하지만 나중에 해도 됩니다.\n",
    "\n",
    "코딩을 시작해보겠습니다.\n",
    "\n",
    "먼저 생성할 것은 **스칼라(scalar)**입니다.\n",
    "\n",
    "스칼라는 단일 숫자이며, 텐서 용어로는 0차원 텐서입니다.\n",
    "\n",
    "> **참고:** 이것이 이 코스의 경향입니다. 구체적인 코드 작성에 집중할 것입니다. 하지만 종종 PyTorch 문서를 읽고 익숙해지는 연습을 할 것입니다. 결국 이 코스를 마친 후에는 더 배우고 싶어할 것이고, 문서는 자주 찾게 될 곳이기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUDgG2zk7Us5",
    "outputId": "0ac22bd2-16bc-4307-f312-31ae89d6c375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqSuhW7rTGey"
   },
   "source": [
    "위에서 `tensor(7)`이 출력된 것을 보셨나요?\n",
    "\n",
    "이는 `scalar`가 단일 숫자임에도 불구하고 `torch.Tensor` 타입이라는 의미입니다.\n",
    "\n",
    "`ndim` 속성을 사용하여 텐서의 차원을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV98Yz868bav",
    "outputId": "502a625e-ff3c-4fc4-b523-f7634ea82128"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZO2YW_QGTGez"
   },
   "source": [
    "텐서에서 숫자를 가져오고 싶다면 어떻게 해야 할까요?\n",
    "\n",
    "즉, `torch.Tensor`에서 Python 정수로 변환하려면?\n",
    "\n",
    "이를 위해 `item()` 메서드를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k4cyKumPfbE",
    "outputId": "1f6a7916-0c7c-403f-8ebd-875454a94470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Python number within a tensor (only works with one-element tensors)\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYs7ulrATGe0"
   },
   "source": [
    "좋습니다, 이제 **벡터(vector)**를 살펴보겠습니다.\n",
    "\n",
    "벡터는 1차원 텐서이지만 많은 숫자를 포함할 수 있습니다.\n",
    "\n",
    "예를 들어, 집의 `[침실, 화장실]`을 설명하기 위해 벡터 `[3, 2]`를 가질 수 있습니다. 또는 집의 `[침실, 화장실, 주차장]`을 설명하기 위해 `[3, 2, 2]`를 가질 수 있습니다.\n",
    "\n",
    "여기서 중요한 경향은 벡터가 표현할 수 있는 것이 유연하다는 것입니다(텐서도 마찬가지입니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IZF6ASs8QH9",
    "outputId": "e556ed2a-e58a-440f-b103-0f06c91bc75c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXxRUUW2TGe1"
   },
   "source": [
    "훌륭합니다, `vector`는 이제 제가 좋아하는 숫자인 7이 두 개 들어있습니다.\n",
    "\n",
    "몇 개의 차원을 가질 것 같나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03hm3VVv8kr4",
    "outputId": "2035bb26-0189-4b28-fa02-34220d44677f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0VYvSGbTGe1"
   },
   "source": [
    "흠, 이상하네요, `vector`는 두 개의 숫자를 포함하고 있지만 단일 차원만 가지고 있습니다.\n",
    "\n",
    "비밀을 알려드리겠습니다.\n",
    "\n",
    "PyTorch에서 텐서가 가진 차원의 수는 외부의 대괄호(`[`)의 수로 알 수 있고, 한 쪽만 세면 됩니다.\n",
    "\n",
    "`vector`는 몇 개의 대괄호를 가지고 있나요?\n",
    "\n",
    "텐서의 또 다른 중요한 개념은 `shape` 속성입니다. shape는 내부의 요소들이 어떻게 배열되어 있는지 알려줍니다.\n",
    "\n",
    "`vector`의 shape를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6zREV1bDTGe2",
    "outputId": "2a6e7ceb-7eb2-422b-b006-2c6e4825272f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of vector\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aWKppNyTGe2"
   },
   "source": [
    "위의 결과는 `torch.Size([2])`를 반환하는데, 이는 우리의 벡터가 `[2]`의 shape를 가진다는 의미입니다. 이는 대괄호 안에 넣은 두 개의 요소(`[7, 7]`) 때문입니다.\n",
    "\n",
    "이제 **행렬(matrix)**을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5iNwCYL8QO9",
    "outputId": "88fc63a7-4130-4c7a-a574-c61e85d2e99e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3U1bCdjTGe3"
   },
   "source": [
    "와! 더 많은 숫자들이네요! 행렬은 벡터만큼 유연하지만, 추가 차원을 가지고 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LREUbeb8r8j",
    "outputId": "636246b0-b109-472a-c6d5-8601a9e08654"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhXXgq-dTGe3"
   },
   "source": [
    "`MATRIX`는 두 개의 차원을 가지고 있습니다(한 쪽의 외부 대괄호 수를 세어보셨나요?).\n",
    "\n",
    "어떤 `shape`를 가질 것 같나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TL26I31TGe3",
    "outputId": "f05ec0b6-0bc1-4381-9474-56cbe6c67139"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvLpUvrKTGe4"
   },
   "source": [
    "`MATRIX`가 두 요소 깊이와 두 요소 너비이기 때문에 `torch.Size([2, 2])` 출력을 얻습니다.\n",
    "\n",
    "**텐서**를 만들어보는 것은 어떨까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEMDQr188QWW",
    "outputId": "4230e6bd-1844-4210-eea8-245bb8b8b265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmJKkXD7TGe4"
   },
   "source": [
    "와! 정말 멋진 텐서네요.\n",
    "\n",
    "텐서는 거의 모든 것을 나타낼 수 있다는 점을 강조하고 싶습니다.\n",
    "\n",
    "방금 만든 것은 스테이크와 아몬드 버터 가게의 판매 수치일 수 있습니다(제가 좋아하는 음식 두 가지입니다).\n",
    "\n",
    "![a simple tensor in google sheets showing day of week, steak sales and almond butter sales](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
    "\n",
    "몇 개의 차원을 가질 것 같나요? (힌트: 대괄호 세기 트릭을 사용하세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dhuEsjS8QcT",
    "outputId": "7a45df1b-fc32-4cc5-e330-527c6ef7ba5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions for TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln9dys5VTGe4"
   },
   "source": [
    "그리고 shape는 어떨까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdVv4iNRTGe5",
    "outputId": "d8ac706c-020b-4926-b145-d44e41f35e90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxk8GU7oTGe5"
   },
   "source": [
    "좋습니다, `torch.Size([1, 3, 3])`을 출력합니다.\n",
    "\n",
    "차원은 외부에서 내부로 갑니다.\n",
    "\n",
    "즉, 3x3의 1차원이 있다는 의미입니다.\n",
    "\n",
    "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
    "\n",
    "> **참고:** `scalar`와 `vector`에는 소문자를, `MATRIX`와 `TENSOR`에는 대문자를 사용한 것을 눈치채셨을 것입니다. 이는 의도적인 것입니다. 실제로는 스칼라와 벡터가 `y`나 `a`와 같은 소문자로 표시되는 것을 자주 볼 수 있습니다. 그리고 행렬과 텐서는 `X`나 `W`와 같은 대문자로 표시됩니다.\n",
    ">\n",
    "> 행렬과 텐서라는 이름이 서로 바꿔서 사용되는 것도 눈치채셨을 것입니다. 이는 일반적입니다. PyTorch에서는 종종 `torch.Tensor`를 다루기 때문에(따라서 텐서라는 이름), 하지만 내부의 shape와 차원이 실제로 무엇인지를 결정합니다.\n",
    "\n",
    "요약해보겠습니다.\n",
    "\n",
    "| 이름 | 무엇인가? | 차원 수 | 소문자 또는 대문자 (일반적/예시) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **scalar** | 단일 숫자 | 0 | 소문자 (`a`) | \n",
    "| **vector** | 방향이 있는 숫자 (예: 방향이 있는 풍속)이지만 다른 많은 숫자들도 가질 수 있음 | 1 | 소문자 (`y`) |\n",
    "| **matrix** | 숫자의 2차원 배열 | 2 | 대문자 (`Q`) |\n",
    "| **tensor** | 숫자의 n차원 배열 | 임의의 수일 수 있음, 0차원 텐서는 스칼라, 1차원 텐서는 벡터 | 대문자 (`X`) | \n",
    "\n",
    "![scalar vector matrix tensor and what they look like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dms7G4nkTGe5"
   },
   "source": [
    "### 랜덤 텐서\n",
    "\n",
    "텐서가 어떤 형태의 데이터를 나타낸다는 것을 확인했습니다.\n",
    "\n",
    "그리고 신경망과 같은 머신러닝 모델은 텐서 내에서 조작하고 패턴을 찾습니다.\n",
    "\n",
    "하지만 PyTorch로 머신러닝 모델을 구축할 때는 텐서를 수동으로 생성하는 경우는 드뭅니다(지금까지 해온 것처럼).\n",
    "\n",
    "대신, 머신러닝 모델은 종종 큰 랜덤 숫자 텐서로 시작하여 데이터를 통해 작업하면서 더 나은 표현을 위해 이 랜덤 숫자들을 조정합니다.\n",
    "\n",
    "본질적으로:\n",
    "\n",
    "`랜덤 숫자로 시작 -> 데이터 보기 -> 랜덤 숫자 업데이트 -> 데이터 보기 -> 랜덤 숫자 업데이트...`\n",
    "\n",
    "데이터 과학자로서 머신러닝 모델이 시작하는 방법(초기화), 데이터를 보는 방법(표현), 랜덤 숫자를 업데이트하는 방법(최적화)을 정의할 수 있습니다.\n",
    "\n",
    "나중에 이 단계들을 직접 다뤄보겠습니다.\n",
    "\n",
    "지금은 랜덤 숫자의 텐서를 만드는 방법을 살펴보겠습니다.\n",
    "\n",
    "[`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html)를 사용하고 `size` 매개변수를 전달하여 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOJEtDx--GnK",
    "outputId": "2680d44b-e31c-4ab1-d5b1-c0cd76706a0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6541, 0.4807, 0.2162, 0.6168],\n",
       "         [0.4428, 0.6608, 0.6194, 0.8620],\n",
       "         [0.2795, 0.6055, 0.4958, 0.5483]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wB1c_cXTGe5"
   },
   "source": [
    "`torch.rand()`의 유연성은 `size`를 원하는 대로 조정할 수 있다는 것입니다.\n",
    "\n",
    "예를 들어, 일반적인 이미지 형태인 `[224, 224, 3]` (`[높이, 너비, 색상_채널]`)의 랜덤 텐서를 원한다고 가정해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMF_NUp3Ym__",
    "outputId": "8346b853-0b1e-481a-d9ee-a410ee21bab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MQNTY0eTGe6"
   },
   "source": [
    "### 0과 1\n",
    "\n",
    "때로는 텐서를 0이나 1로 채우고 싶을 것입니다.\n",
    "\n",
    "이는 마스킹에서 자주 발생합니다(모델이 학습하지 않도록 텐서의 일부 값을 0으로 마스킹하는 것처럼).\n",
    "\n",
    "[`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)로 0으로 가득 찬 텐서를 만들어보겠습니다.\n",
    "\n",
    "다시 한번, `size` 매개변수가 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCzhd0hl9Vp6",
    "outputId": "9c8ec87f-d8c9-4751-a13e-6a5e986daaa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDQBZJRUZWTN"
   },
   "source": [
    "모든 1로 가득 찬 텐서를 만들기 위해 [`torch.ones()`](https://pytorch.org/docs/stable/generated/torch.ones.html)를 대신 사용하여 같은 작업을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRe6sSXiTGe6",
    "outputId": "3f45b0b8-7f65-423d-c664-f5b5f7866fd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hib1NYrSarL2"
   },
   "source": [
    "### 범위와 같은 텐서 생성\n",
    "\n",
    "때로는 1부터 10까지 또는 0부터 100까지와 같은 숫자 범위를 원할 수 있습니다.\n",
    "\n",
    "`torch.arange(start, end, step)`을 사용하여 할 수 있습니다.\n",
    "\n",
    "여기서:\n",
    "* `start` = 범위의 시작 (예: 0)\n",
    "* `end` = 범위의 끝 (예: 10)\n",
    "* `step` = 각 값 사이의 단계 수 (예: 1)\n",
    "\n",
    "> **참고:** Python에서는 `range()`를 사용하여 범위를 만들 수 있습니다. 하지만 PyTorch에서는 `torch.range()`가 더 이상 사용되지 않으며 향후 오류를 표시할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IqUs81d9W4W",
    "outputId": "2a6f0c08-052e-4b36-b4eb-6a537239026f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3695928/193451495.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(), torch.range() is deprecated \n",
    "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
    "\n",
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-bXf0Ugbh-D"
   },
   "source": [
    "때로는 다른 텐서와 같은 shape를 가진 특정 유형의 텐서를 원할 수 있습니다.\n",
    "\n",
    "예를 들어, 이전 텐서와 같은 shape를 가진 모든 0의 텐서.\n",
    "\n",
    "이를 위해 [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) 또는 [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html)을 사용할 수 있으며, 이는 각각 `input`과 같은 shape로 0 또는 1로 채워진 텐서를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvXwUut5BhHq",
    "outputId": "096b2f8e-8c21-4ace-97b9-c36b92b2fe77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huKZ6QlYTGe7"
   },
   "source": [
    "### 텐서 데이터 타입\n",
    "\n",
    "PyTorch에는 [많은 다른 텐서 데이터 타입](https://pytorch.org/docs/stable/tensors.html#data-types)이 있습니다.\n",
    "\n",
    "일부는 CPU 전용이고 일부는 GPU에 더 적합합니다.\n",
    "\n",
    "어떤 것을 사용할지 아는 것은 시간이 걸릴 수 있습니다.\n",
    "\n",
    "일반적으로 `torch.cuda`가 어디든 보이면 텐서가 GPU용으로 사용되고 있습니다(Nvidia GPU가 CUDA라는 컴퓨팅 도구 키트를 사용하기 때문입니다).\n",
    "\n",
    "가장 일반적인 유형(그리고 일반적으로 기본값)은 `torch.float32` 또는 `torch.float`입니다.\n",
    "\n",
    "이것은 \"32비트 부동 소수점\"이라고 합니다.\n",
    "\n",
    "하지만 16비트 부동 소수점(`torch.float16` 또는 `torch.half`)과 64비트 부동 소수점(`torch.float64` 또는 `torch.double`)도 있습니다.\n",
    "\n",
    "그리고 더 혼란스럽게도 8비트, 16비트, 32비트, 64비트 정수도 있습니다.\n",
    "\n",
    "그리고 더 많습니다!\n",
    "\n",
    "> **참고:** 정수는 `7`과 같은 평평한 둥근 숫자이고, float는 `7.0`과 같은 소수점이 있습니다.\n",
    "\n",
    "이 모든 것의 이유는 **컴퓨팅의 정밀도**와 관련이 있습니다.\n",
    "\n",
    "정밀도는 숫자를 설명하는 데 사용되는 세부 정보의 양입니다.\n",
    "\n",
    "정밀도 값(8, 16, 32)이 높을수록 숫자를 표현하는 데 사용되는 세부 정보와 데이터가 더 많습니다.\n",
    "\n",
    "이는 딥러닝과 수치 컴퓨팅에서 중요합니다. 많은 연산을 수행하기 때문에 계산해야 할 세부 정보가 많을수록 사용해야 하는 컴퓨팅이 더 많기 때문입니다.\n",
    "\n",
    "따라서 낮은 정밀도 데이터 타입은 일반적으로 계산이 더 빠르지만 정확도와 같은 평가 메트릭에서 일부 성능을 희생합니다(계산은 더 빠르지만 덜 정확함).\n",
    "\n",
    "> **Resources:** \n",
    "  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Read the [Wikipedia page for an overview of what precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)) is.\n",
    "\n",
    "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3MoGnpw9XaF",
    "outputId": "61070939-8c52-4ac6-bed7-e64b3ce24615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhP8kzDfe_ty"
   },
   "source": [
    "shape 문제(텐서 shape가 일치하지 않음) 외에도, PyTorch에서 자주 만나게 될 다른 두 가지 가장 일반적인 문제는 데이터 타입과 디바이스 문제입니다.\n",
    "\n",
    "예를 들어, 텐서 중 하나는 `torch.float32`이고 다른 하나는 `torch.float16`입니다(PyTorch는 종종 텐서가 같은 형식이기를 좋아합니다).\n",
    "\n",
    "또는 텐서 중 하나는 CPU에 있고 다른 하나는 GPU에 있습니다(PyTorch는 텐서 간 계산이 같은 디바이스에서 이루어지기를 좋아합니다).\n",
    "\n",
    "나중에 이 디바이스 이야기를 더 자세히 살펴보겠습니다.\n",
    "\n",
    "지금은 `dtype=torch.float16`으로 텐서를 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKSuajld_09s",
    "outputId": "cbac29d9-3371-4fe1-b47c-3af4623b5fbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUjkB2AX7Upz"
   },
   "source": [
    "## 텐서에서 정보 가져오기\n",
    "\n",
    "텐서를 생성한 후(또는 다른 사람이나 PyTorch 모듈이 생성한 후), 텐서에서 일부 정보를 가져오고 싶을 수 있습니다.\n",
    "\n",
    "이전에 본 것들이지만 텐서에 대해 알아보고 싶은 세 가지 가장 일반적인 속성은 다음과 같습니다:\n",
    "* `shape` - 텐서의 shape는 무엇인가? (일부 연산은 특정 shape 규칙을 요구함)\n",
    "* `dtype` - 텐서 내의 요소들이 어떤 데이터 타입으로 저장되어 있는가?\n",
    "* `device` - 텐서가 어떤 디바이스에 저장되어 있는가? (보통 GPU 또는 CPU)\n",
    "\n",
    "랜덤 텐서를 만들고 그에 대한 세부 정보를 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd_X4D0j7Umq",
    "outputId": "86045713-ab36-4c8e-840c-e788f80c5266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4688, 0.0055, 0.8551, 0.0646],\n",
      "        [0.6538, 0.5157, 0.4071, 0.2109],\n",
      "        [0.9960, 0.3061, 0.9369, 0.7008]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45K-E5uPg6cj"
   },
   "source": [
    "> **참고:** PyTorch에서 문제가 발생할 때, 위의 세 속성 중 하나와 관련된 경우가 매우 많습니다. 따라서 오류 메시지가 나타날 때 \"무엇, 무엇, 어디\"라는 작은 노래를 불러보세요:\n",
    "  * \"*내 텐서의 shape는 무엇인가? 데이터 타입은 무엇이고 어디에 저장되어 있는가? shape, 데이터 타입, 어디 어디 어디*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdiWvoAi7UjL"
   },
   "source": [
    "## 텐서 조작 (텐서 연산)\n",
    "\n",
    "딥러닝에서 데이터(이미지, 텍스트, 비디오, 오디오, 단백질 구조 등)는 텐서로 표현됩니다.\n",
    "\n",
    "모델은 이러한 텐서를 조사하고 입력 데이터의 패턴 표현을 만들기 위해 텐서에 대한 일련의 연산(수백만 개 이상일 수 있음)을 수행하여 학습합니다.\n",
    "\n",
    "이러한 연산은 종종 다음과 같은 멋진 춤입니다:\n",
    "* 덧셈\n",
    "* 뺄셈\n",
    "* 곱셈 (요소별)\n",
    "* 나눗셈\n",
    "* 행렬 곱셈\n",
    "\n",
    "그게 전부입니다. 물론 여기저기에 몇 개 더 있지만 이것들이 신경망의 기본 구성 요소입니다.\n",
    "\n",
    "이러한 구성 요소를 올바른 방식으로 쌓으면 가장 정교한 신경망을 만들 수 있습니다(레고처럼!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk_6Dd7L7Uce"
   },
   "source": [
    "### 기본 연산\n",
    "\n",
    "기본적인 연산인 덧셈(`+`), 뺄셈(`-`), 곱셈(`*`)부터 시작해보겠습니다.\n",
    "\n",
    "예상하신 대로 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X71WpQoPD7a4",
    "outputId": "ab30f13e-fc67-4ae4-c5ce-1006410dba07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sp4TlTWWEFeO",
    "outputId": "ce7d2296-881f-4eb3-802e-fd12bc25d6ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1VEHnuRkn8Q"
   },
   "source": [
    "위의 텐서 값들이 `tensor([110, 120, 130])`가 되지 않은 것을 주목하세요. 이는 텐서 내부의 값들이 재할당되지 않는 한 변경되지 않기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuB1UjCIEJIA",
    "outputId": "57cae862-c145-4681-d74b-fe6d77f2125a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYvqGpUTk1o6"
   },
   "source": [
    "숫자를 빼고 이번에는 `tensor` 변수를 재할당해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4iWKoLsENry",
    "outputId": "14d6771d-eb57-4b11-88a7-b1bb308ddc6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFgZY-PaFNXa",
    "outputId": "3536ea54-a056-444c-cd5d-6d438ddda965"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CYXDoIOzk-6I"
   },
   "source": [
    "PyTorch는 기본 연산을 수행하기 위해 [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (곱셈의 줄임말)과 [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html)와 같은 많은 내장 함수들도 가지고 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVysdk3kFWbY",
    "outputId": "3a5bf687-cf24-4224-9e76-975f84638ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxuPJIpNFbqO",
    "outputId": "f04cafd9-eaea-4254-df1a-5ab3b524d74e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original tensor is still unchanged \n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70UNL33AlVQq"
   },
   "source": [
    "하지만 `torch.mul()` 대신 `*`와 같은 연산자 기호를 사용하는 것이 더 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5v3RkR0F2Jq",
    "outputId": "0137caab-5ea1-4d95-f4c5-a0baa0fd652d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT5fVuyu7q5z"
   },
   "source": [
    "### 행렬 곱셈 (필요한 전부입니다)\n",
    "\n",
    "머신러닝과 딥러닝 알고리즘(신경망과 같은)에서 가장 일반적인 연산 중 하나는 [행렬 곱셈](https://www.mathsisfun.com/algebra/matrix-multiplying.html)입니다.\n",
    "\n",
    "PyTorch는 [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) 메서드에서 행렬 곱셈 기능을 구현합니다.\n",
    "\n",
    "행렬 곱셈에서 기억해야 할 두 가지 주요 규칙은 다음과 같습니다:\n",
    "\n",
    "1. **내부 차원**이 일치해야 합니다:\n",
    "  * `(3, 2) @ (3, 2)` won't work\n",
    "  * `(2, 3) @ (3, 2)` will work\n",
    "  * `(3, 2) @ (2, 3)` will work\n",
    "2. 결과 행렬은 **외부 차원**의 shape를 가집니다:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "> **참고:** Python에서 \"`@`\"는 행렬 곱셈의 기호입니다.\n",
    "\n",
    "> **자료:** `torch.matmul()`을 사용한 행렬 곱셈의 모든 규칙을 [PyTorch 문서](https://pytorch.org/docs/stable/generated/torch.matmul.html)에서 볼 수 있습니다.\n",
    "\n",
    "텐서를 만들고 요소별 곱셈과 행렬 곱셈을 수행해보겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE7loucmDlEM",
    "outputId": "44032bf9-c1f7-42fc-c842-dbe7a5c1221a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUAZ3_b0vOKv"
   },
   "source": [
    "요소별 곱셈과 행렬 곱셈의 차이점은 값의 덧셈입니다.\n",
    "\n",
    "값이 `[1, 2, 3]`인 `tensor` 변수에 대해:\n",
    "\n",
    "| 연산 | 계산 | 코드 |\n",
    "| ----- | ----- | ----- |\n",
    "| **요소별 곱셈** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "| **행렬 곱셈** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i42gkUeHvI_1",
    "outputId": "18a630ce-bb56-4c40-81b4-9fdbb2ed7a4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvCBiiTTDk8y",
    "outputId": "cf623247-8f1b-49f1-e788-16da3ed1e59c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4E_pROBDk2r",
    "outputId": "a09af00f-277b-479e-b0a2-ad6311ee5413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obbginUMv43A"
   },
   "source": [
    "행렬 곱셈을 수동으로 할 수 있지만 권장하지 않습니다.\n",
    "\n",
    "내장된 `torch.matmul()` 메서드가 더 빠릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qMSaLOoJscL",
    "outputId": "8bcad8a2-c900-4966-e13c-ff2cc02b9207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 773 µs, sys: 0 ns, total: 773 µs\n",
      "Wall time: 499 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand \n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVWiKB0KwH74",
    "outputId": "fce58235-5c09-49ec-f34b-a90e5640281e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 µs, sys: 83 µs, total: 229 µs\n",
      "Wall time: 171 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ4DDmo1TGe-"
   },
   "source": [
    "## 딥러닝에서 가장 일반적인 오류 중 하나 (shape 오류)\n",
    "\n",
    "딥러닝의 많은 부분이 행렬에 대한 곱셈과 연산 수행이며, 행렬은 어떤 shape와 크기를 결합할 수 있는지에 대한 엄격한 규칙이 있기 때문에, 딥러닝에서 자주 만나게 될 가장 일반적인 오류 중 하나는 shape 불일치입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rN5RcoD4Jo6y",
    "outputId": "20f6c65b-86f4-4903-d253-f6cbf0583934"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb Cell 75\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m tensor_A \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                          [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                          [\u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m tensor_B \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m7\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                          [\u001b[39m8\u001b[39m, \u001b[39m11\u001b[39m], \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                          [\u001b[39m9\u001b[39m, \u001b[39m12\u001b[39m]], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y134sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m torch\u001b[39m.\u001b[39;49mmatmul(tensor_A, tensor_B)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNA6MZEFxWVt"
   },
   "source": [
    "`tensor_A`와 `tensor_B`의 내부 차원을 일치시켜 행렬 곱셈이 작동하도록 할 수 있습니다.\n",
    "\n",
    "이를 수행하는 방법 중 하나는 **전치(transpose)**입니다(주어진 텐서의 차원을 바꾸는 것).\n",
    "\n",
    "PyTorch에서 전치를 수행하는 방법은 다음과 같습니다:\n",
    "* `torch.transpose(input, dim0, dim1)` - 여기서 `input`은 전치하고자 하는 텐서이고 `dim0`과 `dim1`은 바꿀 차원입니다.\n",
    "* `tensor.T` - 여기서 `tensor`는 전치하고자 하는 텐서입니다.\n",
    "\n",
    "후자를 시도해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUqgaANiy1wq",
    "outputId": "e48bbf0c-8008-434e-d372-caa658b2f36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DveqxO7iy_Fi",
    "outputId": "1bd2e85b-ea4d-4948-c408-8eb46ef3534c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35rEIu-NKtVE",
    "outputId": "0b32c7f1-556e-45d4-de22-388419e93dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfcFEqfLjN24"
   },
   "source": [
    "`torch.matmul()`의 줄임말인 [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html)도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3rJvW_TTGe_",
    "outputId": "2c501972-20bf-4a83-ad4a-b5f1b2424097"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXKozI4T0hFi"
   },
   "source": [
    "전치 없이는 행렬 곱셈의 규칙이 충족되지 않아 위와 같은 오류가 발생합니다.\n",
    "\n",
    "시각적으로 보면 어떨까요?\n",
    "\n",
    "![행렬 곱셈의 시각적 데모](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
    "\n",
    "http://matrixmultiplication.xyz/에서 이와 같은 행렬 곱셈 시각화를 직접 만들 수 있습니다.\n",
    "\n",
    "> **참고:** 이와 같은 행렬 곱셈은 두 행렬의 [**내적(dot product)**](https://www.mathsisfun.com/algebra/vectors-dot-product.html)라고도 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA64Z4DmkB31"
   },
   "source": [
    "신경망은 행렬 곱셈과 내적으로 가득합니다.\n",
    "\n",
    "[`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) 모듈(나중에 실제로 보게 될 것입니다)은 피드포워드 레이어 또는 완전 연결 레이어라고도 하며, 입력 `x`와 가중치 행렬 `A` 간의 행렬 곱셈을 구현합니다.\n",
    "\n",
    "$$\n",
    "y = x\\cdot{A^T} + b\n",
    "$$\n",
    "\n",
    "여기서:\n",
    "* `x`는 레이어의 입력입니다(딥러닝은 `torch.nn.Linear()`와 같은 레이어들이 서로 위에 쌓인 스택입니다).\n",
    "* `A`는 레이어에 의해 생성된 가중치 행렬로, 신경망이 데이터의 패턴을 더 잘 표현하도록 학습하면서 조정되는 랜덤 숫자로 시작합니다(\"`T`\"를 주목하세요, 가중치 행렬이 전치되기 때문입니다).\n",
    "  * **참고:** 가중치 행렬을 보여주기 위해 `W`나 `X`와 같은 다른 문자를 자주 볼 수도 있습니다.\n",
    "* `b`는 가중치와 입력을 약간 오프셋하는 데 사용되는 편향 항입니다.\n",
    "* `y`는 출력입니다(패턴을 발견하려는 희망으로 입력을 조작한 것입니다).\n",
    "\n",
    "이는 선형 함수입니다(고등학교나 다른 곳에서 $y = mx+b$와 같은 것을 본 적이 있을 것입니다), 직선을 그리는 데 사용할 수 있습니다!\n",
    "\n",
    "선형 레이어를 가지고 놀아보겠습니다.\n",
    "\n",
    "아래의 `in_features`와 `out_features` 값을 변경해보고 어떤 일이 일어나는지 확인해보세요.\n",
    "\n",
    "shape와 관련된 것을 눈치채셨나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mC_MjKW1LX7T",
    "outputId": "768f75d2-c978-4df3-e18a-4684d46bdfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIGrP5j1pN7j"
   },
   "source": [
    "> **질문:** 위에서 `in_features`를 2에서 3으로 변경하면 어떻게 될까요? 오류가 발생할까요? 오류를 해결하기 위해 입력(`x`)의 shape를 어떻게 변경할 수 있을까요? 힌트: 위에서 `tensor_B`에 대해 무엇을 해야 했나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPNF0nMWoGEj"
   },
   "source": [
    "이전에 해본 적이 없다면, 행렬 곱셈은 처음에는 혼란스러운 주제일 수 있습니다.\n",
    "\n",
    "하지만 몇 번 가지고 놀아보고 심지어 몇 개의 신경망을 열어보면, 어디에나 있다는 것을 알게 될 것입니다.\n",
    "\n",
    "기억하세요, 행렬 곱셈이 필요한 전부입니다.\n",
    "\n",
    "![행렬 곱셈이 필요한 전부입니다](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
    "\n",
    "*신경망 레이어를 파헤치고 직접 구축하기 시작하면, 어디에나 행렬 곱셈을 발견하게 될 것입니다. **출처:** https://marksaroufim.substack.com/p/working-class-deep-learner*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjMmrJOOPv5e"
   },
   "source": [
    "### 최솟값, 최댓값, 평균, 합계 등 찾기 (집계)\n",
    "\n",
    "이제 텐서를 조작하는 몇 가지 방법을 보았으니, 텐서를 집계하는 몇 가지 방법을 살펴보겠습니다(더 많은 값에서 더 적은 값으로).\n",
    "\n",
    "먼저 텐서를 만들고 그 최댓값, 최솟값, 평균, 합계를 찾아보겠습니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrFQbe5fP1Rk",
    "outputId": "034013c1-b384-4a0d-edf8-295ed3a456f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-J-wfMdlsEco"
   },
   "source": [
    "이제 몇 가지 집계를 수행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5wSP9YKP3Lb",
    "outputId": "3aa238c7-646f-434f-a55c-292aabef7227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHoKpsg3sKQE"
   },
   "source": [
    "> **참고:** `torch.mean()`과 같은 일부 메서드는 텐서가 `torch.float32`(가장 일반적) 또는 다른 특정 데이터 타입에 있어야 하며, 그렇지 않으면 연산이 실패할 수 있습니다.\n",
    "\n",
    "`torch` 메서드를 사용하여 위와 같은 작업을 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Cr23Y9uP3HO",
    "outputId": "9c86d805-eef2-465c-e2c8-2bccd515e6d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7ApCaZjDkvp"
   },
   "source": [
    "### 위치별 최솟값/최댓값\n",
    "\n",
    "[`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html)와 [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html)을 사용하여 최댓값 또는 최솟값이 발생하는 텐서의 인덱스를 찾을 수도 있습니다.\n",
    "\n",
    "이는 실제 값 자체가 아니라 가장 높은(또는 가장 낮은) 값이 있는 위치만 원할 때 유용합니다([softmax 활성화 함수](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html)를 사용하는 나중 섹션에서 이를 볼 것입니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzNBl9JSGlHi",
    "outputId": "01e0740e-c34f-469b-9c8f-9e6e5f0363af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBu33WihOXBk"
   },
   "source": [
    "### 텐서 데이터 타입 변경\n",
    "\n",
    "언급했듯이, 딥러닝 연산에서 일반적인 문제는 텐서가 서로 다른 데이터 타입에 있다는 것입니다.\n",
    "\n",
    "하나의 텐서가 `torch.float64`에 있고 다른 하나가 `torch.float32`에 있다면, 일부 오류가 발생할 수 있습니다.\n",
    "\n",
    "하지만 해결책이 있습니다.\n",
    "\n",
    "[`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html)을 사용하여 텐서의 데이터 타입을 변경할 수 있습니다. 여기서 `dtype` 매개변수는 사용하고자 하는 데이터 타입입니다.\n",
    "\n",
    "먼저 텐서를 만들고 그 데이터 타입을 확인해보겠습니다(기본값은 `torch.float32`입니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY2FEsCAOaLu",
    "outputId": "507f1ade-7c7a-4172-fa48-60c9ac4831c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR30FHEc92of"
   },
   "source": [
    "이제 이전과 같은 텐서를 만들지만 데이터 타입을 `torch.float16`으로 변경하겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cac8gRYjOeab",
    "outputId": "96e5ce12-bc29-4a2b-f81c-bfc89ea2d075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a float16 tensor\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndVlKJZ4-7_5"
   },
   "source": [
    "그리고 `torch.int8` 텐서를 만들기 위해 비슷한 작업을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Yqovld2Oj6s",
    "outputId": "667da17f-e38f-404a-bd2d-63683e45c99a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44GxVabar-xe"
   },
   "source": [
    "> **참고:** 다른 데이터 타입은 처음에는 혼란스러울 수 있습니다. 하지만 이렇게 생각해보세요, 숫자가 낮을수록(예: 32, 16, 8) 컴퓨터가 값을 덜 정확하게 저장합니다. 그리고 저장 공간이 적을수록 일반적으로 더 빠른 계산과 더 작은 전체 모델을 만듭니다. 모바일 기반 신경망은 종종 8비트 정수로 작동하며, float32 대응물보다 작고 빠르게 실행되지만 덜 정확합니다. 이에 대한 자세한 내용은 [컴퓨팅의 정밀도](https://en.wikipedia.org/wiki/Precision_(computer_science))에 대해 읽어보시기 바랍니다.\n",
    "\n",
    "> **연습:** 지금까지 꽤 많은 텐서 메서드를 다뤘지만 [`torch.Tensor` 문서](https://pytorch.org/docs/stable/tensors.html)에는 더 많은 것들이 있습니다. 10분 정도 스크롤하면서 눈에 띄는 것들을 살펴보시기 바랍니다. 클릭해서 코드로 직접 작성해보고 어떤 일이 일어나는지 확인해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CkCtAYmGsHY"
   },
   "source": [
    "### 모양 변경, 스택킹, 스퀴징 및 언스퀴징\n",
    "\n",
    "종종 텐서 내부의 값을 실제로 변경하지 않고 텐서의 모양을 변경하거나 차원을 바꾸고 싶을 때가 있습니다.\n",
    "\n",
    "이를 위해 인기 있는 몇 가지 방법들이 있습니다:\n",
    "\n",
    "| 메서드 | 한 줄 설명 |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | `input`을 `shape`로 모양 변경(호환되는 경우), `torch.Tensor.reshape()`도 사용 가능. |\n",
    "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | 다른 `shape`로 원본 텐서의 뷰를 반환하지만 원본 텐서와 같은 데이터를 공유. |\n",
    "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | 새로운 차원(`dim`)을 따라 `tensors` 시퀀스를 연결, 모든 `tensors`는 같은 크기여야 함. |\n",
    "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | 값이 `1`인 모든 차원을 제거하도록 `input`을 압축. |\n",
    "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | `dim`에 값이 `1`인 차원이 추가된 `input`을 반환. | \n",
    "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | 차원이 `dims`로 순열(재배열)된 원본 `input`의 *뷰*를 반환. | \n",
    "\n",
    "왜 이런 것들을 할까요?\n",
    "\n",
    "딥러닝 모델(신경망)은 어떤 방식으로든 텐서를 조작하는 것이기 때문입니다. 그리고 행렬 곱셈의 규칙 때문에 shape 불일치가 있으면 오류가 발생합니다. 이러한 메서드들은 텐서의 올바른 요소들이 다른 텐서의 올바른 요소들과 혼합되도록 도와줍니다.\n",
    "\n",
    "이들을 시도해보겠습니다.\n",
    "\n",
    "먼저 텐서를 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYjRTLOzG4Ev",
    "outputId": "f7f2719c-15ce-406b-dc8f-4477046cd5d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_VarMO9CoT8"
   },
   "source": [
    "이제 `torch.reshape()`로 추가 차원을 추가해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US4WjpQ3SG-8",
    "outputId": "c519d59e-85f1-4a10-eaaa-acb487028e3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tig5xm0jCxuU"
   },
   "source": [
    "`torch.view()`로 뷰를 변경할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDN2BNe5TGfB",
    "outputId": "3df1b0d6-2548-4ecc-ca25-0c4e28a6e536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "# See more: https://stackoverflow.com/a/54507446/7900723\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8joAaUEC2NX"
   },
   "source": [
    "하지만 `torch.view()`로 텐서의 뷰를 변경하는 것은 실제로 *같은* 텐서의 새로운 뷰만 만든다는 것을 기억하세요.\n",
    "\n",
    "따라서 뷰를 변경하면 원본 텐서도 변경됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DxURVvXTGfC",
    "outputId": "668d194d-dd0a-4db1-da00-9c3fd8849186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxnqDBlpDDJ_"
   },
   "source": [
    "새로운 텐서를 자신 위에 다섯 번 쌓고 싶다면 `torch.stack()`으로 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pX5Adf3ORiTK",
    "outputId": "703e8568-61df-4ebd-f4d3-a6366dc265c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET56QzNHDuOI"
   },
   "source": [
    "텐서에서 모든 단일 차원을 제거하는 것은 어떨까요?\n",
    "\n",
    "이를 위해 `torch.squeeze()`를 사용할 수 있습니다(저는 이를 텐서를 *압축*하여 1보다 큰 차원만 가지도록 하는 것으로 기억합니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2Y2HEoDRxJZ",
    "outputId": "dd0645a6-1cdd-46bc-a3a2-433d9cd09336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acjDLk8WD8NC"
   },
   "source": [
    "그리고 `torch.squeeze()`의 반대 작업을 하려면 `torch.unsqueeze()`를 사용하여 특정 인덱스에 값이 1인 차원을 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUC-DEEwSYv7",
    "outputId": "da60e019-3ea6-42f8-8e47-ba037ead737f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9DuJzXgFbM5"
   },
   "source": [
    "`torch.permute(input, dims)`로 축 값의 순서를 재배열할 수도 있습니다. 여기서 `input`은 새로운 `dims`로 *뷰*가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCRGCX8DTGfC",
    "outputId": "6853328b-a1cf-4470-f366-106a231a189c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06LKaFemGBoE"
   },
   "source": [
    "> **참고**: 순열은 *뷰*를 반환하기 때문에(원본과 같은 데이터를 공유), 순열된 텐서의 값은 원본 텐서와 같으며, 뷰의 값을 변경하면 원본의 값도 변경됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEPqVL7fTGfC"
   },
   "source": [
    "## 인덱싱 (텐서에서 데이터 선택)\n",
    "\n",
    "때로는 텐서에서 특정 데이터를 선택하고 싶을 때가 있습니다(예: 첫 번째 열이나 두 번째 행만).\n",
    "\n",
    "이를 위해 인덱싱을 사용할 수 있습니다.\n",
    "\n",
    "Python 리스트나 NumPy 배열에서 인덱싱을 해본 적이 있다면, PyTorch에서 텐서로 인덱싱하는 것은 매우 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSXzdxCQTGfD",
    "outputId": "05a72c08-5f8c-433a-cd31-46065686f825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQG5krnKG43B"
   },
   "source": [
    "인덱싱 값은 외부 차원 -> 내부 차원으로 갑니다(대괄호를 확인해보세요)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zv_Z3IAzTGfD",
    "outputId": "cf6c0936-7600-4af4-9b6f-f6b8ac9b4c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "# Let's index bracket by bracket\n",
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaLjaIFxHe89"
   },
   "source": [
    "`:`를 사용하여 \"이 차원의 모든 값\"을 지정하고 쉼표(`,`)를 사용하여 다른 차원을 추가할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCT09pqeTGfD",
    "outputId": "a91f9b73-f8f0-476a-9c69-fcd03b042f6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwDx_gMsTGfD",
    "outputId": "8165cfd9-a88d-4212-8c45-1eb84ef5be83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiw3_1E3TGfD",
    "outputId": "12fa4749-cf52-4e88-c2c0-44d26aeb633c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFVEgrKhTGfD",
    "outputId": "69eadeb9-11b3-4b48-cb95-0b3305c1274c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "x[0, 0, :] # same as x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ik0r11RIxtm"
   },
   "source": [
    "인덱싱은 처음에는 꽤 혼란스러울 수 있습니다, 특히 더 큰 텐서의 경우(저도 올바르게 하기 위해 여러 번 시도해야 합니다). 하지만 약간의 연습과 데이터 탐색자의 모토(***시각화, 시각화, 시각화***)를 따르면, 요령을 터득하기 시작할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ZaW0Bq7rCm"
   },
   "source": [
    "## PyTorch 텐서와 NumPy\n",
    "\n",
    "NumPy는 인기 있는 Python 수치 계산 라이브러리이므로, PyTorch는 NumPy와 잘 상호작용할 수 있는 기능을 가지고 있습니다.\n",
    "\n",
    "NumPy에서 PyTorch로(그리고 다시 돌아가기 위해) 사용하고 싶은 두 가지 주요 메서드는 다음과 같습니다:\n",
    "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy 배열 -> PyTorch 텐서.\n",
    "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch 텐서 -> NumPy 배열.\n",
    "\n",
    "이들을 시도해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDrDCnvY7rKS",
    "outputId": "86155a63-01f9-4372-e889-61a65ebf0fb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16JG6cONLPnO"
   },
   "source": [
    "> **참고:** 기본적으로 NumPy 배열은 데이터 타입 `float64`로 생성되며, PyTorch 텐서로 변환하면 같은 데이터 타입을 유지합니다(위와 같이).\n",
    ">\n",
    "> 하지만 많은 PyTorch 계산은 기본적으로 `float32`를 사용합니다.\n",
    "> \n",
    "> 따라서 NumPy 배열 (float64) -> PyTorch 텐서 (float64) -> PyTorch 텐서 (float32)로 변환하고 싶다면, `tensor = torch.from_numpy(array).type(torch.float32)`를 사용할 수 있습니다.\n",
    "\n",
    "위에서 `tensor`를 재할당했기 때문에, 텐서를 변경해도 배열은 그대로 유지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovwl7VCREv8L",
    "outputId": "efd21eb9-0010-436a-dc29-f851e3d7d77a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the array, keep the tensor\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geVvu1p0MTWc"
   },
   "source": [
    "그리고 PyTorch 텐서에서 NumPy 배열로 가고 싶다면 `tensor.numpy()`를 호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xw_7ZyVaTKxQ",
    "outputId": "54d6f347-d3f6-44df-9155-83d980c31780"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt8yEV1jMfi2"
   },
   "source": [
    "그리고 위와 같은 규칙이 적용됩니다. 원본 `tensor`를 변경하면 새로운 `numpy_tensor`는 그대로 유지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMp6ZSkET4_Y",
    "outputId": "100678a4-c220-4a44-e4a5-0542359cb9de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, keep the array the same\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gU3ubCrUkI-"
   },
   "source": [
    "## 재현성 (랜덤에서 랜덤을 제거하려고 시도)\n",
    "\n",
    "신경망과 머신러닝에 대해 더 많이 배우면서, 랜덤성이 얼마나 중요한 역할을 하는지 발견하기 시작할 것입니다.\n",
    "\n",
    "정확히는 의사랜덤성입니다. 결국 설계된 대로 컴퓨터는 근본적으로 결정론적이기 때문에(각 단계가 예측 가능), 그들이 만드는 랜덤성은 시뮬레이션된 랜덤성입니다(이에 대해서도 논쟁이 있지만, 저는 컴퓨터 과학자가 아니므로 더 자세한 내용은 직접 찾아보시기 바랍니다).\n",
    "\n",
    "그렇다면 이것이 신경망과 딥러닝과 어떤 관련이 있을까요?\n",
    "\n",
    "신경망이 데이터의 패턴을 설명하기 위해 랜덤 숫자로 시작한다고 논의했습니다(이 숫자들은 좋지 않은 설명입니다). 그리고 텐서 연산(그리고 아직 논의하지 않은 몇 가지 다른 것들)을 사용하여 그 랜덤 숫자들을 개선하여 데이터의 패턴을 더 잘 설명하려고 시도합니다.\n",
    "\n",
    "간단히 말하면:\n",
    "\n",
    "``랜덤 숫자로 시작 -> 텐서 연산 -> 더 좋게 만들려고 시도 (계속 반복)``\n",
    "\n",
    "랜덤성은 좋고 강력하지만, 때로는 랜덤성이 조금 덜했으면 좋겠을 때가 있습니다.\n",
    "\n",
    "왜일까요?\n",
    "\n",
    "반복 가능한 실험을 수행할 수 있도록 하기 위해서입니다.\n",
    "\n",
    "예를 들어, X 성능을 달성할 수 있는 알고리즘을 만듭니다.\n",
    "\n",
    "그리고 친구가 당신이 미치지 않았는지 확인하기 위해 시도해봅니다.\n",
    "\n",
    "그들이 어떻게 그런 일을 할 수 있을까요?\n",
    "\n",
    "바로 **재현성**이 들어오는 곳입니다.\n",
    "\n",
    "다시 말해, 같은 코드를 실행할 때 내 컴퓨터에서 얻는 것과 같은(또는 매우 유사한) 결과를 당신의 컴퓨터에서 얻을 수 있을까요?\n",
    "\n",
    "PyTorch에서 재현성의 간단한 예를 살펴보겠습니다.\n",
    "\n",
    "랜덤이므로 서로 다를 것으로 예상되는 두 개의 랜덤 텐서를 만드는 것으로 시작하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSwxnwEbTGfF",
    "outputId": "73b34154-734f-496f-9b55-b6aaa137e854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
      "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
      "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
      "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
      "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPU6mDKJnr8M"
   },
   "source": [
    "예상했던 대로, 텐서들은 서로 다른 값으로 나옵니다.\n",
    "\n",
    "하지만 *같은* 값을 가진 두 개의 랜덤 텐서를 만들고 싶다면 어떨까요?\n",
    "\n",
    "즉, 텐서들은 여전히 랜덤 값을 포함하지만 같은 맛을 가질 것입니다.\n",
    "\n",
    "바로 [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html)가 들어오는 곳입니다. 여기서 `seed`는 랜덤성에 맛을 주는 정수(예: `42`이지만 무엇이든 될 수 있음)입니다.\n",
    "\n",
    "더 *맛있는* 랜덤 텐서를 만들어서 시도해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sB6d1GfYTGfF",
    "outputId": "4d11d38e-4406-4aff-9a81-cf13aa89ee5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# # Set the random seed\n",
    "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called \n",
    "# Without this, tensor_D would be different to tensor_C \n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uct53Xr5QRC_"
   },
   "source": [
    "좋습니다!\n",
    "\n",
    "시드를 설정하는 것이 작동한 것 같습니다.\n",
    "\n",
    "> **자료:** 방금 다룬 내용은 PyTorch에서 재현성의 표면만 긁어본 것입니다. 일반적인 재현성과 랜덤 시드에 대한 더 자세한 내용은 다음을 확인해보시기 바랍니다:\n",
    "> * [PyTorch 재현성 문서](https://pytorch.org/docs/stable/notes/randomness.html) (10분 동안 읽어보는 것이 좋은 연습이 될 것이며, 지금 이해하지 못하더라도 인지하는 것이 중요합니다).\n",
    "> * [위키피디아 랜덤 시드 페이지](https://en.wikipedia.org/wiki/Random_seed) (랜덤 시드와 일반적인 의사랜덤성에 대한 좋은 개요를 제공할 것입니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxIIM7t27rQ-"
   },
   "source": [
    "## GPU에서 텐서 실행하기 (그리고 더 빠른 계산 만들기)\n",
    "\n",
    "딥러닝 알고리즘은 많은 수치 연산을 필요로 합니다.\n",
    "\n",
    "그리고 기본적으로 이러한 연산은 종종 CPU(컴퓨터 처리 장치)에서 수행됩니다.\n",
    "\n",
    "하지만 GPU(그래픽 처리 장치)라는 또 다른 일반적인 하드웨어가 있으며, 이는 신경망이 필요로 하는 특정 유형의 연산(행렬 곱셈)을 CPU보다 훨씬 빠르게 수행할 수 있습니다.\n",
    "\n",
    "당신의 컴퓨터에도 하나가 있을 수 있습니다.\n",
    "\n",
    "만약 그렇다면, 신경망을 훈련할 때마다 가능한 한 사용하도록 해야 합니다. 훈련 시간을 극적으로 단축시킬 가능성이 높기 때문입니다.\n",
    "\n",
    "GPU에 접근하는 방법과 PyTorch가 GPU를 사용하도록 하는 방법이 몇 가지 있습니다.\n",
    "\n",
    "> **참고:** 이 과정에서 \"GPU\"를 언급할 때, 달리 명시하지 않는 한 [CUDA가 활성화된 Nvidia GPU](https://developer.nvidia.com/cuda-gpus)를 의미합니다(CUDA는 GPU가 그래픽뿐만 아니라 범용 컴퓨팅에 사용될 수 있도록 도와주는 컴퓨팅 플랫폼 및 API입니다).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UiR6QpoYQH_"
   },
   "source": [
    "\n",
    "### 1. GPU 얻기\n",
    "\n",
    "GPU라고 말할 때 무엇이 일어나는지 이미 알고 있을 수 있습니다. 하지만 그렇지 않다면, GPU에 접근하는 몇 가지 방법이 있습니다.\n",
    "\n",
    "| **방법** | **설정 난이도** | **장점** | **단점** | **설정 방법** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Google Colab | 쉬움 | 무료 사용, 거의 설정 불필요, 링크만으로 다른 사람과 작업 공유 가능 | 데이터 출력 저장 안됨, 제한된 컴퓨팅, 타임아웃 대상 | [Google Colab 가이드 따르기](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
    "| 자신의 것 사용 | 보통 | 자신의 머신에서 모든 것을 로컬로 실행 | GPU는 무료가 아님, 선행 비용 필요 | [PyTorch 설치 가이드라인](https://pytorch.org/get-started/locally/) 따르기 |\n",
    "| 클라우드 컴퓨팅 (AWS, GCP, Azure) | 보통-어려움 | 적은 선행 비용, 거의 무한한 컴퓨팅 접근 | 지속적으로 실행하면 비쌀 수 있음, 올바르게 설정하는 데 시간 소요 | [PyTorch 설치 가이드라인](https://pytorch.org/get-started/cloud-partners/) 따르기 |\n",
    "\n",
    "GPU를 사용하는 더 많은 옵션이 있지만, 위의 세 가지로 지금은 충분합니다.\n",
    "\n",
    "개인적으로 저는 소규모 실험(그리고 이 과정 만들기)을 위해 Google Colab과 제 개인 컴퓨터의 조합을 사용하고, 더 많은 컴퓨팅 파워가 필요할 때 클라우드 리소스로 갑니다.\n",
    "\n",
    "> **자료:** 자신만의 GPU를 구매하려고 하지만 무엇을 얻을지 확실하지 않다면, [Tim Dettmers의 훌륭한 가이드](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/)가 있습니다.\n",
    "\n",
    "Nvidia GPU에 접근할 수 있는지 확인하려면 `!nvidia-smi`를 실행할 수 있습니다. 여기서 `!`(뱅이라고도 함)는 \"명령줄에서 이것을 실행\"을 의미합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEMcO-9zYc-w",
    "outputId": "77405db7-3494-4add-cfc7-8415e52a0412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 21 08:34:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 40%   30C    P8     7W / 280W |    177MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1061      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "|    0   N/A  N/A   2671131      G   /usr/lib/xorg/Xorg                 97MiB |\n",
      "|    0   N/A  N/A   2671256      G   /usr/bin/gnome-shell                9MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvkB9p5zYf8E"
   },
   "source": [
    "If you don't have a Nvidia GPU accessible, the above will output something like:\n",
    "\n",
    "```\n",
    "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
    "```\n",
    "\n",
    "In that case, go back up and follow the install steps.\n",
    "\n",
    "If you do have a GPU, the line above will output something like:\n",
    "\n",
    "```\n",
    "Wed Jan 19 22:09:08 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvibZ6e0YcDk"
   },
   "source": [
    "\n",
    "\n",
    "### 2. PyTorch가 GPU에서 실행되도록 하기\n",
    "\n",
    "GPU에 접근할 준비가 되면, 다음 단계는 PyTorch가 데이터 저장(텐서)과 데이터 계산(텐서에 대한 연산 수행)에 사용하도록 하는 것입니다.\n",
    "\n",
    "이를 위해 [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) 패키지를 사용할 수 있습니다.\n",
    "\n",
    "말로 설명하는 것보다 직접 시도해보겠습니다.\n",
    "\n",
    "[`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available)을 사용하여 PyTorch가 GPU에 접근할 수 있는지 테스트할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OweDLgwjEvZ2",
    "outputId": "3a278a24-3ec3-4b1f-8f96-298086fa6ea6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jedZcx2PZFpL"
   },
   "source": [
    "위의 출력이 `True`라면 PyTorch가 GPU를 보고 사용할 수 있고, `False`라면 GPU를 볼 수 없으며, 그 경우 설치 단계를 다시 거쳐야 합니다.\n",
    "\n",
    "이제 코드가 CPU *또는* GPU(사용 가능한 경우)에서 실행되도록 설정하고 싶다고 가정해보겠습니다.\n",
    "\n",
    "그렇게 하면 당신이나 다른 사람이 코드를 실행하기로 결정할 때, 사용하는 컴퓨팅 장치에 관계없이 작동할 것입니다.\n",
    "\n",
    "어떤 종류의 장치가 사용 가능한지 저장할 `device` 변수를 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j92HBCKB7rYa",
    "outputId": "8cca1643-645c-4b67-f1f5-37066f6b9549"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjFyPP2WaCch"
   },
   "source": [
    "위의 출력이 `\"cuda\"`라면 사용 가능한 CUDA 장치(GPU)를 사용하도록 모든 PyTorch 코드를 설정할 수 있고, `\"cpu\"`라면 PyTorch 코드는 CPU를 계속 사용할 것입니다.\n",
    "\n",
    "> **참고:** PyTorch에서는 [**장치 독립적 코드**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code)를 작성하는 것이 모범 사례입니다. 이는 CPU(항상 사용 가능) 또는 GPU(사용 가능한 경우)에서 실행될 코드를 의미합니다.\n",
    "\n",
    "더 빠른 컴퓨팅을 원한다면 GPU를 사용할 수 있지만, *훨씬* 빠른 컴퓨팅을 원한다면 여러 GPU를 사용할 수 있습니다.\n",
    "\n",
    "[`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)를 사용하여 PyTorch가 접근할 수 있는 GPU의 수를 셀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MArsn0DFTGfG",
    "outputId": "de717df5-bb67-4900-805e-a6f00ad0b409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVNf1hiqa-gO"
   },
   "source": [
    "PyTorch가 접근할 수 있는 GPU의 수를 아는 것은 하나의 GPU에서 특정 프로세스를 실행하고 다른 GPU에서 다른 프로세스를 실행하고 싶을 때 유용합니다(PyTorch는 *모든* GPU에서 프로세스를 실행할 수 있는 기능도 있습니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 PyTorch가 Apple Silicon에서 실행되도록 하기\n",
    "\n",
    "Apple의 M1/M2/M3 GPU에서 PyTorch를 실행하려면 [`torch.backends.mps`](https://pytorch.org/docs/stable/notes/mps.html) 모듈을 사용할 수 있습니다.\n",
    "\n",
    "macOS와 PyTorch의 버전이 업데이트되었는지 확인하세요.\n",
    "\n",
    "`torch.backends.mps.is_available()`을 사용하여 PyTorch가 GPU에 접근할 수 있는지 테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Apple Silicon GPU\n",
    "import torch\n",
    "torch.backends.mps.is_available() # Note this will print false if you're not running on a Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전과 같이, 위의 출력이 `\"mps\"`라면 사용 가능한 Apple Silicon GPU를 사용하도록 모든 PyTorch 코드를 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
    "else:\n",
    "    device = \"cpu\" # Default to CPU if no GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqQLcuj68OA-"
   },
   "source": [
    "### 3. 텐서(그리고 모델)를 GPU에 넣기\n",
    "\n",
    "[`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html)를 호출하여 텐서(그리고 모델, 나중에 볼 것입니다)를 특정 장치에 넣을 수 있습니다. 여기서 `device`는 텐서(또는 모델)가 가고 싶은 대상 장치입니다.\n",
    "\n",
    "왜 이렇게 할까요?\n",
    "\n",
    "GPU는 CPU보다 훨씬 빠른 수치 계산을 제공하며, GPU를 사용할 수 없는 경우 **장치 독립적 코드**(위 참조) 때문에 CPU에서 실행됩니다.\n",
    "\n",
    "> **참고:** `to(device)`를 사용하여 텐서를 GPU에 넣는 것(예: `some_tensor.to(device)`)은 해당 텐서의 복사본을 반환합니다. 예를 들어, 같은 텐서가 CPU와 GPU에 있을 것입니다. 텐서를 덮어쓰려면 재할당하세요:\n",
    ">\n",
    "> `some_tensor = some_tensor.to(device)`\n",
    "\n",
    "텐서를 만들고 GPU에 넣어보겠습니다(사용 가능한 경우)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhI3srFXEHfP",
    "outputId": "2f4f6435-fdc4-4e99-e87c-9421c2100f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxXeRKO0TGfG"
   },
   "source": [
    "GPU가 사용 가능하다면, 위 코드는 다음과 같은 출력을 생성할 것입니다:\n",
    "\n",
    "```\n",
    "tensor([1, 2, 3]) cpu\n",
    "tensor([1, 2, 3], device='cuda:0')\n",
    "```\n",
    "\n",
    "두 번째 텐서에 `device='cuda:0'`가 있는 것에 주목하세요. 이는 사용 가능한 0번 GPU에 저장되어 있음을 의미합니다(GPU 인덱스는 0부터 시작하며, 두 개의 GPU가 있다면 각각 `'cuda:0'`와 `'cuda:1'`가 되고, `'cuda:n'`까지 이어집니다).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4puyUX4Bci5D"
   },
   "source": [
    "### 4. 텐서를 다시 CPU로 옮기기\n",
    "\n",
    "텐서를 CPU로 다시 옮기고 싶다면 어떻게 할까요?\n",
    "\n",
    "예를 들어, 텐서를 NumPy와 상호작용하고 싶다면 이렇게 해야 합니다(NumPy는 GPU를 활용하지 않습니다).\n",
    "\n",
    "`tensor_on_gpu`에 [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) 메서드를 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "3ChSLJgPTGfG",
    "outputId": "32e92f62-db28-4dc7-ce93-c2ab33229252"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb Cell 157\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y312sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22544954414e2d525458227d/home/daniel/code/pytorch/pytorch-course/pytorch-deep-learning/00_pytorch_fundamentals.ipynb#Y312sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m tensor_on_gpu\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhymtkRDTGfG"
   },
   "source": [
    "대신, 텐서를 CPU로 되돌려 NumPy에서 사용할 수 있도록 하려면 [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html)를 사용할 수 있습니다.\n",
    "\n",
    "이는 텐서를 CPU 메모리로 복사하여 CPU에서 사용할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN15s-NdTGfG",
    "outputId": "9fffb6f2-c200-4f9c-d987-d9ab5d9cba49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyzNH5lrTGfH"
   },
   "source": [
    "위 코드는 GPU 텐서의 복사본을 CPU 메모리에 반환하므로 원본 텐서는 여전히 GPU에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5u83PCRTGfH",
    "outputId": "4cb931e2-7c8d-49b9-a7de-db3d3c6589b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlmBpnuPTGfH"
   },
   "source": [
    "## 연습 문제\n",
    "\n",
    "모든 연습 문제는 위의 코드를 연습하는 데 초점을 맞춥니다.\n",
    "\n",
    "각 섹션을 참고하거나 연결된 자료를 따라가며 완료할 수 있습니다.\n",
    "\n",
    "**자료:**\n",
    "\n",
    "* [00 연습 템플릿 노트북](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
    "* [00 예시 해답 노트북](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (이것을 보기 전에 연습을 먼저 시도하세요).\n",
    "\n",
    "1. 문서 읽기 - 딥러닝(및 일반적인 코딩 학습)의 큰 부분은 사용하는 프레임워크의 문서에 익숙해지는 것입니다. 이 과정의 나머지 부분에서 PyTorch 문서를 자주 사용할 것입니다. 따라서 다음을 10분 정도 읽어보는 것을 권장합니다(지금 당장 이해하지 못해도 괜찮습니다. 초점은 완전한 이해가 아니라 인지입니다). [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) 및 [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics) 문서를 참고하세요.\n",
    "2. shape가 `(7, 7)`인 랜덤 텐서를 생성하세요.\n",
    "3. 2번에서 만든 텐서와 shape가 `(1, 7)`인 다른 랜덤 텐서를 사용해 행렬 곱셈을 수행하세요(힌트: 두 번째 텐서를 전치해야 할 수 있습니다).\n",
    "4. 랜덤 시드를 `0`으로 설정하고 2번과 3번을 다시 수행하세요.\n",
    "5. 랜덤 시드와 관련하여, `torch.manual_seed()`로 설정하는 방법을 보았는데 GPU에서도 동일한 것이 있을까요? (힌트: `torch.cuda` 문서를 살펴봐야 합니다). 있다면 GPU 랜덤 시드를 `1234`로 설정하세요.\n",
    "6. shape가 `(2, 3)`인 랜덤 텐서 두 개를 생성하고 둘 다 GPU로 보냅니다(이를 위해 GPU 접근이 필요합니다). 텐서를 생성할 때 `torch.manual_seed(1234)`를 설정합니다(GPU 랜덤 시드일 필요는 없습니다).\n",
    "7. 6번에서 생성한 텐서들에 대해 행렬 곱셈을 수행하세요(다시 말하지만, 텐서 중 하나의 shape를 조정해야 할 수 있습니다).\n",
    "8. 7번의 출력의 최댓값과 최솟값을 찾으세요.\n",
    "9. 7번의 출력에서 최댓값과 최솟값의 인덱스를 찾으세요.\n",
    "10. shape가 `(1, 1, 1, 10)`인 랜덤 텐서를 만들고, 모든 `1` 차원을 제거하여 shape가 `(10)`인 텐서를 만드세요. 생성할 때 시드를 `7`로 설정하고 첫 번째 텐서와 그 shape, 두 번째 텐서와 그 shape를 출력하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlmBpnuPTGfH"
   },
   "source": [
    "## 추가 학습\n",
    "\n",
    "* [PyTorch 기본 튜토리얼](https://pytorch.org/tutorials/beginner/basics/intro.html)을 1시간 정도 살펴보세요(특히 [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)와 [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) 섹션을 추천합니다).\n",
    "* 텐서가 데이터를 어떻게 표현할 수 있는지 더 알고 싶다면 이 영상을 참고하세요: [What’s a tensor?](https://youtu.be/f5liqUk0ZTw)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "00_pytorch_fundamentals.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
