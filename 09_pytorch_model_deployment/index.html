
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Learn important machine learning concepts hands-on by writing PyTorch code.">
      
      
      
        <link rel="canonical" href="https://www.learnpytorch.io/09_pytorch_model_deployment/">
      
      
        <link rel="prev" href="../08_pytorch_paper_replicating/">
      
      
        <link rel="next" href="../pytorch_2_intro/">
      
      
        
      
      
      <link rel="icon" href="../assets/ztm-logo-and-pytorch-logo.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.14+insiders-4.35.1">
    
    
      
        <title>09. PyTorch Model Deployment - Zero to Mastery Learn PyTorch for Deep Learning</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.14411569.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.df142b89.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  
<meta property="og:type" content="website" />
<meta property="og:title" content="09. PyTorch Model Deployment - Zero to Mastery Learn PyTorch for Deep Learning" />
<meta property="og:description" content="Learn important machine learning concepts hands-on by writing PyTorch code." />
<meta property="og:image" content="https://www.learnpytorch.io/assets/images/social/09_pytorch_model_deployment.png" />
<meta property="og:image:type" content="image/png" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:url" content="https://www.learnpytorch.io/09_pytorch_model_deployment/" />
<meta property="twitter:card" content="summary_large_image" />
<meta property="twitter.title" content="09. PyTorch Model Deployment - Zero to Mastery Learn PyTorch for Deep Learning" />
<meta property="twitter:description" content="Learn important machine learning concepts hands-on by writing PyTorch code." />
<meta property="twitter:image" content="https://www.learnpytorch.io/assets/images/social/09_pytorch_model_deployment.png" />
</head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#09-pytorch-model-deployment" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Zero to Mastery Learn PyTorch for Deep Learning" class="md-header__button md-logo" aria-label="Zero to Mastery Learn PyTorch for Deep Learning" data-md-component="logo">
      
  <img src="../assets/ztm-logo-and-pytorch-logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Zero to Mastery Learn PyTorch for Deep Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              09. PyTorch Model Deployment
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mrdbourke/pytorch-deep-learning/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    mrdbourke/pytorch_deep_learning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Zero to Mastery Learn PyTorch for Deep Learning" class="md-nav__button md-logo" aria-label="Zero to Mastery Learn PyTorch for Deep Learning" data-md-component="logo">
      
  <img src="../assets/ztm-logo-and-pytorch-logo.png" alt="logo">

    </a>
    Zero to Mastery Learn PyTorch for Deep Learning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mrdbourke/pytorch-deep-learning/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    mrdbourke/pytorch_deep_learning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../00_pytorch_fundamentals/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    00. PyTorch Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../01_pytorch_workflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    01. PyTorch Workflow Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../02_pytorch_classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    02. PyTorch Neural Network Classification
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../03_pytorch_computer_vision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    03. PyTorch Computer Vision
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../04_pytorch_custom_datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    04. PyTorch Custom Datasets
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../05_pytorch_going_modular/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    05. PyTorch Going Modular
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../06_pytorch_transfer_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    06. PyTorch Transfer Learning
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../07_pytorch_experiment_tracking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    07. PyTorch Experiment Tracking
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../08_pytorch_paper_replicating/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    08. PyTorch Paper Replicating
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    
  
    09. PyTorch Model Deployment
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    
  
    09. PyTorch Model Deployment
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-machine-learning-model-deployment" class="md-nav__link">
    <span class="md-ellipsis">
      
        What is machine learning model deployment?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-deploy-a-machine-learning-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why deploy a machine learning model?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#different-types-of-machine-learning-model-deployment" class="md-nav__link">
    <span class="md-ellipsis">
      
        Different types of machine learning model deployment
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Different types of machine learning model deployment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wheres-it-going-to-go" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where's it going to go?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hows-it-going-to-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        How's it going to function?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ways-to-deploy-a-machine-learning-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ways to deploy a machine learning model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-were-going-to-cover" class="md-nav__link">
    <span class="md-ellipsis">
      
        What we're going to cover
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#where-can-you-get-help" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where can you get help?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#0-getting-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        0. Getting setup
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-getting-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Getting data
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-foodvision-mini-model-deployment-experiment-outline" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. FoodVision Mini model deployment experiment outline
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-creating-an-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Creating an EffNetB2 feature extractor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Creating an EffNetB2 feature extractor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-creating-a-function-to-make-an-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 Creating a function to make an EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-creating-dataloaders-for-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 Creating DataLoaders for EffNetB2
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-training-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 Training EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-inspecting-effnetb2-loss-curves" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4 Inspecting EffNetB2 loss curves
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-saving-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.5 Saving EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-checking-the-size-of-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.6 Checking the size of EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#37-collecting-effnetb2-feature-extractor-stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.7 Collecting EffNetB2 feature extractor stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-creating-a-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Creating a ViT feature extractor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Creating a ViT feature extractor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-create-dataloaders-for-vit" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.1 Create DataLoaders for ViT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-training-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2 Training ViT feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-inspecting-vit-loss-curves" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.3 Inspecting ViT loss curves
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-saving-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.4 Saving ViT feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-checking-the-size-of-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.5 Checking the size of ViT feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46-collecting-vit-feature-extractor-stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.6 Collecting ViT feature extractor stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-making-predictions-with-our-trained-models-and-timing-them" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Making predictions with our trained models and timing them
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Making predictions with our trained models and timing them">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-creating-a-function-to-make-predictions-across-the-test-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.1 Creating a function to make predictions across the test dataset
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-making-and-timing-predictions-with-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.2 Making and timing predictions with EffNetB2
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-making-and-timing-predictions-with-vit" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.3 Making and timing predictions with ViT
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-comparing-model-results-prediction-times-and-size" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Comparing model results, prediction times and size
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Comparing model results, prediction times and size">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-visualizing-the-speed-vs-performance-tradeoff" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.1 Visualizing the speed vs. performance tradeoff
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-bringing-foodvision-mini-to-life-by-creating-a-gradio-demo" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. Bringing FoodVision Mini to life by creating a Gradio demo
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Bringing FoodVision Mini to life by creating a Gradio demo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-gradio-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.1 Gradio overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-creating-a-function-to-map-our-inputs-and-outputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.2 Creating a function to map our inputs and outputs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-creating-a-list-of-example-images" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.3 Creating a list of example images
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-building-a-gradio-interface" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.4 Building a Gradio interface
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-turning-our-foodvision-mini-gradio-demo-into-a-deployable-app" class="md-nav__link">
    <span class="md-ellipsis">
      
        8. Turning our FoodVision Mini Gradio Demo into a deployable app
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Turning our FoodVision Mini Gradio Demo into a deployable app">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-what-is-hugging-face-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.1 What is Hugging Face Spaces?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-deployed-gradio-app-structure" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.2 Deployed Gradio app structure
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-creating-a-demos-folder-to-store-our-foodvision-mini-app-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.3 Creating a demos folder to store our FoodVision Mini app files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-creating-a-folder-of-example-images-to-use-with-our-foodvision-mini-demo" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.4 Creating a folder of example images to use with our FoodVision Mini demo
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-moving-our-trained-effnetb2-model-to-our-foodvision-mini-demo-directory" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.5 Moving our trained EffNetB2 model to our FoodVision Mini demo directory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86-turning-our-effnetb2-model-into-a-python-script-modelpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.6 Turning our EffNetB2 model into a Python script (model.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#87-turning-our-foodvision-mini-gradio-app-into-a-python-script-apppy" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.7 Turning our FoodVision Mini Gradio app into a Python script (app.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#88-creating-a-requirements-file-for-foodvision-mini-requirementstxt" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.8 Creating a requirements file for FoodVision Mini (requirements.txt)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-deploying-our-foodvision-mini-app-to-huggingface-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        9. Deploying our FoodVision Mini app to HuggingFace Spaces
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Deploying our FoodVision Mini app to HuggingFace Spaces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-downloading-our-foodvision-mini-app-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.1 Downloading our FoodVision Mini app files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-running-our-foodvision-mini-demo-locally" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.2 Running our FoodVision Mini demo locally
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-uploading-to-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.3 Uploading to Hugging Face
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-creating-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10. Creating FoodVision Big
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Creating FoodVision Big">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-creating-a-model-and-transforms-for-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.1 Creating a model and transforms for FoodVision Big
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-getting-data-for-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.2 Getting data for FoodVision Big
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-creating-a-subset-of-the-food101-dataset-for-faster-experimenting" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.3 Creating a subset of the Food101 dataset for faster experimenting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-turning-our-food101-datasets-into-dataloaders" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.4 Turning our Food101 datasets into DataLoaders
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-training-foodvision-big-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.5 Training FoodVision Big model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-inspecting-loss-curves-of-foodvision-big-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.6 Inspecting loss curves of FoodVision Big model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#107-saving-and-loading-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.7 Saving and loading FoodVision Big
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#108-checking-foodvision-big-model-size" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.8 Checking FoodVision Big model size
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-turning-our-foodvision-big-model-into-a-deployable-app" class="md-nav__link">
    <span class="md-ellipsis">
      
        11. Turning our FoodVision Big model into a deployable app
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. Turning our FoodVision Big model into a deployable app">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-downloading-an-example-image-and-moving-it-to-the-examples-directory" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.1 Downloading an example image and moving it to the examples directory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-saving-food101-class-names-to-file-class_namestxt" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.2 Saving Food101 class names to file (class_names.txt)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-turning-our-foodvision-big-model-into-a-python-script-modelpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.3 Turning our FoodVision Big model into a Python script (model.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-turning-our-foodvision-big-gradio-app-into-a-python-script-apppy" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.4 Turning our FoodVision Big Gradio app into a Python script (app.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#115-creating-a-requirements-file-for-foodvision-big-requirementstxt" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.5 Creating a requirements file for FoodVision Big (requirements.txt)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#116-downloading-our-foodvision-big-app-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.6 Downloading our FoodVision Big app files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#117-deploying-our-foodvision-big-app-to-huggingface-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.7 Deploying our FoodVision Big app to HuggingFace Spaces
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#main-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      
        Main takeaways
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exercises
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extra-curriculum" class="md-nav__link">
    <span class="md-ellipsis">
      
        Extra-curriculum
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_2_intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    A Quick PyTorch 2.0 Tutorial
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_extra_resources/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    PyTorch Extra Resources
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_cheatsheet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    PyTorch Cheatsheet
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_most_common_errors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    
  
    The Three Most Common Errors in PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-machine-learning-model-deployment" class="md-nav__link">
    <span class="md-ellipsis">
      
        What is machine learning model deployment?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-deploy-a-machine-learning-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why deploy a machine learning model?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#different-types-of-machine-learning-model-deployment" class="md-nav__link">
    <span class="md-ellipsis">
      
        Different types of machine learning model deployment
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Different types of machine learning model deployment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wheres-it-going-to-go" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where's it going to go?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hows-it-going-to-function" class="md-nav__link">
    <span class="md-ellipsis">
      
        How's it going to function?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ways-to-deploy-a-machine-learning-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ways to deploy a machine learning model
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-were-going-to-cover" class="md-nav__link">
    <span class="md-ellipsis">
      
        What we're going to cover
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#where-can-you-get-help" class="md-nav__link">
    <span class="md-ellipsis">
      
        Where can you get help?
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#0-getting-setup" class="md-nav__link">
    <span class="md-ellipsis">
      
        0. Getting setup
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-getting-data" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Getting data
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-foodvision-mini-model-deployment-experiment-outline" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. FoodVision Mini model deployment experiment outline
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-creating-an-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Creating an EffNetB2 feature extractor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Creating an EffNetB2 feature extractor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-creating-a-function-to-make-an-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.1 Creating a function to make an EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-creating-dataloaders-for-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.2 Creating DataLoaders for EffNetB2
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-training-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.3 Training EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-inspecting-effnetb2-loss-curves" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.4 Inspecting EffNetB2 loss curves
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-saving-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.5 Saving EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-checking-the-size-of-effnetb2-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.6 Checking the size of EffNetB2 feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#37-collecting-effnetb2-feature-extractor-stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        3.7 Collecting EffNetB2 feature extractor stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-creating-a-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Creating a ViT feature extractor
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Creating a ViT feature extractor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-create-dataloaders-for-vit" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.1 Create DataLoaders for ViT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-training-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.2 Training ViT feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-inspecting-vit-loss-curves" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.3 Inspecting ViT loss curves
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-saving-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.4 Saving ViT feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-checking-the-size-of-vit-feature-extractor" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.5 Checking the size of ViT feature extractor
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46-collecting-vit-feature-extractor-stats" class="md-nav__link">
    <span class="md-ellipsis">
      
        4.6 Collecting ViT feature extractor stats
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-making-predictions-with-our-trained-models-and-timing-them" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. Making predictions with our trained models and timing them
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Making predictions with our trained models and timing them">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-creating-a-function-to-make-predictions-across-the-test-dataset" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.1 Creating a function to make predictions across the test dataset
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-making-and-timing-predictions-with-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.2 Making and timing predictions with EffNetB2
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-making-and-timing-predictions-with-vit" class="md-nav__link">
    <span class="md-ellipsis">
      
        5.3 Making and timing predictions with ViT
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-comparing-model-results-prediction-times-and-size" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. Comparing model results, prediction times and size
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Comparing model results, prediction times and size">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-visualizing-the-speed-vs-performance-tradeoff" class="md-nav__link">
    <span class="md-ellipsis">
      
        6.1 Visualizing the speed vs. performance tradeoff
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-bringing-foodvision-mini-to-life-by-creating-a-gradio-demo" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. Bringing FoodVision Mini to life by creating a Gradio demo
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Bringing FoodVision Mini to life by creating a Gradio demo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-gradio-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.1 Gradio overview
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-creating-a-function-to-map-our-inputs-and-outputs" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.2 Creating a function to map our inputs and outputs
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-creating-a-list-of-example-images" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.3 Creating a list of example images
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-building-a-gradio-interface" class="md-nav__link">
    <span class="md-ellipsis">
      
        7.4 Building a Gradio interface
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-turning-our-foodvision-mini-gradio-demo-into-a-deployable-app" class="md-nav__link">
    <span class="md-ellipsis">
      
        8. Turning our FoodVision Mini Gradio Demo into a deployable app
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Turning our FoodVision Mini Gradio Demo into a deployable app">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-what-is-hugging-face-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.1 What is Hugging Face Spaces?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-deployed-gradio-app-structure" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.2 Deployed Gradio app structure
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-creating-a-demos-folder-to-store-our-foodvision-mini-app-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.3 Creating a demos folder to store our FoodVision Mini app files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-creating-a-folder-of-example-images-to-use-with-our-foodvision-mini-demo" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.4 Creating a folder of example images to use with our FoodVision Mini demo
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-moving-our-trained-effnetb2-model-to-our-foodvision-mini-demo-directory" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.5 Moving our trained EffNetB2 model to our FoodVision Mini demo directory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86-turning-our-effnetb2-model-into-a-python-script-modelpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.6 Turning our EffNetB2 model into a Python script (model.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#87-turning-our-foodvision-mini-gradio-app-into-a-python-script-apppy" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.7 Turning our FoodVision Mini Gradio app into a Python script (app.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#88-creating-a-requirements-file-for-foodvision-mini-requirementstxt" class="md-nav__link">
    <span class="md-ellipsis">
      
        8.8 Creating a requirements file for FoodVision Mini (requirements.txt)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-deploying-our-foodvision-mini-app-to-huggingface-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        9. Deploying our FoodVision Mini app to HuggingFace Spaces
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Deploying our FoodVision Mini app to HuggingFace Spaces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-downloading-our-foodvision-mini-app-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.1 Downloading our FoodVision Mini app files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-running-our-foodvision-mini-demo-locally" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.2 Running our FoodVision Mini demo locally
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-uploading-to-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      
        9.3 Uploading to Hugging Face
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-creating-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10. Creating FoodVision Big
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Creating FoodVision Big">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-creating-a-model-and-transforms-for-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.1 Creating a model and transforms for FoodVision Big
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-getting-data-for-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.2 Getting data for FoodVision Big
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-creating-a-subset-of-the-food101-dataset-for-faster-experimenting" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.3 Creating a subset of the Food101 dataset for faster experimenting
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#104-turning-our-food101-datasets-into-dataloaders" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.4 Turning our Food101 datasets into DataLoaders
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#105-training-foodvision-big-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.5 Training FoodVision Big model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#106-inspecting-loss-curves-of-foodvision-big-model" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.6 Inspecting loss curves of FoodVision Big model
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#107-saving-and-loading-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.7 Saving and loading FoodVision Big
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#108-checking-foodvision-big-model-size" class="md-nav__link">
    <span class="md-ellipsis">
      
        10.8 Checking FoodVision Big model size
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-turning-our-foodvision-big-model-into-a-deployable-app" class="md-nav__link">
    <span class="md-ellipsis">
      
        11. Turning our FoodVision Big model into a deployable app
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="11. Turning our FoodVision Big model into a deployable app">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#111-downloading-an-example-image-and-moving-it-to-the-examples-directory" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.1 Downloading an example image and moving it to the examples directory
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#112-saving-food101-class-names-to-file-class_namestxt" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.2 Saving Food101 class names to file (class_names.txt)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#113-turning-our-foodvision-big-model-into-a-python-script-modelpy" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.3 Turning our FoodVision Big model into a Python script (model.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#114-turning-our-foodvision-big-gradio-app-into-a-python-script-apppy" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.4 Turning our FoodVision Big Gradio app into a Python script (app.py)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#115-creating-a-requirements-file-for-foodvision-big-requirementstxt" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.5 Creating a requirements file for FoodVision Big (requirements.txt)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#116-downloading-our-foodvision-big-app-files" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.6 Downloading our FoodVision Big app files
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#117-deploying-our-foodvision-big-app-to-huggingface-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      
        11.7 Deploying our FoodVision Big app to HuggingFace Spaces
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#main-takeaways" class="md-nav__link">
    <span class="md-ellipsis">
      
        Main takeaways
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      
        Exercises
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extra-curriculum" class="md-nav__link">
    <span class="md-ellipsis">
      
        Extra-curriculum
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


<script>
(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :
    typeof define === 'function' && define.amd ? define(factory) :
    (global = global || self, global.ClipboardCopyElement = factory());
  }(this, function () { 'use strict';

    function createNode(text) {
      const node = document.createElement('pre');
      node.style.width = '1px';
      node.style.height = '1px';
      node.style.position = 'fixed';
      node.style.top = '5px';
      node.textContent = text;
      return node;
    }

    function copyNode(node) {
      if ('clipboard' in navigator) {
        // eslint-disable-next-line flowtype/no-flow-fix-me-comments
        // $FlowFixMe Clipboard is not defined in Flow yet.
        return navigator.clipboard.writeText(node.textContent);
      }

      const selection = getSelection();

      if (selection == null) {
        return Promise.reject(new Error());
      }

      selection.removeAllRanges();
      const range = document.createRange();
      range.selectNodeContents(node);
      selection.addRange(range);
      document.execCommand('copy');
      selection.removeAllRanges();
      return Promise.resolve();
    }
    function copyText(text) {
      if ('clipboard' in navigator) {
        // eslint-disable-next-line flowtype/no-flow-fix-me-comments
        // $FlowFixMe Clipboard is not defined in Flow yet.
        return navigator.clipboard.writeText(text);
      }

      const body = document.body;

      if (!body) {
        return Promise.reject(new Error());
      }

      const node = createNode(text);
      body.appendChild(node);
      copyNode(node);
      body.removeChild(node);
      return Promise.resolve();
    }

    function copy(button) {
      const id = button.getAttribute('for');
      const text = button.getAttribute('value');

      function trigger() {
        button.dispatchEvent(new CustomEvent('clipboard-copy', {
          bubbles: true
        }));
      }

      if (text) {
        copyText(text).then(trigger);
      } else if (id) {
        const root = 'getRootNode' in Element.prototype ? button.getRootNode() : button.ownerDocument;
        if (!(root instanceof Document || 'ShadowRoot' in window && root instanceof ShadowRoot)) return;
        const node = root.getElementById(id);
        if (node) copyTarget(node).then(trigger);
      }
    }

    function copyTarget(content) {
      if (content instanceof HTMLInputElement || content instanceof HTMLTextAreaElement) {
        return copyText(content.value);
      } else if (content instanceof HTMLAnchorElement && content.hasAttribute('href')) {
        return copyText(content.href);
      } else {
        return copyNode(content);
      }
    }

    function clicked(event) {
      const button = event.currentTarget;

      if (button instanceof HTMLElement) {
        copy(button);
      }
    }

    function keydown(event) {
      if (event.key === ' ' || event.key === 'Enter') {
        const button = event.currentTarget;

        if (button instanceof HTMLElement) {
          event.preventDefault();
          copy(button);
        }
      }
    }

    function focused(event) {
      event.currentTarget.addEventListener('keydown', keydown);
    }

    function blurred(event) {
      event.currentTarget.removeEventListener('keydown', keydown);
    }

    class ClipboardCopyElement extends HTMLElement {
      constructor() {
        super();
        this.addEventListener('click', clicked);
        this.addEventListener('focus', focused);
        this.addEventListener('blur', blurred);
      }

      connectedCallback() {
        if (!this.hasAttribute('tabindex')) {
          this.setAttribute('tabindex', '0');
        }

        if (!this.hasAttribute('role')) {
          this.setAttribute('role', 'button');
        }
      }

      get value() {
        return this.getAttribute('value') || '';
      }

      set value(text) {
        this.setAttribute('value', text);
      }

    }

    if (!window.customElements.get('clipboard-copy')) {
      window.ClipboardCopyElement = ClipboardCopyElement;
      window.customElements.define('clipboard-copy', ClipboardCopyElement);
    }

    return ClipboardCopyElement;

  }));
</script>
<script>
      document.addEventListener('clipboard-copy', function(event) {
        const notice = event.target.querySelector('.notice')
        notice.hidden = false
        setTimeout(function() {
          notice.hidden = true
        }, 1000)
      })
</script>




<style type="text/css">
    
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight-ipynb .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight-ipynb { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight-ipynb .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight-ipynb .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight-ipynb .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight-ipynb .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight-ipynb .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight-ipynb .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight-ipynb .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight-ipynb .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight-ipynb .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight-ipynb .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight-ipynb .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight-ipynb .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight-ipynb .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight-ipynb .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight-ipynb .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight-ipynb .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight-ipynb .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight-ipynb .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight-ipynb .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight-ipynb .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight-ipynb .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight-ipynb .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight-ipynb .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight-ipynb .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight-ipynb .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight-ipynb .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight-ipynb .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight-ipynb .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight-ipynb .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight-ipynb .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight-ipynb .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight-ipynb .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight-ipynb .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight-ipynb .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight-ipynb .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight-ipynb .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight-ipynb .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight-ipynb .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight-ipynb .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight-ipynb .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight-ipynb .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>




<style type="text/css">
/*
This file is taken from the built JupyterLab theme.css
Found on share/nbconvert/templates/lab/static
Some changes have been made and marked with CHANGE
*/

.jupyter-wrapper {
    /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

    --jp-shadow-base-lightness: 0;
    --jp-shadow-umbra-color: rgba(
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        0.2
    );
    --jp-shadow-penumbra-color: rgba(
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        0.14
    );
    --jp-shadow-ambient-color: rgba(
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        0.12
    );
    --jp-elevation-z0: none;
    --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
        0px 1px 1px 0px var(--jp-shadow-penumbra-color),
        0px 1px 3px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
        0px 2px 2px 0px var(--jp-shadow-penumbra-color),
        0px 1px 5px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
        0px 4px 5px 0px var(--jp-shadow-penumbra-color),
        0px 1px 10px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
        0px 6px 10px 0px var(--jp-shadow-penumbra-color),
        0px 1px 18px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
        0px 8px 10px 1px var(--jp-shadow-penumbra-color),
        0px 3px 14px 2px var(--jp-shadow-ambient-color);
    --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
        0px 12px 17px 2px var(--jp-shadow-penumbra-color),
        0px 5px 22px 4px var(--jp-shadow-ambient-color);
    --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
        0px 16px 24px 2px var(--jp-shadow-penumbra-color),
        0px 6px 30px 5px var(--jp-shadow-ambient-color);
    --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
        0px 20px 31px 3px var(--jp-shadow-penumbra-color),
        0px 8px 38px 7px var(--jp-shadow-ambient-color);
    --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
        0px 24px 38px 3px var(--jp-shadow-penumbra-color),
        0px 9px 46px 8px var(--jp-shadow-ambient-color);

    /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

    --jp-border-width: 1px;
    --jp-border-color0: var(--md-grey-400);
    --jp-border-color1: var(--md-grey-400);
    --jp-border-color2: var(--md-grey-300);
    --jp-border-color3: var(--md-grey-200);
    --jp-border-radius: 2px;

    /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

    --jp-ui-font-scale-factor: 1.2;
    --jp-ui-font-size0: 0.83333em;
    --jp-ui-font-size1: 13px; /* Base font size */
    --jp-ui-font-size2: 1.2em;
    --jp-ui-font-size3: 1.44em;

    --jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
        Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
        "Segoe UI Symbol";

    /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

    /* Defaults use Material Design specification */
    --jp-ui-font-color0: rgba(0, 0, 0, 1);
    --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
    --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
    --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

    /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

    --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
    --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
    --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
    --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

    /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

    --jp-content-line-height: 1.6;
    --jp-content-font-scale-factor: 1.2;
    --jp-content-font-size0: 0.83333em;
    --jp-content-font-size1: 14px; /* Base font size */
    --jp-content-font-size2: 1.2em;
    --jp-content-font-size3: 1.44em;
    --jp-content-font-size4: 1.728em;
    --jp-content-font-size5: 2.0736em;

    /* This gives a magnification of about 125% in presentation mode over normal. */
    --jp-content-presentation-font-size1: 17px;

    --jp-content-heading-line-height: 1;
    --jp-content-heading-margin-top: 1.2em;
    --jp-content-heading-margin-bottom: 0.8em;
    --jp-content-heading-font-weight: 500;

    /* Defaults use Material Design specification */
    --jp-content-font-color0: rgba(0, 0, 0, 1);
    --jp-content-font-color1: rgba(0, 0, 0, 0.87);
    --jp-content-font-color2: rgba(0, 0, 0, 0.54);
    --jp-content-font-color3: rgba(0, 0, 0, 0.38);

    --jp-content-link-color: var(--md-blue-700);

    --jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
        Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
        "Segoe UI Symbol";

    /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

    --jp-code-font-size: 13px;
    --jp-code-line-height: 1.3077; /* 17px for 13px base */
    --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
    --jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono",
        monospace;
    --jp-code-font-family: var(--jp-code-font-family-default);

    /* This gives a magnification of about 125% in presentation mode over normal. */
    --jp-code-presentation-font-size: 16px;

    /* may need to tweak cursor width if you change font size */
    --jp-code-cursor-width0: 1.4px;
    --jp-code-cursor-width1: 2px;
    --jp-code-cursor-width2: 4px;

    /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

    --jp-layout-color0: white;
    --jp-layout-color1: white;
    --jp-layout-color2: var(--md-grey-200);
    --jp-layout-color3: var(--md-grey-400);
    --jp-layout-color4: var(--md-grey-600);

    /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

    --jp-inverse-layout-color0: #111111;
    --jp-inverse-layout-color1: var(--md-grey-900);
    --jp-inverse-layout-color2: var(--md-grey-800);
    --jp-inverse-layout-color3: var(--md-grey-700);
    --jp-inverse-layout-color4: var(--md-grey-600);

    /* Brand/accent */

    --jp-brand-color0: var(--md-blue-900);
    --jp-brand-color1: var(--md-blue-700);
    --jp-brand-color2: var(--md-blue-300);
    --jp-brand-color3: var(--md-blue-100);
    --jp-brand-color4: var(--md-blue-50);

    --jp-accent-color0: var(--md-green-900);
    --jp-accent-color1: var(--md-green-700);
    --jp-accent-color2: var(--md-green-300);
    --jp-accent-color3: var(--md-green-100);

    /* State colors (warn, error, success, info) */

    --jp-warn-color0: var(--md-orange-900);
    --jp-warn-color1: var(--md-orange-700);
    --jp-warn-color2: var(--md-orange-300);
    --jp-warn-color3: var(--md-orange-100);

    --jp-error-color0: var(--md-red-900);
    --jp-error-color1: var(--md-red-700);
    --jp-error-color2: var(--md-red-300);
    --jp-error-color3: var(--md-red-100);

    --jp-success-color0: var(--md-green-900);
    --jp-success-color1: var(--md-green-700);
    --jp-success-color2: var(--md-green-300);
    --jp-success-color3: var(--md-green-100);

    --jp-info-color0: var(--md-cyan-900);
    --jp-info-color1: var(--md-cyan-700);
    --jp-info-color2: var(--md-cyan-300);
    --jp-info-color3: var(--md-cyan-100);

    /* Cell specific styles */

    --jp-cell-padding: 5px;

    --jp-cell-collapser-width: 8px;
    --jp-cell-collapser-min-height: 20px;
    --jp-cell-collapser-not-active-hover-opacity: 0.6;

    --jp-cell-editor-background: var(--md-grey-100);
    --jp-cell-editor-border-color: var(--md-grey-300);
    --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
    --jp-cell-editor-active-background: var(--jp-layout-color0);
    --jp-cell-editor-active-border-color: var(--jp-brand-color1);

    --jp-cell-prompt-width: 64px;
    --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
    --jp-cell-prompt-letter-spacing: 0px;
    --jp-cell-prompt-opacity: 1;
    --jp-cell-prompt-not-active-opacity: 0.5;
    --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
    /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
    --jp-cell-inprompt-font-color: #307fc1;
    /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
    --jp-cell-outprompt-font-color: #bf5b3d;

    /* Notebook specific styles */

    --jp-notebook-padding: 10px;
    --jp-notebook-select-background: var(--jp-layout-color1);
    --jp-notebook-multiselected-color: var(--md-blue-50);

    /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
    --jp-notebook-scroll-padding: calc(
        100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
            var(--jp-code-padding) - var(--jp-cell-padding) - 1px
    );

    /* Rendermime styles */

    --jp-rendermime-error-background: #fdd;
    --jp-rendermime-table-row-background: var(--md-grey-100);
    --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

    /* Dialog specific styles */

    --jp-dialog-background: rgba(0, 0, 0, 0.25);

    /* Console specific styles */

    --jp-console-padding: 10px;

    /* Toolbar specific styles */

    --jp-toolbar-border-color: var(--jp-border-color1);
    --jp-toolbar-micro-height: 8px;
    --jp-toolbar-background: var(--jp-layout-color1);
    --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
    --jp-toolbar-header-margin: 4px 4px 0px 4px;
    --jp-toolbar-active-background: var(--md-grey-300);

    /* Statusbar specific styles */

    --jp-statusbar-height: 24px;

    /* Input field styles */

    --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
    --jp-input-active-background: var(--jp-layout-color1);
    --jp-input-hover-background: var(--jp-layout-color1);
    --jp-input-background: var(--md-grey-100);
    --jp-input-border-color: var(--jp-border-color1);
    --jp-input-active-border-color: var(--jp-brand-color1);
    --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

    /* General editor styles */

    --jp-editor-selected-background: #d9d9d9;
    --jp-editor-selected-focused-background: #d7d4f0;
    --jp-editor-cursor-color: var(--jp-ui-font-color0);

    /* Code mirror specific styles */

    --jp-mirror-editor-keyword-color: #008000;
    --jp-mirror-editor-atom-color: #88f;
    --jp-mirror-editor-number-color: #080;
    --jp-mirror-editor-def-color: #00f;
    --jp-mirror-editor-variable-color: var(--md-grey-900);
    --jp-mirror-editor-variable-2-color: #05a;
    --jp-mirror-editor-variable-3-color: #085;
    --jp-mirror-editor-punctuation-color: #05a;
    --jp-mirror-editor-property-color: #05a;
    --jp-mirror-editor-operator-color: #aa22ff;
    --jp-mirror-editor-comment-color: #408080;
    --jp-mirror-editor-string-color: #ba2121;
    --jp-mirror-editor-string-2-color: #708;
    --jp-mirror-editor-meta-color: #aa22ff;
    --jp-mirror-editor-qualifier-color: #555;
    --jp-mirror-editor-builtin-color: #008000;
    --jp-mirror-editor-bracket-color: #997;
    --jp-mirror-editor-tag-color: #170;
    --jp-mirror-editor-attribute-color: #00c;
    --jp-mirror-editor-header-color: blue;
    --jp-mirror-editor-quote-color: #090;
    --jp-mirror-editor-link-color: #00c;
    --jp-mirror-editor-error-color: #f00;
    --jp-mirror-editor-hr-color: #999;

    /* Vega extension styles */

    --jp-vega-background: white;

    /* Sidebar-related styles */

    --jp-sidebar-min-width: 250px;

    /* Search-related styles */

    --jp-search-toggle-off-opacity: 0.5;
    --jp-search-toggle-hover-opacity: 0.8;
    --jp-search-toggle-on-opacity: 1;
    --jp-search-selected-match-background-color: rgb(245, 200, 0);
    --jp-search-selected-match-color: black;
    --jp-search-unselected-match-background-color: var(
        --jp-inverse-layout-color0
    );
    --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

    /* Icon colors that work well with light or dark backgrounds */
    --jp-icon-contrast-color0: var(--md-purple-600);
    --jp-icon-contrast-color1: var(--md-green-600);
    --jp-icon-contrast-color2: var(--md-pink-600);
    --jp-icon-contrast-color3: var(--md-blue-600);
}

[data-md-color-scheme="slate"] .jupyter-wrapper {
    /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

    /* The dark theme shadows need a bit of work, but this will probably also require work on the core layout
   * colors used in the theme as well. */
    --jp-shadow-base-lightness: 32;
    --jp-shadow-umbra-color: rgba(
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        0.2
    );
    --jp-shadow-penumbra-color: rgba(
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        0.14
    );
    --jp-shadow-ambient-color: rgba(
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        var(--jp-shadow-base-lightness),
        0.12
    );
    --jp-elevation-z0: none;
    --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
        0px 1px 1px 0px var(--jp-shadow-penumbra-color),
        0px 1px 3px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
        0px 2px 2px 0px var(--jp-shadow-penumbra-color),
        0px 1px 5px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
        0px 4px 5px 0px var(--jp-shadow-penumbra-color),
        0px 1px 10px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
        0px 6px 10px 0px var(--jp-shadow-penumbra-color),
        0px 1px 18px 0px var(--jp-shadow-ambient-color);
    --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
        0px 8px 10px 1px var(--jp-shadow-penumbra-color),
        0px 3px 14px 2px var(--jp-shadow-ambient-color);
    --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
        0px 12px 17px 2px var(--jp-shadow-penumbra-color),
        0px 5px 22px 4px var(--jp-shadow-ambient-color);
    --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
        0px 16px 24px 2px var(--jp-shadow-penumbra-color),
        0px 6px 30px 5px var(--jp-shadow-ambient-color);
    --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
        0px 20px 31px 3px var(--jp-shadow-penumbra-color),
        0px 8px 38px 7px var(--jp-shadow-ambient-color);
    --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
        0px 24px 38px 3px var(--jp-shadow-penumbra-color),
        0px 9px 46px 8px var(--jp-shadow-ambient-color);

    /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

    --jp-border-width: 1px;
    --jp-border-color0: var(--md-grey-700);
    --jp-border-color1: var(--md-grey-700);
    --jp-border-color2: var(--md-grey-800);
    --jp-border-color3: var(--md-grey-900);
    --jp-border-radius: 2px;

    /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

    --jp-ui-font-scale-factor: 1.2;
    --jp-ui-font-size0: 0.83333em;
    --jp-ui-font-size1: 13px; /* Base font size */
    --jp-ui-font-size2: 1.2em;
    --jp-ui-font-size3: 1.44em;

    --jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
        Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
        "Segoe UI Symbol";

    /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

    /* Defaults use Material Design specification */
    --jp-ui-font-color0: rgba(255, 255, 255, 1);
    --jp-ui-font-color1: rgba(255, 255, 255, 0.87);
    --jp-ui-font-color2: rgba(255, 255, 255, 0.54);
    --jp-ui-font-color3: rgba(255, 255, 255, 0.38);

    /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

    --jp-ui-inverse-font-color0: rgba(0, 0, 0, 1);
    --jp-ui-inverse-font-color1: rgba(0, 0, 0, 0.8);
    --jp-ui-inverse-font-color2: rgba(0, 0, 0, 0.5);
    --jp-ui-inverse-font-color3: rgba(0, 0, 0, 0.3);

    /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

    --jp-content-line-height: 1.6;
    --jp-content-font-scale-factor: 1.2;
    --jp-content-font-size0: 0.83333em;
    --jp-content-font-size1: 14px; /* Base font size */
    --jp-content-font-size2: 1.2em;
    --jp-content-font-size3: 1.44em;
    --jp-content-font-size4: 1.728em;
    --jp-content-font-size5: 2.0736em;

    /* This gives a magnification of about 125% in presentation mode over normal. */
    --jp-content-presentation-font-size1: 17px;

    --jp-content-heading-line-height: 1;
    --jp-content-heading-margin-top: 1.2em;
    --jp-content-heading-margin-bottom: 0.8em;
    --jp-content-heading-font-weight: 500;

    /* Defaults use Material Design specification */
    --jp-content-font-color0: rgba(255, 255, 255, 1);
    --jp-content-font-color1: rgba(255, 255, 255, 1);
    --jp-content-font-color2: rgba(255, 255, 255, 0.7);
    --jp-content-font-color3: rgba(255, 255, 255, 0.5);

    --jp-content-link-color: var(--md-blue-300);

    --jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
        Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji",
        "Segoe UI Symbol";

    /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

    --jp-code-font-size: 13px;
    --jp-code-line-height: 1.3077; /* 17px for 13px base */
    --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
    --jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono",
        monospace;
    --jp-code-font-family: var(--jp-code-font-family-default);

    /* This gives a magnification of about 125% in presentation mode over normal. */
    --jp-code-presentation-font-size: 16px;

    /* may need to tweak cursor width if you change font size */
    --jp-code-cursor-width0: 1.4px;
    --jp-code-cursor-width1: 2px;
    --jp-code-cursor-width2: 4px;

    /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

    --jp-layout-color0: #111111;
    --jp-layout-color1: var(--md-grey-900);
    --jp-layout-color2: var(--md-grey-800);
    --jp-layout-color3: var(--md-grey-700);
    --jp-layout-color4: var(--md-grey-600);

    /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

    --jp-inverse-layout-color0: white;
    --jp-inverse-layout-color1: white;
    --jp-inverse-layout-color2: var(--md-grey-200);
    --jp-inverse-layout-color3: var(--md-grey-400);
    --jp-inverse-layout-color4: var(--md-grey-600);

    /* Brand/accent */

    --jp-brand-color0: var(--md-blue-700);
    --jp-brand-color1: var(--md-blue-500);
    --jp-brand-color2: var(--md-blue-300);
    --jp-brand-color3: var(--md-blue-100);
    --jp-brand-color4: var(--md-blue-50);

    --jp-accent-color0: var(--md-green-700);
    --jp-accent-color1: var(--md-green-500);
    --jp-accent-color2: var(--md-green-300);
    --jp-accent-color3: var(--md-green-100);

    /* State colors (warn, error, success, info) */

    --jp-warn-color0: var(--md-orange-700);
    --jp-warn-color1: var(--md-orange-500);
    --jp-warn-color2: var(--md-orange-300);
    --jp-warn-color3: var(--md-orange-100);

    --jp-error-color0: var(--md-red-700);
    --jp-error-color1: var(--md-red-500);
    --jp-error-color2: var(--md-red-300);
    --jp-error-color3: var(--md-red-100);

    --jp-success-color0: var(--md-green-700);
    --jp-success-color1: var(--md-green-500);
    --jp-success-color2: var(--md-green-300);
    --jp-success-color3: var(--md-green-100);

    --jp-info-color0: var(--md-cyan-700);
    --jp-info-color1: var(--md-cyan-500);
    --jp-info-color2: var(--md-cyan-300);
    --jp-info-color3: var(--md-cyan-100);

    /* Cell specific styles */

    --jp-cell-padding: 5px;

    --jp-cell-collapser-width: 8px;
    --jp-cell-collapser-min-height: 20px;
    --jp-cell-collapser-not-active-hover-opacity: 0.6;

    --jp-cell-editor-background: var(--jp-layout-color1);
    --jp-cell-editor-border-color: var(--md-grey-700);
    --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
    --jp-cell-editor-active-background: var(--jp-layout-color0);
    --jp-cell-editor-active-border-color: var(--jp-brand-color1);

    --jp-cell-prompt-width: 64px;
    --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
    --jp-cell-prompt-letter-spacing: 0px;
    --jp-cell-prompt-opacity: 1;
    --jp-cell-prompt-not-active-opacity: 1;
    --jp-cell-prompt-not-active-font-color: var(--md-grey-300);

    /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
    --jp-cell-inprompt-font-color: #307fc1;
    /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
    --jp-cell-outprompt-font-color: #bf5b3d;

    /* Notebook specific styles */

    --jp-notebook-padding: 10px;
    --jp-notebook-select-background: var(--jp-layout-color1);
    --jp-notebook-multiselected-color: rgba(33, 150, 243, 0.24);

    /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
    --jp-notebook-scroll-padding: calc(
        100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
            var(--jp-code-padding) - var(--jp-cell-padding) - 1px
    );

    /* Rendermime styles */

    --jp-rendermime-error-background: rgba(244, 67, 54, 0.28);
    --jp-rendermime-table-row-background: var(--md-grey-900);
    --jp-rendermime-table-row-hover-background: rgba(3, 169, 244, 0.2);

    /* Dialog specific styles */

    --jp-dialog-background: rgba(0, 0, 0, 0.6);

    /* Console specific styles */

    --jp-console-padding: 10px;

    /* Toolbar specific styles */

    --jp-toolbar-border-color: var(--jp-border-color2);
    --jp-toolbar-micro-height: 8px;
    --jp-toolbar-background: var(--jp-layout-color1);
    --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.8);
    --jp-toolbar-header-margin: 4px 4px 0px 4px;
    --jp-toolbar-active-background: var(--jp-layout-color0);

    /* Statusbar specific styles */

    --jp-statusbar-height: 24px;

    /* Input field styles */

    --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
    --jp-input-active-background: var(--jp-layout-color0);
    --jp-input-hover-background: var(--jp-layout-color2);
    --jp-input-background: var(--md-grey-800);
    --jp-input-border-color: var(--jp-border-color1);
    --jp-input-active-border-color: var(--jp-brand-color1);
    --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

    /* General editor styles */

    --jp-editor-selected-background: var(--jp-layout-color2);
    --jp-editor-selected-focused-background: rgba(33, 150, 243, 0.24);
    --jp-editor-cursor-color: var(--jp-ui-font-color0);

    /* Code mirror specific styles */

    --jp-mirror-editor-keyword-color: var(--md-green-500);
    --jp-mirror-editor-atom-color: var(--md-blue-300);
    --jp-mirror-editor-number-color: var(--md-green-400);
    --jp-mirror-editor-def-color: var(--md-blue-600);
    --jp-mirror-editor-variable-color: var(--md-grey-300);
    --jp-mirror-editor-variable-2-color: var(--md-blue-400);
    --jp-mirror-editor-variable-3-color: var(--md-green-600);
    --jp-mirror-editor-punctuation-color: var(--md-blue-400);
    --jp-mirror-editor-property-color: var(--md-blue-400);
    --jp-mirror-editor-operator-color: #aa22ff;
    --jp-mirror-editor-comment-color: #408080;
    --jp-mirror-editor-string-color: #ff7070;
    --jp-mirror-editor-string-2-color: var(--md-purple-300);
    --jp-mirror-editor-meta-color: #aa22ff;
    --jp-mirror-editor-qualifier-color: #555;
    --jp-mirror-editor-builtin-color: var(--md-green-600);
    --jp-mirror-editor-bracket-color: #997;
    --jp-mirror-editor-tag-color: var(--md-green-700);
    --jp-mirror-editor-attribute-color: var(--md-blue-700);
    --jp-mirror-editor-header-color: var(--md-blue-500);
    --jp-mirror-editor-quote-color: var(--md-green-300);
    --jp-mirror-editor-link-color: var(--md-blue-700);
    --jp-mirror-editor-error-color: #f00;
    --jp-mirror-editor-hr-color: #999;

    /* Vega extension styles */

    --jp-vega-background: var(--md-grey-400);

    /* Sidebar-related styles */

    --jp-sidebar-min-width: 250px;

    /* Search-related styles */

    --jp-search-toggle-off-opacity: 0.6;
    --jp-search-toggle-hover-opacity: 0.8;
    --jp-search-toggle-on-opacity: 1;
    --jp-search-selected-match-background-color: rgb(255, 225, 0);
    --jp-search-selected-match-color: black;
    --jp-search-unselected-match-background-color: var(
        --jp-inverse-layout-color0
    );
    --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

    /* scrollbar related styles. Supports every browser except Edge. */

    /* colors based on JetBrain's Darcula theme */

    --jp-scrollbar-background-color: #3f4244;
    --jp-scrollbar-thumb-color: 88, 96, 97; /* need to specify thumb color as an RGB triplet */

    --jp-scrollbar-endpad: 3px; /* the minimum gap between the thumb and the ends of a scrollbar */

    /* hacks for setting the thumb shape. These do nothing in Firefox */

    --jp-scrollbar-thumb-margin: 3.5px; /* the space in between the sides of the thumb and the track */
    --jp-scrollbar-thumb-radius: 9px; /* set to a large-ish value for rounded endcaps on the thumb */

    /* Icon colors that work well with light or dark backgrounds */
    --jp-icon-contrast-color0: var(--md-purple-600);
    --jp-icon-contrast-color1: var(--md-green-600);
    --jp-icon-contrast-color2: var(--md-pink-600);
    --jp-icon-contrast-color3: var(--md-blue-600);
}

:root{--md-red-50: #ffebee;--md-red-100: #ffcdd2;--md-red-200: #ef9a9a;--md-red-300: #e57373;--md-red-400: #ef5350;--md-red-500: #f44336;--md-red-600: #e53935;--md-red-700: #d32f2f;--md-red-800: #c62828;--md-red-900: #b71c1c;--md-red-A100: #ff8a80;--md-red-A200: #ff5252;--md-red-A400: #ff1744;--md-red-A700: #d50000;--md-pink-50: #fce4ec;--md-pink-100: #f8bbd0;--md-pink-200: #f48fb1;--md-pink-300: #f06292;--md-pink-400: #ec407a;--md-pink-500: #e91e63;--md-pink-600: #d81b60;--md-pink-700: #c2185b;--md-pink-800: #ad1457;--md-pink-900: #880e4f;--md-pink-A100: #ff80ab;--md-pink-A200: #ff4081;--md-pink-A400: #f50057;--md-pink-A700: #c51162;--md-purple-50: #f3e5f5;--md-purple-100: #e1bee7;--md-purple-200: #ce93d8;--md-purple-300: #ba68c8;--md-purple-400: #ab47bc;--md-purple-500: #9c27b0;--md-purple-600: #8e24aa;--md-purple-700: #7b1fa2;--md-purple-800: #6a1b9a;--md-purple-900: #4a148c;--md-purple-A100: #ea80fc;--md-purple-A200: #e040fb;--md-purple-A400: #d500f9;--md-purple-A700: #aa00ff;--md-deep-purple-50: #ede7f6;--md-deep-purple-100: #d1c4e9;--md-deep-purple-200: #b39ddb;--md-deep-purple-300: #9575cd;--md-deep-purple-400: #7e57c2;--md-deep-purple-500: #673ab7;--md-deep-purple-600: #5e35b1;--md-deep-purple-700: #512da8;--md-deep-purple-800: #4527a0;--md-deep-purple-900: #311b92;--md-deep-purple-A100: #b388ff;--md-deep-purple-A200: #7c4dff;--md-deep-purple-A400: #651fff;--md-deep-purple-A700: #6200ea;--md-indigo-50: #e8eaf6;--md-indigo-100: #c5cae9;--md-indigo-200: #9fa8da;--md-indigo-300: #7986cb;--md-indigo-400: #5c6bc0;--md-indigo-500: #3f51b5;--md-indigo-600: #3949ab;--md-indigo-700: #303f9f;--md-indigo-800: #283593;--md-indigo-900: #1a237e;--md-indigo-A100: #8c9eff;--md-indigo-A200: #536dfe;--md-indigo-A400: #3d5afe;--md-indigo-A700: #304ffe;--md-blue-50: #e3f2fd;--md-blue-100: #bbdefb;--md-blue-200: #90caf9;--md-blue-300: #64b5f6;--md-blue-400: #42a5f5;--md-blue-500: #2196f3;--md-blue-600: #1e88e5;--md-blue-700: #1976d2;--md-blue-800: #1565c0;--md-blue-900: #0d47a1;--md-blue-A100: #82b1ff;--md-blue-A200: #448aff;--md-blue-A400: #2979ff;--md-blue-A700: #2962ff;--md-light-blue-50: #e1f5fe;--md-light-blue-100: #b3e5fc;--md-light-blue-200: #81d4fa;--md-light-blue-300: #4fc3f7;--md-light-blue-400: #29b6f6;--md-light-blue-500: #03a9f4;--md-light-blue-600: #039be5;--md-light-blue-700: #0288d1;--md-light-blue-800: #0277bd;--md-light-blue-900: #01579b;--md-light-blue-A100: #80d8ff;--md-light-blue-A200: #40c4ff;--md-light-blue-A400: #00b0ff;--md-light-blue-A700: #0091ea;--md-cyan-50: #e0f7fa;--md-cyan-100: #b2ebf2;--md-cyan-200: #80deea;--md-cyan-300: #4dd0e1;--md-cyan-400: #26c6da;--md-cyan-500: #00bcd4;--md-cyan-600: #00acc1;--md-cyan-700: #0097a7;--md-cyan-800: #00838f;--md-cyan-900: #006064;--md-cyan-A100: #84ffff;--md-cyan-A200: #18ffff;--md-cyan-A400: #00e5ff;--md-cyan-A700: #00b8d4;--md-teal-50: #e0f2f1;--md-teal-100: #b2dfdb;--md-teal-200: #80cbc4;--md-teal-300: #4db6ac;--md-teal-400: #26a69a;--md-teal-500: #009688;--md-teal-600: #00897b;--md-teal-700: #00796b;--md-teal-800: #00695c;--md-teal-900: #004d40;--md-teal-A100: #a7ffeb;--md-teal-A200: #64ffda;--md-teal-A400: #1de9b6;--md-teal-A700: #00bfa5;--md-green-50: #e8f5e9;--md-green-100: #c8e6c9;--md-green-200: #a5d6a7;--md-green-300: #81c784;--md-green-400: #66bb6a;--md-green-500: #4caf50;--md-green-600: #43a047;--md-green-700: #388e3c;--md-green-800: #2e7d32;--md-green-900: #1b5e20;--md-green-A100: #b9f6ca;--md-green-A200: #69f0ae;--md-green-A400: #00e676;--md-green-A700: #00c853;--md-light-green-50: #f1f8e9;--md-light-green-100: #dcedc8;--md-light-green-200: #c5e1a5;--md-light-green-300: #aed581;--md-light-green-400: #9ccc65;--md-light-green-500: #8bc34a;--md-light-green-600: #7cb342;--md-light-green-700: #689f38;--md-light-green-800: #558b2f;--md-light-green-900: #33691e;--md-light-green-A100: #ccff90;--md-light-green-A200: #b2ff59;--md-light-green-A400: #76ff03;--md-light-green-A700: #64dd17;--md-lime-50: #f9fbe7;--md-lime-100: #f0f4c3;--md-lime-200: #e6ee9c;--md-lime-300: #dce775;--md-lime-400: #d4e157;--md-lime-500: #cddc39;--md-lime-600: #c0ca33;--md-lime-700: #afb42b;--md-lime-800: #9e9d24;--md-lime-900: #827717;--md-lime-A100: #f4ff81;--md-lime-A200: #eeff41;--md-lime-A400: #c6ff00;--md-lime-A700: #aeea00;--md-yellow-50: #fffde7;--md-yellow-100: #fff9c4;--md-yellow-200: #fff59d;--md-yellow-300: #fff176;--md-yellow-400: #ffee58;--md-yellow-500: #ffeb3b;--md-yellow-600: #fdd835;--md-yellow-700: #fbc02d;--md-yellow-800: #f9a825;--md-yellow-900: #f57f17;--md-yellow-A100: #ffff8d;--md-yellow-A200: #ffff00;--md-yellow-A400: #ffea00;--md-yellow-A700: #ffd600;--md-amber-50: #fff8e1;--md-amber-100: #ffecb3;--md-amber-200: #ffe082;--md-amber-300: #ffd54f;--md-amber-400: #ffca28;--md-amber-500: #ffc107;--md-amber-600: #ffb300;--md-amber-700: #ffa000;--md-amber-800: #ff8f00;--md-amber-900: #ff6f00;--md-amber-A100: #ffe57f;--md-amber-A200: #ffd740;--md-amber-A400: #ffc400;--md-amber-A700: #ffab00;--md-orange-50: #fff3e0;--md-orange-100: #ffe0b2;--md-orange-200: #ffcc80;--md-orange-300: #ffb74d;--md-orange-400: #ffa726;--md-orange-500: #ff9800;--md-orange-600: #fb8c00;--md-orange-700: #f57c00;--md-orange-800: #ef6c00;--md-orange-900: #e65100;--md-orange-A100: #ffd180;--md-orange-A200: #ffab40;--md-orange-A400: #ff9100;--md-orange-A700: #ff6d00;--md-deep-orange-50: #fbe9e7;--md-deep-orange-100: #ffccbc;--md-deep-orange-200: #ffab91;--md-deep-orange-300: #ff8a65;--md-deep-orange-400: #ff7043;--md-deep-orange-500: #ff5722;--md-deep-orange-600: #f4511e;--md-deep-orange-700: #e64a19;--md-deep-orange-800: #d84315;--md-deep-orange-900: #bf360c;--md-deep-orange-A100: #ff9e80;--md-deep-orange-A200: #ff6e40;--md-deep-orange-A400: #ff3d00;--md-deep-orange-A700: #dd2c00;--md-brown-50: #efebe9;--md-brown-100: #d7ccc8;--md-brown-200: #bcaaa4;--md-brown-300: #a1887f;--md-brown-400: #8d6e63;--md-brown-500: #795548;--md-brown-600: #6d4c41;--md-brown-700: #5d4037;--md-brown-800: #4e342e;--md-brown-900: #3e2723;--md-grey-50: #fafafa;--md-grey-100: #f5f5f5;--md-grey-200: #eeeeee;--md-grey-300: #e0e0e0;--md-grey-400: #bdbdbd;--md-grey-500: #9e9e9e;--md-grey-600: #757575;--md-grey-700: #616161;--md-grey-800: #424242;--md-grey-900: #212121;--md-blue-grey-50: #eceff1;--md-blue-grey-100: #cfd8dc;--md-blue-grey-200: #b0bec5;--md-blue-grey-300: #90a4ae;--md-blue-grey-400: #78909c;--md-blue-grey-500: #607d8b;--md-blue-grey-600: #546e7a;--md-blue-grey-700: #455a64;--md-blue-grey-800: #37474f;--md-blue-grey-900: #263238}.jupyter-wrapper{/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*//*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/}.jupyter-wrapper [data-jp-theme-scrollbars=true]{scrollbar-color:rgb(var(--jp-scrollbar-thumb-color)) var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar{scrollbar-color:rgba(var(--jp-scrollbar-thumb-color), 0.5) rgba(0,0,0,0)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-corner{background:var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-thumb{background:rgb(var(--jp-scrollbar-thumb-color));border:var(--jp-scrollbar-thumb-margin) solid rgba(0,0,0,0);background-clip:content-box;border-radius:var(--jp-scrollbar-thumb-radius)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-track:horizontal{border-left:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color);border-right:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-track:vertical{border-top:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color);border-bottom:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-corner,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-corner{background-color:rgba(0,0,0,0)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-thumb{background:rgba(var(--jp-scrollbar-thumb-color), 0.5);border:var(--jp-scrollbar-thumb-margin) solid rgba(0,0,0,0);background-clip:content-box;border-radius:var(--jp-scrollbar-thumb-radius)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal{border-left:var(--jp-scrollbar-endpad) solid rgba(0,0,0,0);border-right:var(--jp-scrollbar-endpad) solid rgba(0,0,0,0)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical{border-top:var(--jp-scrollbar-endpad) solid rgba(0,0,0,0);border-bottom:var(--jp-scrollbar-endpad) solid rgba(0,0,0,0)}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal]{min-height:16px;max-height:16px;min-width:45px;border-top:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical]{min-width:16px;max-width:16px;min-height:45px;border-left:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar-button{background-color:#f0f0f0;background-position:center center;min-height:15px;max-height:15px;min-width:15px;max-width:15px}.jupyter-wrapper .lm-ScrollBar-button:hover{background-color:#dadada}.jupyter-wrapper .lm-ScrollBar-button.lm-mod-active{background-color:#cdcdcd}.jupyter-wrapper .lm-ScrollBar-track{background:#f0f0f0}.jupyter-wrapper .lm-ScrollBar-thumb{background:#cdcdcd}.jupyter-wrapper .lm-ScrollBar-thumb:hover{background:#bababa}.jupyter-wrapper .lm-ScrollBar-thumb.lm-mod-active{background:#a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-thumb{height:100%;min-width:15px;border-left:1px solid #a0a0a0;border-right:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-thumb{width:100%;min-height:15px;border-top:1px solid #a0a0a0;border-bottom:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-button[data-action=decrement]{background-image:var(--jp-icon-caret-left);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-button[data-action=increment]{background-image:var(--jp-icon-caret-right);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-button[data-action=decrement]{background-image:var(--jp-icon-caret-up);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-button[data-action=increment]{background-image:var(--jp-icon-caret-down);background-size:17px}.jupyter-wrapper .p-Widget,.jupyter-wrapper .lm-Widget{box-sizing:border-box;position:relative;overflow:hidden;cursor:default}.jupyter-wrapper .p-Widget.p-mod-hidden,.jupyter-wrapper .lm-Widget.lm-mod-hidden{display:none !important}.jupyter-wrapper .p-CommandPalette,.jupyter-wrapper .lm-CommandPalette{display:flex;flex-direction:column;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-CommandPalette-search,.jupyter-wrapper .lm-CommandPalette-search{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-content,.jupyter-wrapper .lm-CommandPalette-content{flex:1 1 auto;margin:0;padding:0;min-height:0;overflow:auto;list-style-type:none}.jupyter-wrapper .p-CommandPalette-header,.jupyter-wrapper .lm-CommandPalette-header{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .p-CommandPalette-item,.jupyter-wrapper .lm-CommandPalette-item{display:flex;flex-direction:row}.jupyter-wrapper .p-CommandPalette-itemIcon,.jupyter-wrapper .lm-CommandPalette-itemIcon{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-itemContent,.jupyter-wrapper .lm-CommandPalette-itemContent{flex:1 1 auto;overflow:hidden}.jupyter-wrapper .p-CommandPalette-itemShortcut,.jupyter-wrapper .lm-CommandPalette-itemShortcut{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-itemLabel,.jupyter-wrapper .lm-CommandPalette-itemLabel{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .p-DockPanel,.jupyter-wrapper .lm-DockPanel{z-index:0}.jupyter-wrapper .p-DockPanel-widget,.jupyter-wrapper .lm-DockPanel-widget{z-index:0}.jupyter-wrapper .p-DockPanel-tabBar,.jupyter-wrapper .lm-DockPanel-tabBar{z-index:1}.jupyter-wrapper .p-DockPanel-handle,.jupyter-wrapper .lm-DockPanel-handle{z-index:2}.jupyter-wrapper .p-DockPanel-handle.p-mod-hidden,.jupyter-wrapper .lm-DockPanel-handle.lm-mod-hidden{display:none !important}.jupyter-wrapper .p-DockPanel-handle:after,.jupyter-wrapper .lm-DockPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:""}.jupyter-wrapper .p-DockPanel-handle[data-orientation=horizontal],.jupyter-wrapper .lm-DockPanel-handle[data-orientation=horizontal]{cursor:ew-resize}.jupyter-wrapper .p-DockPanel-handle[data-orientation=vertical],.jupyter-wrapper .lm-DockPanel-handle[data-orientation=vertical]{cursor:ns-resize}.jupyter-wrapper .p-DockPanel-handle[data-orientation=horizontal]:after,.jupyter-wrapper .lm-DockPanel-handle[data-orientation=horizontal]:after{left:50%;min-width:8px;transform:translateX(-50%)}.jupyter-wrapper .p-DockPanel-handle[data-orientation=vertical]:after,.jupyter-wrapper .lm-DockPanel-handle[data-orientation=vertical]:after{top:50%;min-height:8px;transform:translateY(-50%)}.jupyter-wrapper .p-DockPanel-overlay,.jupyter-wrapper .lm-DockPanel-overlay{z-index:3;box-sizing:border-box;pointer-events:none}.jupyter-wrapper .p-DockPanel-overlay.p-mod-hidden,.jupyter-wrapper .lm-DockPanel-overlay.lm-mod-hidden{display:none !important}.jupyter-wrapper .p-Menu,.jupyter-wrapper .lm-Menu{z-index:10000;position:absolute;white-space:nowrap;overflow-x:hidden;overflow-y:auto;outline:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-Menu-content,.jupyter-wrapper .lm-Menu-content{margin:0;padding:0;display:table;list-style-type:none}.jupyter-wrapper .p-Menu-item,.jupyter-wrapper .lm-Menu-item{display:table-row}.jupyter-wrapper .p-Menu-item.p-mod-hidden,.jupyter-wrapper .p-Menu-item.p-mod-collapsed,.jupyter-wrapper .lm-Menu-item.lm-mod-hidden,.jupyter-wrapper .lm-Menu-item.lm-mod-collapsed{display:none !important}.jupyter-wrapper .p-Menu-itemIcon,.jupyter-wrapper .p-Menu-itemSubmenuIcon,.jupyter-wrapper .lm-Menu-itemIcon,.jupyter-wrapper .lm-Menu-itemSubmenuIcon{display:table-cell;text-align:center}.jupyter-wrapper .p-Menu-itemLabel,.jupyter-wrapper .lm-Menu-itemLabel{display:table-cell;text-align:left}.jupyter-wrapper .p-Menu-itemShortcut,.jupyter-wrapper .lm-Menu-itemShortcut{display:table-cell;text-align:right}.jupyter-wrapper .p-MenuBar,.jupyter-wrapper .lm-MenuBar{outline:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-MenuBar-content,.jupyter-wrapper .lm-MenuBar-content{margin:0;padding:0;display:flex;flex-direction:row;list-style-type:none}.jupyter-wrapper .p--MenuBar-item,.jupyter-wrapper .lm-MenuBar-item{box-sizing:border-box}.jupyter-wrapper .p-MenuBar-itemIcon,.jupyter-wrapper .p-MenuBar-itemLabel,.jupyter-wrapper .lm-MenuBar-itemIcon,.jupyter-wrapper .lm-MenuBar-itemLabel{display:inline-block}.jupyter-wrapper .p-ScrollBar,.jupyter-wrapper .lm-ScrollBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-ScrollBar[data-orientation=horizontal],.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal]{flex-direction:row}.jupyter-wrapper .p-ScrollBar[data-orientation=vertical],.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical]{flex-direction:column}.jupyter-wrapper .p-ScrollBar-button,.jupyter-wrapper .lm-ScrollBar-button{box-sizing:border-box;flex:0 0 auto}.jupyter-wrapper .p-ScrollBar-track,.jupyter-wrapper .lm-ScrollBar-track{box-sizing:border-box;position:relative;overflow:hidden;flex:1 1 auto}.jupyter-wrapper .p-ScrollBar-thumb,.jupyter-wrapper .lm-ScrollBar-thumb{box-sizing:border-box;position:absolute}.jupyter-wrapper .p-SplitPanel-child,.jupyter-wrapper .lm-SplitPanel-child{z-index:0}.jupyter-wrapper .p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel-handle{z-index:1}.jupyter-wrapper .p-SplitPanel-handle.p-mod-hidden,.jupyter-wrapper .lm-SplitPanel-handle.lm-mod-hidden{display:none !important}.jupyter-wrapper .p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:""}.jupyter-wrapper .p-SplitPanel[data-orientation=horizontal]>.p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel[data-orientation=horizontal]>.lm-SplitPanel-handle{cursor:ew-resize}.jupyter-wrapper .p-SplitPanel[data-orientation=vertical]>.p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel[data-orientation=vertical]>.lm-SplitPanel-handle{cursor:ns-resize}.jupyter-wrapper .p-SplitPanel[data-orientation=horizontal]>.p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel[data-orientation=horizontal]>.lm-SplitPanel-handle:after{left:50%;min-width:8px;transform:translateX(-50%)}.jupyter-wrapper .p-SplitPanel[data-orientation=vertical]>.p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel[data-orientation=vertical]>.lm-SplitPanel-handle:after{top:50%;min-height:8px;transform:translateY(-50%)}.jupyter-wrapper .p-TabBar,.jupyter-wrapper .lm-TabBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-TabBar[data-orientation=horizontal],.jupyter-wrapper .lm-TabBar[data-orientation=horizontal]{flex-direction:row}.jupyter-wrapper .p-TabBar[data-orientation=vertical],.jupyter-wrapper .lm-TabBar[data-orientation=vertical]{flex-direction:column}.jupyter-wrapper .p-TabBar-content,.jupyter-wrapper .lm-TabBar-content{margin:0;padding:0;display:flex;flex:1 1 auto;list-style-type:none}.jupyter-wrapper .p-TabBar[data-orientation=horizontal]>.p-TabBar-content,.jupyter-wrapper .lm-TabBar[data-orientation=horizontal]>.lm-TabBar-content{flex-direction:row}.jupyter-wrapper .p-TabBar[data-orientation=vertical]>.p-TabBar-content,.jupyter-wrapper .lm-TabBar[data-orientation=vertical]>.lm-TabBar-content{flex-direction:column}.jupyter-wrapper .p-TabBar-tab,.jupyter-wrapper .lm-TabBar-tab{display:flex;flex-direction:row;box-sizing:border-box;overflow:hidden}.jupyter-wrapper .p-TabBar-tabIcon,.jupyter-wrapper .p-TabBar-tabCloseIcon,.jupyter-wrapper .lm-TabBar-tabIcon,.jupyter-wrapper .lm-TabBar-tabCloseIcon{flex:0 0 auto}.jupyter-wrapper .p-TabBar-tabLabel,.jupyter-wrapper .lm-TabBar-tabLabel{flex:1 1 auto;overflow:hidden;white-space:nowrap}.jupyter-wrapper .p-TabBar-tab.p-mod-hidden,.jupyter-wrapper .lm-TabBar-tab.lm-mod-hidden{display:none !important}.jupyter-wrapper .p-TabBar.p-mod-dragging .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging .lm-TabBar-tab{position:relative}.jupyter-wrapper .p-TabBar.p-mod-dragging[data-orientation=horizontal] .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging[data-orientation=horizontal] .lm-TabBar-tab{left:0;transition:left 150ms ease}.jupyter-wrapper .p-TabBar.p-mod-dragging[data-orientation=vertical] .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging[data-orientation=vertical] .lm-TabBar-tab{top:0;transition:top 150ms ease}.jupyter-wrapper .p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging .lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging{transition:none}.jupyter-wrapper .p-TabPanel-tabBar,.jupyter-wrapper .lm-TabPanel-tabBar{z-index:1}.jupyter-wrapper .p-TabPanel-stackedPanel,.jupyter-wrapper .lm-TabPanel-stackedPanel{z-index:0}.jupyter-wrapper ::-moz-selection{background:rgba(125,188,255,.6)}.jupyter-wrapper ::selection{background:rgba(125,188,255,.6)}.jupyter-wrapper .bp3-heading{color:#182026;font-weight:600;margin:0 0 10px;padding:0}.jupyter-wrapper .bp3-dark .bp3-heading{color:#f5f8fa}.jupyter-wrapper h1.bp3-heading,.jupyter-wrapper .bp3-running-text h1{line-height:40px;font-size:36px}.jupyter-wrapper h2.bp3-heading,.jupyter-wrapper .bp3-running-text h2{line-height:32px;font-size:28px}.jupyter-wrapper h3.bp3-heading,.jupyter-wrapper .bp3-running-text h3{line-height:25px;font-size:22px}.jupyter-wrapper h4.bp3-heading,.jupyter-wrapper .bp3-running-text h4{line-height:21px;font-size:18px}.jupyter-wrapper h5.bp3-heading,.jupyter-wrapper .bp3-running-text h5{line-height:19px;font-size:16px}.jupyter-wrapper h6.bp3-heading,.jupyter-wrapper .bp3-running-text h6{line-height:16px;font-size:14px}.jupyter-wrapper .bp3-ui-text{text-transform:none;line-height:1.28581;letter-spacing:0;font-size:14px;font-weight:400}.jupyter-wrapper .bp3-monospace-text{text-transform:none;font-family:monospace}.jupyter-wrapper .bp3-text-muted{color:#5c7080}.jupyter-wrapper .bp3-dark .bp3-text-muted{color:#a7b6c2}.jupyter-wrapper .bp3-text-disabled{color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-dark .bp3-text-disabled{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-text-overflow-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal}.jupyter-wrapper .bp3-running-text{line-height:1.5;font-size:14px}.jupyter-wrapper .bp3-running-text h1{color:#182026;font-weight:600;margin-top:40px;margin-bottom:20px}.jupyter-wrapper .bp3-dark .bp3-running-text h1{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h2{color:#182026;font-weight:600;margin-top:40px;margin-bottom:20px}.jupyter-wrapper .bp3-dark .bp3-running-text h2{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h3{color:#182026;font-weight:600;margin-top:40px;margin-bottom:20px}.jupyter-wrapper .bp3-dark .bp3-running-text h3{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h4{color:#182026;font-weight:600;margin-top:40px;margin-bottom:20px}.jupyter-wrapper .bp3-dark .bp3-running-text h4{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h5{color:#182026;font-weight:600;margin-top:40px;margin-bottom:20px}.jupyter-wrapper .bp3-dark .bp3-running-text h5{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h6{color:#182026;font-weight:600;margin-top:40px;margin-bottom:20px}.jupyter-wrapper .bp3-dark .bp3-running-text h6{color:#f5f8fa}.jupyter-wrapper .bp3-running-text hr{margin:20px 0;border:none;border-bottom:1px solid rgba(16,22,26,.15)}.jupyter-wrapper .bp3-dark .bp3-running-text hr{border-color:rgba(255,255,255,.15)}.jupyter-wrapper .bp3-running-text p{margin:0 0 10px;padding:0}.jupyter-wrapper .bp3-text-large{font-size:16px}.jupyter-wrapper .bp3-text-small{font-size:12px}.jupyter-wrapper a{text-decoration:none;color:#106ba3}.jupyter-wrapper a:hover{cursor:pointer;text-decoration:underline;color:#106ba3}.jupyter-wrapper a .bp3-icon,.jupyter-wrapper a .bp3-icon-standard,.jupyter-wrapper a .bp3-icon-large{color:inherit}.jupyter-wrapper a code,.jupyter-wrapper .bp3-dark a code{color:inherit}.jupyter-wrapper .bp3-dark a,.jupyter-wrapper .bp3-dark a:hover{color:#48aff0}.jupyter-wrapper .bp3-dark a .bp3-icon,.jupyter-wrapper .bp3-dark a .bp3-icon-standard,.jupyter-wrapper .bp3-dark a .bp3-icon-large,.jupyter-wrapper .bp3-dark a:hover .bp3-icon,.jupyter-wrapper .bp3-dark a:hover .bp3-icon-standard,.jupyter-wrapper .bp3-dark a:hover .bp3-icon-large{color:inherit}.jupyter-wrapper .bp3-running-text code,.jupyter-wrapper .bp3-code{text-transform:none;font-family:monospace;border-radius:3px;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2);background:rgba(255,255,255,.7);padding:2px 5px;color:#5c7080;font-size:smaller}.jupyter-wrapper .bp3-dark .bp3-running-text code,.jupyter-wrapper .bp3-running-text .bp3-dark code,.jupyter-wrapper .bp3-dark .bp3-code{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);background:rgba(16,22,26,.3);color:#a7b6c2}.jupyter-wrapper .bp3-running-text a>code,.jupyter-wrapper a>.bp3-code{color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-running-text a>code,.jupyter-wrapper .bp3-running-text .bp3-dark a>code,.jupyter-wrapper .bp3-dark a>.bp3-code{color:inherit}.jupyter-wrapper .bp3-running-text pre,.jupyter-wrapper .bp3-code-block{text-transform:none;font-family:monospace;display:block;margin:10px 0;border-radius:3px;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);background:rgba(255,255,255,.7);padding:13px 15px 12px;line-height:1.4;color:#182026;font-size:13px;word-break:break-all;word-wrap:break-word}.jupyter-wrapper .bp3-dark .bp3-running-text pre,.jupyter-wrapper .bp3-running-text .bp3-dark pre,.jupyter-wrapper .bp3-dark .bp3-code-block{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);background:rgba(16,22,26,.3);color:#f5f8fa}.jupyter-wrapper .bp3-running-text pre>code,.jupyter-wrapper .bp3-code-block>code{-webkit-box-shadow:none;box-shadow:none;background:none;padding:0;color:inherit;font-size:inherit}.jupyter-wrapper .bp3-running-text kbd,.jupyter-wrapper .bp3-key{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);background:#fff;min-width:24px;height:24px;padding:3px 6px;vertical-align:middle;line-height:24px;color:#5c7080;font-family:inherit;font-size:12px}.jupyter-wrapper .bp3-running-text kbd .bp3-icon,.jupyter-wrapper .bp3-key .bp3-icon,.jupyter-wrapper .bp3-running-text kbd .bp3-icon-standard,.jupyter-wrapper .bp3-key .bp3-icon-standard,.jupyter-wrapper .bp3-running-text kbd .bp3-icon-large,.jupyter-wrapper .bp3-key .bp3-icon-large{margin-right:5px}.jupyter-wrapper .bp3-dark .bp3-running-text kbd,.jupyter-wrapper .bp3-running-text .bp3-dark kbd,.jupyter-wrapper .bp3-dark .bp3-key{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);background:#394b59;color:#a7b6c2}.jupyter-wrapper .bp3-running-text blockquote,.jupyter-wrapper .bp3-blockquote{margin:0 0 10px;border-left:solid 4px rgba(167,182,194,.5);padding:0 20px}.jupyter-wrapper .bp3-dark .bp3-running-text blockquote,.jupyter-wrapper .bp3-running-text .bp3-dark blockquote,.jupyter-wrapper .bp3-dark .bp3-blockquote{border-color:rgba(115,134,148,.5)}.jupyter-wrapper .bp3-running-text ul,.jupyter-wrapper .bp3-running-text ol,.jupyter-wrapper .bp3-list{margin:10px 0;padding-left:30px}.jupyter-wrapper .bp3-running-text ul li:not(:last-child),.jupyter-wrapper .bp3-running-text ol li:not(:last-child),.jupyter-wrapper .bp3-list li:not(:last-child){margin-bottom:5px}.jupyter-wrapper .bp3-running-text ul ol,.jupyter-wrapper .bp3-running-text ol ol,.jupyter-wrapper .bp3-list ol,.jupyter-wrapper .bp3-running-text ul ul,.jupyter-wrapper .bp3-running-text ol ul,.jupyter-wrapper .bp3-list ul{margin-top:5px}.jupyter-wrapper .bp3-list-unstyled{margin:0;padding:0;list-style:none}.jupyter-wrapper .bp3-list-unstyled li{padding:0}.jupyter-wrapper .bp3-rtl{text-align:right}.jupyter-wrapper .bp3-dark{color:#f5f8fa}.jupyter-wrapper :focus{outline:rgba(19,124,189,.6) auto 2px;outline-offset:2px;-moz-outline-radius:6px}.jupyter-wrapper .bp3-focus-disabled :focus{outline:none !important}.jupyter-wrapper .bp3-focus-disabled :focus~.bp3-control-indicator{outline:none !important}.jupyter-wrapper .bp3-alert{max-width:400px;padding:20px}.jupyter-wrapper .bp3-alert-body{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-alert-body .bp3-icon{margin-top:0;margin-right:20px;font-size:40px}.jupyter-wrapper .bp3-alert-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;margin-top:10px}.jupyter-wrapper .bp3-alert-footer .bp3-button{margin-left:10px}.jupyter-wrapper .bp3-breadcrumbs{display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0;cursor:default;height:30px;padding:0;list-style:none}.jupyter-wrapper .bp3-breadcrumbs>li{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}.jupyter-wrapper .bp3-breadcrumbs>li::after{display:block;margin:0 5px;background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");width:16px;height:16px;content:""}.jupyter-wrapper .bp3-breadcrumbs>li:last-of-type::after{display:none}.jupyter-wrapper .bp3-breadcrumb,.jupyter-wrapper .bp3-breadcrumb-current,.jupyter-wrapper .bp3-breadcrumbs-collapsed{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:16px}.jupyter-wrapper .bp3-breadcrumb,.jupyter-wrapper .bp3-breadcrumbs-collapsed{color:#5c7080}.jupyter-wrapper .bp3-breadcrumb:hover{text-decoration:none}.jupyter-wrapper .bp3-breadcrumb.bp3-disabled{cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-breadcrumb .bp3-icon{margin-right:5px}.jupyter-wrapper .bp3-breadcrumb-current{color:inherit;font-weight:600}.jupyter-wrapper .bp3-breadcrumb-current .bp3-input{vertical-align:baseline;font-size:inherit;font-weight:inherit}.jupyter-wrapper .bp3-breadcrumbs-collapsed{margin-right:2px;border:none;border-radius:3px;background:#ced9e0;cursor:pointer;padding:1px 5px;vertical-align:text-bottom}.jupyter-wrapper .bp3-breadcrumbs-collapsed::before{display:block;background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;width:16px;height:16px;content:""}.jupyter-wrapper .bp3-breadcrumbs-collapsed:hover{background:#bfccd6;text-decoration:none;color:#182026}.jupyter-wrapper .bp3-dark .bp3-breadcrumb,.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs>li::after{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-breadcrumb.bp3-disabled{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-breadcrumb-current{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed:hover{background:rgba(16,22,26,.6);color:#f5f8fa}.jupyter-wrapper .bp3-button{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;border:none;border-radius:3px;cursor:pointer;padding:5px 10px;vertical-align:middle;text-align:left;font-size:14px;min-width:30px;min-height:30px}.jupyter-wrapper .bp3-button>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-button>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-button::before,.jupyter-wrapper .bp3-button>*{margin-right:7px}.jupyter-wrapper .bp3-button:empty::before,.jupyter-wrapper .bp3-button>:last-child{margin-right:0}.jupyter-wrapper .bp3-button:empty{padding:0 !important}.jupyter-wrapper .bp3-button:disabled,.jupyter-wrapper .bp3-button.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-button.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-button.bp3-align-right,.jupyter-wrapper .bp3-align-right .bp3-button{text-align:right}.jupyter-wrapper .bp3-button.bp3-align-left,.jupyter-wrapper .bp3-align-left .bp3-button{text-align:left}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]){-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-color:#f5f8fa;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));color:#182026}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-clip:padding-box;background-color:#ebf1f5}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);background-color:#d8e1e8;background-image:none}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled{outline:none;-webkit-box-shadow:none;box-shadow:none;background-color:rgba(206,217,224,.5);background-image:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active:hover,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-button.bp3-intent-primary{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#137cbd;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-primary:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#106ba3}.jupyter-wrapper .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background-color:#0e5a8a;background-image:none}.jupyter-wrapper .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-disabled{border-color:rgba(0,0,0,0);-webkit-box-shadow:none;box-shadow:none;background-color:rgba(19,124,189,.5);background-image:none;color:rgba(255,255,255,.6)}.jupyter-wrapper .bp3-button.bp3-intent-success{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#0f9960;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-success:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#0d8050}.jupyter-wrapper .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background-color:#0a6640;background-image:none}.jupyter-wrapper .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-disabled{border-color:rgba(0,0,0,0);-webkit-box-shadow:none;box-shadow:none;background-color:rgba(15,153,96,.5);background-image:none;color:rgba(255,255,255,.6)}.jupyter-wrapper .bp3-button.bp3-intent-warning{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#d9822b;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-warning:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#bf7326}.jupyter-wrapper .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background-color:#a66321;background-image:none}.jupyter-wrapper .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-disabled{border-color:rgba(0,0,0,0);-webkit-box-shadow:none;box-shadow:none;background-color:rgba(217,130,43,.5);background-image:none;color:rgba(255,255,255,.6)}.jupyter-wrapper .bp3-button.bp3-intent-danger{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#db3737;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-danger:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#c23030}.jupyter-wrapper .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background-color:#a82a2a;background-image:none}.jupyter-wrapper .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-disabled{border-color:rgba(0,0,0,0);-webkit-box-shadow:none;box-shadow:none;background-color:rgba(219,55,55,.5);background-image:none;color:rgba(255,255,255,.6)}.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-button-spinner .bp3-spinner-head{stroke:#fff}.jupyter-wrapper .bp3-button.bp3-large,.jupyter-wrapper .bp3-large .bp3-button{min-width:40px;min-height:40px;padding:5px 15px;font-size:16px}.jupyter-wrapper .bp3-button.bp3-large::before,.jupyter-wrapper .bp3-button.bp3-large>*,.jupyter-wrapper .bp3-large .bp3-button::before,.jupyter-wrapper .bp3-large .bp3-button>*{margin-right:10px}.jupyter-wrapper .bp3-button.bp3-large:empty::before,.jupyter-wrapper .bp3-button.bp3-large>:last-child,.jupyter-wrapper .bp3-large .bp3-button:empty::before,.jupyter-wrapper .bp3-large .bp3-button>:last-child{margin-right:0}.jupyter-wrapper .bp3-button.bp3-small,.jupyter-wrapper .bp3-small .bp3-button{min-width:24px;min-height:24px;padding:0 7px}.jupyter-wrapper .bp3-button.bp3-loading{position:relative}.jupyter-wrapper .bp3-button.bp3-loading[class*=bp3-icon-]::before{visibility:hidden}.jupyter-wrapper .bp3-button.bp3-loading .bp3-button-spinner{position:absolute;margin:0}.jupyter-wrapper .bp3-button.bp3-loading>:not(.bp3-button-spinner){visibility:hidden}.jupyter-wrapper .bp3-button[class*=bp3-icon-]::before{line-height:1;font-family:"Icons16",sans-serif;font-size:16px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;color:#5c7080}.jupyter-wrapper .bp3-button .bp3-icon,.jupyter-wrapper .bp3-button .bp3-icon-standard,.jupyter-wrapper .bp3-button .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-button .bp3-icon.bp3-align-right,.jupyter-wrapper .bp3-button .bp3-icon-standard.bp3-align-right,.jupyter-wrapper .bp3-button .bp3-icon-large.bp3-align-right{margin-left:7px}.jupyter-wrapper .bp3-button .bp3-icon:first-child:last-child,.jupyter-wrapper .bp3-button .bp3-spinner+.bp3-icon:last-child{margin:0 -7px}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]){-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#394b59;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):hover,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);background-color:#202b33;background-image:none}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):disabled,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background-color:rgba(57,75,89,.5);background-image:none;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-])[class*=bp3-icon-]::before{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon-large{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:active,.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-].bp3-active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:disabled,.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-].bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background-image:none;color:rgba(255,255,255,.3)}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-] .bp3-button-spinner .bp3-spinner-head{stroke:#8a9ba8}.jupyter-wrapper .bp3-button:disabled::before,.jupyter-wrapper .bp3-button:disabled .bp3-icon,.jupyter-wrapper .bp3-button:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-button:disabled .bp3-icon-large,.jupyter-wrapper .bp3-button.bp3-disabled::before,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon-standard,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon-large,.jupyter-wrapper .bp3-button[class*=bp3-intent-]::before,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon-standard,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon-large{color:inherit !important}.jupyter-wrapper .bp3-button.bp3-minimal{-webkit-box-shadow:none;box-shadow:none;background:none}.jupyter-wrapper .bp3-button.bp3-minimal:hover{-webkit-box-shadow:none;box-shadow:none;background:rgba(167,182,194,.3);text-decoration:none;color:#182026}.jupyter-wrapper .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:rgba(115,134,148,.3);color:#182026}.jupyter-wrapper .bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-button.bp3-minimal:disabled:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled:hover{background:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-button.bp3-minimal:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal{-webkit-box-shadow:none;box-shadow:none;background:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{background:none;cursor:not-allowed;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{background:none;color:rgba(16,107,163,.5)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{background:none;color:rgba(72,175,240,.5)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{background:none;color:rgba(13,128,80,.5)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{background:none;color:rgba(61,204,145,.5)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{background:none;color:rgba(191,115,38,.5)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{background:none;color:rgba(255,179,102,.5)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{background:none;color:rgba(194,48,48,.5)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{background:none;color:rgba(255,115,115,.5)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper a.bp3-button{text-align:center;text-decoration:none;-webkit-transition:none;transition:none}.jupyter-wrapper a.bp3-button,.jupyter-wrapper a.bp3-button:hover,.jupyter-wrapper a.bp3-button:active{color:#182026}.jupyter-wrapper a.bp3-button.bp3-disabled{color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-button-text{-webkit-box-flex:0;-ms-flex:0 1 auto;flex:0 1 auto}.jupyter-wrapper .bp3-button.bp3-align-left .bp3-button-text,.jupyter-wrapper .bp3-button.bp3-align-right .bp3-button-text,.jupyter-wrapper .bp3-button-group.bp3-align-left .bp3-button-text,.jupyter-wrapper .bp3-button-group.bp3-align-right .bp3-button-text{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.jupyter-wrapper .bp3-button-group .bp3-button{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;z-index:4}.jupyter-wrapper .bp3-button-group .bp3-button:focus{z-index:5}.jupyter-wrapper .bp3-button-group .bp3-button:hover{z-index:6}.jupyter-wrapper .bp3-button-group .bp3-button:active,.jupyter-wrapper .bp3-button-group .bp3-button.bp3-active{z-index:7}.jupyter-wrapper .bp3-button-group .bp3-button:disabled,.jupyter-wrapper .bp3-button-group .bp3-button.bp3-disabled{z-index:3}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]{z-index:9}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:focus{z-index:10}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:hover{z-index:11}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:active,.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-].bp3-active{z-index:12}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:disabled,.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-].bp3-disabled{z-index:8}.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:first-child) .bp3-button,.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:first-child){border-top-left-radius:0;border-bottom-left-radius:0}.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:last-child){margin-right:-1px;border-top-right-radius:0;border-bottom-right-radius:0}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button{-webkit-box-shadow:none;box-shadow:none;background:none}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:hover{-webkit-box-shadow:none;box-shadow:none;background:rgba(167,182,194,.3);text-decoration:none;color:#182026}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:rgba(115,134,148,.3);color:#182026}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{background:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{-webkit-box-shadow:none;box-shadow:none;background:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{background:none;cursor:not-allowed;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{background:none;color:rgba(16,107,163,.5)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{background:none;color:rgba(72,175,240,.5)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{background:none;color:rgba(13,128,80,.5)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{background:none;color:rgba(61,204,145,.5)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{background:none;color:rgba(191,115,38,.5)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{background:none;color:rgba(255,179,102,.5)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{background:none;color:rgba(194,48,48,.5)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{background:none;color:rgba(255,115,115,.5)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button-group .bp3-popover-wrapper,.jupyter-wrapper .bp3-button-group .bp3-popover-target{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-button-group .bp3-button.bp3-fill,.jupyter-wrapper .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group.bp3-vertical{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;vertical-align:top}.jupyter-wrapper .bp3-button-group.bp3-vertical.bp3-fill{width:unset;height:100%}.jupyter-wrapper .bp3-button-group.bp3-vertical .bp3-button{margin-right:0 !important;width:100%}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:first-child .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:first-child{border-radius:3px 3px 0 0}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:last-child .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:last-child{border-radius:0 0 3px 3px}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:not(:last-child){margin-bottom:-1px}.jupyter-wrapper .bp3-button-group.bp3-align-left .bp3-button{text-align:left}.jupyter-wrapper .bp3-dark .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-dark .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:last-child){margin-right:1px}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-vertical>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-vertical>.bp3-button:not(:last-child){margin-bottom:1px}.jupyter-wrapper .bp3-callout{line-height:1.5;font-size:14px;position:relative;border-radius:3px;background-color:rgba(138,155,168,.15);width:100%;padding:10px 12px 9px}.jupyter-wrapper .bp3-callout[class*=bp3-icon-]{padding-left:40px}.jupyter-wrapper .bp3-callout[class*=bp3-icon-]::before{line-height:1;font-family:"Icons20",sans-serif;font-size:20px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;position:absolute;top:10px;left:10px;color:#5c7080}.jupyter-wrapper .bp3-callout.bp3-callout-icon{padding-left:40px}.jupyter-wrapper .bp3-callout.bp3-callout-icon>.bp3-icon:first-child{position:absolute;top:10px;left:10px;color:#5c7080}.jupyter-wrapper .bp3-callout .bp3-heading{margin-top:0;margin-bottom:5px;line-height:20px}.jupyter-wrapper .bp3-callout .bp3-heading:last-child{margin-bottom:0}.jupyter-wrapper .bp3-dark .bp3-callout{background-color:rgba(138,155,168,.2)}.jupyter-wrapper .bp3-dark .bp3-callout[class*=bp3-icon-]::before{color:#a7b6c2}.jupyter-wrapper .bp3-callout.bp3-intent-primary{background-color:rgba(19,124,189,.15)}.jupyter-wrapper .bp3-callout.bp3-intent-primary[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-callout.bp3-intent-primary>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-primary .bp3-heading{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary{background-color:rgba(19,124,189,.25)}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{color:#48aff0}.jupyter-wrapper .bp3-callout.bp3-intent-success{background-color:rgba(15,153,96,.15)}.jupyter-wrapper .bp3-callout.bp3-intent-success[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-callout.bp3-intent-success>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-success .bp3-heading{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success{background-color:rgba(15,153,96,.25)}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{color:#3dcc91}.jupyter-wrapper .bp3-callout.bp3-intent-warning{background-color:rgba(217,130,43,.15)}.jupyter-wrapper .bp3-callout.bp3-intent-warning[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-callout.bp3-intent-warning>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-warning .bp3-heading{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning{background-color:rgba(217,130,43,.25)}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{color:#ffb366}.jupyter-wrapper .bp3-callout.bp3-intent-danger{background-color:rgba(219,55,55,.15)}.jupyter-wrapper .bp3-callout.bp3-intent-danger[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-callout.bp3-intent-danger>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-danger .bp3-heading{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger{background-color:rgba(219,55,55,.25)}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger[class*=bp3-icon-]::before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{color:#ff7373}.jupyter-wrapper .bp3-running-text .bp3-callout{margin:20px 0}.jupyter-wrapper .bp3-card{border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);background-color:#fff;padding:20px;-webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9),box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9),box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-card.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);background-color:#30404d}.jupyter-wrapper .bp3-elevation-0{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0)}.jupyter-wrapper .bp3-elevation-0.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-0{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0)}.jupyter-wrapper .bp3-elevation-1{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-elevation-1.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-1{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-elevation-2{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 1px 1px rgba(16,22,26,.2),0 2px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 1px 1px rgba(16,22,26,.2),0 2px 6px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-elevation-2.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-2{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.4),0 2px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.4),0 2px 6px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-elevation-3{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-elevation-3.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-3{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-elevation-4{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-elevation-4.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-4{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-card.bp3-interactive:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);cursor:pointer}.jupyter-wrapper .bp3-card.bp3-interactive:hover.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card.bp3-interactive:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-card.bp3-interactive:active{opacity:.9;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);-webkit-transition-duration:0;transition-duration:0}.jupyter-wrapper .bp3-card.bp3-interactive:active.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card.bp3-interactive:active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-collapse{height:0;overflow-y:hidden;-webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-collapse .bp3-collapse-body{-webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-collapse .bp3-collapse-body[aria-hidden=true]{display:none}.jupyter-wrapper .bp3-context-menu .bp3-popover-target{display:block}.jupyter-wrapper .bp3-context-menu-popover-target{position:fixed}.jupyter-wrapper .bp3-divider{margin:5px;border-right:1px solid rgba(16,22,26,.15);border-bottom:1px solid rgba(16,22,26,.15)}.jupyter-wrapper .bp3-dark .bp3-divider{border-color:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dialog-container{opacity:1;-webkit-transform:scale(1);transform:scale(1);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:100%;min-height:100%;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-enter>.bp3-dialog,.jupyter-wrapper .bp3-dialog-container.bp3-overlay-appear>.bp3-dialog{opacity:0;-webkit-transform:scale(0.5);transform:scale(0.5)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-enter-active>.bp3-dialog,.jupyter-wrapper .bp3-dialog-container.bp3-overlay-appear-active>.bp3-dialog{opacity:1;-webkit-transform:scale(1);transform:scale(1);-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:opacity,transform;transition-property:opacity,transform,-webkit-transform;-webkit-transition-duration:300ms;transition-duration:300ms;-webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-exit>.bp3-dialog{opacity:1;-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-exit-active>.bp3-dialog{opacity:0;-webkit-transform:scale(0.5);transform:scale(0.5);-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:opacity,transform;transition-property:opacity,transform,-webkit-transform;-webkit-transition-duration:300ms;transition-duration:300ms;-webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-dialog{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:30px 0;border-radius:6px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);background:#ebf1f5;width:500px;padding-bottom:20px;pointer-events:all;-webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text}.jupyter-wrapper .bp3-dialog:focus{outline:0}.jupyter-wrapper .bp3-dialog.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-dialog{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);background:#293742;color:#f5f8fa}.jupyter-wrapper .bp3-dialog-header{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:6px 6px 0 0;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.15);box-shadow:0 1px 0 rgba(16,22,26,.15);background:#fff;min-height:40px;padding-right:5px;padding-left:20px}.jupyter-wrapper .bp3-dialog-header .bp3-icon-large,.jupyter-wrapper .bp3-dialog-header .bp3-icon{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-right:10px;color:#5c7080}.jupyter-wrapper .bp3-dialog-header .bp3-heading{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;margin:0;line-height:inherit}.jupyter-wrapper .bp3-dialog-header .bp3-heading:last-child{margin-right:20px}.jupyter-wrapper .bp3-dark .bp3-dialog-header{-webkit-box-shadow:0 1px 0 rgba(16,22,26,.4);box-shadow:0 1px 0 rgba(16,22,26,.4);background:#30404d}.jupyter-wrapper .bp3-dark .bp3-dialog-header .bp3-icon-large,.jupyter-wrapper .bp3-dark .bp3-dialog-header .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dialog-body{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;margin:20px;line-height:18px}.jupyter-wrapper .bp3-dialog-footer{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin:0 20px}.jupyter-wrapper .bp3-dialog-footer-actions{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end}.jupyter-wrapper .bp3-dialog-footer-actions .bp3-button{margin-left:10px}.jupyter-wrapper .bp3-drawer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:0;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);background:#fff;padding:0}.jupyter-wrapper .bp3-drawer:focus{outline:0}.jupyter-wrapper .bp3-drawer.bp3-position-top{top:0;right:0;left:0;height:50%}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-appear{-webkit-transform:translateY(-100%);transform:translateY(-100%)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{-webkit-transform:translateY(-100%);transform:translateY(-100%);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-position-bottom{right:0;bottom:0;left:0;height:50%}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{-webkit-transform:translateY(100%);transform:translateY(100%)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{-webkit-transform:translateY(100%);transform:translateY(100%);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-position-left{top:0;bottom:0;left:0;width:50%}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-appear{-webkit-transform:translateX(-100%);transform:translateX(-100%)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translateX(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-exit{-webkit-transform:translateX(0);transform:translateX(0)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{-webkit-transform:translateX(-100%);transform:translateX(-100%);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-position-right{top:0;right:0;bottom:0;width:50%}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-appear{-webkit-transform:translateX(100%);transform:translateX(100%)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translateX(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-exit{-webkit-transform:translateX(0);transform:translateX(0)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{-webkit-transform:translateX(100%);transform:translateX(100%);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical){top:0;right:0;bottom:0;width:50%}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-enter,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{-webkit-transform:translateX(100%);transform:translateX(100%)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translateX(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{-webkit-transform:translateX(0);transform:translateX(0)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{-webkit-transform:translateX(100%);transform:translateX(100%);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical{right:0;bottom:0;left:0;height:50%}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-appear{-webkit-transform:translateY(100%);transform:translateY(100%)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-exit-active{-webkit-transform:translateY(100%);transform:translateY(100%);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-drawer.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-drawer{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);background:#30404d;color:#f5f8fa}.jupyter-wrapper .bp3-drawer-header{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;border-radius:0;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.15);box-shadow:0 1px 0 rgba(16,22,26,.15);min-height:40px;padding:5px;padding-left:20px}.jupyter-wrapper .bp3-drawer-header .bp3-icon-large,.jupyter-wrapper .bp3-drawer-header .bp3-icon{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-right:10px;color:#5c7080}.jupyter-wrapper .bp3-drawer-header .bp3-heading{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;margin:0;line-height:inherit}.jupyter-wrapper .bp3-drawer-header .bp3-heading:last-child{margin-right:20px}.jupyter-wrapper .bp3-dark .bp3-drawer-header{-webkit-box-shadow:0 1px 0 rgba(16,22,26,.4);box-shadow:0 1px 0 rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-drawer-header .bp3-icon-large,.jupyter-wrapper .bp3-dark .bp3-drawer-header .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-drawer-body{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;overflow:auto;line-height:18px}.jupyter-wrapper .bp3-drawer-footer{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.15);box-shadow:inset 0 1px 0 rgba(16,22,26,.15);padding:10px 20px}.jupyter-wrapper .bp3-dark .bp3-drawer-footer{-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.4);box-shadow:inset 0 1px 0 rgba(16,22,26,.4)}.jupyter-wrapper .bp3-editable-text{display:inline-block;position:relative;cursor:text;max-width:100%;vertical-align:top;white-space:nowrap}.jupyter-wrapper .bp3-editable-text::before{position:absolute;top:-3px;right:-3px;bottom:-3px;left:-3px;border-radius:3px;content:"";-webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9),box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9),box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-editable-text:hover::before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15)}.jupyter-wrapper .bp3-editable-text.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);background-color:#fff}.jupyter-wrapper .bp3-editable-text.bp3-disabled::before{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{color:#137cbd}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary:hover::before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(19,124,189,.4);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(19,124,189,.4)}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{color:#0f9960}.jupyter-wrapper .bp3-editable-text.bp3-intent-success:hover::before{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px rgba(15,153,96,.4);box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px rgba(15,153,96,.4)}.jupyter-wrapper .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{color:#d9822b}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning:hover::before{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px rgba(217,130,43,.4);box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px rgba(217,130,43,.4)}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{color:#db3737}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger:hover::before{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px rgba(219,55,55,.4);box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px rgba(219,55,55,.4)}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-dark .bp3-editable-text:hover::before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(255,255,255,.15);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(255,255,255,.15)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);background-color:rgba(16,22,26,.3)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-disabled::before{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{-webkit-box-shadow:0 0 0 0 rgba(72,175,240,0),0 0 0 0 rgba(72,175,240,0),inset 0 0 0 1px rgba(72,175,240,.4);box-shadow:0 0 0 0 rgba(72,175,240,0),0 0 0 0 rgba(72,175,240,0),inset 0 0 0 1px rgba(72,175,240,.4)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #48aff0,0 0 0 3px rgba(72,175,240,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #48aff0,0 0 0 3px rgba(72,175,240,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{-webkit-box-shadow:0 0 0 0 rgba(61,204,145,0),0 0 0 0 rgba(61,204,145,0),inset 0 0 0 1px rgba(61,204,145,.4);box-shadow:0 0 0 0 rgba(61,204,145,0),0 0 0 0 rgba(61,204,145,0),inset 0 0 0 1px rgba(61,204,145,.4)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #3dcc91,0 0 0 3px rgba(61,204,145,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #3dcc91,0 0 0 3px rgba(61,204,145,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{-webkit-box-shadow:0 0 0 0 rgba(255,179,102,0),0 0 0 0 rgba(255,179,102,0),inset 0 0 0 1px rgba(255,179,102,.4);box-shadow:0 0 0 0 rgba(255,179,102,0),0 0 0 0 rgba(255,179,102,0),inset 0 0 0 1px rgba(255,179,102,.4)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #ffb366,0 0 0 3px rgba(255,179,102,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #ffb366,0 0 0 3px rgba(255,179,102,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{-webkit-box-shadow:0 0 0 0 rgba(255,115,115,0),0 0 0 0 rgba(255,115,115,0),inset 0 0 0 1px rgba(255,115,115,.4);box-shadow:0 0 0 0 rgba(255,115,115,0),0 0 0 0 rgba(255,115,115,0),inset 0 0 0 1px rgba(255,115,115,.4)}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{-webkit-box-shadow:0 0 0 1px #ff7373,0 0 0 3px rgba(255,115,115,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #ff7373,0 0 0 3px rgba(255,115,115,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text-content{display:inherit;position:relative;min-width:inherit;max-width:inherit;vertical-align:top;text-transform:inherit;letter-spacing:inherit;color:inherit;font:inherit;resize:none}.jupyter-wrapper .bp3-editable-text-input{border:none;-webkit-box-shadow:none;box-shadow:none;background:none;width:100%;padding:0;white-space:pre-wrap}.jupyter-wrapper .bp3-editable-text-input::-webkit-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-editable-text-input::-moz-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-editable-text-input:-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-editable-text-input::-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-editable-text-input::placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-editable-text-input:focus{outline:none}.jupyter-wrapper .bp3-editable-text-input::-ms-clear{display:none}.jupyter-wrapper .bp3-editable-text-content{overflow:hidden;padding-right:2px;text-overflow:ellipsis;white-space:pre}.jupyter-wrapper .bp3-editable-text-editing>.bp3-editable-text-content{position:absolute;left:0;visibility:hidden}.jupyter-wrapper .bp3-editable-text-placeholder>.bp3-editable-text-content{color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-dark .bp3-editable-text-placeholder>.bp3-editable-text-content{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-editable-text.bp3-multiline{display:block}.jupyter-wrapper .bp3-editable-text.bp3-multiline .bp3-editable-text-content{overflow:auto;white-space:pre-wrap;word-wrap:break-word}.jupyter-wrapper .bp3-control-group{-webkit-transform:translateZ(0);transform:translateZ(0);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch}.jupyter-wrapper .bp3-control-group>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-control-group>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-control-group .bp3-button,.jupyter-wrapper .bp3-control-group .bp3-html-select,.jupyter-wrapper .bp3-control-group .bp3-input,.jupyter-wrapper .bp3-control-group .bp3-select{position:relative}.jupyter-wrapper .bp3-control-group .bp3-input{z-index:2;border-radius:inherit}.jupyter-wrapper .bp3-control-group .bp3-input:focus{z-index:14;border-radius:3px}.jupyter-wrapper .bp3-control-group .bp3-input[class*=bp3-intent]{z-index:13}.jupyter-wrapper .bp3-control-group .bp3-input[class*=bp3-intent]:focus{z-index:15}.jupyter-wrapper .bp3-control-group .bp3-input[readonly],.jupyter-wrapper .bp3-control-group .bp3-input:disabled,.jupyter-wrapper .bp3-control-group .bp3-input.bp3-disabled{z-index:1}.jupyter-wrapper .bp3-control-group .bp3-input-group[class*=bp3-intent] .bp3-input{z-index:13}.jupyter-wrapper .bp3-control-group .bp3-input-group[class*=bp3-intent] .bp3-input:focus{z-index:15}.jupyter-wrapper .bp3-control-group .bp3-button,.jupyter-wrapper .bp3-control-group .bp3-html-select select,.jupyter-wrapper .bp3-control-group .bp3-select select{-webkit-transform:translateZ(0);transform:translateZ(0);z-index:4;border-radius:inherit}.jupyter-wrapper .bp3-control-group .bp3-button:focus,.jupyter-wrapper .bp3-control-group .bp3-html-select select:focus,.jupyter-wrapper .bp3-control-group .bp3-select select:focus{z-index:5}.jupyter-wrapper .bp3-control-group .bp3-button:hover,.jupyter-wrapper .bp3-control-group .bp3-html-select select:hover,.jupyter-wrapper .bp3-control-group .bp3-select select:hover{z-index:6}.jupyter-wrapper .bp3-control-group .bp3-button:active,.jupyter-wrapper .bp3-control-group .bp3-html-select select:active,.jupyter-wrapper .bp3-control-group .bp3-select select:active{z-index:7}.jupyter-wrapper .bp3-control-group .bp3-button[readonly],.jupyter-wrapper .bp3-control-group .bp3-button:disabled,.jupyter-wrapper .bp3-control-group .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[readonly],.jupyter-wrapper .bp3-control-group .bp3-html-select select:disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[readonly],.jupyter-wrapper .bp3-control-group .bp3-select select:disabled,.jupyter-wrapper .bp3-control-group .bp3-select select.bp3-disabled{z-index:3}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent],.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent],.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]{z-index:9}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:focus,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:focus,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:focus{z-index:10}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:hover,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:hover,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:hover{z-index:11}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:active,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:active,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:active{z-index:12}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent].bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent].bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent].bp3-disabled{z-index:8}.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-icon,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-button,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-input-action{z-index:16}.jupyter-wrapper .bp3-control-group .bp3-select::after,.jupyter-wrapper .bp3-control-group .bp3-html-select::after,.jupyter-wrapper .bp3-control-group .bp3-select>.bp3-icon,.jupyter-wrapper .bp3-control-group .bp3-html-select>.bp3-icon{z-index:17}.jupyter-wrapper .bp3-control-group:not(.bp3-vertical)>*{margin-right:-1px}.jupyter-wrapper .bp3-dark .bp3-control-group:not(.bp3-vertical)>*{margin-right:0}.jupyter-wrapper .bp3-dark .bp3-control-group:not(.bp3-vertical)>.bp3-button+.bp3-button{margin-left:1px}.jupyter-wrapper .bp3-control-group .bp3-popover-wrapper,.jupyter-wrapper .bp3-control-group .bp3-popover-target{border-radius:inherit}.jupyter-wrapper .bp3-control-group>:first-child{border-radius:3px 0 0 3px}.jupyter-wrapper .bp3-control-group>:last-child{margin-right:0;border-radius:0 3px 3px 0}.jupyter-wrapper .bp3-control-group>:only-child{margin-right:0;border-radius:3px}.jupyter-wrapper .bp3-control-group .bp3-input-group .bp3-button{border-radius:3px}.jupyter-wrapper .bp3-control-group>.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-control-group.bp3-fill>*:not(.bp3-fixed){-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-control-group.bp3-vertical{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.jupyter-wrapper .bp3-control-group.bp3-vertical>*{margin-top:-1px}.jupyter-wrapper .bp3-control-group.bp3-vertical>:first-child{margin-top:0;border-radius:3px 3px 0 0}.jupyter-wrapper .bp3-control-group.bp3-vertical>:last-child{border-radius:0 0 3px 3px}.jupyter-wrapper .bp3-control{display:block;position:relative;margin-bottom:10px;cursor:pointer;text-transform:none}.jupyter-wrapper .bp3-control input:checked~.bp3-control-indicator{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#137cbd;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));color:#fff}.jupyter-wrapper .bp3-control:hover input:checked~.bp3-control-indicator{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#106ba3}.jupyter-wrapper .bp3-control input:not(:disabled):active:checked~.bp3-control-indicator{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background:#0e5a8a}.jupyter-wrapper .bp3-control input:disabled:checked~.bp3-control-indicator{-webkit-box-shadow:none;box-shadow:none;background:rgba(19,124,189,.5)}.jupyter-wrapper .bp3-dark .bp3-control input:checked~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control:hover input:checked~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-control input:not(:disabled):active:checked~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background-color:#0e5a8a}.jupyter-wrapper .bp3-dark .bp3-control input:disabled:checked~.bp3-control-indicator{-webkit-box-shadow:none;box-shadow:none;background:rgba(14,90,138,.5)}.jupyter-wrapper .bp3-control:not(.bp3-align-right){padding-left:26px}.jupyter-wrapper .bp3-control:not(.bp3-align-right) .bp3-control-indicator{margin-left:-26px}.jupyter-wrapper .bp3-control.bp3-align-right{padding-right:26px}.jupyter-wrapper .bp3-control.bp3-align-right .bp3-control-indicator{margin-right:-26px}.jupyter-wrapper .bp3-control.bp3-disabled{cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-control.bp3-inline{display:inline-block;margin-right:20px}.jupyter-wrapper .bp3-control input{position:absolute;top:0;left:0;opacity:0;z-index:-1}.jupyter-wrapper .bp3-control .bp3-control-indicator{display:inline-block;position:relative;margin-top:-3px;margin-right:10px;border:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-clip:padding-box;background-color:#f5f8fa;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));cursor:pointer;width:1em;height:1em;vertical-align:middle;font-size:16px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-control .bp3-control-indicator::before{display:block;width:1em;height:1em;content:""}.jupyter-wrapper .bp3-control:hover .bp3-control-indicator{background-color:#ebf1f5}.jupyter-wrapper .bp3-control input:not(:disabled):active~.bp3-control-indicator{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);background:#d8e1e8}.jupyter-wrapper .bp3-control input:disabled~.bp3-control-indicator{-webkit-box-shadow:none;box-shadow:none;background:rgba(206,217,224,.5);cursor:not-allowed}.jupyter-wrapper .bp3-control input:focus~.bp3-control-indicator{outline:rgba(19,124,189,.6) auto 2px;outline-offset:2px;-moz-outline-radius:6px}.jupyter-wrapper .bp3-control.bp3-align-right .bp3-control-indicator{float:right;margin-top:1px;margin-left:10px}.jupyter-wrapper .bp3-control.bp3-large{font-size:16px}.jupyter-wrapper .bp3-control.bp3-large:not(.bp3-align-right){padding-left:30px}.jupyter-wrapper .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{margin-left:-30px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right{padding-right:30px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{margin-right:-30px}.jupyter-wrapper .bp3-control.bp3-large .bp3-control-indicator{font-size:20px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{margin-top:0}.jupyter-wrapper .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#137cbd;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));color:#fff}.jupyter-wrapper .bp3-control.bp3-checkbox:hover input:indeterminate~.bp3-control-indicator{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);background-color:#106ba3}.jupyter-wrapper .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate~.bp3-control-indicator{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background:#0e5a8a}.jupyter-wrapper .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{-webkit-box-shadow:none;box-shadow:none;background:rgba(19,124,189,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);background-color:#0e5a8a}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{-webkit-box-shadow:none;box-shadow:none;background:rgba(14,90,138,.5)}.jupyter-wrapper .bp3-control.bp3-checkbox .bp3-control-indicator{border-radius:3px}.jupyter-wrapper .bp3-control.bp3-checkbox input:checked~.bp3-control-indicator::before{background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e")}.jupyter-wrapper .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator::before{background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e")}.jupyter-wrapper .bp3-control.bp3-radio .bp3-control-indicator{border-radius:50%}.jupyter-wrapper .bp3-control.bp3-radio input:checked~.bp3-control-indicator::before{background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%)}.jupyter-wrapper .bp3-control.bp3-radio input:checked:disabled~.bp3-control-indicator::before{opacity:.5}.jupyter-wrapper .bp3-control.bp3-radio input:focus~.bp3-control-indicator{-moz-outline-radius:16px}.jupyter-wrapper .bp3-control.bp3-switch input~.bp3-control-indicator{background:rgba(167,182,194,.5)}.jupyter-wrapper .bp3-control.bp3-switch:hover input~.bp3-control-indicator{background:rgba(115,134,148,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:not(:disabled):active~.bp3-control-indicator{background:rgba(92,112,128,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:disabled~.bp3-control-indicator{background:rgba(206,217,224,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:disabled~.bp3-control-indicator::before{background:rgba(255,255,255,.8)}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator{background:#137cbd}.jupyter-wrapper .bp3-control.bp3-switch:hover input:checked~.bp3-control-indicator{background:#106ba3}.jupyter-wrapper .bp3-control.bp3-switch input:checked:not(:disabled):active~.bp3-control-indicator{background:#0e5a8a}.jupyter-wrapper .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator{background:rgba(19,124,189,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator::before{background:rgba(255,255,255,.8)}.jupyter-wrapper .bp3-control.bp3-switch:not(.bp3-align-right){padding-left:38px}.jupyter-wrapper .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{margin-left:-38px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-align-right{padding-right:38px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{margin-right:-38px}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator{border:none;border-radius:1.75em;-webkit-box-shadow:none !important;box-shadow:none !important;width:auto;min-width:1.75em;-webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator::before{position:absolute;left:0;margin:2px;border-radius:50%;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);background:#fff;width:calc(1em - 4px);height:calc(1em - 4px);-webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator::before{left:calc(100% - 1em)}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){padding-left:45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{margin-left:-45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large.bp3-align-right{padding-right:45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{margin-right:-45px}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input~.bp3-control-indicator{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch:hover input~.bp3-control-indicator{background:rgba(16,22,26,.7)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active~.bp3-control-indicator{background:rgba(16,22,26,.9)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:disabled~.bp3-control-indicator{background:rgba(57,75,89,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:disabled~.bp3-control-indicator::before{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked~.bp3-control-indicator{background:#137cbd}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch:hover input:checked~.bp3-control-indicator{background:#106ba3}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active~.bp3-control-indicator{background:#0e5a8a}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator{background:rgba(14,90,138,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator::before{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background:#394b59}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked~.bp3-control-indicator::before{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-control.bp3-switch .bp3-switch-inner-text{text-align:center;font-size:.7em}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{visibility:hidden;margin-right:1.2em;margin-left:.5em;line-height:0}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{visibility:visible;margin-right:.5em;margin-left:1.2em;line-height:1em}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator .bp3-control-indicator-child:first-child{visibility:visible;line-height:1em}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator .bp3-control-indicator-child:last-child{visibility:hidden;line-height:0}.jupyter-wrapper .bp3-dark .bp3-control{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-control.bp3-disabled{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-control .bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#394b59;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0))}.jupyter-wrapper .bp3-dark .bp3-control:hover .bp3-control-indicator{background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-control input:not(:disabled):active~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);background:#202b33}.jupyter-wrapper .bp3-dark .bp3-control input:disabled~.bp3-control-indicator{-webkit-box-shadow:none;box-shadow:none;background:rgba(57,75,89,.5);cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked~.bp3-control-indicator,.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-file-input{display:inline-block;position:relative;cursor:pointer;height:30px}.jupyter-wrapper .bp3-file-input input{opacity:0;margin:0;min-width:200px}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input{-webkit-box-shadow:none;box-shadow:none;background:rgba(206,217,224,.5);cursor:not-allowed;color:rgba(92,112,128,.6);resize:none}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input::after,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input::after{outline:none;-webkit-box-shadow:none;box-shadow:none;background-color:rgba(206,217,224,.5);background-image:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input::after.bp3-active,.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input::after.bp3-active:hover,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input::after.bp3-active,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input::after.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input{-webkit-box-shadow:none;box-shadow:none;background:rgba(57,75,89,.5);color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input::after,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input::after{-webkit-box-shadow:none;box-shadow:none;background-color:rgba(57,75,89,.5);background-image:none;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input::after.bp3-active,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input::after.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{color:#182026}.jupyter-wrapper .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{color:#f5f8fa}.jupyter-wrapper .bp3-file-input.bp3-fill{width:100%}.jupyter-wrapper .bp3-file-input.bp3-large,.jupyter-wrapper .bp3-large .bp3-file-input{height:40px}.jupyter-wrapper .bp3-file-input .bp3-file-upload-input-custom-text::after{content:attr(bp3-button-text)}.jupyter-wrapper .bp3-file-upload-input{outline:none;border:none;border-radius:3px;-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);background:#fff;height:30px;padding:0 10px;vertical-align:middle;line-height:30px;color:#182026;font-size:14px;font-weight:400;-webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-appearance:none;-moz-appearance:none;appearance:none;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;position:absolute;top:0;right:0;left:0;padding-right:80px;color:rgba(92,112,128,.6);-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-file-upload-input::-webkit-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-file-upload-input::-moz-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-file-upload-input:-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-file-upload-input::-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-file-upload-input::placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-file-upload-input:focus,.jupyter-wrapper .bp3-file-upload-input.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-file-upload-input[type=search],.jupyter-wrapper .bp3-file-upload-input.bp3-round{border-radius:30px;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:10px}.jupyter-wrapper .bp3-file-upload-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px rgba(16,22,26,.15)}.jupyter-wrapper .bp3-file-upload-input:disabled,.jupyter-wrapper .bp3-file-upload-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background:rgba(206,217,224,.5);cursor:not-allowed;color:rgba(92,112,128,.6);resize:none}.jupyter-wrapper .bp3-file-upload-input::after{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-color:#f5f8fa;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));color:#182026;min-width:24px;min-height:24px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;position:absolute;top:0;right:0;margin:3px;border-radius:3px;width:70px;text-align:center;line-height:24px;content:"Browse"}.jupyter-wrapper .bp3-file-upload-input::after:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-clip:padding-box;background-color:#ebf1f5}.jupyter-wrapper .bp3-file-upload-input::after:active,.jupyter-wrapper .bp3-file-upload-input::after.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);background-color:#d8e1e8;background-image:none}.jupyter-wrapper .bp3-file-upload-input::after:disabled,.jupyter-wrapper .bp3-file-upload-input::after.bp3-disabled{outline:none;-webkit-box-shadow:none;box-shadow:none;background-color:rgba(206,217,224,.5);background-image:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-file-upload-input::after:disabled.bp3-active,.jupyter-wrapper .bp3-file-upload-input::after:disabled.bp3-active:hover,.jupyter-wrapper .bp3-file-upload-input::after.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-file-upload-input:hover::after{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-clip:padding-box;background-color:#ebf1f5}.jupyter-wrapper .bp3-file-upload-input:active::after{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);background-color:#d8e1e8;background-image:none}.jupyter-wrapper .bp3-large .bp3-file-upload-input{height:40px;line-height:40px;font-size:16px;padding-right:95px}.jupyter-wrapper .bp3-large .bp3-file-upload-input[type=search],.jupyter-wrapper .bp3-large .bp3-file-upload-input.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-large .bp3-file-upload-input::after{min-width:30px;min-height:30px;margin:5px;width:85px;line-height:30px}.jupyter-wrapper .bp3-dark .bp3-file-upload-input{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);background:rgba(16,22,26,.3);color:#f5f8fa;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-moz-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:disabled,.jupyter-wrapper .bp3-dark .bp3-file-upload-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background:rgba(57,75,89,.5);color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#394b59;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after:hover,.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after:active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after.bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after:active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after.bp3-active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);background-color:#202b33;background-image:none}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after:disabled,.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background-color:rgba(57,75,89,.5);background-image:none;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:hover::after{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:active::after{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);background-color:#202b33;background-image:none}.jupyter-wrapper .bp3-file-upload-input::after{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1)}.jupyter-wrapper .bp3-form-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:0 0 15px}.jupyter-wrapper .bp3-form-group label.bp3-label{margin-bottom:5px}.jupyter-wrapper .bp3-form-group .bp3-control{margin-top:7px}.jupyter-wrapper .bp3-form-group .bp3-form-helper-text{margin-top:5px;color:#5c7080;font-size:12px}.jupyter-wrapper .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{color:#106ba3}.jupyter-wrapper .bp3-form-group.bp3-intent-success .bp3-form-helper-text{color:#0d8050}.jupyter-wrapper .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{color:#bf7326}.jupyter-wrapper .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{color:#c23030}.jupyter-wrapper .bp3-form-group.bp3-inline{-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.jupyter-wrapper .bp3-form-group.bp3-inline.bp3-large label.bp3-label{margin:0 10px 0 0;line-height:40px}.jupyter-wrapper .bp3-form-group.bp3-inline label.bp3-label{margin:0 10px 0 0;line-height:30px}.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-label,.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-text-muted,.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-form-helper-text{color:rgba(92,112,128,.6) !important}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-form-group .bp3-form-helper-text{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{color:rgba(167,182,194,.6) !important}.jupyter-wrapper .bp3-input-group{display:block;position:relative}.jupyter-wrapper .bp3-input-group .bp3-input{position:relative;width:100%}.jupyter-wrapper .bp3-input-group .bp3-input:not(:first-child){padding-left:30px}.jupyter-wrapper .bp3-input-group .bp3-input:not(:last-child){padding-right:30px}.jupyter-wrapper .bp3-input-group .bp3-input-action,.jupyter-wrapper .bp3-input-group>.bp3-button,.jupyter-wrapper .bp3-input-group>.bp3-icon{position:absolute;top:0}.jupyter-wrapper .bp3-input-group .bp3-input-action:first-child,.jupyter-wrapper .bp3-input-group>.bp3-button:first-child,.jupyter-wrapper .bp3-input-group>.bp3-icon:first-child{left:0}.jupyter-wrapper .bp3-input-group .bp3-input-action:last-child,.jupyter-wrapper .bp3-input-group>.bp3-button:last-child,.jupyter-wrapper .bp3-input-group>.bp3-icon:last-child{right:0}.jupyter-wrapper .bp3-input-group .bp3-button{min-width:24px;min-height:24px;margin:3px;padding:0 7px}.jupyter-wrapper .bp3-input-group .bp3-button:empty{padding:0}.jupyter-wrapper .bp3-input-group>.bp3-icon{z-index:1;color:#5c7080}.jupyter-wrapper .bp3-input-group>.bp3-icon:empty{line-height:1;font-family:"Icons16",sans-serif;font-size:16px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}.jupyter-wrapper .bp3-input-group>.bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input-action>.bp3-spinner{margin:7px}.jupyter-wrapper .bp3-input-group .bp3-tag{margin:5px}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus),.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){color:#5c7080}.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus),.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){color:#a7b6c2}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled{color:rgba(92,112,128,.6) !important}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon-large,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{color:rgba(92,112,128,.6) !important}.jupyter-wrapper .bp3-input-group.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-input-group.bp3-disabled .bp3-icon{color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-button{min-width:30px;min-height:30px;margin:5px}.jupyter-wrapper .bp3-input-group.bp3-large>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input-action>.bp3-spinner{margin:12px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input{height:40px;line-height:40px;font-size:16px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input[type=search],.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input:not(:first-child){padding-left:40px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input:not(:last-child){padding-right:40px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-button{min-width:20px;min-height:20px;margin:2px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-tag{min-width:20px;min-height:20px;margin:2px}.jupyter-wrapper .bp3-input-group.bp3-small>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input-action>.bp3-spinner{margin:4px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input{height:24px;padding-right:8px;padding-left:8px;line-height:24px;font-size:12px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input[type=search],.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input.bp3-round{padding:0 12px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input:not(:first-child){padding-left:24px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input:not(:last-child){padding-right:24px}.jupyter-wrapper .bp3-input-group.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;width:100%}.jupyter-wrapper .bp3-input-group.bp3-round .bp3-button,.jupyter-wrapper .bp3-input-group.bp3-round .bp3-input,.jupyter-wrapper .bp3-input-group.bp3-round .bp3-tag{border-radius:30px}.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-primary>.bp3-icon{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-primary>.bp3-icon{color:#48aff0}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-success>.bp3-icon{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-success>.bp3-icon{color:#3dcc91}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-warning>.bp3-icon{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-warning>.bp3-icon{color:#ffb366}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-danger>.bp3-icon{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-danger>.bp3-icon{color:#ff7373}.jupyter-wrapper .bp3-input{outline:none;border:none;border-radius:3px;-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);background:#fff;height:30px;padding:0 10px;vertical-align:middle;line-height:30px;color:#182026;font-size:14px;font-weight:400;-webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-appearance:none;-moz-appearance:none;appearance:none}.jupyter-wrapper .bp3-input::-webkit-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input::-moz-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input:-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input::-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input::placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input:focus,.jupyter-wrapper .bp3-input.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input[type=search],.jupyter-wrapper .bp3-input.bp3-round{border-radius:30px;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:10px}.jupyter-wrapper .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px rgba(16,22,26,.15)}.jupyter-wrapper .bp3-input:disabled,.jupyter-wrapper .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background:rgba(206,217,224,.5);cursor:not-allowed;color:rgba(92,112,128,.6);resize:none}.jupyter-wrapper .bp3-input.bp3-large{height:40px;line-height:40px;font-size:16px}.jupyter-wrapper .bp3-input.bp3-large[type=search],.jupyter-wrapper .bp3-input.bp3-large.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-input.bp3-small{height:24px;padding-right:8px;padding-left:8px;line-height:24px;font-size:12px}.jupyter-wrapper .bp3-input.bp3-small[type=search],.jupyter-wrapper .bp3-input.bp3-small.bp3-round{padding:0 12px}.jupyter-wrapper .bp3-input.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;width:100%}.jupyter-wrapper .bp3-dark .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);background:rgba(16,22,26,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-input::-webkit-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-input::-moz-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-input:-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-input::-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-input::placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background:rgba(57,75,89,.5);color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-input.bp3-intent-primary{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-primary:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-primary[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-input.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-input.bp3-intent-primary.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-success{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-success:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-success[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-input.bp3-intent-success:disabled,.jupyter-wrapper .bp3-input.bp3-intent-success.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #0f9960,0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-warning{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-warning:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-warning[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-input.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-input.bp3-intent-warning.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #d9822b,0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-danger{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-danger:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-input.bp3-intent-danger[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-input.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-input.bp3-intent-danger.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #db3737,0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input::-ms-clear{display:none}.jupyter-wrapper textarea.bp3-input{max-width:100%;padding:10px}.jupyter-wrapper textarea.bp3-input,.jupyter-wrapper textarea.bp3-input.bp3-large,.jupyter-wrapper textarea.bp3-input.bp3-small{height:auto;line-height:inherit}.jupyter-wrapper textarea.bp3-input.bp3-small{padding:8px}.jupyter-wrapper .bp3-dark textarea.bp3-input{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);background:rgba(16,22,26,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark textarea.bp3-input::-webkit-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark textarea.bp3-input::-moz-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark textarea.bp3-input:-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark textarea.bp3-input::-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark textarea.bp3-input::placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark textarea.bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark textarea.bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark textarea.bp3-input:disabled,.jupyter-wrapper .bp3-dark textarea.bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background:rgba(57,75,89,.5);color:rgba(167,182,194,.6)}.jupyter-wrapper label.bp3-label{display:block;margin-top:0;margin-bottom:15px}.jupyter-wrapper label.bp3-label .bp3-html-select,.jupyter-wrapper label.bp3-label .bp3-input,.jupyter-wrapper label.bp3-label .bp3-select,.jupyter-wrapper label.bp3-label .bp3-slider,.jupyter-wrapper label.bp3-label .bp3-popover-wrapper{display:block;margin-top:5px;text-transform:none}.jupyter-wrapper label.bp3-label .bp3-button-group{margin-top:5px}.jupyter-wrapper label.bp3-label .bp3-select select,.jupyter-wrapper label.bp3-label .bp3-html-select select{width:100%;vertical-align:top;font-weight:400}.jupyter-wrapper label.bp3-label.bp3-disabled,.jupyter-wrapper label.bp3-label.bp3-disabled .bp3-text-muted{color:rgba(92,112,128,.6)}.jupyter-wrapper label.bp3-label.bp3-inline{line-height:30px}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-html-select,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input-group,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-select,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-popover-wrapper{display:inline-block;margin:0 0 0 5px;vertical-align:top}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-button-group{margin:0 0 0 5px}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input-group .bp3-input{margin-left:0}.jupyter-wrapper label.bp3-label.bp3-inline.bp3-large{line-height:40px}.jupyter-wrapper label.bp3-label:not(.bp3-inline) .bp3-popover-target{display:block}.jupyter-wrapper .bp3-dark label.bp3-label{color:#f5f8fa}.jupyter-wrapper .bp3-dark label.bp3-label.bp3-disabled,.jupyter-wrapper .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button{-webkit-box-flex:1;-ms-flex:1 1 14px;flex:1 1 14px;width:30px;min-height:0;padding:0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button:first-child{border-radius:0 3px 0 0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button:last-child{border-radius:0 0 3px 0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical:first-child>.bp3-button:first-child{border-radius:3px 0 0 0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical:first-child>.bp3-button:last-child{border-radius:0 0 0 3px}.jupyter-wrapper .bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical>.bp3-button{width:40px}.jupyter-wrapper form{display:block}.jupyter-wrapper .bp3-html-select select,.jupyter-wrapper .bp3-select select{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;border:none;border-radius:3px;cursor:pointer;padding:5px 10px;vertical-align:middle;text-align:left;font-size:14px;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-color:#f5f8fa;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));color:#182026;border-radius:3px;width:100%;height:30px;padding:0 25px 0 10px;-moz-appearance:none;-webkit-appearance:none}.jupyter-wrapper .bp3-html-select select>*,.jupyter-wrapper .bp3-select select>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-html-select select>.bp3-fill,.jupyter-wrapper .bp3-select select>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-html-select select::before,.jupyter-wrapper .bp3-select select::before,.jupyter-wrapper .bp3-html-select select>*,.jupyter-wrapper .bp3-select select>*{margin-right:7px}.jupyter-wrapper .bp3-html-select select:empty::before,.jupyter-wrapper .bp3-select select:empty::before,.jupyter-wrapper .bp3-html-select select>:last-child,.jupyter-wrapper .bp3-select select>:last-child{margin-right:0}.jupyter-wrapper .bp3-html-select select:hover,.jupyter-wrapper .bp3-select select:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-clip:padding-box;background-color:#ebf1f5}.jupyter-wrapper .bp3-html-select select:active,.jupyter-wrapper .bp3-select select:active,.jupyter-wrapper .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-select select.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);background-color:#d8e1e8;background-image:none}.jupyter-wrapper .bp3-html-select select:disabled,.jupyter-wrapper .bp3-select select:disabled,.jupyter-wrapper .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-select select.bp3-disabled{outline:none;-webkit-box-shadow:none;box-shadow:none;background-color:rgba(206,217,224,.5);background-image:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-html-select select:disabled.bp3-active,.jupyter-wrapper .bp3-select select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select select:disabled.bp3-active:hover,.jupyter-wrapper .bp3-select select:disabled.bp3-active:hover,.jupyter-wrapper .bp3-html-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select select.bp3-disabled.bp3-active:hover,.jupyter-wrapper .bp3-select select.bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-html-select.bp3-minimal select,.jupyter-wrapper .bp3-select.bp3-minimal select{-webkit-box-shadow:none;box-shadow:none;background:none}.jupyter-wrapper .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal select:hover{-webkit-box-shadow:none;box-shadow:none;background:rgba(167,182,194,.3);text-decoration:none;color:#182026}.jupyter-wrapper .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:rgba(115,134,148,.3);color:#182026}.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled:hover{background:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select{-webkit-box-shadow:none;box-shadow:none;background:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{background:none;cursor:not-allowed;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{background:none;color:rgba(16,107,163,.5)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{background:none;color:rgba(72,175,240,.5)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{background:none;color:rgba(13,128,80,.5)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{background:none;color:rgba(61,204,145,.5)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{background:none;color:rgba(191,115,38,.5)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{background:none;color:rgba(255,179,102,.5)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{-webkit-box-shadow:none;box-shadow:none;background:none;color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{background:none;color:rgba(194,48,48,.5)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{background:none;color:rgba(255,115,115,.5)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-html-select.bp3-large select,.jupyter-wrapper .bp3-select.bp3-large select{height:40px;padding-right:35px;font-size:16px}.jupyter-wrapper .bp3-dark .bp3-html-select select,.jupyter-wrapper .bp3-dark .bp3-select select{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#394b59;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select select:hover,.jupyter-wrapper .bp3-dark .bp3-select select:hover,.jupyter-wrapper .bp3-dark .bp3-html-select select:active,.jupyter-wrapper .bp3-dark .bp3-select select:active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select select:hover,.jupyter-wrapper .bp3-dark .bp3-select select:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-html-select select:active,.jupyter-wrapper .bp3-dark .bp3-select select:active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);background-color:#202b33;background-image:none}.jupyter-wrapper .bp3-dark .bp3-html-select select:disabled,.jupyter-wrapper .bp3-dark .bp3-select select:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background-color:rgba(57,75,89,.5);background-image:none;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-html-select select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-html-select select:disabled,.jupyter-wrapper .bp3-select select:disabled{-webkit-box-shadow:none;box-shadow:none;background-color:rgba(206,217,224,.5);cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-select .bp3-icon,.jupyter-wrapper .bp3-select::after{position:absolute;top:7px;right:7px;color:#5c7080;pointer-events:none}.jupyter-wrapper .bp3-html-select .bp3-disabled.bp3-icon,.jupyter-wrapper .bp3-select .bp3-disabled.bp3-icon,.jupyter-wrapper .bp3-disabled.bp3-select::after{color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-html-select,.jupyter-wrapper .bp3-select{display:inline-block;position:relative;vertical-align:middle;letter-spacing:normal}.jupyter-wrapper .bp3-html-select select::-ms-expand,.jupyter-wrapper .bp3-select select::-ms-expand{display:none}.jupyter-wrapper .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-select .bp3-icon{color:#5c7080}.jupyter-wrapper .bp3-html-select .bp3-icon:hover,.jupyter-wrapper .bp3-select .bp3-icon:hover{color:#182026}.jupyter-wrapper .bp3-dark .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-select .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-html-select .bp3-icon:hover,.jupyter-wrapper .bp3-dark .bp3-select .bp3-icon:hover{color:#f5f8fa}.jupyter-wrapper .bp3-html-select.bp3-large::after,.jupyter-wrapper .bp3-html-select.bp3-large .bp3-icon,.jupyter-wrapper .bp3-select.bp3-large::after,.jupyter-wrapper .bp3-select.bp3-large .bp3-icon{top:12px;right:12px}.jupyter-wrapper .bp3-html-select.bp3-fill,.jupyter-wrapper .bp3-html-select.bp3-fill select,.jupyter-wrapper .bp3-select.bp3-fill,.jupyter-wrapper .bp3-select.bp3-fill select{width:100%}.jupyter-wrapper .bp3-dark .bp3-html-select option,.jupyter-wrapper .bp3-dark .bp3-select option{background-color:#30404d;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select::after,.jupyter-wrapper .bp3-dark .bp3-select::after{color:#a7b6c2}.jupyter-wrapper .bp3-select::after{line-height:1;font-family:"Icons16",sans-serif;font-size:16px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;content:""}.jupyter-wrapper .bp3-running-text table,.jupyter-wrapper table.bp3-html-table{border-spacing:0;font-size:14px}.jupyter-wrapper .bp3-running-text table th,.jupyter-wrapper table.bp3-html-table th,.jupyter-wrapper .bp3-running-text table td,.jupyter-wrapper table.bp3-html-table td{padding:11px;vertical-align:top;text-align:left}.jupyter-wrapper .bp3-running-text table th,.jupyter-wrapper table.bp3-html-table th{color:#182026;font-weight:600}.jupyter-wrapper .bp3-running-text table td,.jupyter-wrapper table.bp3-html-table td{color:#182026}.jupyter-wrapper .bp3-running-text table tbody tr:first-child th,.jupyter-wrapper table.bp3-html-table tbody tr:first-child th,.jupyter-wrapper .bp3-running-text table tbody tr:first-child td,.jupyter-wrapper table.bp3-html-table tbody tr:first-child td{-webkit-box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15)}.jupyter-wrapper .bp3-dark .bp3-running-text table th,.jupyter-wrapper .bp3-running-text .bp3-dark table th,.jupyter-wrapper .bp3-dark table.bp3-html-table th{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-running-text table td,.jupyter-wrapper .bp3-running-text .bp3-dark table td,.jupyter-wrapper .bp3-dark table.bp3-html-table td{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-running-text table tbody tr:first-child th,.jupyter-wrapper .bp3-running-text .bp3-dark table tbody tr:first-child th,.jupyter-wrapper .bp3-dark table.bp3-html-table tbody tr:first-child th,.jupyter-wrapper .bp3-dark .bp3-running-text table tbody tr:first-child td,.jupyter-wrapper .bp3-running-text .bp3-dark table tbody tr:first-child td,.jupyter-wrapper .bp3-dark table.bp3-html-table tbody tr:first-child td{-webkit-box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15)}.jupyter-wrapper table.bp3-html-table.bp3-html-table-condensed th,.jupyter-wrapper table.bp3-html-table.bp3-html-table-condensed td,.jupyter-wrapper table.bp3-html-table.bp3-small th,.jupyter-wrapper table.bp3-html-table.bp3-small td{padding-top:6px;padding-bottom:6px}.jupyter-wrapper table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{background:rgba(191,204,214,.15)}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15)}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tbody tr td{-webkit-box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15)}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){-webkit-box-shadow:inset 1px 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 1px 0 0 rgba(16,22,26,.15)}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15)}.jupyter-wrapper table.bp3-html-table.bp3-interactive tbody tr:hover td{background-color:rgba(191,204,214,.3);cursor:pointer}.jupyter-wrapper table.bp3-html-table.bp3-interactive tbody tr:active td{background-color:rgba(191,204,214,.4)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{background:rgba(92,112,128,.15)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{-webkit-box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){-webkit-box-shadow:inset 1px 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 1px 0 0 rgba(255,255,255,.15)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{-webkit-box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{background-color:rgba(92,112,128,.3);cursor:pointer}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{background-color:rgba(92,112,128,.4)}.jupyter-wrapper .bp3-key-combo{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center}.jupyter-wrapper .bp3-key-combo>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-key-combo>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-key-combo::before,.jupyter-wrapper .bp3-key-combo>*{margin-right:5px}.jupyter-wrapper .bp3-key-combo:empty::before,.jupyter-wrapper .bp3-key-combo>:last-child{margin-right:0}.jupyter-wrapper .bp3-hotkey-dialog{top:40px;padding-bottom:0}.jupyter-wrapper .bp3-hotkey-dialog .bp3-dialog-body{margin:0;padding:0}.jupyter-wrapper .bp3-hotkey-dialog .bp3-hotkey-label{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1}.jupyter-wrapper .bp3-hotkey-column{margin:auto;max-height:80vh;overflow-y:auto;padding:30px}.jupyter-wrapper .bp3-hotkey-column .bp3-heading{margin-bottom:20px}.jupyter-wrapper .bp3-hotkey-column .bp3-heading:not(:first-child){margin-top:40px}.jupyter-wrapper .bp3-hotkey{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;margin-right:0;margin-left:0}.jupyter-wrapper .bp3-hotkey:not(:last-child){margin-bottom:10px}.jupyter-wrapper .bp3-icon{display:inline-block;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;vertical-align:text-bottom}.jupyter-wrapper .bp3-icon:not(:empty)::before{content:"" !important;content:unset !important}.jupyter-wrapper .bp3-icon>svg{display:block}.jupyter-wrapper .bp3-icon>svg:not([fill]){fill:currentColor}.jupyter-wrapper .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-icon-large.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-icon-large.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-icon-large.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-icon-large.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-danger{color:#ff7373}.jupyter-wrapper span.bp3-icon-standard{line-height:1;font-family:"Icons16",sans-serif;font-size:16px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-block}.jupyter-wrapper span.bp3-icon-large{line-height:1;font-family:"Icons20",sans-serif;font-size:20px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-block}.jupyter-wrapper span.bp3-icon:empty{line-height:1;font-family:"Icons20";font-size:inherit;font-weight:400;font-style:normal}.jupyter-wrapper span.bp3-icon:empty::before{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}.jupyter-wrapper .bp3-icon-add::before{content:""}.jupyter-wrapper .bp3-icon-add-column-left::before{content:""}.jupyter-wrapper .bp3-icon-add-column-right::before{content:""}.jupyter-wrapper .bp3-icon-add-row-bottom::before{content:""}.jupyter-wrapper .bp3-icon-add-row-top::before{content:""}.jupyter-wrapper .bp3-icon-add-to-artifact::before{content:""}.jupyter-wrapper .bp3-icon-add-to-folder::before{content:""}.jupyter-wrapper .bp3-icon-airplane::before{content:""}.jupyter-wrapper .bp3-icon-align-center::before{content:""}.jupyter-wrapper .bp3-icon-align-justify::before{content:""}.jupyter-wrapper .bp3-icon-align-left::before{content:""}.jupyter-wrapper .bp3-icon-align-right::before{content:""}.jupyter-wrapper .bp3-icon-alignment-bottom::before{content:""}.jupyter-wrapper .bp3-icon-alignment-horizontal-center::before{content:""}.jupyter-wrapper .bp3-icon-alignment-left::before{content:""}.jupyter-wrapper .bp3-icon-alignment-right::before{content:""}.jupyter-wrapper .bp3-icon-alignment-top::before{content:""}.jupyter-wrapper .bp3-icon-alignment-vertical-center::before{content:""}.jupyter-wrapper .bp3-icon-annotation::before{content:""}.jupyter-wrapper .bp3-icon-application::before{content:""}.jupyter-wrapper .bp3-icon-applications::before{content:""}.jupyter-wrapper .bp3-icon-archive::before{content:""}.jupyter-wrapper .bp3-icon-arrow-bottom-left::before{content:""}.jupyter-wrapper .bp3-icon-arrow-bottom-right::before{content:""}.jupyter-wrapper .bp3-icon-arrow-down::before{content:""}.jupyter-wrapper .bp3-icon-arrow-left::before{content:""}.jupyter-wrapper .bp3-icon-arrow-right::before{content:""}.jupyter-wrapper .bp3-icon-arrow-top-left::before{content:""}.jupyter-wrapper .bp3-icon-arrow-top-right::before{content:""}.jupyter-wrapper .bp3-icon-arrow-up::before{content:""}.jupyter-wrapper .bp3-icon-arrows-horizontal::before{content:""}.jupyter-wrapper .bp3-icon-arrows-vertical::before{content:""}.jupyter-wrapper .bp3-icon-asterisk::before{content:"*"}.jupyter-wrapper .bp3-icon-automatic-updates::before{content:""}.jupyter-wrapper .bp3-icon-badge::before{content:""}.jupyter-wrapper .bp3-icon-ban-circle::before{content:""}.jupyter-wrapper .bp3-icon-bank-account::before{content:""}.jupyter-wrapper .bp3-icon-barcode::before{content:""}.jupyter-wrapper .bp3-icon-blank::before{content:""}.jupyter-wrapper .bp3-icon-blocked-person::before{content:""}.jupyter-wrapper .bp3-icon-bold::before{content:""}.jupyter-wrapper .bp3-icon-book::before{content:""}.jupyter-wrapper .bp3-icon-bookmark::before{content:""}.jupyter-wrapper .bp3-icon-box::before{content:""}.jupyter-wrapper .bp3-icon-briefcase::before{content:""}.jupyter-wrapper .bp3-icon-bring-data::before{content:""}.jupyter-wrapper .bp3-icon-build::before{content:""}.jupyter-wrapper .bp3-icon-calculator::before{content:""}.jupyter-wrapper .bp3-icon-calendar::before{content:""}.jupyter-wrapper .bp3-icon-camera::before{content:""}.jupyter-wrapper .bp3-icon-caret-down::before{content:""}.jupyter-wrapper .bp3-icon-caret-left::before{content:""}.jupyter-wrapper .bp3-icon-caret-right::before{content:""}.jupyter-wrapper .bp3-icon-caret-up::before{content:""}.jupyter-wrapper .bp3-icon-cell-tower::before{content:""}.jupyter-wrapper .bp3-icon-changes::before{content:""}.jupyter-wrapper .bp3-icon-chart::before{content:""}.jupyter-wrapper .bp3-icon-chat::before{content:""}.jupyter-wrapper .bp3-icon-chevron-backward::before{content:""}.jupyter-wrapper .bp3-icon-chevron-down::before{content:""}.jupyter-wrapper .bp3-icon-chevron-forward::before{content:""}.jupyter-wrapper .bp3-icon-chevron-left::before{content:""}.jupyter-wrapper .bp3-icon-chevron-right::before{content:""}.jupyter-wrapper .bp3-icon-chevron-up::before{content:""}.jupyter-wrapper .bp3-icon-circle::before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-down::before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-left::before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-right::before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-up::before{content:""}.jupyter-wrapper .bp3-icon-citation::before{content:""}.jupyter-wrapper .bp3-icon-clean::before{content:""}.jupyter-wrapper .bp3-icon-clipboard::before{content:""}.jupyter-wrapper .bp3-icon-cloud::before{content:""}.jupyter-wrapper .bp3-icon-cloud-download::before{content:""}.jupyter-wrapper .bp3-icon-cloud-upload::before{content:""}.jupyter-wrapper .bp3-icon-code::before{content:""}.jupyter-wrapper .bp3-icon-code-block::before{content:""}.jupyter-wrapper .bp3-icon-cog::before{content:""}.jupyter-wrapper .bp3-icon-collapse-all::before{content:""}.jupyter-wrapper .bp3-icon-column-layout::before{content:""}.jupyter-wrapper .bp3-icon-comment::before{content:""}.jupyter-wrapper .bp3-icon-comparison::before{content:""}.jupyter-wrapper .bp3-icon-compass::before{content:""}.jupyter-wrapper .bp3-icon-compressed::before{content:""}.jupyter-wrapper .bp3-icon-confirm::before{content:""}.jupyter-wrapper .bp3-icon-console::before{content:""}.jupyter-wrapper .bp3-icon-contrast::before{content:""}.jupyter-wrapper .bp3-icon-control::before{content:""}.jupyter-wrapper .bp3-icon-credit-card::before{content:""}.jupyter-wrapper .bp3-icon-cross::before{content:""}.jupyter-wrapper .bp3-icon-crown::before{content:""}.jupyter-wrapper .bp3-icon-cube::before{content:""}.jupyter-wrapper .bp3-icon-cube-add::before{content:""}.jupyter-wrapper .bp3-icon-cube-remove::before{content:""}.jupyter-wrapper .bp3-icon-curved-range-chart::before{content:""}.jupyter-wrapper .bp3-icon-cut::before{content:""}.jupyter-wrapper .bp3-icon-dashboard::before{content:""}.jupyter-wrapper .bp3-icon-data-lineage::before{content:""}.jupyter-wrapper .bp3-icon-database::before{content:""}.jupyter-wrapper .bp3-icon-delete::before{content:""}.jupyter-wrapper .bp3-icon-delta::before{content:""}.jupyter-wrapper .bp3-icon-derive-column::before{content:""}.jupyter-wrapper .bp3-icon-desktop::before{content:""}.jupyter-wrapper .bp3-icon-diagram-tree::before{content:""}.jupyter-wrapper .bp3-icon-direction-left::before{content:""}.jupyter-wrapper .bp3-icon-direction-right::before{content:""}.jupyter-wrapper .bp3-icon-disable::before{content:""}.jupyter-wrapper .bp3-icon-document::before{content:""}.jupyter-wrapper .bp3-icon-document-open::before{content:""}.jupyter-wrapper .bp3-icon-document-share::before{content:""}.jupyter-wrapper .bp3-icon-dollar::before{content:"$"}.jupyter-wrapper .bp3-icon-dot::before{content:""}.jupyter-wrapper .bp3-icon-double-caret-horizontal::before{content:""}.jupyter-wrapper .bp3-icon-double-caret-vertical::before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-down::before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-left::before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-right::before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-up::before{content:""}.jupyter-wrapper .bp3-icon-doughnut-chart::before{content:""}.jupyter-wrapper .bp3-icon-download::before{content:""}.jupyter-wrapper .bp3-icon-drag-handle-horizontal::before{content:""}.jupyter-wrapper .bp3-icon-drag-handle-vertical::before{content:""}.jupyter-wrapper .bp3-icon-draw::before{content:""}.jupyter-wrapper .bp3-icon-drive-time::before{content:""}.jupyter-wrapper .bp3-icon-duplicate::before{content:""}.jupyter-wrapper .bp3-icon-edit::before{content:""}.jupyter-wrapper .bp3-icon-eject::before{content:""}.jupyter-wrapper .bp3-icon-endorsed::before{content:""}.jupyter-wrapper .bp3-icon-envelope::before{content:""}.jupyter-wrapper .bp3-icon-equals::before{content:""}.jupyter-wrapper .bp3-icon-eraser::before{content:""}.jupyter-wrapper .bp3-icon-error::before{content:""}.jupyter-wrapper .bp3-icon-euro::before{content:""}.jupyter-wrapper .bp3-icon-exchange::before{content:""}.jupyter-wrapper .bp3-icon-exclude-row::before{content:""}.jupyter-wrapper .bp3-icon-expand-all::before{content:""}.jupyter-wrapper .bp3-icon-export::before{content:""}.jupyter-wrapper .bp3-icon-eye-off::before{content:""}.jupyter-wrapper .bp3-icon-eye-on::before{content:""}.jupyter-wrapper .bp3-icon-eye-open::before{content:""}.jupyter-wrapper .bp3-icon-fast-backward::before{content:""}.jupyter-wrapper .bp3-icon-fast-forward::before{content:""}.jupyter-wrapper .bp3-icon-feed::before{content:""}.jupyter-wrapper .bp3-icon-feed-subscribed::before{content:""}.jupyter-wrapper .bp3-icon-film::before{content:""}.jupyter-wrapper .bp3-icon-filter::before{content:""}.jupyter-wrapper .bp3-icon-filter-keep::before{content:""}.jupyter-wrapper .bp3-icon-filter-list::before{content:""}.jupyter-wrapper .bp3-icon-filter-open::before{content:""}.jupyter-wrapper .bp3-icon-filter-remove::before{content:""}.jupyter-wrapper .bp3-icon-flag::before{content:""}.jupyter-wrapper .bp3-icon-flame::before{content:""}.jupyter-wrapper .bp3-icon-flash::before{content:""}.jupyter-wrapper .bp3-icon-floppy-disk::before{content:""}.jupyter-wrapper .bp3-icon-flow-branch::before{content:""}.jupyter-wrapper .bp3-icon-flow-end::before{content:""}.jupyter-wrapper .bp3-icon-flow-linear::before{content:""}.jupyter-wrapper .bp3-icon-flow-review::before{content:""}.jupyter-wrapper .bp3-icon-flow-review-branch::before{content:""}.jupyter-wrapper .bp3-icon-flows::before{content:""}.jupyter-wrapper .bp3-icon-folder-close::before{content:""}.jupyter-wrapper .bp3-icon-folder-new::before{content:""}.jupyter-wrapper .bp3-icon-folder-open::before{content:""}.jupyter-wrapper .bp3-icon-folder-shared::before{content:""}.jupyter-wrapper .bp3-icon-folder-shared-open::before{content:""}.jupyter-wrapper .bp3-icon-follower::before{content:""}.jupyter-wrapper .bp3-icon-following::before{content:""}.jupyter-wrapper .bp3-icon-font::before{content:""}.jupyter-wrapper .bp3-icon-fork::before{content:""}.jupyter-wrapper .bp3-icon-form::before{content:""}.jupyter-wrapper .bp3-icon-full-circle::before{content:""}.jupyter-wrapper .bp3-icon-full-stacked-chart::before{content:""}.jupyter-wrapper .bp3-icon-fullscreen::before{content:""}.jupyter-wrapper .bp3-icon-function::before{content:""}.jupyter-wrapper .bp3-icon-gantt-chart::before{content:""}.jupyter-wrapper .bp3-icon-geolocation::before{content:""}.jupyter-wrapper .bp3-icon-geosearch::before{content:""}.jupyter-wrapper .bp3-icon-git-branch::before{content:""}.jupyter-wrapper .bp3-icon-git-commit::before{content:""}.jupyter-wrapper .bp3-icon-git-merge::before{content:""}.jupyter-wrapper .bp3-icon-git-new-branch::before{content:""}.jupyter-wrapper .bp3-icon-git-pull::before{content:""}.jupyter-wrapper .bp3-icon-git-push::before{content:""}.jupyter-wrapper .bp3-icon-git-repo::before{content:""}.jupyter-wrapper .bp3-icon-glass::before{content:""}.jupyter-wrapper .bp3-icon-globe::before{content:""}.jupyter-wrapper .bp3-icon-globe-network::before{content:""}.jupyter-wrapper .bp3-icon-graph::before{content:""}.jupyter-wrapper .bp3-icon-graph-remove::before{content:""}.jupyter-wrapper .bp3-icon-greater-than::before{content:""}.jupyter-wrapper .bp3-icon-greater-than-or-equal-to::before{content:""}.jupyter-wrapper .bp3-icon-grid::before{content:""}.jupyter-wrapper .bp3-icon-grid-view::before{content:""}.jupyter-wrapper .bp3-icon-group-objects::before{content:""}.jupyter-wrapper .bp3-icon-grouped-bar-chart::before{content:""}.jupyter-wrapper .bp3-icon-hand::before{content:""}.jupyter-wrapper .bp3-icon-hand-down::before{content:""}.jupyter-wrapper .bp3-icon-hand-left::before{content:""}.jupyter-wrapper .bp3-icon-hand-right::before{content:""}.jupyter-wrapper .bp3-icon-hand-up::before{content:""}.jupyter-wrapper .bp3-icon-header::before{content:""}.jupyter-wrapper .bp3-icon-header-one::before{content:""}.jupyter-wrapper .bp3-icon-header-two::before{content:""}.jupyter-wrapper .bp3-icon-headset::before{content:""}.jupyter-wrapper .bp3-icon-heart::before{content:""}.jupyter-wrapper .bp3-icon-heart-broken::before{content:""}.jupyter-wrapper .bp3-icon-heat-grid::before{content:""}.jupyter-wrapper .bp3-icon-heatmap::before{content:""}.jupyter-wrapper .bp3-icon-help::before{content:"?"}.jupyter-wrapper .bp3-icon-helper-management::before{content:""}.jupyter-wrapper .bp3-icon-highlight::before{content:""}.jupyter-wrapper .bp3-icon-history::before{content:""}.jupyter-wrapper .bp3-icon-home::before{content:""}.jupyter-wrapper .bp3-icon-horizontal-bar-chart::before{content:""}.jupyter-wrapper .bp3-icon-horizontal-bar-chart-asc::before{content:""}.jupyter-wrapper .bp3-icon-horizontal-bar-chart-desc::before{content:""}.jupyter-wrapper .bp3-icon-horizontal-distribution::before{content:""}.jupyter-wrapper .bp3-icon-id-number::before{content:""}.jupyter-wrapper .bp3-icon-image-rotate-left::before{content:""}.jupyter-wrapper .bp3-icon-image-rotate-right::before{content:""}.jupyter-wrapper .bp3-icon-import::before{content:""}.jupyter-wrapper .bp3-icon-inbox::before{content:""}.jupyter-wrapper .bp3-icon-inbox-filtered::before{content:""}.jupyter-wrapper .bp3-icon-inbox-geo::before{content:""}.jupyter-wrapper .bp3-icon-inbox-search::before{content:""}.jupyter-wrapper .bp3-icon-inbox-update::before{content:""}.jupyter-wrapper .bp3-icon-info-sign::before{content:""}.jupyter-wrapper .bp3-icon-inheritance::before{content:""}.jupyter-wrapper .bp3-icon-inner-join::before{content:""}.jupyter-wrapper .bp3-icon-insert::before{content:""}.jupyter-wrapper .bp3-icon-intersection::before{content:""}.jupyter-wrapper .bp3-icon-ip-address::before{content:""}.jupyter-wrapper .bp3-icon-issue::before{content:""}.jupyter-wrapper .bp3-icon-issue-closed::before{content:""}.jupyter-wrapper .bp3-icon-issue-new::before{content:""}.jupyter-wrapper .bp3-icon-italic::before{content:""}.jupyter-wrapper .bp3-icon-join-table::before{content:""}.jupyter-wrapper .bp3-icon-key::before{content:""}.jupyter-wrapper .bp3-icon-key-backspace::before{content:""}.jupyter-wrapper .bp3-icon-key-command::before{content:""}.jupyter-wrapper .bp3-icon-key-control::before{content:""}.jupyter-wrapper .bp3-icon-key-delete::before{content:""}.jupyter-wrapper .bp3-icon-key-enter::before{content:""}.jupyter-wrapper .bp3-icon-key-escape::before{content:""}.jupyter-wrapper .bp3-icon-key-option::before{content:""}.jupyter-wrapper .bp3-icon-key-shift::before{content:""}.jupyter-wrapper .bp3-icon-key-tab::before{content:""}.jupyter-wrapper .bp3-icon-known-vehicle::before{content:""}.jupyter-wrapper .bp3-icon-label::before{content:""}.jupyter-wrapper .bp3-icon-layer::before{content:""}.jupyter-wrapper .bp3-icon-layers::before{content:""}.jupyter-wrapper .bp3-icon-layout::before{content:""}.jupyter-wrapper .bp3-icon-layout-auto::before{content:""}.jupyter-wrapper .bp3-icon-layout-balloon::before{content:""}.jupyter-wrapper .bp3-icon-layout-circle::before{content:""}.jupyter-wrapper .bp3-icon-layout-grid::before{content:""}.jupyter-wrapper .bp3-icon-layout-group-by::before{content:""}.jupyter-wrapper .bp3-icon-layout-hierarchy::before{content:""}.jupyter-wrapper .bp3-icon-layout-linear::before{content:""}.jupyter-wrapper .bp3-icon-layout-skew-grid::before{content:""}.jupyter-wrapper .bp3-icon-layout-sorted-clusters::before{content:""}.jupyter-wrapper .bp3-icon-learning::before{content:""}.jupyter-wrapper .bp3-icon-left-join::before{content:""}.jupyter-wrapper .bp3-icon-less-than::before{content:""}.jupyter-wrapper .bp3-icon-less-than-or-equal-to::before{content:""}.jupyter-wrapper .bp3-icon-lifesaver::before{content:""}.jupyter-wrapper .bp3-icon-lightbulb::before{content:""}.jupyter-wrapper .bp3-icon-link::before{content:""}.jupyter-wrapper .bp3-icon-list::before{content:""}.jupyter-wrapper .bp3-icon-list-columns::before{content:""}.jupyter-wrapper .bp3-icon-list-detail-view::before{content:""}.jupyter-wrapper .bp3-icon-locate::before{content:""}.jupyter-wrapper .bp3-icon-lock::before{content:""}.jupyter-wrapper .bp3-icon-log-in::before{content:""}.jupyter-wrapper .bp3-icon-log-out::before{content:""}.jupyter-wrapper .bp3-icon-manual::before{content:""}.jupyter-wrapper .bp3-icon-manually-entered-data::before{content:""}.jupyter-wrapper .bp3-icon-map::before{content:""}.jupyter-wrapper .bp3-icon-map-create::before{content:""}.jupyter-wrapper .bp3-icon-map-marker::before{content:""}.jupyter-wrapper .bp3-icon-maximize::before{content:""}.jupyter-wrapper .bp3-icon-media::before{content:""}.jupyter-wrapper .bp3-icon-menu::before{content:""}.jupyter-wrapper .bp3-icon-menu-closed::before{content:""}.jupyter-wrapper .bp3-icon-menu-open::before{content:""}.jupyter-wrapper .bp3-icon-merge-columns::before{content:""}.jupyter-wrapper .bp3-icon-merge-links::before{content:""}.jupyter-wrapper .bp3-icon-minimize::before{content:""}.jupyter-wrapper .bp3-icon-minus::before{content:""}.jupyter-wrapper .bp3-icon-mobile-phone::before{content:""}.jupyter-wrapper .bp3-icon-mobile-video::before{content:""}.jupyter-wrapper .bp3-icon-moon::before{content:""}.jupyter-wrapper .bp3-icon-more::before{content:""}.jupyter-wrapper .bp3-icon-mountain::before{content:""}.jupyter-wrapper .bp3-icon-move::before{content:""}.jupyter-wrapper .bp3-icon-mugshot::before{content:""}.jupyter-wrapper .bp3-icon-multi-select::before{content:""}.jupyter-wrapper .bp3-icon-music::before{content:""}.jupyter-wrapper .bp3-icon-new-drawing::before{content:""}.jupyter-wrapper .bp3-icon-new-grid-item::before{content:""}.jupyter-wrapper .bp3-icon-new-layer::before{content:""}.jupyter-wrapper .bp3-icon-new-layers::before{content:""}.jupyter-wrapper .bp3-icon-new-link::before{content:""}.jupyter-wrapper .bp3-icon-new-object::before{content:""}.jupyter-wrapper .bp3-icon-new-person::before{content:""}.jupyter-wrapper .bp3-icon-new-prescription::before{content:""}.jupyter-wrapper .bp3-icon-new-text-box::before{content:""}.jupyter-wrapper .bp3-icon-ninja::before{content:""}.jupyter-wrapper .bp3-icon-not-equal-to::before{content:""}.jupyter-wrapper .bp3-icon-notifications::before{content:""}.jupyter-wrapper .bp3-icon-notifications-updated::before{content:""}.jupyter-wrapper .bp3-icon-numbered-list::before{content:""}.jupyter-wrapper .bp3-icon-numerical::before{content:""}.jupyter-wrapper .bp3-icon-office::before{content:""}.jupyter-wrapper .bp3-icon-offline::before{content:""}.jupyter-wrapper .bp3-icon-oil-field::before{content:""}.jupyter-wrapper .bp3-icon-one-column::before{content:""}.jupyter-wrapper .bp3-icon-outdated::before{content:""}.jupyter-wrapper .bp3-icon-page-layout::before{content:""}.jupyter-wrapper .bp3-icon-panel-stats::before{content:""}.jupyter-wrapper .bp3-icon-panel-table::before{content:""}.jupyter-wrapper .bp3-icon-paperclip::before{content:""}.jupyter-wrapper .bp3-icon-paragraph::before{content:""}.jupyter-wrapper .bp3-icon-path::before{content:""}.jupyter-wrapper .bp3-icon-path-search::before{content:""}.jupyter-wrapper .bp3-icon-pause::before{content:""}.jupyter-wrapper .bp3-icon-people::before{content:""}.jupyter-wrapper .bp3-icon-percentage::before{content:""}.jupyter-wrapper .bp3-icon-person::before{content:""}.jupyter-wrapper .bp3-icon-phone::before{content:""}.jupyter-wrapper .bp3-icon-pie-chart::before{content:""}.jupyter-wrapper .bp3-icon-pin::before{content:""}.jupyter-wrapper .bp3-icon-pivot::before{content:""}.jupyter-wrapper .bp3-icon-pivot-table::before{content:""}.jupyter-wrapper .bp3-icon-play::before{content:""}.jupyter-wrapper .bp3-icon-plus::before{content:"+"}.jupyter-wrapper .bp3-icon-polygon-filter::before{content:""}.jupyter-wrapper .bp3-icon-power::before{content:""}.jupyter-wrapper .bp3-icon-predictive-analysis::before{content:""}.jupyter-wrapper .bp3-icon-prescription::before{content:""}.jupyter-wrapper .bp3-icon-presentation::before{content:""}.jupyter-wrapper .bp3-icon-print::before{content:""}.jupyter-wrapper .bp3-icon-projects::before{content:""}.jupyter-wrapper .bp3-icon-properties::before{content:""}.jupyter-wrapper .bp3-icon-property::before{content:""}.jupyter-wrapper .bp3-icon-publish-function::before{content:""}.jupyter-wrapper .bp3-icon-pulse::before{content:""}.jupyter-wrapper .bp3-icon-random::before{content:""}.jupyter-wrapper .bp3-icon-record::before{content:""}.jupyter-wrapper .bp3-icon-redo::before{content:""}.jupyter-wrapper .bp3-icon-refresh::before{content:""}.jupyter-wrapper .bp3-icon-regression-chart::before{content:""}.jupyter-wrapper .bp3-icon-remove::before{content:""}.jupyter-wrapper .bp3-icon-remove-column::before{content:""}.jupyter-wrapper .bp3-icon-remove-column-left::before{content:""}.jupyter-wrapper .bp3-icon-remove-column-right::before{content:""}.jupyter-wrapper .bp3-icon-remove-row-bottom::before{content:""}.jupyter-wrapper .bp3-icon-remove-row-top::before{content:""}.jupyter-wrapper .bp3-icon-repeat::before{content:""}.jupyter-wrapper .bp3-icon-reset::before{content:""}.jupyter-wrapper .bp3-icon-resolve::before{content:""}.jupyter-wrapper .bp3-icon-rig::before{content:""}.jupyter-wrapper .bp3-icon-right-join::before{content:""}.jupyter-wrapper .bp3-icon-ring::before{content:""}.jupyter-wrapper .bp3-icon-rotate-document::before{content:""}.jupyter-wrapper .bp3-icon-rotate-page::before{content:""}.jupyter-wrapper .bp3-icon-satellite::before{content:""}.jupyter-wrapper .bp3-icon-saved::before{content:""}.jupyter-wrapper .bp3-icon-scatter-plot::before{content:""}.jupyter-wrapper .bp3-icon-search::before{content:""}.jupyter-wrapper .bp3-icon-search-around::before{content:""}.jupyter-wrapper .bp3-icon-search-template::before{content:""}.jupyter-wrapper .bp3-icon-search-text::before{content:""}.jupyter-wrapper .bp3-icon-segmented-control::before{content:""}.jupyter-wrapper .bp3-icon-select::before{content:""}.jupyter-wrapper .bp3-icon-selection::before{content:""}.jupyter-wrapper .bp3-icon-send-to::before{content:""}.jupyter-wrapper .bp3-icon-send-to-graph::before{content:""}.jupyter-wrapper .bp3-icon-send-to-map::before{content:""}.jupyter-wrapper .bp3-icon-series-add::before{content:""}.jupyter-wrapper .bp3-icon-series-configuration::before{content:""}.jupyter-wrapper .bp3-icon-series-derived::before{content:""}.jupyter-wrapper .bp3-icon-series-filtered::before{content:""}.jupyter-wrapper .bp3-icon-series-search::before{content:""}.jupyter-wrapper .bp3-icon-settings::before{content:""}.jupyter-wrapper .bp3-icon-share::before{content:""}.jupyter-wrapper .bp3-icon-shield::before{content:""}.jupyter-wrapper .bp3-icon-shop::before{content:""}.jupyter-wrapper .bp3-icon-shopping-cart::before{content:""}.jupyter-wrapper .bp3-icon-signal-search::before{content:""}.jupyter-wrapper .bp3-icon-sim-card::before{content:""}.jupyter-wrapper .bp3-icon-slash::before{content:""}.jupyter-wrapper .bp3-icon-small-cross::before{content:""}.jupyter-wrapper .bp3-icon-small-minus::before{content:""}.jupyter-wrapper .bp3-icon-small-plus::before{content:""}.jupyter-wrapper .bp3-icon-small-tick::before{content:""}.jupyter-wrapper .bp3-icon-snowflake::before{content:""}.jupyter-wrapper .bp3-icon-social-media::before{content:""}.jupyter-wrapper .bp3-icon-sort::before{content:""}.jupyter-wrapper .bp3-icon-sort-alphabetical::before{content:""}.jupyter-wrapper .bp3-icon-sort-alphabetical-desc::before{content:""}.jupyter-wrapper .bp3-icon-sort-asc::before{content:""}.jupyter-wrapper .bp3-icon-sort-desc::before{content:""}.jupyter-wrapper .bp3-icon-sort-numerical::before{content:""}.jupyter-wrapper .bp3-icon-sort-numerical-desc::before{content:""}.jupyter-wrapper .bp3-icon-split-columns::before{content:""}.jupyter-wrapper .bp3-icon-square::before{content:""}.jupyter-wrapper .bp3-icon-stacked-chart::before{content:""}.jupyter-wrapper .bp3-icon-star::before{content:""}.jupyter-wrapper .bp3-icon-star-empty::before{content:""}.jupyter-wrapper .bp3-icon-step-backward::before{content:""}.jupyter-wrapper .bp3-icon-step-chart::before{content:""}.jupyter-wrapper .bp3-icon-step-forward::before{content:""}.jupyter-wrapper .bp3-icon-stop::before{content:""}.jupyter-wrapper .bp3-icon-stopwatch::before{content:""}.jupyter-wrapper .bp3-icon-strikethrough::before{content:""}.jupyter-wrapper .bp3-icon-style::before{content:""}.jupyter-wrapper .bp3-icon-swap-horizontal::before{content:""}.jupyter-wrapper .bp3-icon-swap-vertical::before{content:""}.jupyter-wrapper .bp3-icon-symbol-circle::before{content:""}.jupyter-wrapper .bp3-icon-symbol-cross::before{content:""}.jupyter-wrapper .bp3-icon-symbol-diamond::before{content:""}.jupyter-wrapper .bp3-icon-symbol-square::before{content:""}.jupyter-wrapper .bp3-icon-symbol-triangle-down::before{content:""}.jupyter-wrapper .bp3-icon-symbol-triangle-up::before{content:""}.jupyter-wrapper .bp3-icon-tag::before{content:""}.jupyter-wrapper .bp3-icon-take-action::before{content:""}.jupyter-wrapper .bp3-icon-taxi::before{content:""}.jupyter-wrapper .bp3-icon-text-highlight::before{content:""}.jupyter-wrapper .bp3-icon-th::before{content:""}.jupyter-wrapper .bp3-icon-th-derived::before{content:""}.jupyter-wrapper .bp3-icon-th-disconnect::before{content:""}.jupyter-wrapper .bp3-icon-th-filtered::before{content:""}.jupyter-wrapper .bp3-icon-th-list::before{content:""}.jupyter-wrapper .bp3-icon-thumbs-down::before{content:""}.jupyter-wrapper .bp3-icon-thumbs-up::before{content:""}.jupyter-wrapper .bp3-icon-tick::before{content:""}.jupyter-wrapper .bp3-icon-tick-circle::before{content:""}.jupyter-wrapper .bp3-icon-time::before{content:""}.jupyter-wrapper .bp3-icon-timeline-area-chart::before{content:""}.jupyter-wrapper .bp3-icon-timeline-bar-chart::before{content:""}.jupyter-wrapper .bp3-icon-timeline-events::before{content:""}.jupyter-wrapper .bp3-icon-timeline-line-chart::before{content:""}.jupyter-wrapper .bp3-icon-tint::before{content:""}.jupyter-wrapper .bp3-icon-torch::before{content:""}.jupyter-wrapper .bp3-icon-tractor::before{content:""}.jupyter-wrapper .bp3-icon-train::before{content:""}.jupyter-wrapper .bp3-icon-translate::before{content:""}.jupyter-wrapper .bp3-icon-trash::before{content:""}.jupyter-wrapper .bp3-icon-tree::before{content:""}.jupyter-wrapper .bp3-icon-trending-down::before{content:""}.jupyter-wrapper .bp3-icon-trending-up::before{content:""}.jupyter-wrapper .bp3-icon-truck::before{content:""}.jupyter-wrapper .bp3-icon-two-columns::before{content:""}.jupyter-wrapper .bp3-icon-unarchive::before{content:""}.jupyter-wrapper .bp3-icon-underline::before{content:""}.jupyter-wrapper .bp3-icon-undo::before{content:""}.jupyter-wrapper .bp3-icon-ungroup-objects::before{content:""}.jupyter-wrapper .bp3-icon-unknown-vehicle::before{content:""}.jupyter-wrapper .bp3-icon-unlock::before{content:""}.jupyter-wrapper .bp3-icon-unpin::before{content:""}.jupyter-wrapper .bp3-icon-unresolve::before{content:""}.jupyter-wrapper .bp3-icon-updated::before{content:""}.jupyter-wrapper .bp3-icon-upload::before{content:""}.jupyter-wrapper .bp3-icon-user::before{content:""}.jupyter-wrapper .bp3-icon-variable::before{content:""}.jupyter-wrapper .bp3-icon-vertical-bar-chart-asc::before{content:""}.jupyter-wrapper .bp3-icon-vertical-bar-chart-desc::before{content:""}.jupyter-wrapper .bp3-icon-vertical-distribution::before{content:""}.jupyter-wrapper .bp3-icon-video::before{content:""}.jupyter-wrapper .bp3-icon-volume-down::before{content:""}.jupyter-wrapper .bp3-icon-volume-off::before{content:""}.jupyter-wrapper .bp3-icon-volume-up::before{content:""}.jupyter-wrapper .bp3-icon-walk::before{content:""}.jupyter-wrapper .bp3-icon-warning-sign::before{content:""}.jupyter-wrapper .bp3-icon-waterfall-chart::before{content:""}.jupyter-wrapper .bp3-icon-widget::before{content:""}.jupyter-wrapper .bp3-icon-widget-button::before{content:""}.jupyter-wrapper .bp3-icon-widget-footer::before{content:""}.jupyter-wrapper .bp3-icon-widget-header::before{content:""}.jupyter-wrapper .bp3-icon-wrench::before{content:""}.jupyter-wrapper .bp3-icon-zoom-in::before{content:""}.jupyter-wrapper .bp3-icon-zoom-out::before{content:""}.jupyter-wrapper .bp3-icon-zoom-to-fit::before{content:""}.jupyter-wrapper .bp3-submenu>.bp3-popover-wrapper{display:block}.jupyter-wrapper .bp3-submenu .bp3-popover-target{display:block}.jupyter-wrapper .bp3-submenu.bp3-popover{-webkit-box-shadow:none;box-shadow:none;padding:0 5px}.jupyter-wrapper .bp3-submenu.bp3-popover>.bp3-popover-content{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-dark .bp3-submenu.bp3-popover,.jupyter-wrapper .bp3-submenu.bp3-popover.bp3-dark{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-submenu.bp3-popover>.bp3-popover-content,.jupyter-wrapper .bp3-submenu.bp3-popover.bp3-dark>.bp3-popover-content{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-menu{margin:0;border-radius:3px;background:#fff;min-width:180px;padding:5px;list-style:none;text-align:left;color:#182026}.jupyter-wrapper .bp3-menu-divider{display:block;margin:5px;border-top:1px solid rgba(16,22,26,.15)}.jupyter-wrapper .bp3-dark .bp3-menu-divider{border-top-color:rgba(255,255,255,.15)}.jupyter-wrapper .bp3-menu-item{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;border-radius:2px;padding:5px 7px;text-decoration:none;line-height:20px;color:inherit;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-menu-item>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-menu-item>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-menu-item::before,.jupyter-wrapper .bp3-menu-item>*{margin-right:7px}.jupyter-wrapper .bp3-menu-item:empty::before,.jupyter-wrapper .bp3-menu-item>:last-child{margin-right:0}.jupyter-wrapper .bp3-menu-item>.bp3-fill{word-break:break-word}.jupyter-wrapper .bp3-menu-item:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item{background-color:rgba(167,182,194,.3);cursor:pointer;text-decoration:none}.jupyter-wrapper .bp3-menu-item.bp3-disabled{background-color:inherit;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-dark .bp3-menu-item{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-menu-item{background-color:rgba(138,155,168,.15);color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled{background-color:inherit;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active{background-color:#137cbd}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active{background-color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover::before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover::after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-success::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active{background-color:#0f9960}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active{background-color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover::before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover::after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active{background-color:#d9822b}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active{background-color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover::before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover::after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active{background-color:#db3737}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active{background-color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover::before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover::after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active::before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active::after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item::before{line-height:1;font-family:"Icons16",sans-serif;font-size:16px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;margin-right:7px}.jupyter-wrapper .bp3-menu-item::before,.jupyter-wrapper .bp3-menu-item>.bp3-icon{margin-top:2px;color:#5c7080}.jupyter-wrapper .bp3-menu-item .bp3-menu-item-label{color:#5c7080}.jupyter-wrapper .bp3-menu-item:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-active,.jupyter-wrapper .bp3-menu-item:active{background-color:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-menu-item.bp3-disabled{outline:none !important;background-color:inherit !important;cursor:not-allowed !important;color:rgba(92,112,128,.6) !important}.jupyter-wrapper .bp3-menu-item.bp3-disabled::before,.jupyter-wrapper .bp3-menu-item.bp3-disabled>.bp3-icon,.jupyter-wrapper .bp3-menu-item.bp3-disabled .bp3-menu-item-label{color:rgba(92,112,128,.6) !important}.jupyter-wrapper .bp3-large .bp3-menu-item{padding:9px 7px;line-height:22px;font-size:16px}.jupyter-wrapper .bp3-large .bp3-menu-item .bp3-icon{margin-top:3px}.jupyter-wrapper .bp3-large .bp3-menu-item::before{line-height:1;font-family:"Icons20",sans-serif;font-size:20px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;margin-top:1px;margin-right:10px}.jupyter-wrapper button.bp3-menu-item{border:none;background:none;width:100%;text-align:left}.jupyter-wrapper .bp3-menu-header{display:block;margin:5px;border-top:1px solid rgba(16,22,26,.15);cursor:default;padding-left:2px}.jupyter-wrapper .bp3-dark .bp3-menu-header{border-top-color:rgba(255,255,255,.15)}.jupyter-wrapper .bp3-menu-header:first-of-type{border-top:none}.jupyter-wrapper .bp3-menu-header>h6{color:#182026;font-weight:600;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;margin:0;padding:10px 7px 0 1px;line-height:17px}.jupyter-wrapper .bp3-dark .bp3-menu-header>h6{color:#f5f8fa}.jupyter-wrapper .bp3-menu-header:first-of-type>h6{padding-top:0}.jupyter-wrapper .bp3-large .bp3-menu-header>h6{padding-top:15px;padding-bottom:5px;font-size:18px}.jupyter-wrapper .bp3-large .bp3-menu-header:first-of-type>h6{padding-top:0}.jupyter-wrapper .bp3-dark .bp3-menu{background:#30404d;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{background-color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active{background-color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item::before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item::after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{background-color:#0f9960}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active{background-color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item::before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item::after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{background-color:#d9822b}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active{background-color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item::before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item::after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{background-color:#db3737}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active{background-color:#c23030}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item::before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item::after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item::before,.jupyter-wrapper .bp3-dark .bp3-menu-item>.bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-menu-item .bp3-menu-item-label{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item:active{background-color:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled{color:rgba(167,182,194,.6) !important}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled::before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{color:rgba(167,182,194,.6) !important}.jupyter-wrapper .bp3-dark .bp3-menu-divider,.jupyter-wrapper .bp3-dark .bp3-menu-header{border-color:rgba(255,255,255,.15)}.jupyter-wrapper .bp3-dark .bp3-menu-header>h6{color:#f5f8fa}.jupyter-wrapper .bp3-label .bp3-menu{margin-top:5px}.jupyter-wrapper .bp3-navbar{position:relative;z-index:10;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);background-color:#fff;width:100%;height:50px;padding:0 15px}.jupyter-wrapper .bp3-navbar.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-navbar{background-color:#394b59}.jupyter-wrapper .bp3-navbar.bp3-dark{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-navbar{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-navbar.bp3-fixed-top{position:fixed;top:0;right:0;left:0}.jupyter-wrapper .bp3-navbar-heading{margin-right:15px;font-size:16px}.jupyter-wrapper .bp3-navbar-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:50px}.jupyter-wrapper .bp3-navbar-group.bp3-align-left{float:left}.jupyter-wrapper .bp3-navbar-group.bp3-align-right{float:right}.jupyter-wrapper .bp3-navbar-divider{margin:0 10px;border-left:1px solid rgba(16,22,26,.15);height:20px}.jupyter-wrapper .bp3-dark .bp3-navbar-divider{border-left-color:rgba(255,255,255,.15)}.jupyter-wrapper .bp3-non-ideal-state{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:100%;height:100%;text-align:center}.jupyter-wrapper .bp3-non-ideal-state>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-non-ideal-state>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-non-ideal-state::before,.jupyter-wrapper .bp3-non-ideal-state>*{margin-bottom:20px}.jupyter-wrapper .bp3-non-ideal-state:empty::before,.jupyter-wrapper .bp3-non-ideal-state>:last-child{margin-bottom:0}.jupyter-wrapper .bp3-non-ideal-state>*{max-width:400px}.jupyter-wrapper .bp3-non-ideal-state-visual{color:rgba(92,112,128,.6);font-size:60px}.jupyter-wrapper .bp3-dark .bp3-non-ideal-state-visual{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-overflow-list{display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:nowrap;flex-wrap:nowrap;min-width:0}.jupyter-wrapper .bp3-overflow-list-spacer{-ms-flex-negative:1;flex-shrink:1;width:1px}.jupyter-wrapper body.bp3-overlay-open{overflow:hidden}.jupyter-wrapper .bp3-overlay{position:static;top:0;right:0;bottom:0;left:0;z-index:20}.jupyter-wrapper .bp3-overlay:not(.bp3-overlay-open){pointer-events:none}.jupyter-wrapper .bp3-overlay.bp3-overlay-container{position:fixed;overflow:hidden}.jupyter-wrapper .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{position:absolute}.jupyter-wrapper .bp3-overlay.bp3-overlay-scroll-container{position:fixed;overflow:auto}.jupyter-wrapper .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{position:absolute}.jupyter-wrapper .bp3-overlay.bp3-overlay-inline{display:inline;overflow:visible}.jupyter-wrapper .bp3-overlay-content{position:fixed;z-index:20}.jupyter-wrapper .bp3-overlay-inline .bp3-overlay-content,.jupyter-wrapper .bp3-overlay-scroll-container .bp3-overlay-content{position:absolute}.jupyter-wrapper .bp3-overlay-backdrop{position:fixed;top:0;right:0;bottom:0;left:0;opacity:1;z-index:20;background-color:rgba(16,22,26,.7);overflow:auto;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-enter,.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-appear{opacity:0}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-enter-active,.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-appear-active{opacity:1;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-exit{opacity:1}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-exit-active{opacity:0;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-overlay-backdrop:focus{outline:none}.jupyter-wrapper .bp3-overlay-inline .bp3-overlay-backdrop{position:absolute}.jupyter-wrapper .bp3-panel-stack{position:relative;overflow:hidden}.jupyter-wrapper .bp3-panel-stack-header{display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-negative:0;flex-shrink:0;-webkit-box-align:center;-ms-flex-align:center;align-items:center;z-index:1;-webkit-box-shadow:0 1px rgba(16,22,26,.15);box-shadow:0 1px rgba(16,22,26,.15);height:30px}.jupyter-wrapper .bp3-dark .bp3-panel-stack-header{-webkit-box-shadow:0 1px rgba(255,255,255,.15);box-shadow:0 1px rgba(255,255,255,.15)}.jupyter-wrapper .bp3-panel-stack-header>span{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1;flex:1;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch}.jupyter-wrapper .bp3-panel-stack-header .bp3-heading{margin:0 5px}.jupyter-wrapper .bp3-button.bp3-panel-stack-header-back{margin-left:5px;padding-left:0;white-space:nowrap}.jupyter-wrapper .bp3-button.bp3-panel-stack-header-back .bp3-icon{margin:0 2px}.jupyter-wrapper .bp3-panel-stack-view{position:absolute;top:0;right:0;bottom:0;left:0;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin-right:-1px;border-right:1px solid rgba(16,22,26,.15);background-color:#fff;overflow-y:auto}.jupyter-wrapper .bp3-dark .bp3-panel-stack-view{background-color:#30404d}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-enter,.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-appear{-webkit-transform:translateX(100%);transform:translateX(100%);opacity:0}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-enter-active,.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-appear-active{-webkit-transform:translate(0%);transform:translate(0%);opacity:1;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-duration:400ms;transition-duration:400ms;-webkit-transition-timing-function:ease;transition-timing-function:ease;-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-exit{-webkit-transform:translate(0%);transform:translate(0%);opacity:1}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-exit-active{-webkit-transform:translateX(-50%);transform:translateX(-50%);opacity:0;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-duration:400ms;transition-duration:400ms;-webkit-transition-timing-function:ease;transition-timing-function:ease;-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-enter,.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-appear{-webkit-transform:translateX(-50%);transform:translateX(-50%);opacity:0}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-enter-active,.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-appear-active{-webkit-transform:translate(0%);transform:translate(0%);opacity:1;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-duration:400ms;transition-duration:400ms;-webkit-transition-timing-function:ease;transition-timing-function:ease;-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-exit{-webkit-transform:translate(0%);transform:translate(0%);opacity:1}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-exit-active{-webkit-transform:translateX(100%);transform:translateX(100%);opacity:0;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-duration:400ms;transition-duration:400ms;-webkit-transition-timing-function:ease;transition-timing-function:ease;-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-popover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);-webkit-transform:scale(1);transform:scale(1);display:inline-block;z-index:20;border-radius:3px}.jupyter-wrapper .bp3-popover .bp3-popover-arrow{position:absolute;width:30px;height:30px}.jupyter-wrapper .bp3-popover .bp3-popover-arrow::before{margin:5px;width:20px;height:20px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover{margin-top:-17px;margin-bottom:17px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow{bottom:-11px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(-90deg);transform:rotate(-90deg)}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover{margin-left:17px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow{left:-11px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(0);transform:rotate(0)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover{margin-top:17px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow{top:-11px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover{margin-right:17px;margin-left:-17px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow{right:-11px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.jupyter-wrapper .bp3-tether-element-attached-middle>.bp3-popover>.bp3-popover-arrow{top:50%;-webkit-transform:translateY(-50%);transform:translateY(-50%)}.jupyter-wrapper .bp3-tether-element-attached-center>.bp3-popover>.bp3-popover-arrow{right:50%;-webkit-transform:translateX(50%);transform:translateX(50%)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow{top:-0.3934px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow{right:-0.3934px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow{left:-0.3934px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow{bottom:-0.3934px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:top left;transform-origin:top left}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:top center;transform-origin:top center}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:top right;transform-origin:top right}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:center left;transform-origin:center left}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:center center;transform-origin:center center}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:center right;transform-origin:center right}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:bottom left;transform-origin:bottom left}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:bottom center;transform-origin:bottom center}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:bottom right;transform-origin:bottom right}.jupyter-wrapper .bp3-popover .bp3-popover-content{background:#fff;color:inherit}.jupyter-wrapper .bp3-popover .bp3-popover-arrow::before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.2);box-shadow:1px 1px 6px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-popover .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.1}.jupyter-wrapper .bp3-popover .bp3-popover-arrow-fill{fill:#fff}.jupyter-wrapper .bp3-popover-enter>.bp3-popover,.jupyter-wrapper .bp3-popover-appear>.bp3-popover{-webkit-transform:scale(0.3);transform:scale(0.3)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-popover,.jupyter-wrapper .bp3-popover-appear-active>.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:300ms;transition-duration:300ms;-webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-popover-exit>.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-popover{-webkit-transform:scale(0.3);transform:scale(0.3);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:300ms;transition-duration:300ms;-webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-popover .bp3-popover-content{position:relative;border-radius:3px}.jupyter-wrapper .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{max-width:350px;padding:20px}.jupyter-wrapper .bp3-popover-target+.bp3-overlay .bp3-popover.bp3-popover-content-sizing{width:350px}.jupyter-wrapper .bp3-popover.bp3-minimal{margin:0 !important}.jupyter-wrapper .bp3-popover.bp3-minimal .bp3-popover-arrow{display:none}.jupyter-wrapper .bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-enter>.bp3-popover.bp3-minimal.bp3-popover,.jupyter-wrapper .bp3-popover-appear>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-popover.bp3-minimal.bp3-popover,.jupyter-wrapper .bp3-popover-appear-active>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-popover-exit>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-popover.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-popover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-content,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-content{background:#30404d;color:inherit}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow::before,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow::before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.4);box-shadow:1px 1px 6px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow-border,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.2}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow-fill,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow-fill{fill:#30404d}.jupyter-wrapper .bp3-popover-arrow::before{display:block;position:absolute;-webkit-transform:rotate(45deg);transform:rotate(45deg);border-radius:2px;content:""}.jupyter-wrapper .bp3-tether-pinned .bp3-popover-arrow{display:none}.jupyter-wrapper .bp3-popover-backdrop{background:rgba(255,255,255,0)}.jupyter-wrapper .bp3-transition-container{opacity:1;display:-webkit-box;display:-ms-flexbox;display:flex;z-index:20}.jupyter-wrapper .bp3-transition-container.bp3-popover-enter,.jupyter-wrapper .bp3-transition-container.bp3-popover-appear{opacity:0}.jupyter-wrapper .bp3-transition-container.bp3-popover-enter-active,.jupyter-wrapper .bp3-transition-container.bp3-popover-appear-active{opacity:1;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-transition-container.bp3-popover-exit{opacity:1}.jupyter-wrapper .bp3-transition-container.bp3-popover-exit-active{opacity:0;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-transition-container:focus{outline:none}.jupyter-wrapper .bp3-transition-container.bp3-popover-leave .bp3-popover-content{pointer-events:none}.jupyter-wrapper .bp3-transition-container[data-x-out-of-boundaries]{display:none}.jupyter-wrapper span.bp3-popover-target{display:inline-block}.jupyter-wrapper .bp3-popover-wrapper.bp3-fill{width:100%}.jupyter-wrapper .bp3-portal{position:absolute;top:0;right:0;left:0}@-webkit-keyframes linear-progress-bar-stripes{from{background-position:0 0}to{background-position:30px 0}}@keyframes linear-progress-bar-stripes{from{background-position:0 0}to{background-position:30px 0}}.jupyter-wrapper .bp3-progress-bar{display:block;position:relative;border-radius:40px;background:rgba(92,112,128,.2);width:100%;height:8px;overflow:hidden}.jupyter-wrapper .bp3-progress-bar .bp3-progress-meter{position:absolute;border-radius:40px;background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);background-color:rgba(92,112,128,.8);background-size:30px 30px;width:100%;height:100%;-webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{animation:linear-progress-bar-stripes 300ms linear infinite reverse}.jupyter-wrapper .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{background-image:none}.jupyter-wrapper .bp3-dark .bp3-progress-bar{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-dark .bp3-progress-bar .bp3-progress-meter{background-color:#8a9ba8}.jupyter-wrapper .bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{background-color:#137cbd}.jupyter-wrapper .bp3-progress-bar.bp3-intent-success .bp3-progress-meter{background-color:#0f9960}.jupyter-wrapper .bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{background-color:#d9822b}.jupyter-wrapper .bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{background-color:#db3737}@-webkit-keyframes skeleton-glow{from{border-color:rgba(206,217,224,.2);background:rgba(206,217,224,.2)}to{border-color:rgba(92,112,128,.2);background:rgba(92,112,128,.2)}}@keyframes skeleton-glow{from{border-color:rgba(206,217,224,.2);background:rgba(206,217,224,.2)}to{border-color:rgba(92,112,128,.2);background:rgba(92,112,128,.2)}}.jupyter-wrapper .bp3-skeleton{border-color:rgba(206,217,224,.2) !important;border-radius:2px;-webkit-box-shadow:none !important;box-shadow:none !important;background:rgba(206,217,224,.2);background-clip:padding-box !important;cursor:default;color:rgba(0,0,0,0) !important;-webkit-animation:1000ms linear infinite alternate skeleton-glow;animation:1000ms linear infinite alternate skeleton-glow;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-skeleton::before,.jupyter-wrapper .bp3-skeleton::after,.jupyter-wrapper .bp3-skeleton *{visibility:hidden !important}.jupyter-wrapper .bp3-slider{width:100%;min-width:150px;height:40px;position:relative;outline:none;cursor:default;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-slider:hover{cursor:pointer}.jupyter-wrapper .bp3-slider:active{cursor:-webkit-grabbing;cursor:grabbing}.jupyter-wrapper .bp3-slider.bp3-disabled{opacity:.5;cursor:not-allowed}.jupyter-wrapper .bp3-slider.bp3-slider-unlabeled{height:16px}.jupyter-wrapper .bp3-slider-track,.jupyter-wrapper .bp3-slider-progress{top:5px;right:0;left:0;height:6px;position:absolute}.jupyter-wrapper .bp3-slider-track{border-radius:3px;overflow:hidden}.jupyter-wrapper .bp3-slider-progress{background:rgba(92,112,128,.2)}.jupyter-wrapper .bp3-dark .bp3-slider-progress{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-slider-progress.bp3-intent-primary{background-color:#137cbd}.jupyter-wrapper .bp3-slider-progress.bp3-intent-success{background-color:#0f9960}.jupyter-wrapper .bp3-slider-progress.bp3-intent-warning{background-color:#d9822b}.jupyter-wrapper .bp3-slider-progress.bp3-intent-danger{background-color:#db3737}.jupyter-wrapper .bp3-slider-handle{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-color:#f5f8fa;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));color:#182026;position:absolute;top:0;left:0;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);cursor:pointer;width:16px;height:16px}.jupyter-wrapper .bp3-slider-handle:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-clip:padding-box;background-color:#ebf1f5}.jupyter-wrapper .bp3-slider-handle:active,.jupyter-wrapper .bp3-slider-handle.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);background-color:#d8e1e8;background-image:none}.jupyter-wrapper .bp3-slider-handle:disabled,.jupyter-wrapper .bp3-slider-handle.bp3-disabled{outline:none;-webkit-box-shadow:none;box-shadow:none;background-color:rgba(206,217,224,.5);background-image:none;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-slider-handle:disabled.bp3-active,.jupyter-wrapper .bp3-slider-handle:disabled.bp3-active:hover,.jupyter-wrapper .bp3-slider-handle.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-slider-handle.bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-slider-handle:focus{z-index:1}.jupyter-wrapper .bp3-slider-handle:hover{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);background-clip:padding-box;background-color:#ebf1f5;z-index:2;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);cursor:-webkit-grab;cursor:grab}.jupyter-wrapper .bp3-slider-handle.bp3-active{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);background-color:#d8e1e8;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),inset 0 1px 1px rgba(16,22,26,.1);box-shadow:0 0 0 1px rgba(16,22,26,.2),inset 0 1px 1px rgba(16,22,26,.1);cursor:-webkit-grabbing;cursor:grabbing}.jupyter-wrapper .bp3-disabled .bp3-slider-handle{-webkit-box-shadow:none;box-shadow:none;background:#bfccd6;pointer-events:none}.jupyter-wrapper .bp3-dark .bp3-slider-handle{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#394b59;background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover,.jupyter-wrapper .bp3-dark .bp3-slider-handle:active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.4);background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-slider-handle:active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);background-color:#202b33;background-image:none}.jupyter-wrapper .bp3-dark .bp3-slider-handle:disabled,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-disabled{-webkit-box-shadow:none;box-shadow:none;background-color:rgba(57,75,89,.5);background-image:none;color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-slider-handle:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-slider-handle,.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover{background-color:#394b59}.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{background-color:#293742}.jupyter-wrapper .bp3-dark .bp3-disabled .bp3-slider-handle{border-color:#5c7080;-webkit-box-shadow:none;box-shadow:none;background:#5c7080}.jupyter-wrapper .bp3-slider-handle .bp3-slider-label{margin-left:8px;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);background:#394b59;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-slider-handle .bp3-slider-label{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);background:#e1e8ed;color:#394b59}.jupyter-wrapper .bp3-disabled .bp3-slider-handle .bp3-slider-label{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-slider-handle.bp3-start,.jupyter-wrapper .bp3-slider-handle.bp3-end{width:8px}.jupyter-wrapper .bp3-slider-handle.bp3-start{border-top-right-radius:0;border-bottom-right-radius:0}.jupyter-wrapper .bp3-slider-handle.bp3-end{margin-left:8px;border-top-left-radius:0;border-bottom-left-radius:0}.jupyter-wrapper .bp3-slider-handle.bp3-end .bp3-slider-label{margin-left:0}.jupyter-wrapper .bp3-slider-label{-webkit-transform:translate(-50%, 20px);transform:translate(-50%, 20px);display:inline-block;position:absolute;padding:2px 5px;vertical-align:top;line-height:1;font-size:12px}.jupyter-wrapper .bp3-slider.bp3-vertical{width:40px;min-width:40px;height:150px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-track,.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-progress{top:0;bottom:0;left:5px;width:6px;height:auto}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-progress{top:auto}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-label{-webkit-transform:translate(20px, 50%);transform:translate(20px, 50%)}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle{top:auto}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{margin-top:-8px;margin-left:0}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end,.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{margin-left:0;width:16px;height:8px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{border-top-left-radius:0;border-bottom-right-radius:3px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{-webkit-transform:translate(20px);transform:translate(20px)}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{margin-bottom:8px;border-top-left-radius:3px;border-bottom-left-radius:0;border-bottom-right-radius:0}@-webkit-keyframes pt-spinner-animation{from{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes pt-spinner-animation{from{-webkit-transform:rotate(0deg);transform:rotate(0deg)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.jupyter-wrapper .bp3-spinner{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;overflow:visible;vertical-align:middle}.jupyter-wrapper .bp3-spinner svg{display:block}.jupyter-wrapper .bp3-spinner path{fill-opacity:0}.jupyter-wrapper .bp3-spinner .bp3-spinner-head{-webkit-transform-origin:center;transform-origin:center;-webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);stroke:rgba(92,112,128,.8);stroke-linecap:round}.jupyter-wrapper .bp3-spinner .bp3-spinner-track{stroke:rgba(92,112,128,.2)}.jupyter-wrapper .bp3-spinner-animation{-webkit-animation:pt-spinner-animation 500ms linear infinite;animation:pt-spinner-animation 500ms linear infinite}.jupyter-wrapper .bp3-no-spin>.bp3-spinner-animation{-webkit-animation:none;animation:none}.jupyter-wrapper .bp3-dark .bp3-spinner .bp3-spinner-head{stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-spinner .bp3-spinner-track{stroke:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-spinner.bp3-intent-primary .bp3-spinner-head{stroke:#137cbd}.jupyter-wrapper .bp3-spinner.bp3-intent-success .bp3-spinner-head{stroke:#0f9960}.jupyter-wrapper .bp3-spinner.bp3-intent-warning .bp3-spinner-head{stroke:#d9822b}.jupyter-wrapper .bp3-spinner.bp3-intent-danger .bp3-spinner-head{stroke:#db3737}.jupyter-wrapper .bp3-tabs.bp3-vertical{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab{border-radius:3px;width:100%;padding:0 10px}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab[aria-selected=true]{-webkit-box-shadow:none;box-shadow:none;background-color:rgba(19,124,189,.2)}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{top:0;right:0;bottom:0;left:0;border-radius:3px;background-color:rgba(19,124,189,.2);height:auto}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-panel{margin-top:0;padding-left:20px}.jupyter-wrapper .bp3-tab-list{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end;position:relative;margin:0;border:none;padding:0;list-style:none}.jupyter-wrapper .bp3-tab-list>*:not(:last-child){margin-right:20px}.jupyter-wrapper .bp3-tab{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;cursor:pointer;max-width:100%;vertical-align:top;line-height:30px;color:#182026;font-size:14px}.jupyter-wrapper .bp3-tab a{display:block;text-decoration:none;color:inherit}.jupyter-wrapper .bp3-tab-indicator-wrapper~.bp3-tab{-webkit-box-shadow:none !important;box-shadow:none !important;background-color:rgba(0,0,0,0) !important}.jupyter-wrapper .bp3-tab[aria-disabled=true]{cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-tab[aria-selected=true]{border-radius:0;-webkit-box-shadow:inset 0 -3px 0 #106ba3;box-shadow:inset 0 -3px 0 #106ba3}.jupyter-wrapper .bp3-tab[aria-selected=true],.jupyter-wrapper .bp3-tab:not([aria-disabled=true]):hover{color:#106ba3}.jupyter-wrapper .bp3-tab:focus{-moz-outline-radius:0}.jupyter-wrapper .bp3-large>.bp3-tab{line-height:40px;font-size:16px}.jupyter-wrapper .bp3-tab-panel{margin-top:20px}.jupyter-wrapper .bp3-tab-panel[aria-hidden=true]{display:none}.jupyter-wrapper .bp3-tab-indicator-wrapper{position:absolute;top:0;left:0;-webkit-transform:translateX(0),translateY(0);transform:translateX(0),translateY(0);-webkit-transition:height,width,-webkit-transform;transition:height,width,-webkit-transform;transition:height,transform,width;transition:height,transform,width,-webkit-transform;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);pointer-events:none}.jupyter-wrapper .bp3-tab-indicator-wrapper .bp3-tab-indicator{position:absolute;right:0;bottom:0;left:0;background-color:#106ba3;height:3px}.jupyter-wrapper .bp3-tab-indicator-wrapper.bp3-no-animation{-webkit-transition:none;transition:none}.jupyter-wrapper .bp3-dark .bp3-tab{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tab[aria-disabled=true]{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-tab[aria-selected=true]{-webkit-box-shadow:inset 0 -3px 0 #48aff0;box-shadow:inset 0 -3px 0 #48aff0}.jupyter-wrapper .bp3-dark .bp3-tab[aria-selected=true],.jupyter-wrapper .bp3-dark .bp3-tab:not([aria-disabled=true]):hover{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-tab-indicator{background-color:#48aff0}.jupyter-wrapper .bp3-flex-expander{-webkit-box-flex:1;-ms-flex:1 1;flex:1 1}.jupyter-wrapper .bp3-tag{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;border:none;border-radius:3px;-webkit-box-shadow:none;box-shadow:none;background-color:#5c7080;min-width:20px;max-width:100%;min-height:20px;padding:2px 6px;line-height:16px;color:#f5f8fa;font-size:12px}.jupyter-wrapper .bp3-tag.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-interactive:hover{background-color:rgba(92,112,128,.85)}.jupyter-wrapper .bp3-tag.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-interactive:active{background-color:rgba(92,112,128,.7)}.jupyter-wrapper .bp3-tag>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag::before,.jupyter-wrapper .bp3-tag>*{margin-right:4px}.jupyter-wrapper .bp3-tag:empty::before,.jupyter-wrapper .bp3-tag>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag:focus{outline:rgba(19,124,189,.6) auto 2px;outline-offset:0;-moz-outline-radius:6px}.jupyter-wrapper .bp3-tag.bp3-round{border-radius:30px;padding-right:8px;padding-left:8px}.jupyter-wrapper .bp3-dark .bp3-tag{background-color:#bfccd6;color:#182026}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive:hover{background-color:rgba(191,204,214,.85)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive:active{background-color:rgba(191,204,214,.7)}.jupyter-wrapper .bp3-dark .bp3-tag>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tag .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tag .bp3-icon-large{fill:currentColor}.jupyter-wrapper .bp3-tag>.bp3-icon,.jupyter-wrapper .bp3-tag .bp3-icon-standard,.jupyter-wrapper .bp3-tag .bp3-icon-large{fill:#fff}.jupyter-wrapper .bp3-tag.bp3-large,.jupyter-wrapper .bp3-large .bp3-tag{min-width:30px;min-height:30px;padding:0 10px;line-height:20px;font-size:14px}.jupyter-wrapper .bp3-tag.bp3-large::before,.jupyter-wrapper .bp3-tag.bp3-large>*,.jupyter-wrapper .bp3-large .bp3-tag::before,.jupyter-wrapper .bp3-large .bp3-tag>*{margin-right:7px}.jupyter-wrapper .bp3-tag.bp3-large:empty::before,.jupyter-wrapper .bp3-tag.bp3-large>:last-child,.jupyter-wrapper .bp3-large .bp3-tag:empty::before,.jupyter-wrapper .bp3-large .bp3-tag>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag.bp3-large.bp3-round,.jupyter-wrapper .bp3-large .bp3-tag.bp3-round{padding-right:12px;padding-left:12px}.jupyter-wrapper .bp3-tag.bp3-intent-primary{background:#137cbd;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive:hover{background-color:rgba(19,124,189,.85)}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive:active{background-color:rgba(19,124,189,.7)}.jupyter-wrapper .bp3-tag.bp3-intent-success{background:#0f9960;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive:hover{background-color:rgba(15,153,96,.85)}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive:active{background-color:rgba(15,153,96,.7)}.jupyter-wrapper .bp3-tag.bp3-intent-warning{background:#d9822b;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive:hover{background-color:rgba(217,130,43,.85)}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive:active{background-color:rgba(217,130,43,.7)}.jupyter-wrapper .bp3-tag.bp3-intent-danger{background:#db3737;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive:hover{background-color:rgba(219,55,55,.85)}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive:active{background-color:rgba(219,55,55,.7)}.jupyter-wrapper .bp3-tag.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-tag.bp3-minimal>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal .bp3-icon-large{fill:#5c7080}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]){background-color:rgba(138,155,168,.2);color:#182026}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:hover{background-color:rgba(92,112,128,.3)}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:active{background-color:rgba(92,112,128,.4)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]){color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:hover{background-color:rgba(191,204,214,.3)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:active{background-color:rgba(191,204,214,.4)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-])>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]) .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]) .bp3-icon-large{fill:#a7b6c2}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary{background-color:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{background-color:rgba(19,124,189,.25)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{background-color:rgba(19,124,189,.35)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{fill:#137cbd}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{background-color:rgba(19,124,189,.25);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{background-color:rgba(19,124,189,.35)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{background-color:rgba(19,124,189,.45)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success{background-color:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{background-color:rgba(15,153,96,.25)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{background-color:rgba(15,153,96,.35)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{fill:#0f9960}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{background-color:rgba(15,153,96,.25);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{background-color:rgba(15,153,96,.35)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{background-color:rgba(15,153,96,.45)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning{background-color:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{background-color:rgba(217,130,43,.25)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{background-color:rgba(217,130,43,.35)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{fill:#d9822b}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{background-color:rgba(217,130,43,.25);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{background-color:rgba(217,130,43,.35)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{background-color:rgba(217,130,43,.45)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger{background-color:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{background-color:rgba(219,55,55,.25)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{background-color:rgba(219,55,55,.35)}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{fill:#db3737}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{background-color:rgba(219,55,55,.25);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{background-color:rgba(219,55,55,.35)}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{background-color:rgba(219,55,55,.45)}.jupyter-wrapper .bp3-tag-remove{display:-webkit-box;display:-ms-flexbox;display:flex;opacity:.5;margin-top:-2px;margin-right:-6px !important;margin-bottom:-2px;border:none;background:none;cursor:pointer;padding:2px;padding-left:0;color:inherit}.jupyter-wrapper .bp3-tag-remove:hover{opacity:.8;background:none;text-decoration:none}.jupyter-wrapper .bp3-tag-remove:active{opacity:1}.jupyter-wrapper .bp3-tag-remove:empty::before{line-height:1;font-family:"Icons16",sans-serif;font-size:16px;font-weight:400;font-style:normal;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;content:""}.jupyter-wrapper .bp3-large .bp3-tag-remove{margin-right:-10px !important;padding:5px;padding-left:0}.jupyter-wrapper .bp3-large .bp3-tag-remove:empty::before{line-height:1;font-family:"Icons20",sans-serif;font-size:20px;font-weight:400;font-style:normal}.jupyter-wrapper .bp3-tag-input{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;cursor:text;height:auto;min-height:30px;padding-right:0;padding-left:5px;line-height:inherit}.jupyter-wrapper .bp3-tag-input>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag-input>.bp3-tag-input-values{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-icon{margin-top:7px;margin-right:7px;margin-left:2px;color:#5c7080}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-ms-flex-item-align:stretch;align-self:stretch;margin-top:5px;margin-right:7px;min-width:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values::before,.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{margin-right:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:empty::before,.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{padding-left:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{margin-bottom:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag{overflow-wrap:break-word}.jupyter-wrapper .bp3-tag-input .bp3-tag.bp3-active{outline:rgba(19,124,189,.6) auto 2px;outline-offset:0;-moz-outline-radius:6px}.jupyter-wrapper .bp3-tag-input .bp3-input-ghost{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;width:80px;line-height:20px}.jupyter-wrapper .bp3-tag-input .bp3-input-ghost:disabled,.jupyter-wrapper .bp3-tag-input .bp3-input-ghost.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-tag-input .bp3-button,.jupyter-wrapper .bp3-tag-input .bp3-spinner{margin:3px;margin-left:0}.jupyter-wrapper .bp3-tag-input .bp3-button{min-width:24px;min-height:24px;padding:0 7px}.jupyter-wrapper .bp3-tag-input.bp3-large{height:auto;min-height:40px}.jupyter-wrapper .bp3-tag-input.bp3-large::before,.jupyter-wrapper .bp3-tag-input.bp3-large>*{margin-right:10px}.jupyter-wrapper .bp3-tag-input.bp3-large:empty::before,.jupyter-wrapper .bp3-tag-input.bp3-large>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-tag-input-icon{margin-top:10px;margin-left:5px}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-input-ghost{line-height:30px}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-button{min-width:30px;min-height:30px;padding:5px 10px;margin:5px;margin-left:0}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-spinner{margin:8px;margin-left:0}.jupyter-wrapper .bp3-tag-input.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);background-color:#fff}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-primary{-webkit-box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-success{-webkit-box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-warning{-webkit-box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-danger{-webkit-box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 1px 1px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-tag-input-icon,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-tag-input-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{color:rgba(167,182,194,.6)}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);background-color:rgba(16,22,26,.3)}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{-webkit-box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{-webkit-box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{-webkit-box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{-webkit-box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-input-ghost{border:none;-webkit-box-shadow:none;box-shadow:none;background:none;padding:0}.jupyter-wrapper .bp3-input-ghost::-webkit-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input-ghost::-moz-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input-ghost:-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input-ghost::-ms-input-placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input-ghost::placeholder{opacity:1;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-input-ghost:focus{outline:none !important}.jupyter-wrapper .bp3-toast{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;position:relative !important;margin:20px 0 0;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);background-color:#fff;min-width:300px;max-width:500px;pointer-events:all}.jupyter-wrapper .bp3-toast.bp3-toast-enter,.jupyter-wrapper .bp3-toast.bp3-toast-appear{-webkit-transform:translateY(-40px);transform:translateY(-40px)}.jupyter-wrapper .bp3-toast.bp3-toast-enter-active,.jupyter-wrapper .bp3-toast.bp3-toast-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:300ms;transition-duration:300ms;-webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-toast.bp3-toast-enter~.bp3-toast,.jupyter-wrapper .bp3-toast.bp3-toast-appear~.bp3-toast{-webkit-transform:translateY(-40px);transform:translateY(-40px)}.jupyter-wrapper .bp3-toast.bp3-toast-enter-active~.bp3-toast,.jupyter-wrapper .bp3-toast.bp3-toast-appear-active~.bp3-toast{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:300ms;transition-duration:300ms;-webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-toast.bp3-toast-exit{opacity:1;-webkit-filter:blur(0);filter:blur(0)}.jupyter-wrapper .bp3-toast.bp3-toast-exit-active{opacity:0;-webkit-filter:blur(10px);filter:blur(10px);-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:opacity,filter;transition-property:opacity,filter,-webkit-filter;-webkit-transition-duration:300ms;transition-duration:300ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-toast.bp3-toast-exit~.bp3-toast{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-toast.bp3-toast-exit-active~.bp3-toast{-webkit-transform:translateY(-40px);transform:translateY(-40px);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:50ms;transition-delay:50ms}.jupyter-wrapper .bp3-toast .bp3-button-group{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding:5px;padding-left:0}.jupyter-wrapper .bp3-toast>.bp3-icon{margin:12px;margin-right:0;color:#5c7080}.jupyter-wrapper .bp3-toast.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-toast{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);background-color:#394b59}.jupyter-wrapper .bp3-toast.bp3-dark>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-toast>.bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] a{color:rgba(255,255,255,.7)}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] a:hover{color:#fff}.jupyter-wrapper .bp3-toast[class*=bp3-intent-]>.bp3-icon{color:#fff}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button::before,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button .bp3-icon,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:active{color:rgba(255,255,255,.7) !important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:focus{outline-color:rgba(255,255,255,.5)}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:hover{background-color:rgba(255,255,255,.15) !important;color:#fff !important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:active{background-color:rgba(255,255,255,.3) !important;color:#fff !important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button::after{background:rgba(255,255,255,.3) !important}.jupyter-wrapper .bp3-toast.bp3-intent-primary{background-color:#137cbd;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-success{background-color:#0f9960;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-warning{background-color:#d9822b;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-danger{background-color:#db3737;color:#fff}.jupyter-wrapper .bp3-toast-message{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;padding:11px;word-break:break-word}.jupyter-wrapper .bp3-toast-container{display:-webkit-box !important;display:-ms-flexbox !important;display:flex !important;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:fixed;right:0;left:0;z-index:40;overflow:hidden;padding:0 20px 20px;pointer-events:none}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-top{top:0;bottom:auto}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-bottom{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;top:auto;bottom:0}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-left{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-right{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active)~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active)~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active~.bp3-toast{-webkit-transform:translateY(60px);transform:translateY(60px)}.jupyter-wrapper .bp3-tooltip{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow{position:absolute;width:22px;height:22px}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow::before{margin:4px;width:14px;height:14px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip{margin-top:-11px;margin-bottom:11px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow{bottom:-8px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(-90deg);transform:rotate(-90deg)}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip{margin-left:11px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow{left:-8px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(0);transform:rotate(0)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip{margin-top:11px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow{top:-8px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip{margin-right:11px;margin-left:-11px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow{right:-8px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.jupyter-wrapper .bp3-tether-element-attached-middle>.bp3-tooltip>.bp3-popover-arrow{top:50%;-webkit-transform:translateY(-50%);transform:translateY(-50%)}.jupyter-wrapper .bp3-tether-element-attached-center>.bp3-tooltip>.bp3-popover-arrow{right:50%;-webkit-transform:translateX(50%);transform:translateX(50%)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow{top:-0.22183px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow{right:-0.22183px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow{left:-0.22183px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow{bottom:-0.22183px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:top left;transform-origin:top left}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:top center;transform-origin:top center}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:top right;transform-origin:top right}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:center left;transform-origin:center left}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:center center;transform-origin:center center}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:center right;transform-origin:center right}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:bottom left;transform-origin:bottom left}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:bottom center;transform-origin:bottom center}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:bottom right;transform-origin:bottom right}.jupyter-wrapper .bp3-tooltip .bp3-popover-content{background:#394b59;color:#f5f8fa}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow::before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.2);box-shadow:1px 1px 6px rgba(16,22,26,.2)}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.1}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow-fill{fill:#394b59}.jupyter-wrapper .bp3-popover-enter>.bp3-tooltip,.jupyter-wrapper .bp3-popover-appear>.bp3-tooltip{-webkit-transform:scale(0.8);transform:scale(0.8)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-tooltip,.jupyter-wrapper .bp3-popover-appear-active>.bp3-tooltip{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-popover-exit>.bp3-tooltip{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-tooltip{-webkit-transform:scale(0.8);transform:scale(0.8);-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-duration:100ms;transition-duration:100ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-tooltip .bp3-popover-content{padding:10px 12px}.jupyter-wrapper .bp3-tooltip.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-tooltip{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-content,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-content{background:#e1e8ed;color:#394b59}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.4);box-shadow:1px 1px 6px rgba(16,22,26,.4)}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.2}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{fill:#e1e8ed}.jupyter-wrapper .bp3-tooltip.bp3-intent-primary .bp3-popover-content{background:#137cbd;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{fill:#137cbd}.jupyter-wrapper .bp3-tooltip.bp3-intent-success .bp3-popover-content{background:#0f9960;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{fill:#0f9960}.jupyter-wrapper .bp3-tooltip.bp3-intent-warning .bp3-popover-content{background:#d9822b;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{fill:#d9822b}.jupyter-wrapper .bp3-tooltip.bp3-intent-danger .bp3-popover-content{background:#db3737;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{fill:#db3737}.jupyter-wrapper .bp3-tooltip-indicator{border-bottom:dotted 1px;cursor:help}.jupyter-wrapper .bp3-tree .bp3-icon,.jupyter-wrapper .bp3-tree .bp3-icon-standard,.jupyter-wrapper .bp3-tree .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-primary{color:#137cbd}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-success{color:#0f9960}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-warning{color:#d9822b}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-danger{color:#db3737}.jupyter-wrapper .bp3-tree-node-list{margin:0;padding-left:0;list-style:none}.jupyter-wrapper .bp3-tree-root{position:relative;background-color:rgba(0,0,0,0);cursor:default;padding-left:0}.jupyter-wrapper .bp3-tree-node-content-0{padding-left:0px}.jupyter-wrapper .bp3-tree-node-content-1{padding-left:23px}.jupyter-wrapper .bp3-tree-node-content-2{padding-left:46px}.jupyter-wrapper .bp3-tree-node-content-3{padding-left:69px}.jupyter-wrapper .bp3-tree-node-content-4{padding-left:92px}.jupyter-wrapper .bp3-tree-node-content-5{padding-left:115px}.jupyter-wrapper .bp3-tree-node-content-6{padding-left:138px}.jupyter-wrapper .bp3-tree-node-content-7{padding-left:161px}.jupyter-wrapper .bp3-tree-node-content-8{padding-left:184px}.jupyter-wrapper .bp3-tree-node-content-9{padding-left:207px}.jupyter-wrapper .bp3-tree-node-content-10{padding-left:230px}.jupyter-wrapper .bp3-tree-node-content-11{padding-left:253px}.jupyter-wrapper .bp3-tree-node-content-12{padding-left:276px}.jupyter-wrapper .bp3-tree-node-content-13{padding-left:299px}.jupyter-wrapper .bp3-tree-node-content-14{padding-left:322px}.jupyter-wrapper .bp3-tree-node-content-15{padding-left:345px}.jupyter-wrapper .bp3-tree-node-content-16{padding-left:368px}.jupyter-wrapper .bp3-tree-node-content-17{padding-left:391px}.jupyter-wrapper .bp3-tree-node-content-18{padding-left:414px}.jupyter-wrapper .bp3-tree-node-content-19{padding-left:437px}.jupyter-wrapper .bp3-tree-node-content-20{padding-left:460px}.jupyter-wrapper .bp3-tree-node-content{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:30px;padding-right:5px}.jupyter-wrapper .bp3-tree-node-content:hover{background-color:rgba(191,204,214,.4)}.jupyter-wrapper .bp3-tree-node-caret,.jupyter-wrapper .bp3-tree-node-caret-none{min-width:30px}.jupyter-wrapper .bp3-tree-node-caret{color:#5c7080;-webkit-transform:rotate(0deg);transform:rotate(0deg);cursor:pointer;padding:7px;-webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9),-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9)}.jupyter-wrapper .bp3-tree-node-caret:hover{color:#182026}.jupyter-wrapper .bp3-dark .bp3-tree-node-caret{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tree-node-caret:hover{color:#f5f8fa}.jupyter-wrapper .bp3-tree-node-caret.bp3-tree-node-caret-open{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tree-node-caret.bp3-icon-standard::before{content:""}.jupyter-wrapper .bp3-tree-node-icon{position:relative;margin-right:7px}.jupyter-wrapper .bp3-tree-node-label{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-tree-node-label span{display:inline}.jupyter-wrapper .bp3-tree-node-secondary-label{padding:0 5px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-tree-node-secondary-label .bp3-popover-wrapper,.jupyter-wrapper .bp3-tree-node-secondary-label .bp3-popover-target{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center}.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-content{background-color:inherit;cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-caret,.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-icon{cursor:not-allowed;color:rgba(92,112,128,.6)}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content{background-color:#137cbd}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon-standard,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon-large{color:#fff}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-tree-node-caret::before{color:rgba(255,255,255,.7)}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-tree-node-caret:hover::before{color:#fff}.jupyter-wrapper .bp3-dark .bp3-tree-node-content:hover{background-color:rgba(92,112,128,.3)}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{color:#0f9960}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{color:#d9822b}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{color:#db3737}.jupyter-wrapper .bp3-dark .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content{background-color:#137cbd}.jupyter-wrapper .bp3-omnibar{-webkit-filter:blur(0);filter:blur(0);opacity:1;top:20vh;left:calc(50% - 250px);z-index:21;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);background-color:#fff;width:500px}.jupyter-wrapper .bp3-omnibar.bp3-overlay-enter,.jupyter-wrapper .bp3-omnibar.bp3-overlay-appear{-webkit-filter:blur(20px);filter:blur(20px);opacity:.2}.jupyter-wrapper .bp3-omnibar.bp3-overlay-enter-active,.jupyter-wrapper .bp3-omnibar.bp3-overlay-appear-active{-webkit-filter:blur(0);filter:blur(0);opacity:1;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:filter,opacity;transition-property:filter,opacity,-webkit-filter;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-omnibar.bp3-overlay-exit{-webkit-filter:blur(0);filter:blur(0);opacity:1}.jupyter-wrapper .bp3-omnibar.bp3-overlay-exit-active{-webkit-filter:blur(20px);filter:blur(20px);opacity:.2;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:filter,opacity;transition-property:filter,opacity,-webkit-filter;-webkit-transition-duration:200ms;transition-duration:200ms;-webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);-webkit-transition-delay:0;transition-delay:0}.jupyter-wrapper .bp3-omnibar .bp3-input{border-radius:0;background-color:rgba(0,0,0,0)}.jupyter-wrapper .bp3-omnibar .bp3-input,.jupyter-wrapper .bp3-omnibar .bp3-input:focus{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-omnibar .bp3-menu{border-radius:0;-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.15);box-shadow:inset 0 1px 0 rgba(16,22,26,.15);background-color:rgba(0,0,0,0);max-height:calc(60vh - 40px);overflow:auto}.jupyter-wrapper .bp3-omnibar .bp3-menu:empty{display:none}.jupyter-wrapper .bp3-dark .bp3-omnibar,.jupyter-wrapper .bp3-omnibar.bp3-dark{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);background-color:#30404d}.jupyter-wrapper .bp3-omnibar-overlay .bp3-overlay-backdrop{background-color:rgba(16,22,26,.2)}.jupyter-wrapper .bp3-select-popover .bp3-popover-content{padding:5px}.jupyter-wrapper .bp3-select-popover .bp3-input-group{margin-bottom:0}.jupyter-wrapper .bp3-select-popover .bp3-menu{max-width:400px;max-height:300px;overflow:auto;padding:0}.jupyter-wrapper .bp3-select-popover .bp3-menu:not(:first-child){padding-top:5px}.jupyter-wrapper .bp3-multi-select{min-width:150px}.jupyter-wrapper .bp3-multi-select-popover .bp3-menu{max-width:400px;max-height:300px;overflow:auto}.jupyter-wrapper .bp3-select-popover .bp3-popover-content{padding:5px}.jupyter-wrapper .bp3-select-popover .bp3-input-group{margin-bottom:0}.jupyter-wrapper .bp3-select-popover .bp3-menu{max-width:400px;max-height:300px;overflow:auto;padding:0}.jupyter-wrapper .bp3-select-popover .bp3-menu:not(:first-child){padding-top:5px}.jupyter-wrapper :root{--jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-build: url(data:image/svg+xml;base64,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);--jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);--jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);--jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);--jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);--jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-jupyter: url(data:image/svg+xml;base64,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);--jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);--jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);--jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);--jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);--jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);--jp-icon-listings-info: url(data:image/svg+xml;base64,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);--jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);--jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);--jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);--jp-icon-react: url(data:image/svg+xml;base64,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);--jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);--jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);--jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-terminal: url(data:image/svg+xml;base64,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);--jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);--jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);--jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K)}.jupyter-wrapper .jp-AddIcon{background-image:var(--jp-icon-add)}.jupyter-wrapper .jp-BugIcon{background-image:var(--jp-icon-bug)}.jupyter-wrapper .jp-BuildIcon{background-image:var(--jp-icon-build)}.jupyter-wrapper .jp-CaretDownEmptyIcon{background-image:var(--jp-icon-caret-down-empty)}.jupyter-wrapper .jp-CaretDownEmptyThinIcon{background-image:var(--jp-icon-caret-down-empty-thin)}.jupyter-wrapper .jp-CaretDownIcon{background-image:var(--jp-icon-caret-down)}.jupyter-wrapper .jp-CaretLeftIcon{background-image:var(--jp-icon-caret-left)}.jupyter-wrapper .jp-CaretRightIcon{background-image:var(--jp-icon-caret-right)}.jupyter-wrapper .jp-CaretUpEmptyThinIcon{background-image:var(--jp-icon-caret-up-empty-thin)}.jupyter-wrapper .jp-CaretUpIcon{background-image:var(--jp-icon-caret-up)}.jupyter-wrapper .jp-CaseSensitiveIcon{background-image:var(--jp-icon-case-sensitive)}.jupyter-wrapper .jp-CheckIcon{background-image:var(--jp-icon-check)}.jupyter-wrapper .jp-CircleEmptyIcon{background-image:var(--jp-icon-circle-empty)}.jupyter-wrapper .jp-CircleIcon{background-image:var(--jp-icon-circle)}.jupyter-wrapper .jp-ClearIcon{background-image:var(--jp-icon-clear)}.jupyter-wrapper .jp-CloseIcon{background-image:var(--jp-icon-close)}.jupyter-wrapper .jp-ConsoleIcon{background-image:var(--jp-icon-console)}.jupyter-wrapper .jp-CopyIcon{background-image:var(--jp-icon-copy)}.jupyter-wrapper .jp-CutIcon{background-image:var(--jp-icon-cut)}.jupyter-wrapper .jp-DownloadIcon{background-image:var(--jp-icon-download)}.jupyter-wrapper .jp-EditIcon{background-image:var(--jp-icon-edit)}.jupyter-wrapper .jp-EllipsesIcon{background-image:var(--jp-icon-ellipses)}.jupyter-wrapper .jp-ExtensionIcon{background-image:var(--jp-icon-extension)}.jupyter-wrapper .jp-FastForwardIcon{background-image:var(--jp-icon-fast-forward)}.jupyter-wrapper .jp-FileIcon{background-image:var(--jp-icon-file)}.jupyter-wrapper .jp-FileUploadIcon{background-image:var(--jp-icon-file-upload)}.jupyter-wrapper .jp-FilterListIcon{background-image:var(--jp-icon-filter-list)}.jupyter-wrapper .jp-FolderIcon{background-image:var(--jp-icon-folder)}.jupyter-wrapper .jp-Html5Icon{background-image:var(--jp-icon-html5)}.jupyter-wrapper .jp-ImageIcon{background-image:var(--jp-icon-image)}.jupyter-wrapper .jp-InspectorIcon{background-image:var(--jp-icon-inspector)}.jupyter-wrapper .jp-JsonIcon{background-image:var(--jp-icon-json)}.jupyter-wrapper .jp-JupyterFaviconIcon{background-image:var(--jp-icon-jupyter-favicon)}.jupyter-wrapper .jp-JupyterIcon{background-image:var(--jp-icon-jupyter)}.jupyter-wrapper .jp-JupyterlabWordmarkIcon{background-image:var(--jp-icon-jupyterlab-wordmark)}.jupyter-wrapper .jp-KernelIcon{background-image:var(--jp-icon-kernel)}.jupyter-wrapper .jp-KeyboardIcon{background-image:var(--jp-icon-keyboard)}.jupyter-wrapper .jp-LauncherIcon{background-image:var(--jp-icon-launcher)}.jupyter-wrapper .jp-LineFormIcon{background-image:var(--jp-icon-line-form)}.jupyter-wrapper .jp-LinkIcon{background-image:var(--jp-icon-link)}.jupyter-wrapper .jp-ListIcon{background-image:var(--jp-icon-list)}.jupyter-wrapper .jp-ListingsInfoIcon{background-image:var(--jp-icon-listings-info)}.jupyter-wrapper .jp-MarkdownIcon{background-image:var(--jp-icon-markdown)}.jupyter-wrapper .jp-NewFolderIcon{background-image:var(--jp-icon-new-folder)}.jupyter-wrapper .jp-NotTrustedIcon{background-image:var(--jp-icon-not-trusted)}.jupyter-wrapper .jp-NotebookIcon{background-image:var(--jp-icon-notebook)}.jupyter-wrapper .jp-PaletteIcon{background-image:var(--jp-icon-palette)}.jupyter-wrapper .jp-PasteIcon{background-image:var(--jp-icon-paste)}.jupyter-wrapper .jp-PythonIcon{background-image:var(--jp-icon-python)}.jupyter-wrapper .jp-RKernelIcon{background-image:var(--jp-icon-r-kernel)}.jupyter-wrapper .jp-ReactIcon{background-image:var(--jp-icon-react)}.jupyter-wrapper .jp-RefreshIcon{background-image:var(--jp-icon-refresh)}.jupyter-wrapper .jp-RegexIcon{background-image:var(--jp-icon-regex)}.jupyter-wrapper .jp-RunIcon{background-image:var(--jp-icon-run)}.jupyter-wrapper .jp-RunningIcon{background-image:var(--jp-icon-running)}.jupyter-wrapper .jp-SaveIcon{background-image:var(--jp-icon-save)}.jupyter-wrapper .jp-SearchIcon{background-image:var(--jp-icon-search)}.jupyter-wrapper .jp-SettingsIcon{background-image:var(--jp-icon-settings)}.jupyter-wrapper .jp-SpreadsheetIcon{background-image:var(--jp-icon-spreadsheet)}.jupyter-wrapper .jp-StopIcon{background-image:var(--jp-icon-stop)}.jupyter-wrapper .jp-TabIcon{background-image:var(--jp-icon-tab)}.jupyter-wrapper .jp-TerminalIcon{background-image:var(--jp-icon-terminal)}.jupyter-wrapper .jp-TextEditorIcon{background-image:var(--jp-icon-text-editor)}.jupyter-wrapper .jp-TrustedIcon{background-image:var(--jp-icon-trusted)}.jupyter-wrapper .jp-UndoIcon{background-image:var(--jp-icon-undo)}.jupyter-wrapper .jp-VegaIcon{background-image:var(--jp-icon-vega)}.jupyter-wrapper .jp-YamlIcon{background-image:var(--jp-icon-yaml)}.jupyter-wrapper :root{--jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==)}.jupyter-wrapper .jp-Icon,.jupyter-wrapper .jp-MaterialIcon{background-position:center;background-repeat:no-repeat;background-size:16px;min-width:16px;min-height:16px}.jupyter-wrapper .jp-Icon-cover{background-position:center;background-repeat:no-repeat;background-size:cover}.jupyter-wrapper .jp-Icon-16{background-size:16px;min-width:16px;min-height:16px}.jupyter-wrapper .jp-Icon-18{background-size:18px;min-width:18px;min-height:18px}.jupyter-wrapper .jp-Icon-20{background-size:20px;min-width:20px;min-height:20px}.jupyter-wrapper .jp-icon0[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon1[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon2[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon3[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon4[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-accent0[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-accent1[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-accent2[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-accent3[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-accent4[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-accent0[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-accent1[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-accent2[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-accent3[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-accent4[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-none[fill]{fill:none}.jupyter-wrapper .jp-icon-none[stroke]{stroke:none}.jupyter-wrapper .jp-icon-brand0[fill]{fill:var(--jp-brand-color0)}.jupyter-wrapper .jp-icon-brand1[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper .jp-icon-brand2[fill]{fill:var(--jp-brand-color2)}.jupyter-wrapper .jp-icon-brand3[fill]{fill:var(--jp-brand-color3)}.jupyter-wrapper .jp-icon-brand4[fill]{fill:var(--jp-brand-color4)}.jupyter-wrapper .jp-icon-brand0[stroke]{stroke:var(--jp-brand-color0)}.jupyter-wrapper .jp-icon-brand1[stroke]{stroke:var(--jp-brand-color1)}.jupyter-wrapper .jp-icon-brand2[stroke]{stroke:var(--jp-brand-color2)}.jupyter-wrapper .jp-icon-brand3[stroke]{stroke:var(--jp-brand-color3)}.jupyter-wrapper .jp-icon-brand4[stroke]{stroke:var(--jp-brand-color4)}.jupyter-wrapper .jp-icon-warn0[fill]{fill:var(--jp-warn-color0)}.jupyter-wrapper .jp-icon-warn1[fill]{fill:var(--jp-warn-color1)}.jupyter-wrapper .jp-icon-warn2[fill]{fill:var(--jp-warn-color2)}.jupyter-wrapper .jp-icon-warn3[fill]{fill:var(--jp-warn-color3)}.jupyter-wrapper .jp-icon-warn0[stroke]{stroke:var(--jp-warn-color0)}.jupyter-wrapper .jp-icon-warn1[stroke]{stroke:var(--jp-warn-color1)}.jupyter-wrapper .jp-icon-warn2[stroke]{stroke:var(--jp-warn-color2)}.jupyter-wrapper .jp-icon-warn3[stroke]{stroke:var(--jp-warn-color3)}.jupyter-wrapper .jp-icon-contrast0[fill]{fill:var(--jp-icon-contrast-color0)}.jupyter-wrapper .jp-icon-contrast1[fill]{fill:var(--jp-icon-contrast-color1)}.jupyter-wrapper .jp-icon-contrast2[fill]{fill:var(--jp-icon-contrast-color2)}.jupyter-wrapper .jp-icon-contrast3[fill]{fill:var(--jp-icon-contrast-color3)}.jupyter-wrapper .jp-icon-contrast0[stroke]{stroke:var(--jp-icon-contrast-color0)}.jupyter-wrapper .jp-icon-contrast1[stroke]{stroke:var(--jp-icon-contrast-color1)}.jupyter-wrapper .jp-icon-contrast2[stroke]{stroke:var(--jp-icon-contrast-color2)}.jupyter-wrapper .jp-icon-contrast3[stroke]{stroke:var(--jp-icon-contrast-color3)}.jupyter-wrapper #setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper #setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-hover :hover .jp-icon-selectable[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-hover :hover .jp-icon-selectable-inverse[fill]{fill:#fff}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon3[fill]{fill:none}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty.jp-mod-active>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:#fff}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon3[fill]{fill:none}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper #jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper #jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper :root{--jp-warn-color0: var(--md-orange-700)}.jupyter-wrapper .jp-DragIcon{margin-right:4px}.jupyter-wrapper .jp-icon-alt .jp-icon0[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon1[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon2[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon3[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon4[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon0[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon1[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon2[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon3[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon4[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent0[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent1[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent2[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent3[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent4[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hoverShow:not(:hover) svg{display:none !important}.jupyter-wrapper .jp-icon-hover :hover .jp-icon0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon3-hover[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-none-hover[fill]{fill:none}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-none-hover[stroke]{stroke:none}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper :focus{outline:unset;outline-offset:unset;-moz-outline-radius:unset}.jupyter-wrapper .jp-Button{border-radius:var(--jp-border-radius);padding:0px 12px;font-size:var(--jp-ui-font-size1)}.jupyter-wrapper button.jp-Button.bp3-button.bp3-minimal:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-Button.minimal{color:unset !important}.jupyter-wrapper .jp-Button.jp-ToolbarButtonComponent{text-transform:none}.jupyter-wrapper .jp-InputGroup input{box-sizing:border-box;border-radius:0;background-color:rgba(0,0,0,0);color:var(--jp-ui-font-color0);box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color)}.jupyter-wrapper .jp-InputGroup input:focus{box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jupyter-wrapper .jp-InputGroup input::placeholder,.jupyter-wrapper input::placeholder{color:var(--jp-ui-font-color3)}.jupyter-wrapper .jp-BPIcon{display:inline-block;vertical-align:middle;margin:auto}.jupyter-wrapper .bp3-icon.jp-BPIcon>svg:not([fill]){fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-InputGroupAction{padding:6px}.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select{background-color:initial;border:none;border-radius:0;box-shadow:none;color:var(--jp-ui-font-color0);display:block;font-size:var(--jp-ui-font-size1);height:24px;line-height:14px;padding:0 25px 0 10px;text-align:left;-moz-appearance:none;-webkit-appearance:none}.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select:hover,.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select>option{background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color0)}.jupyter-wrapper select{box-sizing:border-box}.jupyter-wrapper .jp-Collapse{display:flex;flex-direction:column;align-items:stretch;border-top:1px solid var(--jp-border-color2);border-bottom:1px solid var(--jp-border-color2)}.jupyter-wrapper .jp-Collapse-header{padding:1px 12px;color:var(--jp-ui-font-color1);background-color:var(--jp-layout-color1);font-size:var(--jp-ui-font-size2)}.jupyter-wrapper .jp-Collapse-header:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-Collapse-contents{padding:0px 12px 0px 12px;background-color:var(--jp-layout-color1);color:var(--jp-ui-font-color1);overflow:auto}.jupyter-wrapper :root{--jp-private-commandpalette-search-height: 28px}.jupyter-wrapper .lm-CommandPalette{padding-bottom:0px;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .lm-CommandPalette-search{padding:4px;background-color:var(--jp-layout-color1);z-index:2}.jupyter-wrapper .lm-CommandPalette-wrapper{overflow:overlay;padding:0px 9px;background-color:var(--jp-input-active-background);height:30px;box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color)}.jupyter-wrapper .lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper{box-shadow:inset 0 0 0 1px var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jupyter-wrapper .lm-CommandPalette-wrapper::after{content:" ";color:#fff;background-color:var(--jp-brand-color1);position:absolute;top:4px;right:4px;height:30px;width:10px;padding:0px 10px;background-image:var(--jp-icon-search-white);background-size:20px;background-repeat:no-repeat;background-position:center}.jupyter-wrapper .lm-CommandPalette-input{background:rgba(0,0,0,0);width:calc(100% - 18px);float:left;border:none;outline:none;font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);line-height:var(--jp-private-commandpalette-search-height)}.jupyter-wrapper .lm-CommandPalette-input::-webkit-input-placeholder,.jupyter-wrapper .lm-CommandPalette-input::-moz-placeholder,.jupyter-wrapper .lm-CommandPalette-input:-ms-input-placeholder{color:var(--jp-ui-font-color3);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .lm-CommandPalette-header:first-child{margin-top:0px}.jupyter-wrapper .lm-CommandPalette-header{border-bottom:solid var(--jp-border-width) var(--jp-border-color2);color:var(--jp-ui-font-color1);cursor:pointer;display:flex;font-size:var(--jp-ui-font-size0);font-weight:600;letter-spacing:1px;margin-top:8px;padding:8px 0 8px 12px;text-transform:uppercase}.jupyter-wrapper .lm-CommandPalette-header.lm-mod-active{background:var(--jp-layout-color2)}.jupyter-wrapper .lm-CommandPalette-header>mark{background-color:rgba(0,0,0,0);font-weight:bold;color:var(--jp-ui-font-color1)}.jupyter-wrapper .lm-CommandPalette-item{padding:4px 12px 4px 4px;color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);font-weight:400;display:flex}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled{color:var(--jp-ui-font-color3)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active{background:var(--jp-layout-color3)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled){background:var(--jp-layout-color4)}.jupyter-wrapper .lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled){background:var(--jp-layout-color2)}.jupyter-wrapper .lm-CommandPalette-itemContent{overflow:hidden}.jupyter-wrapper .lm-CommandPalette-itemLabel>mark{color:var(--jp-ui-font-color0);background-color:rgba(0,0,0,0);font-weight:bold}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled mark{color:var(--jp-ui-font-color3)}.jupyter-wrapper .lm-CommandPalette-item .lm-CommandPalette-itemIcon{margin:0 4px 0 0;position:relative;width:16px;top:2px;flex:0 0 auto}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon{opacity:.4}.jupyter-wrapper .lm-CommandPalette-item .lm-CommandPalette-itemShortcut{flex:0 0 auto}.jupyter-wrapper .lm-CommandPalette-itemCaption{display:none}.jupyter-wrapper .lm-CommandPalette-content{background-color:var(--jp-layout-color1)}.jupyter-wrapper .lm-CommandPalette-content:empty:after{content:"No results";margin:auto;margin-top:20px;width:100px;display:block;font-size:var(--jp-ui-font-size2);font-family:var(--jp-ui-font-family);font-weight:lighter}.jupyter-wrapper .lm-CommandPalette-emptyMessage{text-align:center;margin-top:24px;line-height:1.32;padding:0px 8px;color:var(--jp-content-font-color3)}.jupyter-wrapper .jp-Dialog{position:absolute;z-index:10000;display:flex;flex-direction:column;align-items:center;justify-content:center;top:0px;left:0px;margin:0;padding:0;width:100%;height:100%;background:var(--jp-dialog-background)}.jupyter-wrapper .jp-Dialog-content{display:flex;flex-direction:column;margin-left:auto;margin-right:auto;background:var(--jp-layout-color1);padding:24px;padding-bottom:12px;min-width:300px;min-height:150px;max-width:1000px;max-height:500px;box-sizing:border-box;box-shadow:var(--jp-elevation-z20);word-wrap:break-word;border-radius:var(--jp-border-radius);font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color1)}.jupyter-wrapper .jp-Dialog-button{overflow:visible}.jupyter-wrapper button.jp-Dialog-button:focus{outline:1px solid var(--jp-brand-color1);outline-offset:4px;-moz-outline-radius:0px}.jupyter-wrapper button.jp-Dialog-button:focus::-moz-focus-inner{border:0}.jupyter-wrapper .jp-Dialog-header{flex:0 0 auto;padding-bottom:12px;font-size:var(--jp-ui-font-size3);font-weight:400;color:var(--jp-ui-font-color0)}.jupyter-wrapper .jp-Dialog-body{display:flex;flex-direction:column;flex:1 1 auto;font-size:var(--jp-ui-font-size1);background:var(--jp-layout-color1);overflow:auto}.jupyter-wrapper .jp-Dialog-footer{display:flex;flex-direction:row;justify-content:flex-end;flex:0 0 auto;margin-left:-12px;margin-right:-12px;padding:12px}.jupyter-wrapper .jp-Dialog-title{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .jp-Dialog-body>.jp-select-wrapper{width:100%}.jupyter-wrapper .jp-Dialog-body>button{padding:0px 16px}.jupyter-wrapper .jp-Dialog-body>label{line-height:1.4;color:var(--jp-ui-font-color0)}.jupyter-wrapper .jp-Dialog-button.jp-mod-styled:not(:last-child){margin-right:12px}.jupyter-wrapper .jp-HoverBox{position:fixed}.jupyter-wrapper .jp-HoverBox.jp-mod-outofview{display:none}.jupyter-wrapper .jp-IFrame{width:100%;height:100%}.jupyter-wrapper .jp-IFrame>iframe{border:none}.jupyter-wrapper body.lm-mod-override-cursor .jp-IFrame{position:relative}.jupyter-wrapper body.lm-mod-override-cursor .jp-IFrame:before{content:"";position:absolute;top:0;left:0;right:0;bottom:0;background:rgba(0,0,0,0)}.jupyter-wrapper .jp-MainAreaWidget>:focus{outline:none}.jupyter-wrapper :root{--md-red-50: #ffebee;--md-red-100: #ffcdd2;--md-red-200: #ef9a9a;--md-red-300: #e57373;--md-red-400: #ef5350;--md-red-500: #f44336;--md-red-600: #e53935;--md-red-700: #d32f2f;--md-red-800: #c62828;--md-red-900: #b71c1c;--md-red-A100: #ff8a80;--md-red-A200: #ff5252;--md-red-A400: #ff1744;--md-red-A700: #d50000;--md-pink-50: #fce4ec;--md-pink-100: #f8bbd0;--md-pink-200: #f48fb1;--md-pink-300: #f06292;--md-pink-400: #ec407a;--md-pink-500: #e91e63;--md-pink-600: #d81b60;--md-pink-700: #c2185b;--md-pink-800: #ad1457;--md-pink-900: #880e4f;--md-pink-A100: #ff80ab;--md-pink-A200: #ff4081;--md-pink-A400: #f50057;--md-pink-A700: #c51162;--md-purple-50: #f3e5f5;--md-purple-100: #e1bee7;--md-purple-200: #ce93d8;--md-purple-300: #ba68c8;--md-purple-400: #ab47bc;--md-purple-500: #9c27b0;--md-purple-600: #8e24aa;--md-purple-700: #7b1fa2;--md-purple-800: #6a1b9a;--md-purple-900: #4a148c;--md-purple-A100: #ea80fc;--md-purple-A200: #e040fb;--md-purple-A400: #d500f9;--md-purple-A700: #aa00ff;--md-deep-purple-50: #ede7f6;--md-deep-purple-100: #d1c4e9;--md-deep-purple-200: #b39ddb;--md-deep-purple-300: #9575cd;--md-deep-purple-400: #7e57c2;--md-deep-purple-500: #673ab7;--md-deep-purple-600: #5e35b1;--md-deep-purple-700: #512da8;--md-deep-purple-800: #4527a0;--md-deep-purple-900: #311b92;--md-deep-purple-A100: #b388ff;--md-deep-purple-A200: #7c4dff;--md-deep-purple-A400: #651fff;--md-deep-purple-A700: #6200ea;--md-indigo-50: #e8eaf6;--md-indigo-100: #c5cae9;--md-indigo-200: #9fa8da;--md-indigo-300: #7986cb;--md-indigo-400: #5c6bc0;--md-indigo-500: #3f51b5;--md-indigo-600: #3949ab;--md-indigo-700: #303f9f;--md-indigo-800: #283593;--md-indigo-900: #1a237e;--md-indigo-A100: #8c9eff;--md-indigo-A200: #536dfe;--md-indigo-A400: #3d5afe;--md-indigo-A700: #304ffe;--md-blue-50: #e3f2fd;--md-blue-100: #bbdefb;--md-blue-200: #90caf9;--md-blue-300: #64b5f6;--md-blue-400: #42a5f5;--md-blue-500: #2196f3;--md-blue-600: #1e88e5;--md-blue-700: #1976d2;--md-blue-800: #1565c0;--md-blue-900: #0d47a1;--md-blue-A100: #82b1ff;--md-blue-A200: #448aff;--md-blue-A400: #2979ff;--md-blue-A700: #2962ff;--md-light-blue-50: #e1f5fe;--md-light-blue-100: #b3e5fc;--md-light-blue-200: #81d4fa;--md-light-blue-300: #4fc3f7;--md-light-blue-400: #29b6f6;--md-light-blue-500: #03a9f4;--md-light-blue-600: #039be5;--md-light-blue-700: #0288d1;--md-light-blue-800: #0277bd;--md-light-blue-900: #01579b;--md-light-blue-A100: #80d8ff;--md-light-blue-A200: #40c4ff;--md-light-blue-A400: #00b0ff;--md-light-blue-A700: #0091ea;--md-cyan-50: #e0f7fa;--md-cyan-100: #b2ebf2;--md-cyan-200: #80deea;--md-cyan-300: #4dd0e1;--md-cyan-400: #26c6da;--md-cyan-500: #00bcd4;--md-cyan-600: #00acc1;--md-cyan-700: #0097a7;--md-cyan-800: #00838f;--md-cyan-900: #006064;--md-cyan-A100: #84ffff;--md-cyan-A200: #18ffff;--md-cyan-A400: #00e5ff;--md-cyan-A700: #00b8d4;--md-teal-50: #e0f2f1;--md-teal-100: #b2dfdb;--md-teal-200: #80cbc4;--md-teal-300: #4db6ac;--md-teal-400: #26a69a;--md-teal-500: #009688;--md-teal-600: #00897b;--md-teal-700: #00796b;--md-teal-800: #00695c;--md-teal-900: #004d40;--md-teal-A100: #a7ffeb;--md-teal-A200: #64ffda;--md-teal-A400: #1de9b6;--md-teal-A700: #00bfa5;--md-green-50: #e8f5e9;--md-green-100: #c8e6c9;--md-green-200: #a5d6a7;--md-green-300: #81c784;--md-green-400: #66bb6a;--md-green-500: #4caf50;--md-green-600: #43a047;--md-green-700: #388e3c;--md-green-800: #2e7d32;--md-green-900: #1b5e20;--md-green-A100: #b9f6ca;--md-green-A200: #69f0ae;--md-green-A400: #00e676;--md-green-A700: #00c853;--md-light-green-50: #f1f8e9;--md-light-green-100: #dcedc8;--md-light-green-200: #c5e1a5;--md-light-green-300: #aed581;--md-light-green-400: #9ccc65;--md-light-green-500: #8bc34a;--md-light-green-600: #7cb342;--md-light-green-700: #689f38;--md-light-green-800: #558b2f;--md-light-green-900: #33691e;--md-light-green-A100: #ccff90;--md-light-green-A200: #b2ff59;--md-light-green-A400: #76ff03;--md-light-green-A700: #64dd17;--md-lime-50: #f9fbe7;--md-lime-100: #f0f4c3;--md-lime-200: #e6ee9c;--md-lime-300: #dce775;--md-lime-400: #d4e157;--md-lime-500: #cddc39;--md-lime-600: #c0ca33;--md-lime-700: #afb42b;--md-lime-800: #9e9d24;--md-lime-900: #827717;--md-lime-A100: #f4ff81;--md-lime-A200: #eeff41;--md-lime-A400: #c6ff00;--md-lime-A700: #aeea00;--md-yellow-50: #fffde7;--md-yellow-100: #fff9c4;--md-yellow-200: #fff59d;--md-yellow-300: #fff176;--md-yellow-400: #ffee58;--md-yellow-500: #ffeb3b;--md-yellow-600: #fdd835;--md-yellow-700: #fbc02d;--md-yellow-800: #f9a825;--md-yellow-900: #f57f17;--md-yellow-A100: #ffff8d;--md-yellow-A200: #ffff00;--md-yellow-A400: #ffea00;--md-yellow-A700: #ffd600;--md-amber-50: #fff8e1;--md-amber-100: #ffecb3;--md-amber-200: #ffe082;--md-amber-300: #ffd54f;--md-amber-400: #ffca28;--md-amber-500: #ffc107;--md-amber-600: #ffb300;--md-amber-700: #ffa000;--md-amber-800: #ff8f00;--md-amber-900: #ff6f00;--md-amber-A100: #ffe57f;--md-amber-A200: #ffd740;--md-amber-A400: #ffc400;--md-amber-A700: #ffab00;--md-orange-50: #fff3e0;--md-orange-100: #ffe0b2;--md-orange-200: #ffcc80;--md-orange-300: #ffb74d;--md-orange-400: #ffa726;--md-orange-500: #ff9800;--md-orange-600: #fb8c00;--md-orange-700: #f57c00;--md-orange-800: #ef6c00;--md-orange-900: #e65100;--md-orange-A100: #ffd180;--md-orange-A200: #ffab40;--md-orange-A400: #ff9100;--md-orange-A700: #ff6d00;--md-deep-orange-50: #fbe9e7;--md-deep-orange-100: #ffccbc;--md-deep-orange-200: #ffab91;--md-deep-orange-300: #ff8a65;--md-deep-orange-400: #ff7043;--md-deep-orange-500: #ff5722;--md-deep-orange-600: #f4511e;--md-deep-orange-700: #e64a19;--md-deep-orange-800: #d84315;--md-deep-orange-900: #bf360c;--md-deep-orange-A100: #ff9e80;--md-deep-orange-A200: #ff6e40;--md-deep-orange-A400: #ff3d00;--md-deep-orange-A700: #dd2c00;--md-brown-50: #efebe9;--md-brown-100: #d7ccc8;--md-brown-200: #bcaaa4;--md-brown-300: #a1887f;--md-brown-400: #8d6e63;--md-brown-500: #795548;--md-brown-600: #6d4c41;--md-brown-700: #5d4037;--md-brown-800: #4e342e;--md-brown-900: #3e2723;--md-grey-50: #fafafa;--md-grey-100: #f5f5f5;--md-grey-200: #eeeeee;--md-grey-300: #e0e0e0;--md-grey-400: #bdbdbd;--md-grey-500: #9e9e9e;--md-grey-600: #757575;--md-grey-700: #616161;--md-grey-800: #424242;--md-grey-900: #212121;--md-blue-grey-50: #eceff1;--md-blue-grey-100: #cfd8dc;--md-blue-grey-200: #b0bec5;--md-blue-grey-300: #90a4ae;--md-blue-grey-400: #78909c;--md-blue-grey-500: #607d8b;--md-blue-grey-600: #546e7a;--md-blue-grey-700: #455a64;--md-blue-grey-800: #37474f;--md-blue-grey-900: #263238}.jupyter-wrapper .jp-Spinner{position:absolute;display:flex;justify-content:center;align-items:center;z-index:10;left:0;top:0;width:100%;height:100%;background:var(--jp-layout-color0);outline:none}.jupyter-wrapper .jp-SpinnerContent{font-size:10px;margin:50px auto;text-indent:-9999em;width:3em;height:3em;border-radius:50%;background:var(--jp-brand-color3);background:linear-gradient(to right, #f37626 10%, rgba(255, 255, 255, 0) 42%);position:relative;animation:load3 1s infinite linear,fadeIn 1s}.jupyter-wrapper .jp-SpinnerContent:before{width:50%;height:50%;background:#f37626;border-radius:100% 0 0 0;position:absolute;top:0;left:0;content:""}.jupyter-wrapper .jp-SpinnerContent:after{background:var(--jp-layout-color0);width:75%;height:75%;border-radius:50%;content:"";margin:auto;position:absolute;top:0;left:0;bottom:0;right:0}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}@keyframes load3{0%{transform:rotate(0deg)}100%{transform:rotate(360deg)}}.jupyter-wrapper button.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:none;box-sizing:border-box;text-align:center;line-height:32px;height:32px;padding:0px 12px;letter-spacing:.8px;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper input.jp-mod-styled{background:var(--jp-input-background);height:28px;box-sizing:border-box;border:var(--jp-border-width) solid var(--jp-border-color1);padding-left:7px;padding-right:7px;font-size:var(--jp-ui-font-size2);color:var(--jp-ui-font-color0);outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper input.jp-mod-styled:focus{border:var(--jp-border-width) solid var(--md-blue-500);box-shadow:inset 0 0 4px var(--md-blue-300)}.jupyter-wrapper .jp-select-wrapper{display:flex;position:relative;flex-direction:column;padding:1px;background-color:var(--jp-layout-color1);height:28px;box-sizing:border-box;margin-bottom:12px}.jupyter-wrapper .jp-select-wrapper.jp-mod-focused select.jp-mod-styled{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-input-active-background)}.jupyter-wrapper select.jp-mod-styled:hover{background-color:var(--jp-layout-color1);cursor:pointer;color:var(--jp-ui-font-color0);background-color:var(--jp-input-hover-background);box-shadow:inset 0 0px 1px rgba(0,0,0,.5)}.jupyter-wrapper select.jp-mod-styled{flex:1 1 auto;height:32px;width:100%;font-size:var(--jp-ui-font-size2);background:var(--jp-input-background);color:var(--jp-ui-font-color0);padding:0 25px 0 8px;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0px;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper :root{--jp-private-toolbar-height: calc( 28px + var(--jp-border-width) )}.jupyter-wrapper .jp-Toolbar{color:var(--jp-ui-font-color1);flex:0 0 auto;display:flex;flex-direction:row;border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);background:var(--jp-toolbar-background);min-height:var(--jp-toolbar-micro-height);padding:2px;z-index:1}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-item.jp-Toolbar-spacer{flex-grow:1;flex-shrink:1}.jupyter-wrapper .jp-Toolbar-item.jp-Toolbar-kernelStatus{display:inline-block;width:32px;background-repeat:no-repeat;background-position:center;background-size:16px}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-item{flex:0 0 auto;display:flex;padding-left:1px;padding-right:1px;font-size:var(--jp-ui-font-size1);line-height:var(--jp-private-toolbar-height);height:100%}.jupyter-wrapper div.jp-ToolbarButton{color:rgba(0,0,0,0);border:none;box-sizing:border-box;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0px;margin:0px}.jupyter-wrapper button.jp-ToolbarButtonComponent{background:var(--jp-layout-color1);border:none;box-sizing:border-box;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0px 6px;margin:0px;height:24px;border-radius:var(--jp-border-radius);display:flex;align-items:center;text-align:center;font-size:14px;min-width:unset;min-height:unset}.jupyter-wrapper button.jp-ToolbarButtonComponent:disabled{opacity:.4}.jupyter-wrapper button.jp-ToolbarButtonComponent span{padding:0px;flex:0 0 auto}.jupyter-wrapper button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label{font-size:var(--jp-ui-font-size1);line-height:100%;padding-left:2px;color:var(--jp-ui-font-color1)}.jupyter-wrapper body.p-mod-override-cursor *,.jupyter-wrapper body.lm-mod-override-cursor *{cursor:inherit !important}.jupyter-wrapper .jp-JSONEditor{display:flex;flex-direction:column;width:100%}.jupyter-wrapper .jp-JSONEditor-host{flex:1 1 auto;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0px;background:var(--jp-layout-color0);min-height:50px;padding:1px}.jupyter-wrapper .jp-JSONEditor.jp-mod-error .jp-JSONEditor-host{border-color:red;outline-color:red}.jupyter-wrapper .jp-JSONEditor-header{display:flex;flex:1 0 auto;padding:0 0 0 12px}.jupyter-wrapper .jp-JSONEditor-header label{flex:0 0 auto}.jupyter-wrapper .jp-JSONEditor-commitButton{height:16px;width:16px;background-size:18px;background-repeat:no-repeat;background-position:center}.jupyter-wrapper .jp-JSONEditor-host.jp-mod-focused{background-color:var(--jp-input-active-background);border:1px solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jupyter-wrapper .jp-Editor.jp-mod-dropTarget{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jupyter-wrapper .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.jupyter-wrapper .CodeMirror-lines{padding:4px 0}.jupyter-wrapper .CodeMirror pre.CodeMirror-line,.jupyter-wrapper .CodeMirror pre.CodeMirror-line-like{padding:0 4px}.jupyter-wrapper .CodeMirror-scrollbar-filler,.jupyter-wrapper .CodeMirror-gutter-filler{background-color:#fff}.jupyter-wrapper .CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.jupyter-wrapper .CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.jupyter-wrapper .CodeMirror-guttermarker{color:#000}.jupyter-wrapper .CodeMirror-guttermarker-subtle{color:#999}.jupyter-wrapper .CodeMirror-cursor{border-left:1px solid #000;border-right:none;width:0}.jupyter-wrapper .CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.jupyter-wrapper .cm-fat-cursor .CodeMirror-cursor{width:auto;border:0 !important;background:#7e7}.jupyter-wrapper .cm-fat-cursor div.CodeMirror-cursors{z-index:1}.jupyter-wrapper .cm-fat-cursor-mark{background-color:rgba(20,255,20,.5);-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite}.jupyter-wrapper .cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:rgba(0,0,0,0)}}@-webkit-keyframes blink{50%{background-color:rgba(0,0,0,0)}}@keyframes blink{50%{background-color:rgba(0,0,0,0)}}.jupyter-wrapper .cm-tab{display:inline-block;text-decoration:inherit}.jupyter-wrapper .CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:0;overflow:hidden}.jupyter-wrapper .CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.jupyter-wrapper .cm-s-default .cm-header{color:blue}.jupyter-wrapper .cm-s-default .cm-quote{color:#090}.jupyter-wrapper .cm-negative{color:#d44}.jupyter-wrapper .cm-positive{color:#292}.jupyter-wrapper .cm-header,.jupyter-wrapper .cm-strong{font-weight:bold}.jupyter-wrapper .cm-em{font-style:italic}.jupyter-wrapper .cm-link{text-decoration:underline}.jupyter-wrapper .cm-strikethrough{text-decoration:line-through}.jupyter-wrapper .cm-s-default .cm-keyword{color:#708}.jupyter-wrapper .cm-s-default .cm-atom{color:#219}.jupyter-wrapper .cm-s-default .cm-number{color:#164}.jupyter-wrapper .cm-s-default .cm-def{color:blue}.jupyter-wrapper .cm-s-default .cm-variable-2{color:#05a}.jupyter-wrapper .cm-s-default .cm-variable-3,.jupyter-wrapper .cm-s-default .cm-type{color:#085}.jupyter-wrapper .cm-s-default .cm-comment{color:#a50}.jupyter-wrapper .cm-s-default .cm-string{color:#a11}.jupyter-wrapper .cm-s-default .cm-string-2{color:#f50}.jupyter-wrapper .cm-s-default .cm-meta{color:#555}.jupyter-wrapper .cm-s-default .cm-qualifier{color:#555}.jupyter-wrapper .cm-s-default .cm-builtin{color:#30a}.jupyter-wrapper .cm-s-default .cm-bracket{color:#997}.jupyter-wrapper .cm-s-default .cm-tag{color:#170}.jupyter-wrapper .cm-s-default .cm-attribute{color:#00c}.jupyter-wrapper .cm-s-default .cm-hr{color:#999}.jupyter-wrapper .cm-s-default .cm-link{color:#00c}.jupyter-wrapper .cm-s-default .cm-error{color:red}.jupyter-wrapper .cm-invalidchar{color:red}.jupyter-wrapper .CodeMirror-composing{border-bottom:2px solid}.jupyter-wrapper div.CodeMirror span.CodeMirror-matchingbracket{color:#0b0}.jupyter-wrapper div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#a22}.jupyter-wrapper .CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.jupyter-wrapper .CodeMirror-activeline-background{background:#e8f2ff}.jupyter-wrapper .CodeMirror{position:relative;overflow:hidden;background:#fff}.jupyter-wrapper .CodeMirror-scroll{overflow:scroll !important;margin-bottom:-30px;margin-right:-30px;padding-bottom:30px;height:100%;outline:none;position:relative}.jupyter-wrapper .CodeMirror-sizer{position:relative;border-right:30px solid rgba(0,0,0,0)}.jupyter-wrapper .CodeMirror-vscrollbar,.jupyter-wrapper .CodeMirror-hscrollbar,.jupyter-wrapper .CodeMirror-scrollbar-filler,.jupyter-wrapper .CodeMirror-gutter-filler{position:absolute;z-index:6;display:none}.jupyter-wrapper .CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.jupyter-wrapper .CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.jupyter-wrapper .CodeMirror-scrollbar-filler{right:0;bottom:0}.jupyter-wrapper .CodeMirror-gutter-filler{left:0;bottom:0}.jupyter-wrapper .CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.jupyter-wrapper .CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-30px}.jupyter-wrapper .CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:none !important;border:none !important}.jupyter-wrapper .CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.jupyter-wrapper .CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.jupyter-wrapper .CodeMirror-gutter-wrapper ::selection{background-color:rgba(0,0,0,0)}.jupyter-wrapper .CodeMirror-gutter-wrapper ::-moz-selection{background-color:rgba(0,0,0,0)}.jupyter-wrapper .CodeMirror-lines{cursor:text;min-height:1px}.jupyter-wrapper .CodeMirror pre.CodeMirror-line,.jupyter-wrapper .CodeMirror pre.CodeMirror-line-like{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:rgba(0,0,0,0);font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.jupyter-wrapper .CodeMirror-wrap pre.CodeMirror-line,.jupyter-wrapper .CodeMirror-wrap pre.CodeMirror-line-like{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.jupyter-wrapper .CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.jupyter-wrapper .CodeMirror-linewidget{position:relative;z-index:2;padding:.1px}.jupyter-wrapper .CodeMirror-rtl pre{direction:rtl}.jupyter-wrapper .CodeMirror-code{outline:none}.jupyter-wrapper .CodeMirror-scroll,.jupyter-wrapper .CodeMirror-sizer,.jupyter-wrapper .CodeMirror-gutter,.jupyter-wrapper .CodeMirror-gutters,.jupyter-wrapper .CodeMirror-linenumber{-moz-box-sizing:content-box;box-sizing:content-box}.jupyter-wrapper .CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.jupyter-wrapper .CodeMirror-cursor{position:absolute;pointer-events:none}.jupyter-wrapper .CodeMirror-measure pre{position:static}.jupyter-wrapper div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}.jupyter-wrapper div.CodeMirror-dragcursors{visibility:visible}.jupyter-wrapper .CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.jupyter-wrapper .CodeMirror-selected{background:#d9d9d9}.jupyter-wrapper .CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.jupyter-wrapper .CodeMirror-crosshair{cursor:crosshair}.jupyter-wrapper .CodeMirror-line::selection,.jupyter-wrapper .CodeMirror-line>span::selection,.jupyter-wrapper .CodeMirror-line>span>span::selection{background:#d7d4f0}.jupyter-wrapper .CodeMirror-line::-moz-selection,.jupyter-wrapper .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.jupyter-wrapper .cm-searching{background-color:#ffa;background-color:rgba(255,255,0,.4)}.jupyter-wrapper .cm-force-border{padding-right:.1px}@media print{.jupyter-wrapper .CodeMirror div.CodeMirror-cursors{visibility:hidden}}.jupyter-wrapper .cm-tab-wrap-hack:after{content:""}.jupyter-wrapper span.CodeMirror-selectedtext{background:none}.jupyter-wrapper .CodeMirror-dialog{position:absolute;left:0;right:0;background:inherit;z-index:15;padding:.1em .8em;overflow:hidden;color:inherit}.jupyter-wrapper .CodeMirror-dialog-top{border-bottom:1px solid #eee;top:0}.jupyter-wrapper .CodeMirror-dialog-bottom{border-top:1px solid #eee;bottom:0}.jupyter-wrapper .CodeMirror-dialog input{border:none;outline:none;background:rgba(0,0,0,0);width:20em;color:inherit;font-family:monospace}.jupyter-wrapper .CodeMirror-dialog button{font-size:70%}.jupyter-wrapper .CodeMirror-foldmarker{color:blue;text-shadow:#b9f 1px 1px 2px,#b9f -1px -1px 2px,#b9f 1px -1px 2px,#b9f -1px 1px 2px;font-family:arial;line-height:.3;cursor:pointer}.jupyter-wrapper .CodeMirror-foldgutter{width:.7em}.jupyter-wrapper .CodeMirror-foldgutter-open,.jupyter-wrapper .CodeMirror-foldgutter-folded{cursor:pointer}.jupyter-wrapper .CodeMirror-foldgutter-open:after{content:""}.jupyter-wrapper .CodeMirror-foldgutter-folded:after{content:""}.jupyter-wrapper .cm-s-material.CodeMirror{background-color:#263238;color:#eff}.jupyter-wrapper .cm-s-material .CodeMirror-gutters{background:#263238;color:#546e7a;border:none}.jupyter-wrapper .cm-s-material .CodeMirror-guttermarker,.jupyter-wrapper .cm-s-material .CodeMirror-guttermarker-subtle,.jupyter-wrapper .cm-s-material .CodeMirror-linenumber{color:#546e7a}.jupyter-wrapper .cm-s-material .CodeMirror-cursor{border-left:1px solid #fc0}.jupyter-wrapper .cm-s-material div.CodeMirror-selected{background:rgba(128,203,196,.2)}.jupyter-wrapper .cm-s-material.CodeMirror-focused div.CodeMirror-selected{background:rgba(128,203,196,.2)}.jupyter-wrapper .cm-s-material .CodeMirror-line::selection,.jupyter-wrapper .cm-s-material .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-material .CodeMirror-line>span>span::selection{background:rgba(128,203,196,.2)}.jupyter-wrapper .cm-s-material .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-material .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-material .CodeMirror-line>span>span::-moz-selection{background:rgba(128,203,196,.2)}.jupyter-wrapper .cm-s-material .CodeMirror-activeline-background{background:rgba(0,0,0,.5)}.jupyter-wrapper .cm-s-material .cm-keyword{color:#c792ea}.jupyter-wrapper .cm-s-material .cm-operator{color:#89ddff}.jupyter-wrapper .cm-s-material .cm-variable-2{color:#eff}.jupyter-wrapper .cm-s-material .cm-variable-3,.jupyter-wrapper .cm-s-material .cm-type{color:#f07178}.jupyter-wrapper .cm-s-material .cm-builtin{color:#ffcb6b}.jupyter-wrapper .cm-s-material .cm-atom{color:#f78c6c}.jupyter-wrapper .cm-s-material .cm-number{color:#ff5370}.jupyter-wrapper .cm-s-material .cm-def{color:#82aaff}.jupyter-wrapper .cm-s-material .cm-string{color:#c3e88d}.jupyter-wrapper .cm-s-material .cm-string-2{color:#f07178}.jupyter-wrapper .cm-s-material .cm-comment{color:#546e7a}.jupyter-wrapper .cm-s-material .cm-variable{color:#f07178}.jupyter-wrapper .cm-s-material .cm-tag{color:#ff5370}.jupyter-wrapper .cm-s-material .cm-meta{color:#ffcb6b}.jupyter-wrapper .cm-s-material .cm-attribute{color:#c792ea}.jupyter-wrapper .cm-s-material .cm-property{color:#c792ea}.jupyter-wrapper .cm-s-material .cm-qualifier{color:#decb6b}.jupyter-wrapper .cm-s-material .cm-variable-3,.jupyter-wrapper .cm-s-material .cm-type{color:#decb6b}.jupyter-wrapper .cm-s-material .cm-error{color:#fff;background-color:#ff5370}.jupyter-wrapper .cm-s-material .CodeMirror-matchingbracket{text-decoration:underline;color:#fff !important}.jupyter-wrapper .cm-s-zenburn .CodeMirror-gutters{background:#3f3f3f !important}.jupyter-wrapper .cm-s-zenburn .CodeMirror-foldgutter-open,.jupyter-wrapper .CodeMirror-foldgutter-folded{color:#999}.jupyter-wrapper .cm-s-zenburn .CodeMirror-cursor{border-left:1px solid #fff}.jupyter-wrapper .cm-s-zenburn{background-color:#3f3f3f;color:#dcdccc}.jupyter-wrapper .cm-s-zenburn span.cm-builtin{color:#dcdccc;font-weight:bold}.jupyter-wrapper .cm-s-zenburn span.cm-comment{color:#7f9f7f}.jupyter-wrapper .cm-s-zenburn span.cm-keyword{color:#f0dfaf;font-weight:bold}.jupyter-wrapper .cm-s-zenburn span.cm-atom{color:#bfebbf}.jupyter-wrapper .cm-s-zenburn span.cm-def{color:#dcdccc}.jupyter-wrapper .cm-s-zenburn span.cm-variable{color:#dfaf8f}.jupyter-wrapper .cm-s-zenburn span.cm-variable-2{color:#dcdccc}.jupyter-wrapper .cm-s-zenburn span.cm-string{color:#cc9393}.jupyter-wrapper .cm-s-zenburn span.cm-string-2{color:#cc9393}.jupyter-wrapper .cm-s-zenburn span.cm-number{color:#dcdccc}.jupyter-wrapper .cm-s-zenburn span.cm-tag{color:#93e0e3}.jupyter-wrapper .cm-s-zenburn span.cm-property{color:#dfaf8f}.jupyter-wrapper .cm-s-zenburn span.cm-attribute{color:#dfaf8f}.jupyter-wrapper .cm-s-zenburn span.cm-qualifier{color:#7cb8bb}.jupyter-wrapper .cm-s-zenburn span.cm-meta{color:#f0dfaf}.jupyter-wrapper .cm-s-zenburn span.cm-header{color:#f0efd0}.jupyter-wrapper .cm-s-zenburn span.cm-operator{color:#f0efd0}.jupyter-wrapper .cm-s-zenburn span.CodeMirror-matchingbracket{box-sizing:border-box;background:rgba(0,0,0,0);border-bottom:1px solid}.jupyter-wrapper .cm-s-zenburn span.CodeMirror-nonmatchingbracket{border-bottom:1px solid;background:none}.jupyter-wrapper .cm-s-zenburn .CodeMirror-activeline{background:#000}.jupyter-wrapper .cm-s-zenburn .CodeMirror-activeline-background{background:#000}.jupyter-wrapper .cm-s-zenburn div.CodeMirror-selected{background:#545454}.jupyter-wrapper .cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected{background:#4f4f4f}.jupyter-wrapper .cm-s-abcdef.CodeMirror{background:#0f0f0f;color:#defdef}.jupyter-wrapper .cm-s-abcdef div.CodeMirror-selected{background:#515151}.jupyter-wrapper .cm-s-abcdef .CodeMirror-line::selection,.jupyter-wrapper .cm-s-abcdef .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-abcdef .CodeMirror-line>span>span::selection{background:rgba(56,56,56,.99)}.jupyter-wrapper .cm-s-abcdef .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-abcdef .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-abcdef .CodeMirror-line>span>span::-moz-selection{background:rgba(56,56,56,.99)}.jupyter-wrapper .cm-s-abcdef .CodeMirror-gutters{background:#555;border-right:2px solid #314151}.jupyter-wrapper .cm-s-abcdef .CodeMirror-guttermarker{color:#222}.jupyter-wrapper .cm-s-abcdef .CodeMirror-guttermarker-subtle{color:azure}.jupyter-wrapper .cm-s-abcdef .CodeMirror-linenumber{color:#fff}.jupyter-wrapper .cm-s-abcdef .CodeMirror-cursor{border-left:1px solid lime}.jupyter-wrapper .cm-s-abcdef span.cm-keyword{color:#b8860b;font-weight:bold}.jupyter-wrapper .cm-s-abcdef span.cm-atom{color:#77f}.jupyter-wrapper .cm-s-abcdef span.cm-number{color:violet}.jupyter-wrapper .cm-s-abcdef span.cm-def{color:#fffabc}.jupyter-wrapper .cm-s-abcdef span.cm-variable{color:#abcdef}.jupyter-wrapper .cm-s-abcdef span.cm-variable-2{color:#cacbcc}.jupyter-wrapper .cm-s-abcdef span.cm-variable-3,.jupyter-wrapper .cm-s-abcdef span.cm-type{color:#def}.jupyter-wrapper .cm-s-abcdef span.cm-property{color:#fedcba}.jupyter-wrapper .cm-s-abcdef span.cm-operator{color:#ff0}.jupyter-wrapper .cm-s-abcdef span.cm-comment{color:#7a7b7c;font-style:italic}.jupyter-wrapper .cm-s-abcdef span.cm-string{color:#2b4}.jupyter-wrapper .cm-s-abcdef span.cm-meta{color:#c9f}.jupyter-wrapper .cm-s-abcdef span.cm-qualifier{color:#fff700}.jupyter-wrapper .cm-s-abcdef span.cm-builtin{color:#30aabc}.jupyter-wrapper .cm-s-abcdef span.cm-bracket{color:#8a8a8a}.jupyter-wrapper .cm-s-abcdef span.cm-tag{color:#fd4}.jupyter-wrapper .cm-s-abcdef span.cm-attribute{color:#df0}.jupyter-wrapper .cm-s-abcdef span.cm-error{color:red}.jupyter-wrapper .cm-s-abcdef span.cm-header{color:#7fffd4;font-weight:bold}.jupyter-wrapper .cm-s-abcdef span.cm-link{color:#8a2be2}.jupyter-wrapper .cm-s-abcdef .CodeMirror-activeline-background{background:#314151}.jupyter-wrapper .cm-s-base16-light.CodeMirror{background:#f5f5f5;color:#202020}.jupyter-wrapper .cm-s-base16-light div.CodeMirror-selected{background:#e0e0e0}.jupyter-wrapper .cm-s-base16-light .CodeMirror-line::selection,.jupyter-wrapper .cm-s-base16-light .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-base16-light .CodeMirror-line>span>span::selection{background:#e0e0e0}.jupyter-wrapper .cm-s-base16-light .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-base16-light .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-base16-light .CodeMirror-line>span>span::-moz-selection{background:#e0e0e0}.jupyter-wrapper .cm-s-base16-light .CodeMirror-gutters{background:#f5f5f5;border-right:0px}.jupyter-wrapper .cm-s-base16-light .CodeMirror-guttermarker{color:#ac4142}.jupyter-wrapper .cm-s-base16-light .CodeMirror-guttermarker-subtle{color:#b0b0b0}.jupyter-wrapper .cm-s-base16-light .CodeMirror-linenumber{color:#b0b0b0}.jupyter-wrapper .cm-s-base16-light .CodeMirror-cursor{border-left:1px solid #505050}.jupyter-wrapper .cm-s-base16-light span.cm-comment{color:#8f5536}.jupyter-wrapper .cm-s-base16-light span.cm-atom{color:#aa759f}.jupyter-wrapper .cm-s-base16-light span.cm-number{color:#aa759f}.jupyter-wrapper .cm-s-base16-light span.cm-property,.jupyter-wrapper .cm-s-base16-light span.cm-attribute{color:#90a959}.jupyter-wrapper .cm-s-base16-light span.cm-keyword{color:#ac4142}.jupyter-wrapper .cm-s-base16-light span.cm-string{color:#f4bf75}.jupyter-wrapper .cm-s-base16-light span.cm-variable{color:#90a959}.jupyter-wrapper .cm-s-base16-light span.cm-variable-2{color:#6a9fb5}.jupyter-wrapper .cm-s-base16-light span.cm-def{color:#d28445}.jupyter-wrapper .cm-s-base16-light span.cm-bracket{color:#202020}.jupyter-wrapper .cm-s-base16-light span.cm-tag{color:#ac4142}.jupyter-wrapper .cm-s-base16-light span.cm-link{color:#aa759f}.jupyter-wrapper .cm-s-base16-light span.cm-error{background:#ac4142;color:#505050}.jupyter-wrapper .cm-s-base16-light .CodeMirror-activeline-background{background:#dddcdc}.jupyter-wrapper .cm-s-base16-light .CodeMirror-matchingbracket{color:#f5f5f5 !important;background-color:#6a9fb5 !important}.jupyter-wrapper .cm-s-base16-dark.CodeMirror{background:#151515;color:#e0e0e0}.jupyter-wrapper .cm-s-base16-dark div.CodeMirror-selected{background:#303030}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-line::selection,.jupyter-wrapper .cm-s-base16-dark .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-base16-dark .CodeMirror-line>span>span::selection{background:rgba(48,48,48,.99)}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-base16-dark .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-base16-dark .CodeMirror-line>span>span::-moz-selection{background:rgba(48,48,48,.99)}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-gutters{background:#151515;border-right:0px}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-guttermarker{color:#ac4142}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-guttermarker-subtle{color:#505050}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-linenumber{color:#505050}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-cursor{border-left:1px solid #b0b0b0}.jupyter-wrapper .cm-s-base16-dark span.cm-comment{color:#8f5536}.jupyter-wrapper .cm-s-base16-dark span.cm-atom{color:#aa759f}.jupyter-wrapper .cm-s-base16-dark span.cm-number{color:#aa759f}.jupyter-wrapper .cm-s-base16-dark span.cm-property,.jupyter-wrapper .cm-s-base16-dark span.cm-attribute{color:#90a959}.jupyter-wrapper .cm-s-base16-dark span.cm-keyword{color:#ac4142}.jupyter-wrapper .cm-s-base16-dark span.cm-string{color:#f4bf75}.jupyter-wrapper .cm-s-base16-dark span.cm-variable{color:#90a959}.jupyter-wrapper .cm-s-base16-dark span.cm-variable-2{color:#6a9fb5}.jupyter-wrapper .cm-s-base16-dark span.cm-def{color:#d28445}.jupyter-wrapper .cm-s-base16-dark span.cm-bracket{color:#e0e0e0}.jupyter-wrapper .cm-s-base16-dark span.cm-tag{color:#ac4142}.jupyter-wrapper .cm-s-base16-dark span.cm-link{color:#aa759f}.jupyter-wrapper .cm-s-base16-dark span.cm-error{background:#ac4142;color:#b0b0b0}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-activeline-background{background:#202020}.jupyter-wrapper .cm-s-base16-dark .CodeMirror-matchingbracket{text-decoration:underline;color:#fff !important}.jupyter-wrapper .cm-s-dracula.CodeMirror,.jupyter-wrapper .cm-s-dracula .CodeMirror-gutters{background-color:#282a36 !important;color:#f8f8f2 !important;border:none}.jupyter-wrapper .cm-s-dracula .CodeMirror-gutters{color:#282a36}.jupyter-wrapper .cm-s-dracula .CodeMirror-cursor{border-left:solid thin #f8f8f0}.jupyter-wrapper .cm-s-dracula .CodeMirror-linenumber{color:#6d8a88}.jupyter-wrapper .cm-s-dracula .CodeMirror-selected{background:rgba(255,255,255,.1)}.jupyter-wrapper .cm-s-dracula .CodeMirror-line::selection,.jupyter-wrapper .cm-s-dracula .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-dracula .CodeMirror-line>span>span::selection{background:rgba(255,255,255,.1)}.jupyter-wrapper .cm-s-dracula .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-dracula .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-dracula .CodeMirror-line>span>span::-moz-selection{background:rgba(255,255,255,.1)}.jupyter-wrapper .cm-s-dracula span.cm-comment{color:#6272a4}.jupyter-wrapper .cm-s-dracula span.cm-string,.jupyter-wrapper .cm-s-dracula span.cm-string-2{color:#f1fa8c}.jupyter-wrapper .cm-s-dracula span.cm-number{color:#bd93f9}.jupyter-wrapper .cm-s-dracula span.cm-variable{color:#50fa7b}.jupyter-wrapper .cm-s-dracula span.cm-variable-2{color:#fff}.jupyter-wrapper .cm-s-dracula span.cm-def{color:#50fa7b}.jupyter-wrapper .cm-s-dracula span.cm-operator{color:#ff79c6}.jupyter-wrapper .cm-s-dracula span.cm-keyword{color:#ff79c6}.jupyter-wrapper .cm-s-dracula span.cm-atom{color:#bd93f9}.jupyter-wrapper .cm-s-dracula span.cm-meta{color:#f8f8f2}.jupyter-wrapper .cm-s-dracula span.cm-tag{color:#ff79c6}.jupyter-wrapper .cm-s-dracula span.cm-attribute{color:#50fa7b}.jupyter-wrapper .cm-s-dracula span.cm-qualifier{color:#50fa7b}.jupyter-wrapper .cm-s-dracula span.cm-property{color:#66d9ef}.jupyter-wrapper .cm-s-dracula span.cm-builtin{color:#50fa7b}.jupyter-wrapper .cm-s-dracula span.cm-variable-3,.jupyter-wrapper .cm-s-dracula span.cm-type{color:#ffb86c}.jupyter-wrapper .cm-s-dracula .CodeMirror-activeline-background{background:rgba(255,255,255,.1)}.jupyter-wrapper .cm-s-dracula .CodeMirror-matchingbracket{text-decoration:underline;color:#fff !important}.jupyter-wrapper .cm-s-hopscotch.CodeMirror{background:#322931;color:#d5d3d5}.jupyter-wrapper .cm-s-hopscotch div.CodeMirror-selected{background:#433b42 !important}.jupyter-wrapper .cm-s-hopscotch .CodeMirror-gutters{background:#322931;border-right:0px}.jupyter-wrapper .cm-s-hopscotch .CodeMirror-linenumber{color:#797379}.jupyter-wrapper .cm-s-hopscotch .CodeMirror-cursor{border-left:1px solid #989498 !important}.jupyter-wrapper .cm-s-hopscotch span.cm-comment{color:#b33508}.jupyter-wrapper .cm-s-hopscotch span.cm-atom{color:#c85e7c}.jupyter-wrapper .cm-s-hopscotch span.cm-number{color:#c85e7c}.jupyter-wrapper .cm-s-hopscotch span.cm-property,.jupyter-wrapper .cm-s-hopscotch span.cm-attribute{color:#8fc13e}.jupyter-wrapper .cm-s-hopscotch span.cm-keyword{color:#dd464c}.jupyter-wrapper .cm-s-hopscotch span.cm-string{color:#fdcc59}.jupyter-wrapper .cm-s-hopscotch span.cm-variable{color:#8fc13e}.jupyter-wrapper .cm-s-hopscotch span.cm-variable-2{color:#1290bf}.jupyter-wrapper .cm-s-hopscotch span.cm-def{color:#fd8b19}.jupyter-wrapper .cm-s-hopscotch span.cm-error{background:#dd464c;color:#989498}.jupyter-wrapper .cm-s-hopscotch span.cm-bracket{color:#d5d3d5}.jupyter-wrapper .cm-s-hopscotch span.cm-tag{color:#dd464c}.jupyter-wrapper .cm-s-hopscotch span.cm-link{color:#c85e7c}.jupyter-wrapper .cm-s-hopscotch .CodeMirror-matchingbracket{text-decoration:underline;color:#fff !important}.jupyter-wrapper .cm-s-hopscotch .CodeMirror-activeline-background{background:#302020}.jupyter-wrapper .cm-s-mbo.CodeMirror{background:#2c2c2c;color:#ffffec}.jupyter-wrapper .cm-s-mbo div.CodeMirror-selected{background:#716c62}.jupyter-wrapper .cm-s-mbo .CodeMirror-line::selection,.jupyter-wrapper .cm-s-mbo .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-mbo .CodeMirror-line>span>span::selection{background:rgba(113,108,98,.99)}.jupyter-wrapper .cm-s-mbo .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-mbo .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-mbo .CodeMirror-line>span>span::-moz-selection{background:rgba(113,108,98,.99)}.jupyter-wrapper .cm-s-mbo .CodeMirror-gutters{background:#4e4e4e;border-right:0px}.jupyter-wrapper .cm-s-mbo .CodeMirror-guttermarker{color:#fff}.jupyter-wrapper .cm-s-mbo .CodeMirror-guttermarker-subtle{color:gray}.jupyter-wrapper .cm-s-mbo .CodeMirror-linenumber{color:#dadada}.jupyter-wrapper .cm-s-mbo .CodeMirror-cursor{border-left:1px solid #ffffec}.jupyter-wrapper .cm-s-mbo span.cm-comment{color:#95958a}.jupyter-wrapper .cm-s-mbo span.cm-atom{color:#00a8c6}.jupyter-wrapper .cm-s-mbo span.cm-number{color:#00a8c6}.jupyter-wrapper .cm-s-mbo span.cm-property,.jupyter-wrapper .cm-s-mbo span.cm-attribute{color:#9ddfe9}.jupyter-wrapper .cm-s-mbo span.cm-keyword{color:#ffb928}.jupyter-wrapper .cm-s-mbo span.cm-string{color:#ffcf6c}.jupyter-wrapper .cm-s-mbo span.cm-string.cm-property{color:#ffffec}.jupyter-wrapper .cm-s-mbo span.cm-variable{color:#ffffec}.jupyter-wrapper .cm-s-mbo span.cm-variable-2{color:#00a8c6}.jupyter-wrapper .cm-s-mbo span.cm-def{color:#ffffec}.jupyter-wrapper .cm-s-mbo span.cm-bracket{color:#fffffc;font-weight:bold}.jupyter-wrapper .cm-s-mbo span.cm-tag{color:#9ddfe9}.jupyter-wrapper .cm-s-mbo span.cm-link{color:#f54b07}.jupyter-wrapper .cm-s-mbo span.cm-error{border-bottom:#636363;color:#ffffec}.jupyter-wrapper .cm-s-mbo span.cm-qualifier{color:#ffffec}.jupyter-wrapper .cm-s-mbo .CodeMirror-activeline-background{background:#494b41}.jupyter-wrapper .cm-s-mbo .CodeMirror-matchingbracket{color:#ffb928 !important}.jupyter-wrapper .cm-s-mbo .CodeMirror-matchingtag{background:rgba(255,255,255,.37)}.jupyter-wrapper .cm-s-mdn-like.CodeMirror{color:#999;background-color:#fff}.jupyter-wrapper .cm-s-mdn-like div.CodeMirror-selected{background:#cfc}.jupyter-wrapper .cm-s-mdn-like .CodeMirror-line::selection,.jupyter-wrapper .cm-s-mdn-like .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-mdn-like .CodeMirror-line>span>span::selection{background:#cfc}.jupyter-wrapper .cm-s-mdn-like .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-mdn-like .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-mdn-like .CodeMirror-line>span>span::-moz-selection{background:#cfc}.jupyter-wrapper .cm-s-mdn-like .CodeMirror-gutters{background:#f8f8f8;border-left:6px solid rgba(0,83,159,.65);color:#333}.jupyter-wrapper .cm-s-mdn-like .CodeMirror-linenumber{color:#aaa;padding-left:8px}.jupyter-wrapper .cm-s-mdn-like .CodeMirror-cursor{border-left:2px solid #222}.jupyter-wrapper .cm-s-mdn-like .cm-keyword{color:#6262ff}.jupyter-wrapper .cm-s-mdn-like .cm-atom{color:#f90}.jupyter-wrapper .cm-s-mdn-like .cm-number{color:#ca7841}.jupyter-wrapper .cm-s-mdn-like .cm-def{color:#8da6ce}.jupyter-wrapper .cm-s-mdn-like span.cm-variable-2,.jupyter-wrapper .cm-s-mdn-like span.cm-tag{color:#690}.jupyter-wrapper .cm-s-mdn-like span.cm-variable-3,.jupyter-wrapper .cm-s-mdn-like span.cm-def,.jupyter-wrapper .cm-s-mdn-like span.cm-type{color:#07a}.jupyter-wrapper .cm-s-mdn-like .cm-variable{color:#07a}.jupyter-wrapper .cm-s-mdn-like .cm-property{color:#905}.jupyter-wrapper .cm-s-mdn-like .cm-qualifier{color:#690}.jupyter-wrapper .cm-s-mdn-like .cm-operator{color:#cda869}.jupyter-wrapper .cm-s-mdn-like .cm-comment{color:#777;font-weight:normal}.jupyter-wrapper .cm-s-mdn-like .cm-string{color:#07a;font-style:italic}.jupyter-wrapper .cm-s-mdn-like .cm-string-2{color:#bd6b18}.jupyter-wrapper .cm-s-mdn-like .cm-meta{color:#000}.jupyter-wrapper .cm-s-mdn-like .cm-builtin{color:#9b7536}.jupyter-wrapper .cm-s-mdn-like .cm-tag{color:#997643}.jupyter-wrapper .cm-s-mdn-like .cm-attribute{color:#d6bb6d}.jupyter-wrapper .cm-s-mdn-like .cm-header{color:#ff6400}.jupyter-wrapper .cm-s-mdn-like .cm-hr{color:#aeaeae}.jupyter-wrapper .cm-s-mdn-like .cm-link{color:#ad9361;font-style:italic;text-decoration:none}.jupyter-wrapper .cm-s-mdn-like .cm-error{border-bottom:1px solid red}.jupyter-wrapper div.cm-s-mdn-like .CodeMirror-activeline-background{background:#efefff}.jupyter-wrapper div.cm-s-mdn-like span.CodeMirror-matchingbracket{outline:1px solid gray;color:inherit}.jupyter-wrapper .cm-s-mdn-like.CodeMirror{background-image:url(data:image/png;base64,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)}.jupyter-wrapper .cm-s-seti.CodeMirror{background-color:#151718 !important;color:#cfd2d1 !important;border:none}.jupyter-wrapper .cm-s-seti .CodeMirror-gutters{color:#404b53;background-color:#0e1112;border:none}.jupyter-wrapper .cm-s-seti .CodeMirror-cursor{border-left:solid thin #f8f8f0}.jupyter-wrapper .cm-s-seti .CodeMirror-linenumber{color:#6d8a88}.jupyter-wrapper .cm-s-seti.CodeMirror-focused div.CodeMirror-selected{background:rgba(255,255,255,.1)}.jupyter-wrapper .cm-s-seti .CodeMirror-line::selection,.jupyter-wrapper .cm-s-seti .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-seti .CodeMirror-line>span>span::selection{background:rgba(255,255,255,.1)}.jupyter-wrapper .cm-s-seti .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-seti .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-seti .CodeMirror-line>span>span::-moz-selection{background:rgba(255,255,255,.1)}.jupyter-wrapper .cm-s-seti span.cm-comment{color:#41535b}.jupyter-wrapper .cm-s-seti span.cm-string,.jupyter-wrapper .cm-s-seti span.cm-string-2{color:#55b5db}.jupyter-wrapper .cm-s-seti span.cm-number{color:#cd3f45}.jupyter-wrapper .cm-s-seti span.cm-variable{color:#55b5db}.jupyter-wrapper .cm-s-seti span.cm-variable-2{color:#a074c4}.jupyter-wrapper .cm-s-seti span.cm-def{color:#55b5db}.jupyter-wrapper .cm-s-seti span.cm-keyword{color:#ff79c6}.jupyter-wrapper .cm-s-seti span.cm-operator{color:#9fca56}.jupyter-wrapper .cm-s-seti span.cm-keyword{color:#e6cd69}.jupyter-wrapper .cm-s-seti span.cm-atom{color:#cd3f45}.jupyter-wrapper .cm-s-seti span.cm-meta{color:#55b5db}.jupyter-wrapper .cm-s-seti span.cm-tag{color:#55b5db}.jupyter-wrapper .cm-s-seti span.cm-attribute{color:#9fca56}.jupyter-wrapper .cm-s-seti span.cm-qualifier{color:#9fca56}.jupyter-wrapper .cm-s-seti span.cm-property{color:#a074c4}.jupyter-wrapper .cm-s-seti span.cm-variable-3,.jupyter-wrapper .cm-s-seti span.cm-type{color:#9fca56}.jupyter-wrapper .cm-s-seti span.cm-builtin{color:#9fca56}.jupyter-wrapper .cm-s-seti .CodeMirror-activeline-background{background:#101213}.jupyter-wrapper .cm-s-seti .CodeMirror-matchingbracket{text-decoration:underline;color:#fff !important}.jupyter-wrapper .solarized.base03{color:#002b36}.jupyter-wrapper .solarized.base02{color:#073642}.jupyter-wrapper .solarized.base01{color:#586e75}.jupyter-wrapper .solarized.base00{color:#657b83}.jupyter-wrapper .solarized.base0{color:#839496}.jupyter-wrapper .solarized.base1{color:#93a1a1}.jupyter-wrapper .solarized.base2{color:#eee8d5}.jupyter-wrapper .solarized.base3{color:#fdf6e3}.jupyter-wrapper .solarized.solar-yellow{color:#b58900}.jupyter-wrapper .solarized.solar-orange{color:#cb4b16}.jupyter-wrapper .solarized.solar-red{color:#dc322f}.jupyter-wrapper .solarized.solar-magenta{color:#d33682}.jupyter-wrapper .solarized.solar-violet{color:#6c71c4}.jupyter-wrapper .solarized.solar-blue{color:#268bd2}.jupyter-wrapper .solarized.solar-cyan{color:#2aa198}.jupyter-wrapper .solarized.solar-green{color:#859900}.jupyter-wrapper .cm-s-solarized{line-height:1.45em;color-profile:sRGB;rendering-intent:auto}.jupyter-wrapper .cm-s-solarized.cm-s-dark{color:#839496;background-color:#002b36;text-shadow:#002b36 0 1px}.jupyter-wrapper .cm-s-solarized.cm-s-light{background-color:#fdf6e3;color:#657b83;text-shadow:#eee8d5 0 1px}.jupyter-wrapper .cm-s-solarized .CodeMirror-widget{text-shadow:none}.jupyter-wrapper .cm-s-solarized .cm-header{color:#586e75}.jupyter-wrapper .cm-s-solarized .cm-quote{color:#93a1a1}.jupyter-wrapper .cm-s-solarized .cm-keyword{color:#cb4b16}.jupyter-wrapper .cm-s-solarized .cm-atom{color:#d33682}.jupyter-wrapper .cm-s-solarized .cm-number{color:#d33682}.jupyter-wrapper .cm-s-solarized .cm-def{color:#2aa198}.jupyter-wrapper .cm-s-solarized .cm-variable{color:#839496}.jupyter-wrapper .cm-s-solarized .cm-variable-2{color:#b58900}.jupyter-wrapper .cm-s-solarized .cm-variable-3,.jupyter-wrapper .cm-s-solarized .cm-type{color:#6c71c4}.jupyter-wrapper .cm-s-solarized .cm-property{color:#2aa198}.jupyter-wrapper .cm-s-solarized .cm-operator{color:#6c71c4}.jupyter-wrapper .cm-s-solarized .cm-comment{color:#586e75;font-style:italic}.jupyter-wrapper .cm-s-solarized .cm-string{color:#859900}.jupyter-wrapper .cm-s-solarized .cm-string-2{color:#b58900}.jupyter-wrapper .cm-s-solarized .cm-meta{color:#859900}.jupyter-wrapper .cm-s-solarized .cm-qualifier{color:#b58900}.jupyter-wrapper .cm-s-solarized .cm-builtin{color:#d33682}.jupyter-wrapper .cm-s-solarized .cm-bracket{color:#cb4b16}.jupyter-wrapper .cm-s-solarized .CodeMirror-matchingbracket{color:#859900}.jupyter-wrapper .cm-s-solarized .CodeMirror-nonmatchingbracket{color:#dc322f}.jupyter-wrapper .cm-s-solarized .cm-tag{color:#93a1a1}.jupyter-wrapper .cm-s-solarized .cm-attribute{color:#2aa198}.jupyter-wrapper .cm-s-solarized .cm-hr{color:rgba(0,0,0,0);border-top:1px solid #586e75;display:block}.jupyter-wrapper .cm-s-solarized .cm-link{color:#93a1a1;cursor:pointer}.jupyter-wrapper .cm-s-solarized .cm-special{color:#6c71c4}.jupyter-wrapper .cm-s-solarized .cm-em{color:#999;text-decoration:underline;text-decoration-style:dotted}.jupyter-wrapper .cm-s-solarized .cm-error,.jupyter-wrapper .cm-s-solarized .cm-invalidchar{color:#586e75;border-bottom:1px dotted #dc322f}.jupyter-wrapper .cm-s-solarized.cm-s-dark div.CodeMirror-selected{background:#073642}.jupyter-wrapper .cm-s-solarized.cm-s-dark.CodeMirror ::selection{background:rgba(7,54,66,.99)}.jupyter-wrapper .cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-dark .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-dark .CodeMirror-line>span>span::-moz-selection{background:rgba(7,54,66,.99)}.jupyter-wrapper .cm-s-solarized.cm-s-light div.CodeMirror-selected{background:#eee8d5}.jupyter-wrapper .cm-s-solarized.cm-s-light .CodeMirror-line::selection,.jupyter-wrapper .cm-s-light .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-light .CodeMirror-line>span>span::selection{background:#eee8d5}.jupyter-wrapper .cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-ligh .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-ligh .CodeMirror-line>span>span::-moz-selection{background:#eee8d5}.jupyter-wrapper .cm-s-solarized.CodeMirror{-moz-box-shadow:inset 7px 0 12px -6px #000;-webkit-box-shadow:inset 7px 0 12px -6px #000;box-shadow:inset 7px 0 12px -6px #000}.jupyter-wrapper .cm-s-solarized .CodeMirror-gutters{border-right:0}.jupyter-wrapper .cm-s-solarized.cm-s-dark .CodeMirror-gutters{background-color:#073642}.jupyter-wrapper .cm-s-solarized.cm-s-dark .CodeMirror-linenumber{color:#586e75;text-shadow:#021014 0 -1px}.jupyter-wrapper .cm-s-solarized.cm-s-light .CodeMirror-gutters{background-color:#eee8d5}.jupyter-wrapper .cm-s-solarized.cm-s-light .CodeMirror-linenumber{color:#839496}.jupyter-wrapper .cm-s-solarized .CodeMirror-linenumber{padding:0 5px}.jupyter-wrapper .cm-s-solarized .CodeMirror-guttermarker-subtle{color:#586e75}.jupyter-wrapper .cm-s-solarized.cm-s-dark .CodeMirror-guttermarker{color:#ddd}.jupyter-wrapper .cm-s-solarized.cm-s-light .CodeMirror-guttermarker{color:#cb4b16}.jupyter-wrapper .cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text{color:#586e75}.jupyter-wrapper .cm-s-solarized .CodeMirror-cursor{border-left:1px solid #819090}.jupyter-wrapper .cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor{background:#7e7}.jupyter-wrapper .cm-s-solarized.cm-s-light .cm-animate-fat-cursor{background-color:#7e7}.jupyter-wrapper .cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor{background:#586e75}.jupyter-wrapper .cm-s-solarized.cm-s-dark .cm-animate-fat-cursor{background-color:#586e75}.jupyter-wrapper .cm-s-solarized.cm-s-dark .CodeMirror-activeline-background{background:rgba(255,255,255,.06)}.jupyter-wrapper .cm-s-solarized.cm-s-light .CodeMirror-activeline-background{background:rgba(0,0,0,.06)}.jupyter-wrapper .cm-s-the-matrix.CodeMirror{background:#000;color:lime}.jupyter-wrapper .cm-s-the-matrix div.CodeMirror-selected{background:#2d2d2d}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-line::selection,.jupyter-wrapper .cm-s-the-matrix .CodeMirror-line>span::selection,.jupyter-wrapper .cm-s-the-matrix .CodeMirror-line>span>span::selection{background:rgba(45,45,45,.99)}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-line::-moz-selection,.jupyter-wrapper .cm-s-the-matrix .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .cm-s-the-matrix .CodeMirror-line>span>span::-moz-selection{background:rgba(45,45,45,.99)}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-gutters{background:#060;border-right:2px solid lime}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-guttermarker{color:lime}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-guttermarker-subtle{color:#fff}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-linenumber{color:#fff}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-cursor{border-left:1px solid lime}.jupyter-wrapper .cm-s-the-matrix span.cm-keyword{color:#008803;font-weight:bold}.jupyter-wrapper .cm-s-the-matrix span.cm-atom{color:#3ff}.jupyter-wrapper .cm-s-the-matrix span.cm-number{color:#ffb94f}.jupyter-wrapper .cm-s-the-matrix span.cm-def{color:#99c}.jupyter-wrapper .cm-s-the-matrix span.cm-variable{color:#f6c}.jupyter-wrapper .cm-s-the-matrix span.cm-variable-2{color:#c6f}.jupyter-wrapper .cm-s-the-matrix span.cm-variable-3,.jupyter-wrapper .cm-s-the-matrix span.cm-type{color:#96f}.jupyter-wrapper .cm-s-the-matrix span.cm-property{color:#62ffa0}.jupyter-wrapper .cm-s-the-matrix span.cm-operator{color:#999}.jupyter-wrapper .cm-s-the-matrix span.cm-comment{color:#ccc}.jupyter-wrapper .cm-s-the-matrix span.cm-string{color:#39c}.jupyter-wrapper .cm-s-the-matrix span.cm-meta{color:#c9f}.jupyter-wrapper .cm-s-the-matrix span.cm-qualifier{color:#fff700}.jupyter-wrapper .cm-s-the-matrix span.cm-builtin{color:#30a}.jupyter-wrapper .cm-s-the-matrix span.cm-bracket{color:#cc7}.jupyter-wrapper .cm-s-the-matrix span.cm-tag{color:#ffbd40}.jupyter-wrapper .cm-s-the-matrix span.cm-attribute{color:#fff700}.jupyter-wrapper .cm-s-the-matrix span.cm-error{color:red}.jupyter-wrapper .cm-s-the-matrix .CodeMirror-activeline-background{background:#040}.jupyter-wrapper .cm-s-xq-light span.cm-keyword{line-height:1em;font-weight:bold;color:#5a5cad}.jupyter-wrapper .cm-s-xq-light span.cm-atom{color:#6c8cd5}.jupyter-wrapper .cm-s-xq-light span.cm-number{color:#164}.jupyter-wrapper .cm-s-xq-light span.cm-def{text-decoration:underline}.jupyter-wrapper .cm-s-xq-light span.cm-variable{color:#000}.jupyter-wrapper .cm-s-xq-light span.cm-variable-2{color:#000}.jupyter-wrapper .cm-s-xq-light span.cm-variable-3,.jupyter-wrapper .cm-s-xq-light span.cm-type{color:#000}.jupyter-wrapper .cm-s-xq-light span.cm-comment{color:#0080ff;font-style:italic}.jupyter-wrapper .cm-s-xq-light span.cm-string{color:red}.jupyter-wrapper .cm-s-xq-light span.cm-meta{color:#ff0}.jupyter-wrapper .cm-s-xq-light span.cm-qualifier{color:gray}.jupyter-wrapper .cm-s-xq-light span.cm-builtin{color:#7ea656}.jupyter-wrapper .cm-s-xq-light span.cm-bracket{color:#cc7}.jupyter-wrapper .cm-s-xq-light span.cm-tag{color:#3f7f7f}.jupyter-wrapper .cm-s-xq-light span.cm-attribute{color:#7f007f}.jupyter-wrapper .cm-s-xq-light span.cm-error{color:red}.jupyter-wrapper .cm-s-xq-light .CodeMirror-activeline-background{background:#e8f2ff}.jupyter-wrapper .cm-s-xq-light .CodeMirror-matchingbracket{outline:1px solid gray;color:#000 !important;background:#ff0}.jupyter-wrapper .CodeMirror{line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);border:0;border-radius:0;height:auto}.jupyter-wrapper .CodeMirror pre{padding:0 var(--jp-code-padding)}.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-dialog{background-color:var(--jp-layout-color0);color:var(--jp-content-font-color1)}.jupyter-wrapper .CodeMirror-lines{padding:var(--jp-code-padding) 0}.jupyter-wrapper .CodeMirror-linenumber{padding:0 8px}.jupyter-wrapper .jp-CodeMirrorEditor-static{margin:var(--jp-code-padding)}.jupyter-wrapper .jp-CodeMirrorEditor,.jupyter-wrapper .jp-CodeMirrorEditor-static{cursor:text}.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color)}@media screen and (min-width: 2138px)and (max-width: 4319px){.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width1) solid var(--jp-editor-cursor-color)}}@media screen and (min-width: 4320px){.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width2) solid var(--jp-editor-cursor-color)}}.jupyter-wrapper .CodeMirror.jp-mod-readOnly .CodeMirror-cursor{display:none}.jupyter-wrapper .CodeMirror-gutters{border-right:1px solid var(--jp-border-color2);background-color:var(--jp-layout-color0)}.jupyter-wrapper .jp-CollaboratorCursor{border-left:5px solid rgba(0,0,0,0);border-right:5px solid rgba(0,0,0,0);border-top:none;border-bottom:3px solid;background-clip:content-box;margin-left:-5px;margin-right:-5px}.jupyter-wrapper .CodeMirror-selectedtext.cm-searching{background-color:var(--jp-search-selected-match-background-color) !important;color:var(--jp-search-selected-match-color) !important}.jupyter-wrapper .cm-searching{background-color:var(--jp-search-unselected-match-background-color) !important;color:var(--jp-search-unselected-match-color) !important}.jupyter-wrapper .CodeMirror-focused .CodeMirror-selected{background-color:var(--jp-editor-selected-focused-background)}.jupyter-wrapper .CodeMirror-selected{background-color:var(--jp-editor-selected-background)}.jupyter-wrapper .jp-CollaboratorCursor-hover{position:absolute;z-index:1;transform:translateX(-50%);color:#fff;border-radius:3px;padding-left:4px;padding-right:4px;padding-top:1px;padding-bottom:1px;text-align:center;font-size:var(--jp-ui-font-size1);white-space:nowrap}.jupyter-wrapper .jp-CodeMirror-ruler{border-left:1px dashed var(--jp-border-color2)}.jupyter-wrapper .CodeMirror.cm-s-jupyter{background:var(--jp-layout-color0);color:var(--jp-content-font-color1)}.jupyter-wrapper .jp-CodeConsole .CodeMirror.cm-s-jupyter,.jupyter-wrapper .jp-Notebook .CodeMirror.cm-s-jupyter{background:rgba(0,0,0,0)}.jupyter-wrapper .cm-s-jupyter .CodeMirror-cursor{border-left:var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color)}.jupyter-wrapper .cm-s-jupyter span.cm-keyword{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.jupyter-wrapper .cm-s-jupyter span.cm-atom{color:var(--jp-mirror-editor-atom-color)}.jupyter-wrapper .cm-s-jupyter span.cm-number{color:var(--jp-mirror-editor-number-color)}.jupyter-wrapper .cm-s-jupyter span.cm-def{color:var(--jp-mirror-editor-def-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable{color:var(--jp-mirror-editor-variable-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable-2{color:var(--jp-mirror-editor-variable-2-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable-3{color:var(--jp-mirror-editor-variable-3-color)}.jupyter-wrapper .cm-s-jupyter span.cm-punctuation{color:var(--jp-mirror-editor-punctuation-color)}.jupyter-wrapper .cm-s-jupyter span.cm-property{color:var(--jp-mirror-editor-property-color)}.jupyter-wrapper .cm-s-jupyter span.cm-operator{color:var(--jp-mirror-editor-operator-color);font-weight:bold}.jupyter-wrapper .cm-s-jupyter span.cm-comment{color:var(--jp-mirror-editor-comment-color);font-style:italic}.jupyter-wrapper .cm-s-jupyter span.cm-string{color:var(--jp-mirror-editor-string-color)}.jupyter-wrapper .cm-s-jupyter span.cm-string-2{color:var(--jp-mirror-editor-string-2-color)}.jupyter-wrapper .cm-s-jupyter span.cm-meta{color:var(--jp-mirror-editor-meta-color)}.jupyter-wrapper .cm-s-jupyter span.cm-qualifier{color:var(--jp-mirror-editor-qualifier-color)}.jupyter-wrapper .cm-s-jupyter span.cm-builtin{color:var(--jp-mirror-editor-builtin-color)}.jupyter-wrapper .cm-s-jupyter span.cm-bracket{color:var(--jp-mirror-editor-bracket-color)}.jupyter-wrapper .cm-s-jupyter span.cm-tag{color:var(--jp-mirror-editor-tag-color)}.jupyter-wrapper .cm-s-jupyter span.cm-attribute{color:var(--jp-mirror-editor-attribute-color)}.jupyter-wrapper .cm-s-jupyter span.cm-header{color:var(--jp-mirror-editor-header-color)}.jupyter-wrapper .cm-s-jupyter span.cm-quote{color:var(--jp-mirror-editor-quote-color)}.jupyter-wrapper .cm-s-jupyter span.cm-link{color:var(--jp-mirror-editor-link-color)}.jupyter-wrapper .cm-s-jupyter span.cm-error{color:var(--jp-mirror-editor-error-color)}.jupyter-wrapper .cm-s-jupyter span.cm-hr{color:#999}.jupyter-wrapper .cm-s-jupyter span.cm-tab{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);background-position:right;background-repeat:no-repeat}.jupyter-wrapper .cm-s-jupyter .CodeMirror-activeline-background,.jupyter-wrapper .cm-s-jupyter .CodeMirror-gutter{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-RenderedLatex{color:var(--jp-content-font-color1);font-size:var(--jp-content-font-size1);line-height:var(--jp-content-line-height)}.jupyter-wrapper .jp-OutputArea-output.jp-RenderedLatex{padding:var(--jp-code-padding);text-align:left}.jupyter-wrapper .jp-MimeDocument{outline:none}.jupyter-wrapper :root{--jp-private-filebrowser-button-height: 28px;--jp-private-filebrowser-button-width: 48px}.jupyter-wrapper .jp-FileBrowser{display:flex;flex-direction:column;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .jp-FileBrowser-toolbar.jp-Toolbar{border-bottom:none;height:auto;margin:var(--jp-toolbar-header-margin);box-shadow:none}.jupyter-wrapper .jp-BreadCrumbs{flex:0 0 auto;margin:4px 12px}.jupyter-wrapper .jp-BreadCrumbs-item{margin:0px 2px;padding:0px 2px;border-radius:var(--jp-border-radius);cursor:pointer}.jupyter-wrapper .jp-BreadCrumbs-item:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-BreadCrumbs-item:first-child{margin-left:0px}.jupyter-wrapper .jp-BreadCrumbs-item.jp-mod-dropTarget{background-color:var(--jp-brand-color2);opacity:.7}.jupyter-wrapper .jp-FileBrowser-toolbar.jp-Toolbar{padding:0px}.jupyter-wrapper .jp-FileBrowser-toolbar.jp-Toolbar{justify-content:space-evenly}.jupyter-wrapper .jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item{flex:1}.jupyter-wrapper .jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent{width:100%}.jupyter-wrapper .jp-DirListing{flex:1 1 auto;display:flex;flex-direction:column;outline:0}.jupyter-wrapper .jp-DirListing-header{flex:0 0 auto;display:flex;flex-direction:row;overflow:hidden;border-top:var(--jp-border-width) solid var(--jp-border-color2);border-bottom:var(--jp-border-width) solid var(--jp-border-color1);box-shadow:var(--jp-toolbar-box-shadow);z-index:2}.jupyter-wrapper .jp-DirListing-headerItem{padding:4px 12px 2px 12px;font-weight:500}.jupyter-wrapper .jp-DirListing-headerItem:hover{background:var(--jp-layout-color2)}.jupyter-wrapper .jp-DirListing-headerItem.jp-id-name{flex:1 0 84px}.jupyter-wrapper .jp-DirListing-headerItem.jp-id-modified{flex:0 0 112px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right}.jupyter-wrapper .jp-DirListing-narrow .jp-id-modified,.jupyter-wrapper .jp-DirListing-narrow .jp-DirListing-itemModified{display:none}.jupyter-wrapper .jp-DirListing-headerItem.jp-mod-selected{font-weight:600}.jupyter-wrapper .jp-DirListing-content{flex:1 1 auto;margin:0;padding:0;list-style-type:none;overflow:auto;background-color:var(--jp-layout-color1)}.jupyter-wrapper .jp-DirListing.jp-mod-native-drop .jp-DirListing-content{outline:5px dashed rgba(128,128,128,.5);outline-offset:-10px;cursor:copy}.jupyter-wrapper .jp-DirListing-item{display:flex;flex-direction:row;padding:4px 12px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected{color:#fff;background:var(--jp-brand-color1)}.jupyter-wrapper .jp-DirListing-item.jp-mod-dropTarget{background:var(--jp-brand-color3)}.jupyter-wrapper .jp-DirListing-item:hover:not(.jp-mod-selected){background:var(--jp-layout-color2)}.jupyter-wrapper .jp-DirListing-itemIcon{flex:0 0 20px;margin-right:4px}.jupyter-wrapper .jp-DirListing-itemText{flex:1 0 64px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;user-select:none}.jupyter-wrapper .jp-DirListing-itemModified{flex:0 0 125px;text-align:right}.jupyter-wrapper .jp-DirListing-editor{flex:1 0 64px;outline:none;border:none}.jupyter-wrapper .jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before{color:#32cd32;content:"";font-size:8px;position:absolute;left:-8px}.jupyter-wrapper .jp-DirListing-item.lm-mod-drag-image,.jupyter-wrapper .jp-DirListing-item.jp-mod-selected.lm-mod-drag-image{font-size:var(--jp-ui-font-size1);padding-left:4px;margin-left:4px;width:160px;background-color:var(--jp-ui-inverse-font-color2);box-shadow:var(--jp-elevation-z2);border-radius:0px;color:var(--jp-ui-font-color1);transform:translateX(-40%) translateY(-58%)}.jupyter-wrapper .jp-DirListing-deadSpace{flex:1 1 auto;margin:0;padding:0;list-style-type:none;overflow:auto;background-color:var(--jp-layout-color1)}.jupyter-wrapper .jp-Document{min-width:120px;min-height:120px;outline:none}.jupyter-wrapper .jp-FileDialog.jp-mod-conflict input{color:red}.jupyter-wrapper .jp-FileDialog .jp-new-name-title{margin-top:12px}.jupyter-wrapper .jp-OutputArea{overflow-y:auto}.jupyter-wrapper .jp-OutputArea-child{display:flex;flex-direction:row}.jupyter-wrapper .jp-OutputPrompt{flex:0 0 var(--jp-cell-prompt-width);color:var(--jp-cell-outprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid rgba(0,0,0,0);opacity:var(--jp-cell-prompt-opacity);text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .jp-OutputArea-output{height:auto;overflow:auto;user-select:text;-moz-user-select:text;-webkit-user-select:text;-ms-user-select:text}.jupyter-wrapper .jp-OutputArea-child .jp-OutputArea-output{flex-grow:1;flex-shrink:1}.jupyter-wrapper .jp-OutputArea-output.jp-mod-isolated{width:100%;display:block}.jupyter-wrapper body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated{position:relative}.jupyter-wrapper body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before{content:"";position:absolute;top:0;left:0;right:0;bottom:0;background:rgba(0,0,0,0)}.jupyter-wrapper .jp-OutputArea-output pre{border:none;margin:0px;padding:0px;overflow-x:auto;overflow-y:auto;word-break:break-all;word-wrap:break-word;white-space:pre-wrap}.jupyter-wrapper .jp-OutputArea-output.jp-RenderedHTMLCommon table{margin-left:0;margin-right:0}.jupyter-wrapper .jp-OutputArea-output dl,.jupyter-wrapper .jp-OutputArea-output dt,.jupyter-wrapper .jp-OutputArea-output dd{display:block}.jupyter-wrapper .jp-OutputArea-output dl{width:100%;overflow:hidden;padding:0;margin:0}.jupyter-wrapper .jp-OutputArea-output dt{font-weight:bold;float:left;width:20%;padding:0;margin:0}.jupyter-wrapper .jp-OutputArea-output dd{float:left;width:80%;padding:0;margin:0}.jupyter-wrapper .jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt{display:none}.jupyter-wrapper .jp-OutputArea-output.jp-OutputArea-executeResult{margin-left:0px;flex:1 1 auto}.jupyter-wrapper .jp-OutputArea-executeResult.jp-RenderedText{padding-top:var(--jp-code-padding)}.jupyter-wrapper .jp-OutputArea-stdin{line-height:var(--jp-code-line-height);padding-top:var(--jp-code-padding);display:flex}.jupyter-wrapper .jp-Stdin-prompt{color:var(--jp-content-font-color0);padding-right:var(--jp-code-padding);vertical-align:baseline;flex:0 0 auto}.jupyter-wrapper .jp-Stdin-input{font-family:var(--jp-code-font-family);font-size:inherit;color:inherit;background-color:inherit;width:42%;min-width:200px;vertical-align:baseline;padding:0em .25em;margin:0em .25em;flex:0 0 70%}.jupyter-wrapper .jp-Stdin-input:focus{box-shadow:none}.jupyter-wrapper .jp-LinkedOutputView .jp-OutputArea{height:100%;display:block}.jupyter-wrapper .jp-LinkedOutputView .jp-OutputArea-output:only-child{height:100%}.jupyter-wrapper .jp-Collapser{flex:0 0 var(--jp-cell-collapser-width);padding:0px;margin:0px;border:none;outline:none;background:rgba(0,0,0,0);border-radius:var(--jp-border-radius);opacity:1}.jupyter-wrapper .jp-Collapser-child{display:block;width:100%;box-sizing:border-box;position:absolute;top:0px;bottom:0px}.jupyter-wrapper .jp-CellHeader,.jupyter-wrapper .jp-CellFooter{height:0px;width:100%;padding:0px;margin:0px;border:none;outline:none;background:rgba(0,0,0,0)}.jupyter-wrapper .jp-InputArea{display:flex;flex-direction:row}.jupyter-wrapper .jp-InputArea-editor{flex:1 1 auto}.jupyter-wrapper .jp-InputArea-editor{border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);border-radius:0px;background:var(--jp-cell-editor-background)}.jupyter-wrapper .jp-InputPrompt{flex:0 0 var(--jp-cell-prompt-width);color:var(--jp-cell-inprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);opacity:var(--jp-cell-prompt-opacity);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid rgba(0,0,0,0);opacity:var(--jp-cell-prompt-opacity);text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .jp-Placeholder{display:flex;flex-direction:row;flex:1 1 auto}.jupyter-wrapper .jp-Placeholder-prompt{box-sizing:border-box}.jupyter-wrapper .jp-Placeholder-content{flex:1 1 auto;border:none;background:rgba(0,0,0,0);height:20px;box-sizing:border-box}.jupyter-wrapper .jp-Placeholder-content .jp-MoreHorizIcon{width:32px;height:16px;border:1px solid rgba(0,0,0,0);border-radius:var(--jp-border-radius)}.jupyter-wrapper .jp-Placeholder-content .jp-MoreHorizIcon:hover{border:1px solid var(--jp-border-color1);box-shadow:0px 0px 2px 0px rgba(0,0,0,.25);background-color:var(--jp-layout-color0)}.jupyter-wrapper :root{--jp-private-cell-scrolling-output-offset: 5px}.jupyter-wrapper .jp-Cell{padding:var(--jp-cell-padding);margin:0px;border:none;outline:none;background:rgba(0,0,0,0)}.jupyter-wrapper .jp-Cell-inputWrapper,.jupyter-wrapper .jp-Cell-outputWrapper{display:flex;flex-direction:row;padding:0px;margin:0px;overflow:visible}.jupyter-wrapper .jp-Cell-inputArea,.jupyter-wrapper .jp-Cell-outputArea{flex:1 1 auto}.jupyter-wrapper .jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser{border:none !important;background:rgba(0,0,0,0) !important}.jupyter-wrapper .jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser{min-height:var(--jp-cell-collapser-min-height)}.jupyter-wrapper .jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper{margin-top:5px}.jupyter-wrapper .jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output{padding-top:var(--jp-code-padding)}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea{overflow-y:auto;max-height:200px;box-shadow:inset 0 0 6px 2px rgba(0,0,0,.3);margin-left:var(--jp-private-cell-scrolling-output-offset)}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt{flex:0 0 calc(var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset))}.jupyter-wrapper .jp-MarkdownOutput{flex:1 1 auto;margin-top:0;margin-bottom:0;padding-left:var(--jp-code-padding)}.jupyter-wrapper .jp-MarkdownOutput.jp-RenderedHTMLCommon{overflow:auto}.jupyter-wrapper .jp-NotebookPanel-toolbar{padding:2px}.jupyter-wrapper .jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused{border:none;box-shadow:none}.jupyter-wrapper .jp-Notebook-toolbarCellTypeDropdown select{height:24px;font-size:var(--jp-ui-font-size1);line-height:14px;border-radius:0;display:block}.jupyter-wrapper .jp-Notebook-toolbarCellTypeDropdown span{top:5px !important}.jupyter-wrapper :root{--jp-private-notebook-dragImage-width: 304px;--jp-private-notebook-dragImage-height: 36px;--jp-private-notebook-selected-color: var(--md-blue-400);--jp-private-notebook-active-color: var(--md-green-400)}.jupyter-wrapper .jp-NotebookPanel{display:block;height:100%}.jupyter-wrapper .jp-NotebookPanel.jp-Document{min-width:240px;min-height:120px}.jupyter-wrapper .jp-Notebook{padding:var(--jp-notebook-padding);outline:none;overflow:auto;background:var(--jp-layout-color0)}.jupyter-wrapper .jp-Notebook.jp-mod-scrollPastEnd::after{display:block;content:"";min-height:var(--jp-notebook-scroll-padding)}.jupyter-wrapper .jp-Notebook .jp-Cell{overflow:visible}.jupyter-wrapper .jp-Notebook .jp-Cell .jp-InputPrompt{cursor:move}.jupyter-wrapper .jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jupyter-wrapper .jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser{background:var(--jp-brand-color1)}.jupyter-wrapper .jp-Notebook .jp-Cell .jp-Collapser:hover{box-shadow:var(--jp-elevation-z2);background:var(--jp-brand-color1);opacity:var(--jp-cell-collapser-not-active-hover-opacity)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover{background:var(--jp-brand-color0);opacity:1}.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected{background:var(--jp-notebook-multiselected-color)}.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected){background:rgba(0,0,0,0)}.jupyter-wrapper .jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor{border:var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-cell-editor-active-background)}.jupyter-wrapper .jp-Notebook-cell.jp-mod-dropSource{opacity:.5}.jupyter-wrapper .jp-Notebook-cell.jp-mod-dropTarget,.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget{border-top-color:var(--jp-private-notebook-selected-color);border-top-style:solid;border-top-width:2px}.jupyter-wrapper .jp-dragImage{display:flex;flex-direction:row;width:var(--jp-private-notebook-dragImage-width);height:var(--jp-private-notebook-dragImage-height);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background);overflow:visible}.jupyter-wrapper .jp-dragImage-singlePrompt{box-shadow:2px 2px 4px 0px rgba(0,0,0,.12)}.jupyter-wrapper .jp-dragImage .jp-dragImage-content{flex:1 1 auto;z-index:2;font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);line-height:var(--jp-code-line-height);padding:var(--jp-code-padding);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background-color);color:var(--jp-content-font-color3);text-align:left;margin:4px 4px 4px 0px}.jupyter-wrapper .jp-dragImage .jp-dragImage-prompt{flex:0 0 auto;min-width:36px;color:var(--jp-cell-inprompt-font-color);padding:var(--jp-code-padding);padding-left:12px;font-family:var(--jp-cell-prompt-font-family);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:1.9;font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid rgba(0,0,0,0)}.jupyter-wrapper .jp-dragImage-multipleBack{z-index:-1;position:absolute;height:32px;width:300px;top:8px;left:8px;background:var(--jp-layout-color2);border:var(--jp-border-width) solid var(--jp-input-border-color);box-shadow:2px 2px 4px 0px rgba(0,0,0,.12)}.jupyter-wrapper .jp-NotebookTools{display:block;min-width:var(--jp-sidebar-min-width);color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1);overflow:auto}.jupyter-wrapper .jp-NotebookTools-tool{padding:0px 12px 0 12px}.jupyter-wrapper .jp-ActiveCellTool{padding:12px;background-color:var(--jp-layout-color1);border-top:none !important}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-prompt{flex:0 0 auto;padding-left:0px}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-editor{flex:1 1 auto;background:var(--jp-cell-editor-background);border-color:var(--jp-cell-editor-border-color)}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-editor .CodeMirror{background:rgba(0,0,0,0)}.jupyter-wrapper .jp-MetadataEditorTool{flex-direction:column;padding:12px 0px 12px 0px}.jupyter-wrapper .jp-RankedPanel>:not(:first-child){margin-top:12px}.jupyter-wrapper .jp-KeySelector select.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:var(--jp-border-width) solid var(--jp-border-color1)}.jupyter-wrapper .jp-KeySelector label,.jupyter-wrapper .jp-MetadataEditorTool label{line-height:1.4}.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook{--jp-content-font-size1: var(--jp-content-presentation-font-size1);--jp-code-font-size: var(--jp-code-presentation-font-size)}.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt{flex:0 0 110px}.jupyter-wrapper table.dataframe{table-layout:auto !important}.jupyter-wrapper .md-typeset__scrollwrap{margin:0}.jupyter-wrapper .jp-MarkdownOutput{padding:0}.jupyter-wrapper h1 .anchor-link,.jupyter-wrapper h2 .anchor-link,.jupyter-wrapper h3 .anchor-link,.jupyter-wrapper h4 .anchor-link,.jupyter-wrapper h5 .anchor-link,.jupyter-wrapper h6 .anchor-link{display:none;margin-left:.5rem;color:var(--md-default-fg-color--lighter)}.jupyter-wrapper h1 .anchor-link:hover,.jupyter-wrapper h2 .anchor-link:hover,.jupyter-wrapper h3 .anchor-link:hover,.jupyter-wrapper h4 .anchor-link:hover,.jupyter-wrapper h5 .anchor-link:hover,.jupyter-wrapper h6 .anchor-link:hover{text-decoration:none;color:var(--md-accent-fg-color)}.jupyter-wrapper h1:hover .anchor-link,.jupyter-wrapper h2:hover .anchor-link,.jupyter-wrapper h3:hover .anchor-link,.jupyter-wrapper h4:hover .anchor-link,.jupyter-wrapper h5:hover .anchor-link,.jupyter-wrapper h6:hover .anchor-link{display:inline-block}.jupyter-wrapper .jp-InputArea{width:100%}.jupyter-wrapper .jp-Cell-inputArea{width:100%}.jupyter-wrapper .jp-RenderedHTMLCommon{width:100%}.jupyter-wrapper .jp-Cell-inputWrapper .jp-InputPrompt{display:none}.jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt{display:block}.jupyter-wrapper .highlight pre{overflow:auto}.jupyter-wrapper .celltoolbar{border:none;background:#eee;border-radius:2px 2px 0px 0px;width:100%;height:29px;padding-right:4px;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch;box-pack:end;justify-content:flex-start;display:-webkit-flex}.jupyter-wrapper .celltoolbar .tags_button_container{display:flex}.jupyter-wrapper .celltoolbar .tags_button_container .tag-container{display:flex;flex-direction:row;flex-grow:1;overflow:hidden;position:relative}.jupyter-wrapper .celltoolbar .tags_button_container .tag-container .cell-tag{background-color:#fff;white-space:nowrap;margin:3px 4px;padding:0 4px;border-radius:1px;border:1px solid #ccc;box-shadow:none;width:inherit;font-size:11px;font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace;height:22px;display:inline-block}.jupyter-wrapper .jp-InputArea-editor{width:1px}.jupyter-wrapper .jp-InputPrompt{overflow:unset}.jupyter-wrapper .jp-OutputPrompt{overflow:unset}.jupyter-wrapper .jp-RenderedText{font-size:var(--jp-code-font-size)}.jupyter-wrapper .highlight-ipynb{overflow:auto}.jupyter-wrapper .highlight-ipynb pre{margin:0;padding:5px 10px}.jupyter-wrapper table{width:max-content}.jupyter-wrapper table.dataframe{margin-left:auto;margin-right:auto;border:none;border-collapse:collapse;border-spacing:0;color:#000;font-size:12px;table-layout:fixed}.jupyter-wrapper table.dataframe thead{border-bottom:1px solid #000;vertical-align:bottom}.jupyter-wrapper table.dataframe tr,.jupyter-wrapper table.dataframe th,.jupyter-wrapper table.dataframe td{text-align:right;vertical-align:middle;padding:.5em .5em;line-height:normal;white-space:normal;max-width:none;border:none}.jupyter-wrapper table.dataframe th{font-weight:bold}.jupyter-wrapper table.dataframe tbody tr:nth-child(odd){background:#f5f5f5}.jupyter-wrapper table.dataframe tbody tr:hover{background:rgba(66,165,245,.2)}.jupyter-wrapper *+table{margin-top:1em}.jupyter-wrapper .jp-InputArea-editor{position:relative}.jupyter-wrapper .zeroclipboard-container{position:absolute;top:-3px;right:0;z-index:1}.jupyter-wrapper .zeroclipboard-container clipboard-copy{-webkit-appearance:button;-moz-appearance:button;padding:7px 5px;font:11px system-ui,sans-serif;display:inline-block;cursor:default}.jupyter-wrapper .zeroclipboard-container .clipboard-copy-icon{padding:4px 4px 2px;color:#57606a;vertical-align:text-bottom}.jupyter-wrapper .clipboard-copy-txt{display:none}[data-md-color-scheme=slate] .clipboard-copy-icon{color:#fff !important}[data-md-color-scheme=slate] table.dataframe{color:#e9ebfc}[data-md-color-scheme=slate] table.dataframe thead{border-bottom:1px solid rgba(233,235,252,.12)}[data-md-color-scheme=slate] table.dataframe tbody tr:nth-child(odd){background:#222}[data-md-color-scheme=slate] table.dataframe tbody tr:hover{background:rgba(66,165,245,.2)}table{width:max-content}

/*# sourceMappingURL=mkdocs-jupyter.css.map*/</style>


<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --><div class="jupyter-wrapper">
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p><a href="https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/09_pytorch_model_deployment.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<p><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/09_pytorch_model_deployment.ipynb">View Source Code</a> | <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/09_pytorch_model_deployment.pdf">View Slides</a></p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="09-pytorch-model-deployment">09. PyTorch Model Deployment<a class="anchor-link" href="#09-pytorch-model-deployment">&#182;</a></h1><p>Welcome to Milestone Project 3: PyTorch Model Deployment!</p>
<p>We've come a long way with our FoodVision Mini project.</p>
<p>But so far our PyTorch models have only been accessible to us.</p>
<p>How about we bring FoodVision Mini to life and make it publically accessible?</p>
<p>In other words, <strong>we're going to deploy our FoodVision Mini model to the internet as a usable app!</strong></p>
<img src="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/09-model-deployment-what-were-doing-demo-trimmed-cropped-small.gif" alt="demo of foodvision mini computer vision model being used on a mobile device to predict on an image of sushi and getting it right" width=900/>
<p><em>Trying out the <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">deployed version of FoodVision Mini</a> (what we're going to build) on my lunch. The model got it right too !</em></p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="what-is-machine-learning-model-deployment">What is machine learning model deployment?<a class="anchor-link" href="#what-is-machine-learning-model-deployment">&#182;</a></h2><p><strong>Machine learning model deployment</strong> is the process of making your machine learning model accessible to someone or something else.</p>
<p>Someone else being a person who can interact with your model in some way.</p>
<p>For example, someone taking a photo on their smartphone of food and then having our FoodVision Mini model classify it into pizza, steak or sushi.</p>
<p>Something else might be another program, app or even another model that interacts with your machine learning model(s).</p>
<p>For example, a banking database might rely on a machine learning model making predictions as to whether a transaction is fraudulent or not before transferring funds.</p>
<p>Or an operating system may lower its resource consumption based on a machine learning model making predictions on how much power someone generally uses at specific times of day.</p>
<p>These use cases can be mixed and matched as well.</p>
<p>For example, a Tesla car's computer vision system will interact with the car's route planning program (something else) and then the route planning program will get inputs and feedback from the driver (someone else).</p>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-what-is-model-deployment-someone-or-something-else.png" width=900 alt="two use cases for model deployment, making your model available to someone else, for example, someone using it in an app, or making it available to something else such as another program or model"/>
<p><em>Machine learning model deployment involves making your model available to someone or something else. For example, someone might use your model as part of a food recognition app (such as FoodVision Mini or <a href="https://nutrify.app">Nutrify</a>). And something else might be another model or program using your model such as a banking system using a machine learning model to detect if a transaction is fraud or not.</em></p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="why-deploy-a-machine-learning-model">Why deploy a machine learning model?<a class="anchor-link" href="#why-deploy-a-machine-learning-model">&#182;</a></h2><p>One of the most important philosophical questions in machine learning is:</p>
<div align="center">
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-does-it-exist.jpeg" alt="curious dinosaur often referred to as philosoraptor asking the question if a machine learning model never leaves a notebook, does it exist?" width=300/>
</div>
<p>Deploying a model is as important as training one.</p>
<p>Because although you can get a pretty good idea of how your model's going to function by evaluting it on a well crafted test set or visualizing its results, you never really know how it's going to perform until you release it to the wild.</p>
<p>Having people who've never used your model interact with it will often reveal edge cases you never thought of during training.</p>
<p>For example, what happens if someone was to upload a photo that <em>wasn't</em> of food to our FoodVision Mini model?</p>
<p>One solution would be to create another model that first classifies images as &quot;food&quot; or &quot;not food&quot; and passing the target image through that model first (this is what <a href="https://nutrify.app">Nutrify</a> does).</p>
<p>Then if the image is of &quot;food&quot; it goes to our FoodVision Mini model and gets classified into pizza, steak or sushi.</p>
<p>And if it's &quot;not food&quot;, a message is displayed.</p>
<p>But what if these predictions were wrong?</p>
<p>What happens then?</p>
<p>You can see how these questions could keep going.</p>
<p>Thus this highlights the importance of model deployment: it helps you figure out errors in your model that aren't obvious during training/testing.</p>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-pytorch-workflow-with-deployment.png" alt="A PyTorch workflow with added model deployment and monitoring step" width=900/>
<p><em>We covered a PyTorch workflow back in <a href="https://www.learnpytorch.io/01_pytorch_workflow/">01. PyTorch Workflow</a>. But once you've got a good model, deployment is a good next step. Monitoring involves seeing how your model goes on the most important data split: data from the real world. For more resources on deployment and monitoring see <a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and-deep-learning-engineering">PyTorch Extra Resources</a>.</em></p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="different-types-of-machine-learning-model-deployment">Different types of machine learning model deployment<a class="anchor-link" href="#different-types-of-machine-learning-model-deployment">&#182;</a></h2><p>Whole books could be written on the different types of machine learning model deployment (and many good ones are listed in <a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and-deep-learning-engineering">PyTorch Extra Resources</a>).</p>
<p>And the field is still developing in terms of best practices.</p>
<p>But I like to start with the question:</p>
<blockquote>
<p>&quot;What is the most ideal scenario for my machine learning model to be used?&quot;</p>
</blockquote>
<p>And then work backwards from there.</p>
<p>Of course, you may not know this ahead of time. But you're smart enough to imagine such things.</p>
<p>In the case of FoodVision Mini, our ideal scenario might be:</p>
<ul>
<li>Someone takes a photo on a mobile device (through an app or web broswer).</li>
<li>The prediction comes back fast.</li>
</ul>
<p>Easy.</p>
<p>So we've got two main criteria:</p>
<ol>
<li>The model should work on a mobile device (this means there will be some compute constraints).</li>
<li>The model should make predictions <em>fast</em> (because a slow app is a boring app).</li>
</ol>
<p>And of course, depending on your use case, your requirements may vary.</p>
<p>You may notice the above two points break down into another two questions:</p>
<ol>
<li><strong>Where's it going to go?</strong> - As in, where is it going to be stored?</li>
<li><strong>How's it going to function?</strong> - As in, does it return predictions immediately? Or do they come later?</li>
</ol>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-deployment-questions-to-ask.png" alt="some questions to ask when starting to deploy machine learning models, what's the model ideal use case, then work backwards and ask where's my model going to go and how's my model going to function" width=900/>
<p><em>When starting to deploy machine learning models, it's helpful to start by asking what's the most ideal use case and then work backwards from there, asking where the model's going to go and then how it's going to function.</em></p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="wheres-it-going-to-go">Where's it going to go?<a class="anchor-link" href="#wheres-it-going-to-go">&#182;</a></h3><p>When you deploy your machine learning model, where does it live?</p>
<p>The main debate here is usually on-device (also called edge/in the browser) or on the cloud (a computer/server that isn't the <em>actual</em> device someone/something calls the model from).</p>
<p>Both have their pros and cons.</p>
<table>
<thead>
<tr>
  <th><strong>Deployment location</strong></th>
  <th><strong>Pros</strong></th>
  <th><strong>Cons</strong></th>
</tr>
</thead>
<tbody>
<tr>
  <td><strong>On-device (edge/in the browser)</strong></td>
  <td>Can be very fast (since no data leaves the device)</td>
  <td>Limited compute power (larger models take longer to run)</td>
</tr>
<tr>
  <td></td>
  <td>Privacy preserving (again no data has to leave the device)</td>
  <td>Limited storage space (smaller model size required)</td>
</tr>
<tr>
  <td></td>
  <td>No internet connection required (sometimes)</td>
  <td>Device-specific skills often required</td>
</tr>
<tr>
  <td></td>
  <td></td>
  <td></td>
</tr>
<tr>
  <td><strong>On cloud</strong></td>
  <td>Near unlimited compute power (can scale up when needed)</td>
  <td>Costs can get out of hand (if proper scaling limits aren't enforced)</td>
</tr>
<tr>
  <td></td>
  <td>Can deploy one model and use everywhere (via API)</td>
  <td>Predictions can be slower due to data having to leave device and predictions having to come back (network latency)</td>
</tr>
<tr>
  <td></td>
  <td>Links into existing cloud ecosystem</td>
  <td>Data has to leave device (this may cause privacy concerns)</td>
</tr>
</tbody>
</table>
<p>There are more details to these but I've left resources in the <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#extra-curriculum">extra-curriculum</a> to learn more.</p>
<p>Let's give an example.</p>
<p>If we're deploying FoodVision Mini as an app, we want it to perform well and fast.</p>
<p>So which model would we prefer?</p>
<ol>
<li>A model on-device that performs at 95% accuracy with an inference time (latency) of one second per prediction.</li>
<li>A model on the cloud that performs at 98% accuracy with an inference time of 10 seconds per per prediction (bigger, better model but takes longer to compute).</li>
</ol>
<p>I've made these numbers up but they showcase a potential difference between on-device and on the cloud.</p>
<p>Option 1 could potentially be a smaller less performant model that runs fast because its able to fit on a mobile device.</p>
<p>Option 2 could potentially a larger more performant model that requires more compute and storage but it takes a bit longer to run because we have to send data off the device and get it back (so even though the actual prediction might be fast, the network time and data transfer has to factored in).</p>
<p>For FoodVision Mini, we'd likely prefer option 1, because the small hit in performance is far outweighed by the faster inference speed.</p>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployment-on-device-vs-cloud.png" width=900 alt="tesla computer vision system on device vs on the cloud"/>
<p><em>In the case of a Tesla car's computer vision system, which would be better? A smaller model that performs well on device (model is on the car) or a larger model that performs better that's on the cloud? In this case, you'd much prefer the model being on the car. The extra network time it would take for data to go from the car to the cloud and then back to the car just wouldn't be worth it (or potentially even possible with poor signal areas).</em></p>
<blockquote>
<p><strong>Note:</strong> For a full example of seeing what it's like to deploy a PyTorch model to an edge device, see the <a href="https://pytorch.org/tutorials/intermediate/realtime_rpi.html">PyTorch tutorial on achieving real-time inference (30fps+)</a> with a computer vision model on a Raspberry Pi.</p>
</blockquote>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="hows-it-going-to-function">How's it going to function?<a class="anchor-link" href="#hows-it-going-to-function">&#182;</a></h3><p>Back to the ideal use case, when you deploy your machine learning model, how should it work?</p>
<p>As in, would you like predictions returned immediately?</p>
<p>Or is it okay for them to happen later?</p>
<p>These two scenarios are generally referred to as:</p>
<ul>
<li><strong>Online (real-time)</strong> - Predicitions/inference happen <strong>immediately</strong>. For example, someone uploads an image, the image gets transformed and predictions are returned or someone makes a purchase and the transaction is verified to be non-fradulent by a model so the purchase can go through.</li>
<li><strong>Offline (batch)</strong> - Predictions/inference happen <strong>periodically</strong>. For example, a photos application sorts your images into different categories (such as beach, mealtime, family, friends) whilst your mobile device is plugged into charge.</li>
</ul>
<blockquote>
<p><strong>Note:</strong> &quot;Batch&quot; refers to inference being performed on multiple samples at a time. However, to add a little confusion, batch processing can happen immediately/online (multiple images being classified at once) and/or offline (mutliple images being predicted/trained on at once).</p>
</blockquote>
<p>The main difference between each being: predictions being made immediately or periodically.</p>
<p>Periodically can have a varying timescale too, from every few seconds to every few hours or days.</p>
<p>And you can mix and match the two.</p>
<p>In the case of FoodVision Mini, we'd want our inference pipeline to happen online (real-time), so when someone uploads an image of pizza, steak or sushi, the prediction results are returned immediately (any slower than real-time would make a boring experience).</p>
<p>But for our training pipeline, it's okay for it to happen in a batch (offline) fashion, which is what we've been doing throughout the previous chapters.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="ways-to-deploy-a-machine-learning-model">Ways to deploy a machine learning model<a class="anchor-link" href="#ways-to-deploy-a-machine-learning-model">&#182;</a></h3><p>We've discussed a couple of options for deploying machine learning models (on-device and cloud).</p>
<p>And each of these will have their specific requirements:</p>
<table>
<thead>
<tr>
  <th><strong>Tool/resource</strong></th>
  <th><strong>Deployment type</strong></th>
</tr>
</thead>
<tbody>
<tr>
  <td><a href="https://developers.google.com/ml-kit">Google's ML Kit</a></td>
  <td>On-device (Android and iOS)</td>
</tr>
<tr>
  <td><a href="https://developer.apple.com/documentation/coreml">Apple's Core ML</a> and <a href="https://coremltools.readme.io/docs"><code>coremltools</code> Python package</a></td>
  <td>On-device (all Apple devices)</td>
</tr>
<tr>
  <td><a href="https://aws.amazon.com/sagemaker/">Amazon Web Service's (AWS) Sagemaker</a></td>
  <td>Cloud</td>
</tr>
<tr>
  <td><a href="https://cloud.google.com/vertex-ai">Google Cloud's Vertex AI</a></td>
  <td>Cloud</td>
</tr>
<tr>
  <td><a href="https://azure.microsoft.com/en-au/services/machine-learning/">Microsoft's Azure Machine Learning</a></td>
  <td>Cloud</td>
</tr>
<tr>
  <td><a href="https://huggingface.co/spaces">Hugging Face Spaces</a></td>
  <td>Cloud</td>
</tr>
<tr>
  <td>API with <a href="https://fastapi.tiangolo.com">FastAPI</a></td>
  <td>Cloud/self-hosted server</td>
</tr>
<tr>
  <td>API with <a href="https://pytorch.org/serve/">TorchServe</a></td>
  <td>Cloud/self-hosted server</td>
</tr>
<tr>
  <td><a href="https://onnx.ai/index.html">ONNX (Open Neural Network Exchange)</a></td>
  <td>Many/general</td>
</tr>
<tr>
  <td>Many more...</td>
  <td></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Note:</strong> An <a href="https://en.wikipedia.org/wiki/API">application programming interface (API)</a> is a way for two (or more) computer programs to interact with each other. For example, if your model was deployed as API, you would be able to write a program that could send data to it and then receive predictions back.</p>
</blockquote>
<p>Which option you choose will be highly dependent on what you're building/who you're working with.</p>
<p>But with so many options, it can be very intimidating.</p>
<p>So best to start small and keep it simple.</p>
<p>And one of the best ways to do so is by turning your machine learning model into a demo app with <a href="https://gradio.app">Gradio</a> and then deploying it on Hugging Face Spaces.</p>
<p>We'll be doing just that with FoodVision Mini later on.</p>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-tools-and-places-to-deploy-ml-models.png" alt="tools and places to deploy machine learning models" width=900/>
<p><em>A handful of places and tools to host and deploy machine learning models. There are plenty I've missed so if you'd like to add more, please leave a <a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">discussion on GitHub</a>.</em></p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="what-were-going-to-cover">What we're going to cover<a class="anchor-link" href="#what-were-going-to-cover">&#182;</a></h2><p>Enough talking about deploying a machine learning model.</p>
<p>Let's become machine learning engineers and actually deploy one.</p>
<p>Our goal is to deploy our FoodVision Model via a demo Gradio app with the following metrics:</p>
<ol>
<li><strong>Performance:</strong> 95%+ accuracy.</li>
<li><strong>Speed:</strong> real-time inference of 30FPS+ (each prediction has a latency of lower than ~0.03s).</li>
</ol>
<p>We'll start by running an experiment to compare our best two models so far: EffNetB2 and ViT feature extractors.</p>
<p>Then we'll deploy the one which performs closest to our goal metrics.</p>
<p>Finally, we'll finish with a (BIG) surprise bonus.</p>
<table>
<thead>
<tr>
  <th><strong>Topic</strong></th>
  <th><strong>Contents</strong></th>
</tr>
</thead>
<tbody>
<tr>
  <td><strong>0. Getting setup</strong></td>
  <td>We've written a fair bit of useful code over the past few sections, let's download it and make sure we can use it again.</td>
</tr>
<tr>
  <td><strong>1. Get data</strong></td>
  <td>Let's download the <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip"><code>pizza_steak_sushi_20_percent.zip</code></a> dataset so we can train our previously best performing models on the same dataset.</td>
</tr>
<tr>
  <td><strong>2. FoodVision Mini model deployment experiment outline</strong></td>
  <td>Even on the third milestone project, we're still going to be running multiple experiments to see which model (EffNetB2 or ViT) achieves closest to our goal metrics.</td>
</tr>
<tr>
  <td><strong>3. Creating an EffNetB2 feature extractor</strong></td>
  <td>An EfficientNetB2 feature extractor performed the best on our pizza, steak, sushi dataset in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/">07. PyTorch Experiment Tracking</a>, let's recreate it as a candidate for deployment.</td>
</tr>
<tr>
  <td><strong>4. Creating a ViT feature extractor</strong></td>
  <td>A ViT feature extractor has been the best performing model yet on our pizza, steak, sushi dataset in <a href="https://www.learnpytorch.io/08_pytorch_paper_replicating/">08. PyTorch Paper Replicating</a>, let's recreate it as a candidate for deployment alongside EffNetB2.</td>
</tr>
<tr>
  <td><strong>5. Making predictions with our trained models and timing them</strong></td>
  <td>We've built two of the best performing models yet, let's make predictions with them and track their results.</td>
</tr>
<tr>
  <td><strong>6. Comparing model results, prediction times and size</strong></td>
  <td>Let's compare our models to see which performs best with our goals.</td>
</tr>
<tr>
  <td><strong>7. Bringing FoodVision Mini to life by creating a Gradio demo</strong></td>
  <td>One of our models performs better than the other (in terms of our goals), so let's turn it into a working app demo!</td>
</tr>
<tr>
  <td><strong>8. Turning our FoodVision Mini Gradio demo into a deployable app</strong></td>
  <td>Our Gradio app demo works locally, let's prepare it for deployment!</td>
</tr>
<tr>
  <td><strong>9. Deploying our Gradio demo to HuggingFace Spaces</strong></td>
  <td>Let's take FoodVision Mini to the web and make it pubically accessible for all!</td>
</tr>
<tr>
  <td><strong>10. Creating a BIG surprise</strong></td>
  <td>We've built FoodVision Mini, time to step things up a notch.</td>
</tr>
<tr>
  <td><strong>11. Deploying our BIG surprise</strong></td>
  <td>Deploying one app was fun, how about we make it two?</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="where-can-you-get-help">Where can you get help?<a class="anchor-link" href="#where-can-you-get-help">&#182;</a></h2><p>All of the materials for this course <a href="https://github.com/mrdbourke/pytorch-deep-learning">are available on GitHub</a>.</p>
<p>If you run into trouble, you can ask a question on the course <a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">GitHub Discussions page</a>.</p>
<p>And of course, there's the <a href="https://pytorch.org/docs/stable/index.html">PyTorch documentation</a> and <a href="https://discuss.pytorch.org/">PyTorch developer forums</a>, a very helpful place for all things PyTorch.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="0-getting-setup">0. Getting setup<a class="anchor-link" href="#0-getting-setup">&#182;</a></h2><p>As we've done previously, let's make sure we've got all of the modules we'll need for this section.</p>
<p>We'll import the Python scripts (such as <code>data_setup.py</code> and <code>engine.py</code>) we created in <a href="https://www.learnpytorch.io/05_pytorch_going_modular/">05. PyTorch Going Modular</a>.</p>
<p>To do so, we'll download <a href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular"><code>going_modular</code></a> directory from the <a href="https://github.com/mrdbourke/pytorch-deep-learning"><code>pytorch-deep-learning</code> repository</a> (if we don't already have it).</p>
<p>We'll also get the <a href="https://github.com/TylerYep/torchinfo"><code>torchinfo</code></a> package if it's not available.</p>
<p><code>torchinfo</code> will help later on to give us a visual representation of our model.</p>
<p>And since later on we'll be using <code>torchvision</code> v0.13 package (available as of July 2022), we'll make sure we've got the latest versions.</p>
<blockquote>
<p><strong>Note:</strong> If you're using Google Colab, and you don't have a GPU turned on yet, it's now time to turn one on via <code>Runtime -&gt; Change runtime type -&gt; Hardware accelerator -&gt; GPU</code>.</p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-1">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torchvision</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">12</span><span class="p">,</span> <span class="s2">&quot;torch version should be 1.12+&quot;</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">13</span><span class="p">,</span> <span class="s2">&quot;torchvision version should be 0.13+&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;torch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;torchvision version: </span><span class="si">{</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] torch/torchvision versions not as required, installing nightly versions.&quot;</span><span class="p">)</span>
    <span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">torch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="o">--</span><span class="n">extra</span><span class="o">-</span><span class="n">index</span><span class="o">-</span><span class="n">url</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">cu113</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torchvision</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;torch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;torchvision version: </span><span class="si">{</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-1" class="clipboard-copy-txt"># For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+
try:
    import torch
    import torchvision
    assert int(torch.__version__.split(".")[1]) >= 12, "torch version should be 1.12+"
    assert int(torchvision.__version__.split(".")[1]) >= 13, "torchvision version should be 0.13+"
    print(f"torch version: {torch.__version__}")
    print(f"torchvision version: {torchvision.__version__}")
except:
    print(f"[INFO] torch/torchvision versions not as required, installing nightly versions.")
    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
    import torch
    import torchvision
    print(f"torch version: {torch.__version__}")
    print(f"torchvision version: {torchvision.__version__}")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>torch version: 1.13.0.dev20220824+cu113
torchvision version: 0.14.0.dev20220824+cu113
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<blockquote>
<p><strong>Note:</strong> If you're using Google Colab and the cell above starts to install various software packages, you may have to restart your runtime after running the above cell. After restarting, you can run the cell again and verify you've got the right versions of <code>torch</code> and <code>torchvision</code>.</p>
</blockquote>
<p>Now we'll continue with the regular imports, setting up device agnostic code and this time we'll also get the <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/helper_functions.py"><code>helper_functions.py</code></a> script from GitHub.</p>
<p>The <code>helper_functions.py</code> script contains several functions we created in previous sections:</p>
<ul>
<li><code>set_seeds()</code> to set the random seeds (created in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#create-a-helper-function-to-set-seeds">07. PyTorch Experiment Tracking section 0</a>).</li>
<li><code>download_data()</code> to download a data source given a link (created in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#1-get-data">07. PyTorch Experiment Tracking section 1</a>).</li>
<li><code>plot_loss_curves()</code> to inspect our model's training results (created in <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#78-plot-the-loss-curves-of-model-0">04. PyTorch Custom Datasets section 7.8</a>)</li>
</ul>
<blockquote>
<p><strong>Note:</strong> It may be a better idea for many of the functions in the <code>helper_functions.py</code> script to be merged into <code>going_modular/going_modular/utils.py</code>, perhaps that's an extension you'd like to try.</p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-2">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Continue with regular imports</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="c1"># Try to get torchinfo, install it if it doesn&#39;t work</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO] Couldn&#39;t find torchinfo... installing it.&quot;</span><span class="p">)</span>
    <span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">torchinfo</span>
    <span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># Try to import the going_modular directory, download it from GitHub if it doesn&#39;t work</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span><span class="p">,</span> <span class="n">engine</span>
    <span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">download_data</span><span class="p">,</span> <span class="n">set_seeds</span><span class="p">,</span> <span class="n">plot_loss_curves</span>
<span class="k">except</span><span class="p">:</span>
    <span class="c1"># Get the going_modular scripts</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[INFO] Couldn&#39;t find going_modular or helper_functions scripts... downloading them from GitHub.&quot;</span><span class="p">)</span>
    <span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">mrdbourke</span><span class="o">/</span><span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span>
    <span class="err">!</span><span class="n">mv</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">/</span><span class="n">going_modular</span> <span class="o">.</span>
    <span class="err">!</span><span class="n">mv</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">/</span><span class="n">helper_functions</span><span class="o">.</span><span class="n">py</span> <span class="o">.</span> <span class="c1"># get the helper_functions.py script</span>
    <span class="err">!</span><span class="n">rm</span> <span class="o">-</span><span class="n">rf</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span>
    <span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span><span class="p">,</span> <span class="n">engine</span>
    <span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">download_data</span><span class="p">,</span> <span class="n">set_seeds</span><span class="p">,</span> <span class="n">plot_loss_curves</span>
</pre></div>
<div id="cell-2" class="clipboard-copy-txt"># Continue with regular imports
import matplotlib.pyplot as plt
import torch
import torchvision

from torch import nn
from torchvision import transforms

# Try to get torchinfo, install it if it doesn't work
try:
    from torchinfo import summary
except:
    print("[INFO] Couldn't find torchinfo... installing it.")
    !pip install -q torchinfo
    from torchinfo import summary

# Try to import the going_modular directory, download it from GitHub if it doesn't work
try:
    from going_modular.going_modular import data_setup, engine
    from helper_functions import download_data, set_seeds, plot_loss_curves
except:
    # Get the going_modular scripts
    print("[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.")
    !git clone https://github.com/mrdbourke/pytorch-deep-learning
    !mv pytorch-deep-learning/going_modular .
    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script
    !rm -rf pytorch-deep-learning
    from going_modular.going_modular import data_setup, engine
    from helper_functions import download_data, set_seeds, plot_loss_curves</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Finally, we'll setup device-agnostic code to make sure our models run on the GPU.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-3">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">device</span>
</pre></div>
<div id="cell-3" class="clipboard-copy-txt">device = "cuda" if torch.cuda.is_available() else "cpu"
device</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>&#39;cuda&#39;</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="1-getting-data">1. Getting data<a class="anchor-link" href="#1-getting-data">&#182;</a></h2><p>We left off in <a href="https://www.learnpytorch.io/08_pytorch_paper_replicating/#106-save-feature-extractor-vit-model-and-check-file-size">08. PyTorch Paper Replicating</a> comparing our own Vision Transformer (ViT) feature extractor model to the EfficientNetB2 (EffNetB2) feature extractor model we created in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#9-load-in-the-best-model-and-make-predictions-with-it">07. PyTorch Experiment Tracking</a>.</p>
<p>And we found that there was a slight difference in the comparison.</p>
<p>The EffNetB2 model was trained on 20% of the pizza, steak and sushi data from Food101 where as the ViT model was trained on 10%.</p>
<p>Since our goal is to deploy the best model for our FoodVision Mini problem, let's start by downloading the <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip">20% pizza, steak and sushi dataset</a> and train an EffNetB2 feature extractor and ViT feature extractor on it and then compare the two models.</p>
<p>This way we'll be comparing apples to apples (one model trained on a dataset to another model trained on the same dataset).</p>
<blockquote>
<p><strong>Note:</strong> The dataset we're downloading is a sample of the entire <a href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html#food101">Food101 dataset</a> (101 food classes with 1,000 images each). More specifically, 20% refers to 20% of images from the pizza, steak and sushi classes selected at random. You can see how this dataset was created in <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb"><code>extras/04_custom_data_creation.ipynb</code></a> and more details in <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#1-get-data">04. PyTorch Custom Datasets section 1</a>.</p>
</blockquote>
<p>We can download the data using the <code>download_data()</code> function we created in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#1-get-data">07. PyTorch Experiment Tracking section 1</a> from <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/helper_functions.py"><code>helper_functions.py</code></a>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-4">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Download pizza, steak, sushi images from GitHub</span>
<span class="n">data_20_percent_path</span> <span class="o">=</span> <span class="n">download_data</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip&quot;</span><span class="p">,</span>
                                     <span class="n">destination</span><span class="o">=</span><span class="s2">&quot;pizza_steak_sushi_20_percent&quot;</span><span class="p">)</span>

<span class="n">data_20_percent_path</span>
</pre></div>
<div id="cell-4" class="clipboard-copy-txt"># Download pizza, steak, sushi images from GitHub
data_20_percent_path = download_data(source="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip",
                                     destination="pizza_steak_sushi_20_percent")

data_20_percent_path</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] data/pizza_steak_sushi_20_percent directory exists, skipping download.
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>PosixPath(&#39;data/pizza_steak_sushi_20_percent&#39;)</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Wonderful!</p>
<p>Now we've got a dataset, let's creat training and test paths.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-5">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Setup directory paths to train and test images</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">data_20_percent_path</span> <span class="o">/</span> <span class="s2">&quot;train&quot;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">data_20_percent_path</span> <span class="o">/</span> <span class="s2">&quot;test&quot;</span>
</pre></div>
<div id="cell-5" class="clipboard-copy-txt"># Setup directory paths to train and test images
train_dir = data_20_percent_path / "train"
test_dir = data_20_percent_path / "test"</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="2-foodvision-mini-model-deployment-experiment-outline">2. FoodVision Mini model deployment experiment outline<a class="anchor-link" href="#2-foodvision-mini-model-deployment-experiment-outline">&#182;</a></h2><p>The ideal deployed model FoodVision Mini performs well and fast.</p>
<p>We'd like our model to perform as close to real-time as possible.</p>
<p>Real-time in this case being ~30FPS (frames per second) because that's <a href="https://www.healthline.com/health/human-eye-fps">about how fast the human eye can see</a> (there is debate on this but let's just use ~30FPS as our benchmark).</p>
<p>And for classifying three different classes (pizza, steak and sushi), we'd like a model that performs at 95%+ accuracy.</p>
<p>Of course, higher accuracy would be nice but this might sacrifice speed.</p>
<p>So our goals are:</p>
<ol>
<li><strong>Performance</strong> - A model that performs at 95%+ accuracy.</li>
<li><strong>Speed</strong> - A model that can classify an image at ~30FPS (0.03 seconds inference time per image, also known as latency).</li>
</ol>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployments-speed-vs-inference.png" alt="foodvision mini goals in terms of performance and inference time." width=750/>
<p><em>FoodVision Mini deployment goals. We'd like a fast predicting well-performing model (because a slow app is boring).</em></p>
<p>We'll put an emphasis on speed, meaning, we'd prefer a model performing at 90%+ accuracy at ~30FPS than a model performing 95%+ accuracy at 10FPS.</p>
<p>To try and achieve these results, let's bring in our best performing models from the previous sections:</p>
<ol>
<li><strong>EffNetB2 feature extractor</strong> (EffNetB2 for short) - originally created in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#75-create-feature-extractor-models">07. PyTorch Experiment Tracking section 7.5</a> using <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#efficientnet-b2"><code>torchvision.models.efficientnet_b2()</code></a> with adjusted <code>classifier</code> layers.</li>
<li><strong>ViT-B/16 feature extractor</strong> (ViT for short) - originally created in <a href="https://www.learnpytorch.io/08_pytorch_paper_replicating/#10-using-a-pretrained-vit-from-torchvisionmodels-on-the-same-dataset">08. PyTorch Paper Replicating section 10</a> using <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#vit-b-16"><code>torchvision.models.vit_b_16()</code></a> with adjusted <code>head</code> layers.<ul>
<li><strong>Note</strong> ViT-B/16 stands for &quot;Vision Transformer Base, patch size 16&quot;.</li>
</ul>
</li>
</ol>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployment-two-experiments.png" alt="modelling experiments for foodvision mini deployments, one effnetb2 feature extractor model and a vision transformer feature extractor model" width=750 />
<blockquote>
<p><strong>Note:</strong> A &quot;feature extractor model&quot; often starts with a model that has been pretrained on a dataset similar to your own problem. The pretrained model's base layers are often left frozen (the pretrained patterns/weights stay the same) whilst some of the top (or classifier/classification head) layers get customized to your own problem by training on your own data. We covered the concept of a feature extractor model in <a href="https://www.learnpytorch.io/06_pytorch_transfer_learning/#34-freezing-the-base-model-and-changing-the-output-layer-to-suit-our-needs">06. PyTorch Transfer Learning section 3.4</a>.</p>
</blockquote>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="3-creating-an-effnetb2-feature-extractor">3. Creating an EffNetB2 feature extractor<a class="anchor-link" href="#3-creating-an-effnetb2-feature-extractor">&#182;</a></h2><p>We first created an EffNetB2 feature extractor model in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#75-create-feature-extractor-models">07. PyTorch Experiment Tracking section 7.5</a>.</p>
<p>And by the end of that section we saw it performed very well.</p>
<p>So let's now recreate it here so we can compare its results to a ViT feature extractor trained on the same data.</p>
<p>To do so we can:</p>
<ol>
<li>Setup the pretrained weights as <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#torchvision.models.EfficientNet_B2_Weights"><code>weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT</code></a>, where &quot;<code>DEFAULT</code>&quot; means &quot;best currently available&quot; (or could use <code>weights=&quot;DEFAULT&quot;</code>).</li>
<li>Get the pretrained model image transforms from the weights with the <code>transforms()</code> method (we need these so we can convert our images into the same format as the pretrained EffNetB2 was trained on).</li>
<li>Create a pretrained model instance by passing the weights to an instance of <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_b2.html#efficientnet-b2"><code>torchvision.models.efficientnet_b2</code></a>.</li>
<li>Freeze the base layers in the model.</li>
<li>Update the classifier head to suit our own data.</li>
</ol>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-6">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># 1. Setup pretrained EffNetB2 weights</span>
<span class="n">effnetb2_weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>

<span class="c1"># 2. Get EffNetB2 transforms</span>
<span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">effnetb2_weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>

<span class="c1"># 3. Setup pretrained model</span>
<span class="n">effnetb2</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">effnetb2_weights</span><span class="p">)</span> <span class="c1"># could also use weights=&quot;DEFAULT&quot;</span>

<span class="c1"># 4. Freeze the base layers in the model (this will freeze all layers to begin with)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
<div id="cell-6" class="clipboard-copy-txt"># 1. Setup pretrained EffNetB2 weights
effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT

# 2. Get EffNetB2 transforms
effnetb2_transforms = effnetb2_weights.transforms()

# 3. Setup pretrained model
effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights) # could also use weights="DEFAULT"

# 4. Freeze the base layers in the model (this will freeze all layers to begin with)
for param in effnetb2.parameters():
    param.requires_grad = False</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now to change the classifier head, let's first inspect it using the <code>classifier</code> attribute of our model.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-7">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Check out EffNetB2 classifier head</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">classifier</span>
</pre></div>
<div id="cell-7" class="clipboard-copy-txt"># Check out EffNetB2 classifier head
effnetb2.classifier</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>Sequential(
  (0): Dropout(p=0.3, inplace=True)
  (1): Linear(in_features=1408, out_features=1000, bias=True)
)</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Excellent! To change the classifier head to suit our own problem, let's replace the <code>out_features</code> variable with the same number of classes we have (in our case, <code>out_features=3</code>, one for pizza, steak, sushi).</p>
<blockquote>
<p><strong>Note:</strong> This process of changing the output layers/classifier head will be dependent on the problem you're working on. For example, if you wanted a different <em>number</em> of outputs or a different <em>kind</em> of ouput, you would have to change the output layers accordingly.</p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-8">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># 5. Update the classifier head</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="c1"># keep dropout layer same</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="c1"># keep in_features same </span>
              <span class="n">out_features</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span> <span class="c1"># change out_features to suit our number of classes</span>
</pre></div>
<div id="cell-8" class="clipboard-copy-txt"># 5. Update the classifier head
effnetb2.classifier = nn.Sequential(
    nn.Dropout(p=0.3, inplace=True), # keep dropout layer same
    nn.Linear(in_features=1408, # keep in_features same 
              out_features=3)) # change out_features to suit our number of classes</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Beautiful!</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="31-creating-a-function-to-make-an-effnetb2-feature-extractor">3.1 Creating a function to make an EffNetB2 feature extractor<a class="anchor-link" href="#31-creating-a-function-to-make-an-effnetb2-feature-extractor">&#182;</a></h3><p>Looks like our EffNetB2 feature extractor is ready to go, however, since there's quite a few steps involved here, how about we turn the code above into a function we can re-use later?</p>
<p>We'll call it <code>create_effnetb2_model()</code> and it'll take a customizable number of classes and a random seed parameter for reproducibility.</p>
<p>Ideally, it will return an EffNetB2 feature extractor along with its assosciated transforms.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-9">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="k">def</span> <span class="nf">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                          <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates an EfficientNetB2 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of classes in the classifier head. </span>
<span class="sd">            Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): EffNetB2 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): EffNetB2 image transforms.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># 4. Freeze all layers in base model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># 5. Change classifier head with random seed for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div id="cell-9" class="clipboard-copy-txt">def create_effnetb2_model(num_classes:int=3, 
                          seed:int=42):
    """Creates an EfficientNetB2 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of classes in the classifier head. 
            Defaults to 3.
        seed (int, optional): random seed value. Defaults to 42.

    Returns:
        model (torch.nn.Module): EffNetB2 feature extractor model. 
        transforms (torchvision.transforms): EffNetB2 image transforms.
    """
    # 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model
    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.efficientnet_b2(weights=weights)

    # 4. Freeze all layers in base model
    for param in model.parameters():
        param.requires_grad = False

    # 5. Change classifier head with random seed for reproducibility
    torch.manual_seed(seed)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.3, inplace=True),
        nn.Linear(in_features=1408, out_features=num_classes),
    )
    
    return model, transforms</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woohoo! That's a nice looking function, let's try it out.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-10">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="n">effnetb2</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                                      <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
<div id="cell-10" class="clipboard-copy-txt">effnetb2, effnetb2_transforms = create_effnetb2_model(num_classes=3,
                                                      seed=42)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>No errors, nice, now to really try it out, let's get a summary with <code>torchinfo.summary()</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-11">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># # Print EffNetB2 model summary (uncomment for full output) </span>
<span class="c1"># summary(effnetb2, </span>
<span class="c1">#         input_size=(1, 3, 224, 224),</span>
<span class="c1">#         col_names=[&quot;input_size&quot;, &quot;output_size&quot;, &quot;num_params&quot;, &quot;trainable&quot;],</span>
<span class="c1">#         col_width=20,</span>
<span class="c1">#         row_settings=[&quot;var_names&quot;])</span>
</pre></div>
<div id="cell-11" class="clipboard-copy-txt">from torchinfo import summary

# # Print EffNetB2 model summary (uncomment for full output) 
# summary(effnetb2, 
#         input_size=(1, 3, 224, 224),
#         col_names=["input_size", "output_size", "num_params", "trainable"],
#         col_width=20,
#         row_settings=["var_names"])</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-effnetb2-feature-extractor.png" alt="effnetb2 feature extractor model summary" width=900/>
<p>Base layers frozen, top layers trainable and customized!</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="32-creating-dataloaders-for-effnetb2">3.2 Creating DataLoaders for EffNetB2<a class="anchor-link" href="#32-creating-dataloaders-for-effnetb2">&#182;</a></h3><p>Our EffNetB2 feature extractor is ready, time to create some <code>DataLoader</code>s.</p>
<p>We can do this by using the <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/data_setup.py"><code>data_setup.create_dataloaders()</code></a> function we created in <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#2-create-datasets-and-dataloaders-data_setuppy">05. PyTorch Going Modular section 2</a>.</p>
<p>We'll use a <code>batch_size</code> of 32 and transform our images using the <code>effnetb2_transforms</code> so they're in the same format that our <code>effnetb2</code> model was trained on.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-12">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Setup DataLoaders</span>
<span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span>
<span class="n">train_dataloader_effnetb2</span><span class="p">,</span> <span class="n">test_dataloader_effnetb2</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="n">data_setup</span><span class="o">.</span><span class="n">create_dataloaders</span><span class="p">(</span><span class="n">train_dir</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                                                                                 <span class="n">test_dir</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                                                                                 <span class="n">transform</span><span class="o">=</span><span class="n">effnetb2_transforms</span><span class="p">,</span>
                                                                                                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<div id="cell-12" class="clipboard-copy-txt"># Setup DataLoaders
from going_modular.going_modular import data_setup
train_dataloader_effnetb2, test_dataloader_effnetb2, class_names = data_setup.create_dataloaders(train_dir=train_dir,
                                                                                                 test_dir=test_dir,
                                                                                                 transform=effnetb2_transforms,
                                                                                                 batch_size=32)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="33-training-effnetb2-feature-extractor">3.3 Training EffNetB2 feature extractor<a class="anchor-link" href="#33-training-effnetb2-feature-extractor">&#182;</a></h3><p>Model ready, <code>DataLoader</code>s ready, let's train!</p>
<p>Just like in <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#76-create-experiments-and-set-up-training-code">07. PyTorch Experiment Tracking section 7.6</a>, ten epochs should be enough to get good results.</p>
<p>We can do so by creating an optimizer (we'll use <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam"><code>torch.optim.Adam()</code></a> with a learning rate of <code>1e-3</code>), a loss function (we'll use <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html"><code>torch.nn.CrossEntropyLoss()</code></a> for multi-class classification) and then passing these as well as our <code>DataLoader</code>s to the <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py"><code>engine.train()</code></a> function we created in <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them">05. PyTorch Going Modular section 4</a>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-13">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">engine</span>

<span class="c1"># Setup optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                             <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="c1"># Setup loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Set seeds for reproducibility and train the model</span>
<span class="n">set_seeds</span><span class="p">()</span>
<span class="n">effnetb2_results</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2</span><span class="p">,</span>
                                <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader_effnetb2</span><span class="p">,</span>
                                <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader_effnetb2</span><span class="p">,</span>
                                <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                                <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
                                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
<div id="cell-13" class="clipboard-copy-txt">from going_modular.going_modular import engine

# Setup optimizer
optimizer = torch.optim.Adam(params=effnetb2.parameters(),
                             lr=1e-3)
# Setup loss function
loss_fn = torch.nn.CrossEntropyLoss()

# Set seeds for reproducibility and train the model
set_seeds()
effnetb2_results = engine.train(model=effnetb2,
                                train_dataloader=train_dataloader_effnetb2,
                                test_dataloader=test_dataloader_effnetb2,
                                epochs=10,
                                optimizer=optimizer,
                                loss_fn=loss_fn,
                                device=device)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre>
</div>

</div>
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch: 1 | train_loss: 0.9856 | train_acc: 0.5604 | test_loss: 0.7408 | test_acc: 0.9347
Epoch: 2 | train_loss: 0.7175 | train_acc: 0.8438 | test_loss: 0.5869 | test_acc: 0.9409
Epoch: 3 | train_loss: 0.5876 | train_acc: 0.8917 | test_loss: 0.4909 | test_acc: 0.9500
Epoch: 4 | train_loss: 0.4474 | train_acc: 0.9062 | test_loss: 0.4355 | test_acc: 0.9409
Epoch: 5 | train_loss: 0.4290 | train_acc: 0.9104 | test_loss: 0.3915 | test_acc: 0.9443
Epoch: 6 | train_loss: 0.4381 | train_acc: 0.8896 | test_loss: 0.3512 | test_acc: 0.9688
Epoch: 7 | train_loss: 0.4245 | train_acc: 0.8771 | test_loss: 0.3268 | test_acc: 0.9563
Epoch: 8 | train_loss: 0.3897 | train_acc: 0.8958 | test_loss: 0.3457 | test_acc: 0.9381
Epoch: 9 | train_loss: 0.3749 | train_acc: 0.8812 | test_loss: 0.3129 | test_acc: 0.9131
Epoch: 10 | train_loss: 0.3757 | train_acc: 0.8604 | test_loss: 0.2813 | test_acc: 0.9688
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="34-inspecting-effnetb2-loss-curves">3.4 Inspecting EffNetB2 loss curves<a class="anchor-link" href="#34-inspecting-effnetb2-loss-curves">&#182;</a></h3><p>Nice!</p>
<p>As we saw in 07. PyTorch Experiment Tracking, the EffNetB2 feature extractor model works quite well on our data.</p>
<p>Let's turn its results into loss curves to inspect them further.</p>
<blockquote>
<p><strong>Note:</strong> Loss curves are one of the best ways to visualize how your model's performing. For more on loss curves, check out <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#8-what-should-an-ideal-loss-curve-look-like">04. PyTorch Custom Datasets section 8: What should an ideal loss curve look like?</a></p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-14">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">plot_loss_curves</span>

<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">effnetb2_results</span><span class="p">)</span>
</pre></div>
<div id="cell-14" class="clipboard-copy-txt">from helper_functions import plot_loss_curves

plot_loss_curves(effnetb2_results)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2oAAAG5CAYAAAD/HsejAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACMo0lEQVR4nOzdd3hUVf7H8fdJrySk0SGBAKGDhCYdLGBX7GJXdC27rq4/cXfdXV1ddXV31V0Vsa6VtXdRkaYgJSgonQk1tCSEkkJIO78/7hACUhJIcmeSz+t55iEzc+/cbyIy+cw553uMtRYRERERERHxHQFuFyAiIiIiIiIHU1ATERERERHxMQpqIiIiIiIiPkZBTURERERExMcoqImIiIiIiPgYBTUREREREREfo6AmIiIiIiLiYxTURE6AMWa9MeYUt+sQERGpa8aYmcaYncaYULdrEWkMFNRERERE5KiMMcnAUMAC59TjdYPq61oivkZBTaSWGWNCjTFPGGO2eG9P7P/00RiTYIz51BizyxiTZ4z51hgT4H3uHmPMZmNMvjFmlTFmtLvfiYiISKWrgHnAK8DV+x80xrQxxrxvjMkxxuwwxvynynM3GmNWeN/XlhtjTvI+bo0xqVWOe8UY86D36xHGmCzve+I24GVjTFPve2eOd0TvU2NM6yrnxxljXva+5+40xnzofXypMebsKscFG2NyjTG96+hnJFKrFNREat8fgIFAb6AX0B/4o/e5u4AsIBFoBvwesMaYzsBtQD9rbTRwOrC+XqsWERE5squAN7y3040xzYwxgcCnwAYgGWgFTAEwxlwE/MV7XhOcUbgd1bxWcyAOaAdMwPl99WXv/bbAXuA/VY5/DYgAugFJwL+8j78KjK9y3BnAVmvt4mrWIeIqDSeL1L4rgNuttdkAxpj7geeA+4BSoAXQzlrrAb71HlMOhAJdjTE51tr1bhQuIiJyKGPMEJyQ9La1NtcYkwlcjjPC1hK421pb5j38O++fNwB/t9Yu9N731OCSFcCfrbX7vPf3Au9VqechYIb36xbAWCDeWrvTe8gs75+vA/cZY5pYa/cAV+KEOhG/oBE1kdrXEufTxf02eB8DeAznzeorY8xaY8xEAG9ouwPn08dsY8wUY0xLRERE3Hc18JW1Ntd7/03vY22ADVVCWlVtgMzjvF6OtbZ4/x1jTIQx5jljzAZjzB5gNhDrHdFrA+RVCWmVrLVbgDnAOGNMLE6ge+M4axKpdwpqIrVvC84nj/u19T6GtTbfWnuXtbY9cDZw5/61aNbaN621+z+1tMCj9Vu2iIjIwYwx4cDFwHBjzDbvurHf4kzt3w60PULDj01AhyO8bBHOVMX9mh/yvD3k/l1AZ2CAtbYJMGx/ed7rxHmD2OH8F2f640XA99bazUc4TsTnKKiJnLhgY0zY/hvwFvBHY0yiMSYB+BPO9AuMMWcZY1KNMQbYA5QD5caYzsaYUd6mI8U40zzK3fl2REREKp2H837UFWftdW+gC87U/fOArcAjxphI7/vgYO95LwC/M8b0NY5UY8z+DzEXA5cbYwKNMWOA4ceoIRrnfXGXMSYO+PP+J6y1W4EvgGe8TUeCjTHDqpz7IXAS8BucNWsifkNBTeTEfY7zBrL/FgZkAD8BPwM/AA96j+0ITAMKgO+BZ6y1M3HWpz0C5ALbcBZD/77evgMREZHDuxp42Vq70Vq7bf8Np5nHZTizQ1KBjTjNsi4BsNa+AzyEM00yHycwxXlf8zfe83bhrOv+8Bg1PAGE47xHzgOmHvL8lThrwFcC2ThLCfDWsX99WwrwfvW/bRH3GWsPHV0WEREREWkYjDF/AjpZa8cf82ARH6KujyIiIiLSIHmnSl6PM+om4lc09VFEREREGhxjzI04zUa+sNbOdrsekZrS1EcREREREREfoxE1ERERERERH+PaGrWEhASbnJzs1uVFRKQeLVq0KNdam+h2Hf5C75EiIo3D0d4fXQtqycnJZGRkuHV5ERGpR8aYDW7X4E/0Hiki0jgc7f1RUx9FRERERER8jIKaiIiIiIiIj1FQExERERER8THa8FpEGr3S0lKysrIoLi52uxS/FxYWRuvWrQkODna7FBEREb+moCYijV5WVhbR0dEkJydjjHG7HL9lrWXHjh1kZWWRkpLidjkiIiJ+7ZhTH40xLxljso0xS4/wvDHGPGWM8RhjfjLGnFT7ZYqI1J3i4mLi4+MV0k6QMYb4+HiNTIqIiNSC6qxRewUYc5TnxwIdvbcJwLMnXpaISP1SSKsd+jmKiIjUjmMGNWvtbCDvKIecC7xqHfOAWGNMi9oqUEREREREpLGpja6PrYBNVe5neR/7BWPMBGNMhjEmIycnpxYuLSIiIiIi0vDURlA73DwXe7gDrbWTrbXp1tr0xMTEWri0iIj/27VrF88880yNzzvjjDPYtWtXjc+75pprePfdd2t8noiIiNSf2ghqWUCbKvdbA1tq4XVFRBqFIwW18vLyo573+eefExsbW0dViYiIiJtqoz3/x8BtxpgpwABgt7V2ay28rohIvbv/k2Us37KnVl+za8sm/Pnsbkd8fuLEiWRmZtK7d2+Cg4OJioqiRYsWLF68mOXLl3PeeeexadMmiouL+c1vfsOECRMASE5OJiMjg4KCAsaOHcuQIUOYO3curVq14qOPPiI8PPyYtX3zzTf87ne/o6ysjH79+vHss88SGhrKxIkT+fjjjwkKCuK0007j8ccf55133uH+++8nMDCQmJgYZs+eXWs/IxERETnYMYOaMeYtYASQYIzJAv4MBANYaycBnwNnAB6gCLi2rooVEWmIHnnkEZYuXcrixYuZOXMmZ555JkuXLq3ci+yll14iLi6OvXv30q9fP8aNG0d8fPxBr7FmzRreeustnn/+eS6++GLee+89xo8ff9TrFhcXc8011/DNN9/QqVMnrrrqKp599lmuuuoqPvjgA1auXIkxpnJ65QMPPMCXX35Jq1atjmvKpYiIiFTfMYOatfayYzxvgVtrrSIRERcdbeSrvvTv3/+gDaOfeuopPvjgAwA2bdrEmjVrfhHUUlJS6N27NwB9+/Zl/fr1x7zOqlWrSElJoVOnTgBcffXVPP3009x2222EhYVxww03cOaZZ3LWWWcBMHjwYK655houvvhiLrjgglr4TkVERORIamONmisqKiyLN+2itLzC7VJERGpVZGRk5dczZ85k2rRpfP/99yxZsoQ+ffocdkPp0NDQyq8DAwMpKys75nWcz9l+KSgoiAULFjBu3Dg+/PBDxoxxttKcNGkSDz74IJs2baJ3797s2LGjpt+aiEjdKyuBgmy3q5CGbvsy2LurTi/ht0Htm5XZnPf0HBauP9oWbyIivi86Opr8/PzDPrd7926aNm1KREQEK1euZN68ebV23bS0NNavX4/H4wHgtddeY/jw4RQUFLB7927OOOMMnnjiCRYvXgxAZmYmAwYM4IEHHiAhIYFNmzYd5dVFROpZRTksfgv+fRI83hH+nQ5f3AOrv4SSQrerk4Zkz1Z47QJ47/o6vUxtNBNxxaAO8QQHGmauyuHkDglulyMictzi4+MZPHgw3bt3Jzw8nGbNmlU+N2bMGCZNmkTPnj3p3LkzAwcOrLXrhoWF8fLLL3PRRRdVNhO5+eabycvL49xzz6W4uBhrLf/6178AuPvuu1mzZg3WWkaPHk2vXr1qrRYRkeNmLaz5Gqb9BbKXQcs+kH4tbJgLi/4L8ydBQDC0HQipo6HDKGjWAwL8drxC3FRaDP+7AkoK4NS/1umlzJGmvtS19PR0m5GRcUKvMf6F+WzbU8y0O4fXUlUi0hitWLGCLl26uF1Gg3G4n6cxZpG1Nt2lkvxObbxHijQKmxbCtD/DhjkQ1x5G/wm6ngfGu81vaTFs/B4yv4HMGbB9qfN4ZCK0H+kEt/YjIbrZES8hUsla+OBm+GkKXPIGdDnrhF/yaO+PfjuiBjAyLYm/frqcTXlFtImLcLscEREREakPuWvgm/thxScQmQRn/gNOuhoCgw8+LjgMOox0bgD52yBzuvf2Dfz8tvN4sx6QOsoZbWs7CIJCEfmF7592QtqI39dKSDsW/w5qnRP566cwfWU2V5+c7HY5IiI+5dZbb2XOnDkHPfab3/yGa6/VLioi4qf2bIVZj8APr0FwOIz8Awy8BUKjqnd+dHPofblzq6iAbT8dGG37/hmY8yQEhUPykAPTJBM6HRihk8bLMw2+vg+6nAPD7q6XS/p1UGufGEVyfAQzVimoiYgc6umnn3a7BBGR2lG82wlR3z8DFWXQfwIM+x1EnkCfgoAAaNnbuQ29C/blw/o53uA2HaZOdI5r0toZkUsdDSnDISKuNr4j8Sc7MuHd6yCpK5z3bL2tb/TroAbO9Mc3529kb0k54SGBbpcjIiIiIrWltBgWvgDfPg57d0KPi2Hk7yEu5djn1lRoNHQe49wAdq4/ME1y+cfw42tgAqDlSQdG21qlQ6Df/zotR1O8B966DEwgXPpG9Udva4Hf/80alZbEy3PWMzczl9FdtBBURERExO9VlMNPb8OMh2D3JugwGk75M7Sox26zTZMh/TrnVl4GmxcdGG2b/RjMehRCm0DKsAPBrWly/dUnda+iAt6/EXZ44KqP6v2/r98Htf4pcUSEBDJjVbaCmoiIiIg/O7TVfovecO5/oP0Id+sKDIK2A5zbyN9DUR6sm+0EN890WPmpc1xcByewpY521rmFRrtbt5yYGQ/C6qlwxuOQMrTeL+/3QS00KJDBqQnMWJmDtRajxZ4iIiIi/icrA77+M2z4DpqmwIUvO632fXG/s4g46Haec7PW6UK5f7Rt8Ruw8Hln77Y2Aw50k2zeyze/Fzm8pe/Bt95uov1ucKWEBvG3ZVRaEpt37WX19gK3SxERqbFdu3bxzDPPHNe5TzzxBEVFRUc9Jjk5mdzc3ON6fRGROpe7Bv53JbwwGnJXO6MXty2E7hf4R7AxBhI7wcBfwRXvwD3r4aqPYdAtsG83fPMATB4Bj6fCu9fD6i+dqZ3iu7YugQ9vhTYDnb+PLg0E+cHf/mMb0TkRcNr0i4j4m7oOaiIiPmnPVvjkN/D0AGckauQf4Nc/Qv8bf7kfmj8JCoX2w+HUB+Dm7+Cu1XD+ZEg9BdbOgDcvhid7way/w54tblcrhyrIgbcud0ZNL3kNgkJcK8Xvpz4CtIgJp0uLJsxYlc2vRnRwuxwR8WdfTIRtP9fuazbvAWMfOeLTEydOJDMzk969e3PqqaeSlJTE22+/zb59+zj//PO5//77KSws5OKLLyYrK4vy8nLuu+8+tm/fzpYtWxg5ciQJCQnMmDHjmKX885//5KWXXgLghhtu4I477jjsa19yySVMnDiRjz/+mKCgIE477TQef/zxWvuRiEgj9otW+zfC0N9BVKLbldWN6GbQ6xLnVlYCqz6HRa84jVJmPgKdxkD6tc70yAB1MHdVWQm8fRUU5cJ1UyEqydVyGkRQAxiVlsikWWvZXVRKTIQffwojIo3OI488wtKlS1m8eDFfffUV7777LgsWLMBayznnnMPs2bPJycmhZcuWfPbZZwDs3r2bmJgY/vnPfzJjxgwSEo69l9CiRYt4+eWXmT9/PtZaBgwYwPDhw1m7du0vXjsvL48PPviAlStXYoxh165ddfkj8HnGmDHAk0Ag8IK19pFDnm8KvAR0AIqB66y1S73PrQfygXKgzFqbXo+li/iOsn1Oq/3Zj3lb7V/kjKLVRat9XxUUcmBtW95aWPRfZ03bqs8gpi2cdBX0GQ9NWrhdaeP0xf/Bxrkw7kVo2cftahpSUEvi6RmZzF6Tw9m9Wrpdjoj4q6OMfNWHr776iq+++oo+fZw3iIKCAtasWcPQoUP53e9+xz333MNZZ53F0KE17z713Xffcf755xMZGQnABRdcwLfffsuYMWN+8dplZWWEhYVxww03cOaZZ3LWWWfV6vfpT4wxgcDTwKlAFrDQGPOxtXZ5lcN+Dyy21p5vjEnzHj+6yvMjrbVaKCiNU2Wr/b/B7o3utNr3RXHt4dT7nbC66jPIeNnpMjjzYeg8Fvpe62y0rVG2+rHwRVj0Mgy+A3pc6HY1QANZowbQu01TYiOCmbFK69RExH9Za7n33ntZvHgxixcvxuPxcP3119OpUycWLVpEjx49uPfee3nggQeO67UP53CvHRQUxIIFCxg3bhwffvghY8aMOdFvzZ/1BzzW2rXW2hJgCnDuIcd0Bb4BsNauBJKNMdozxl+UFMGmhbD1JygvdbuahsNaWP0VTBoKH97srPm56iO48n2FtKqCQqDb+XD1x3D7D3DybbBxHrwxDp7s7YxA5m9zu8qGbf13zmhax9Nh9J/crqZSgxlRCwwwDO+UyKxVOVRUWAIC1KZfRPxDdHQ0+fn5AJx++uncd999XHHFFURFRbF582aCg4MpKysjLi6O8ePHExUVxSuvvHLQudWZ+jhs2DCuueYaJk6ciLWWDz74gNdee40tW7b84rULCgooKirijDPOYODAgaSmptblj8DXtQI2VbmfBQw45JglwAXAd8aY/kA7oDWwHbDAV8YYCzxnrZ18uIsYYyYAEwDatm1bq9+AVFFS5KxD3boYtiyGLT9C7iqwFc7zgaHQvLuzf1fLPtCyNySm+XdzCzf4U6t9XxLfwWlCMvKPzt5si16G6Q/CDO8oW/q10H6Ufo61addGZ11a0xQY97xPjWA2mKAGzvTHjxZvYUnWLvq0bep2OSIi1RIfH8/gwYPp3r07Y8eO5fLLL2fQoEEAREVF8frrr+PxeLj77rsJCAggODiYZ599FoAJEyYwduxYWrRoccxmIieddBLXXHMN/fv3B5xmIn369OHLL7/8xWvn5+dz7rnnUlxcjLWWf/3rX3X7Q/Bth/vk79DhyUeAJ40xi4GfgR+BMu9zg621W4wxScDXxpiV1trZv3hBJ8BNBkhPTz/88KfUTEkRbF96IJBtXQw5Kw+EssgkJ4h1Odv5s3Sv97glzlS9jBed4/aHt5Z9vAGut8LbkeSucdrRr/gYIhOd1uYnXe1q5zy/FBTibE/Q/QLYkek0H1n8hhPeYts6P9M+4yG6uduV+reSQqfDY3kZXDYFwmLcrugg5khTYepaenq6zcjIqNXX3FlYQt8Hv+a2kanceVrnWn1tEWm4VqxYQZcuXdwuo8E43M/TGLPIX5toGGMGAX+x1p7uvX8vgLX24SMcb4B1QE9r7Z5DnvsLUGCtPWoLzbp4j2zwqoayrYudwJWzCqx3v6rIxIODVss+EN3iyPsjVVQ4zR72v9aWxU6AK3FGvwkKg2bdD7xWi97e8NagPgOvvvxtTgfDH16F4HA4+dcw6FYIjXK7soajbJ8T1DJehvXfQkDQgbVs7UdqlK2mrIV3rnE+VLj8Heh4iitlHO39sUH9a9I0MoQ+bZsyY1WOgpqIiNSWhUBHY0wKsBm4FLi86gHGmFigyLuG7QZgtrV2jzEmEgiw1uZ7vz4NqPkCQzlY6V7YtvTAKNmWxd6RsiqhrEVvSDvLCVItekOTljXbtDYgABJSndv+xgIVFZCXWSUMLoYlU5xOhlAlvPU5cN2GHt4ObbXf7wYYdnfDbbXvpqBQ6D7OueV64IdXYPGbsOITiG0Hfa+G3uOd7QDk2L59HJZ/6Ew1dSmkHUuD+5djVFoSj325iuw9xSQ1CXO7HBGRejNgwAD27dt30GOvvfYaPXr0cKmihsFaW2aMuQ34Eqc9/0vW2mXGmJu9z08CugCvGmPKgeXA9d7TmwEfOINsBAFvWmun1vf34Nf2h7Kqa8qqhrKIBCcYpZ1xYF1ZTUNZdQUEQEJH59bzIuexquFtf3Bc8hYsfN55Pij8l2veEjr7V3grL3Pa6e/Ng6I8KNrhfL1rkxNS9+Y1zlb7bkpIhdMehFH3OUFt0SvOlNMZf4POZzhr2VJGaJTtSFZ+7qz963GxM/rroxrU1EeA5Vv2cMZT3/L3cT25uF+bWn99EWl4VqxYQVpaGqYufrFrZKy1rFy5skFNfXRDo536WLoXti+rMtVwMWSvOCSU9T54CmOTVnUTyk5ERQXs8BwIl1sXe6dNFjjP7w9vVb+P+gpvpXudsHVo6CraH8R2HPz83jxn1OxIOoyCU/6iLo6+IHeNdy3bm85/t6bJB9ayubxxs0/JXgEvnOJ84HLtF85UXRcd7f2xwQU1ay2DHp5On7axPDu+b62/vog0POvWrSM6Opr4+HiFtRNgrWXHjh3k5+eTknLwp+oKajXTKIJaabF3TVmV6YsHhbL4X64p88VQVl0HhTdvEN320yHhrcfBQTSh05HDm7Wwb0+VULWzSujKO0zo8gax0qIj1xgS5bTQD4+r8mf8IY81PfgxrUHzPaXFB9aybfjOWcuWdqazli1leOMeZSvKg+dHOU1EJsyEmFZuV9R41qgBGGMYmZbIJ0u2UlJWQUhQI/7LKCLV0rp1a7KyssjJyXG7FL8XFhZG69at3S5DfEnxHti5DvLWOX/mepzRpZwVzpomcH7xb9EbOo05sLYrprX/hrLDCQiAxE7OrefFzmMV5U54q9oA5cc3YIF3B4f94S0+9ZBQ5v1z/8/vFwyExzo/1/A4J+A26+GEqyMGsabOGijxf8FhzrrKHhdCzmr44b9Ox8jlHzkt6PteDb2vaHyjbOVl8O51sGczXP2pT4S0Y2lwI2oAXy3bxoTXFvHmDQM4OfXYewuJiEjd0ohazfjViJq1UJjrdEjcH8iqfl2Ue/DxkYnQvOeBQNayT8MLZSeianjbP9q4c4MTvMLjIKLpEUa6qjwWFuNTe0GJDygt9q5lexk2zIGAYGeULf1aSB7WOEbZpv4e5j0N5/wHTrrS7WoqNaoRNYDBqQmEBAYwfWW2gpqIiMiJqih3PoXOW3tgZCxvLeStd77eP30PAOMEr6bJzi+CcSnOp/j7/wxr4tI34ScCAiGxs3PrdYnb1UhDERzmNMDpeZGzbcWi/8KSN52uh3HtD6xli2ygvzcvftMJaf1v8qmQdiwNMqhFhgYxoH0cM1Zl88ezurpdjoiIiO8rLYZdG6oEsSojYzs3QEXpgWMDQ5x24HHtIXnwgSAW197ZjFdT6ER8V2JnGPM3GP0nZzrkoldg2p9h9mMw+DfO/nchkW5XWXuyMuCT30DKMDj9IberqZEGGdQARnZO4oFPl7NxRxFt4yPcLkdERMR9xbsPDmKVgWydM2JGleUQIdEQlwzNujn7kVWOjLV32t9rap2IfwsOc0Zte13iNPKZ8ZBzy3gJRv7eWcfm7/+f79kKU65wNre/6L8QGOx2RTXSYIPaqDQnqE1fuZ1rBmtPDxERaUS2LoHty385Mla04+DjIhO9o2JDDg5icSnOeietGxNpHJK6wCWvw8Z58NUf4ePbYd6zzmbQqaf4578FpcXwvytgXz5c+b6zftPPNNiglpwQSUpCJDNW5SioiYhI4/LNA+CZBibAu14sBbqcfXAQa5oModFuVyoivqTtQLj+a2ft2rT74Y0LnZb+p/3Vv/bKsxY+vQM2L3ICaLNubld0XBpsUANn+uPr8zdQVFJGREiD/lZFREQOOO0hGPOod71YiNvViIg/MQa6nQ+dz4SMF2HWo/DccOh1KYz6o/Phj6+b9wwseQtG3Ot8SOWnGnQvzlFpSZSUVTDXs+PYB4uIiDQUSWmQkKqQJiLHLygEBv4Kfr0YBv8alr4P/+4L0/7irHf1VZ5vnOmbXc6GYf/ndjUnpEEHtX4pTYkICWT6qmy3SxERERER8T/hsc5atdszoOu58N2/4Kk+MP85KCtxu7qD7ciEd6+FxC5w3iS/3x/Ov6s/htCgQIakJjBzZTZubewtIiIiIuL3YtvCBZNhwixnzdcX/wfPDHBa/PvC79nFe+Cty5y1uZe9CaFRbld0whp0UANn+uOW3cWs2p7vdikiIiIiIv6tZW+46mO4/B1nT8W3r4KXTodNC9yrqaIC3p8AOzxOG/6mye7VUosafFAbmZYEwPSVmv4oIiIiInLCjIFOp8HNc+DsJ2HnenjxVPjflc70w/o24yFY/QWMeQTaD6//69eRBh/UmjUJo2uLJsxcmeN2KSIiIiIiDUdgEPS9Bm7/wemw6PkGnu4PX9wDhfXUzG/p+/Dt49DnSuh/Y/1cs540+KAGzvTHRRt3sruo1O1SREREREQaltAoGDERfv0D9BkPCybDU72dxiOle+vuult/gg9vgTYD4Mx/+OfG3EfRKILayLQkyisss9ZoVE1EREREpE5EN3emQv7qe2h3stPK/9/psGSKs46sNhXkwJTLISLO2dQ6KLR2X98HNIqg1rtNLE0jgpmhdWoiIiIiInUrKQ0u/x9c/QlEJsAHN8Hk4bB2Zu28flmJ08SkMAcufQOikmrndX1MtYKaMWaMMWaVMcZjjJl4mOebGmM+MMb8ZIxZYIzpXvulHr/AAMPwTonMWp1DeYUPtA8VEREREWnoUobBjTPgghdg70549Vx4/ULYvvzEXnfqPbBxLpzzH2jZp3Zq9UHHDGrGmEDgaWAs0BW4zBjT9ZDDfg8sttb2BK4CnqztQk/UyLQk8gpLWJK1y+1SREREREQah4AA6HkR3JbhbJy9aQFMGgwf3QZ7ttb89Ra+CBkvweDfOK/bgFVnRK0/4LHWrrXWlgBTgHMPOaYr8A2AtXYlkGyMaVarlZ6g4Z0SCTBo+qOIiIiISH0LDnPC1W8Ww4CbnXVr/z4JZvwN9hVU7zXWz3E22k49FUb/uU7L9QXVCWqtgE1V7md5H6tqCXABgDGmP9AOaH3oCxljJhhjMowxGTk59dvYIzYihJPaNmXGKgU1ERERERFXRMTBmIfhtgXQ6XSY9Sg81ccZJSsvO/J5uzbC21dC0xQY9wIEBNZfzS6pTlA7XJ/LQxd6PQI0NcYsBm4HfgR+8ZO21k621qZba9MTExNrWusJG5mWxNLNe8jeU1zv1xYREREREa+49nDRK3DDNxDfAT79LTx7Mqz6AuwhUaOk0OnwWF4Kl70F4bFuVFzvqhPUsoA2Ve63BrZUPcBau8dae621tjfOGrVEYF1tFVlbRqU5HWE0qiYiIiIi4gNap8O1X8Alb4Ath7cuhVfOgs0/OM9b6+yVtm0pjHsREjq6W289qk5QWwh0NMakGGNCgEuBj6seYIyJ9T4HcAMw21q7p3ZLPXFpzaNpERPGdK1TExERERHxDcZAl7PglnlwxuOQsxKeHwnvXg9f3wfLP4RT/gKdTnO70noVdKwDrLVlxpjbgC+BQOAla+0yY8zN3ucnAV2AV40x5cBy4Po6rPm4GWMY0TmJjxdvpqSsgpCgRrGNnIiIiIiI7wsMhv43Qs9LYM4T8P3TUFYMPS5yGpE0MscMagDW2s+Bzw95bFKVr78H/GIcclRaEm8t2MjC9XkMTk1wuxwREREREakqrAmM/hOkXw+rv4DeVzijbo1MtYJaQzI4NZ6QwACmr8xWUBMRERE5grLyCvIKS8gp2EdO/j5yC0q8fzr3dxaVkN4ujqsGtaNpZMixX1CkpmJaQb8b3K7CNY0uqEWEBDGgfRwzVmVz31mH7tstIiIi0nCVV1h2FpVUhq2qwevQIJZXVPKL5nsAESGBJEaHEhkSxL+mrWbSrEwuTm/NDUPb0yYuov6/KZEGqtEFNXCmP97/yXI27CikXXyk2+WIiIiIHDdrLbuKSskp2Edu/r7KETDnfslBj+cVllBe8cv0FRoUQGJ0KAlRobSJi6BP26YkRoc6t6iQyucSokKJDD3w6+Oa7flMnr2WNxds5LV5GzijRwtuGtaBHq1j6vNHINIgNcqgNrKzE9Smr8zm2sEpbpcjIiIiclhFJWX8nLWb7CojXZWjXt4glluwj7LDhK/gQENiVCgJ0aG0iAmjR6uYyvCVELX/TyeERYUGYY5jDVDHZtE8dlEv7jqtMy/PWceb8zfy6U9bGZwaz4RhHRjWMeG4XldEGmlQS06IpH1CJDNW5SioiYiIiE/ZvbeU6Su3M3XpNmatzqG4tKLyucAAQ0JUSGXQ6tK8CQnRoZWBLDEqlMToEBKjwmgSfnzh63g0jwnj3jO6cOuoVN6av5GX5qzj6pcWkNY8mpuGt+esni0JDlS3bZGaaJRBDWBkWhKvzdtAUUkZESGN9scgIiIiPiC3YB9fL3fC2dzMXErLLUnRoVyc3oaRnZNoGRtOYnQoseHBBAT47ghVk7BgbhregWsHp/DR4s1Mnr2W3/5vCY9NXcV1Q1K4tH9bokL1e5dIdTTa/1NGpSXx4nfrmOPZwaldm7ldjoiIiDQyW3bt5ctl25i6dBsL1+dRYaFNXDjXDk7h9G7N6dMm1qdD2dGEBAVwUXobxp3Umpmrs3lu1loe/GwFT32zhisHtePqk5NJig5zu0wRn9Zog1q/5DgiQwKZvjJbQU1ERI7KGDMGeBIIBF6w1j5yyPNNgZeADkAxcJ21dml1zpXGZV1uIVOXbmPq0q0sydoNQKdmUdw2MpXTuzena4smDWpNV0CAYVRaM0alNePHjTuZPHstz8zM5PnZ6xjXtxU3DG1Ph8Qot8sU8UmNNqiFBAUwpGMCM1dlY61tUP8oiohI7THGBAJPA6cCWcBCY8zH1trlVQ77PbDYWnu+MSbNe/zoap4rDZi1lpXb8r3hbBurtucD0LN1DHef3pkx3Zs3mqDSp21Tnh3fl3W5hbzw7VreWZTFlIWbOLVLM24a3p6+7eLcLlHEpzTaoAbO9Mcvl21n5bZ8urRo4nY5IiLim/oDHmvtWgBjzBTgXKBq2OoKPAxgrV1pjEk2xjQD2lfjXGlgKiosS7J2MXXZNr5cuo31O4owBvq1i+O+s7pyerdmtG7aePcbS0mI5KHze/DbUzvx6tz1vDpvA18t3056u6bcNLwDo9OS/HbKp0htatRBbUTnJACmr8xWUBMRkSNpBWyqcj8LGHDIMUuAC4DvjDH9gXZA62qeC4AxZgIwAaBt27a1UrjUn7LyChau31m55mzbnmKCAgyDOsRz47D2nNa1OYnRoW6X6VMSokK587TO3DyiA28v3MTz367jxlcz6JAYyYRh7TmvTytCgwLdLlPENY06qDVrEka3lk2YuSqbW0emul2OiIj4psN9tH/oplWPAE8aYxYDPwM/AmXVPNd50NrJwGSA9PT0wx4jvmVfWTlzM3cw9edtfL1iO3mFJYQGBTCsUyL/170zo9OaERMR7HaZPi8iJIhrBqcwfmA7Pl+6jedmZXLPez/z+FeruXZwMlcMaEdMuH6O0vg06qAGzvTHp2d42FVUQmxEiNvliIiI78kC2lS53xrYUvUAa+0e4FoA4yx6Xue9RRzrXPEvRSVlzF6dwxdLtzF9RTb5+8qIDAlkVJdmjO3enOGdEolU+/njEhQYwDm9WnJ2zxbMzdzBpFmZ/H3qKp6e7uGy/m25bkgKLWPD3S6zwbHW8sPGneQXlzGoQ7xGMX1Io/+XZGRaEv+e7mHW6hzO7d3K7XJERMT3LAQ6GmNSgM3ApcDlVQ8wxsQCRdbaEuAGYLa1do8x5pjniu/bvbeUGSuz+WLp1soNqGMjghnTvTljezTn5A4JhAXrl9vaYoxhcGoCg1MTWLZlN8/PXsvLc9fzytz1nNOrJROGtyetuZasnKj84lI+/HEzr8/bWNnkJio0iJFpSfrQwUc0+p9+r9axxEWGMGNltoKaiIj8grW2zBhzG/AlTov9l6y1y4wxN3ufnwR0AV41xpTjNAq5/mjnuvF9SM0cbQPqMd2a0z8ljqDAALfLbPC6tYzhiUv78LvTO/PSd+uZsnAj7/+4meGdErlpeHsGtY9X5+4aWrltD6/P28AHP2ymsKSc7q2a8Oi4HiQ1CePLpdv4avl2PlmypXIa79juzTWN1yXGWnemwaenp9uMjAxXrn2o3/5vMTNXZZPxx1MJVJchEZFaZ4xZZK1Nd7sOf+FL75GNyZE2oB7bvYXfb0DdUOwqKuGN+Rt5ec46cgtK6NEqhpuGt2dMt+YKzkdRUlbBF0u38sa8jSxYn0dIUABn92zJlYPa0at1zEFht6y8gowNOyu3lKjaGGdM9+ZqjFPLjvb+qKAGfLxkC79+60fe+9XJ9G3X1O1yREQaHAW1mvGl98jGoLi0nNvf+pGvl28HoGNSFGO7N2+QG1A3FMWl5bz/w2Ze+HYta3MLaRsXwQ1DU7iobxvCQzQNdb/Nu/by5vwN/G/hJnILSmgXH8EVA9pyUd82NI08dm+GigrLT5t3V27SXnWridO7N2/0W03UBgW1Y9hdVEqfv37FLSNS+d3pnd0uR0SkwVFQqxlfeo9s6ErKKrj59UXMWJXNbSNTObd3K1KTGscG1A1BeYXl6+XbeW52Jj9u3EXTiGCuGpTMVYPaER/VOEd9Kios33pyee37DUxf6Xz4MCqtGVcOasfQ1ITjHhW21rJq+4HN21duO7B5++ndmjeqzdtrk4JaNVw0aS5FJeV89uuhbpciItLgKKjVjK+9RzZU5RWWX0/5kc9+2srfzu/B5QO0f52/staSsWEnz81ay7QV2wkw0LtNLEM7JjKsUyK9Wsc0+KmROwtLeGfRJt6Yv5ENO4pIiArhkn5tuKx/2zoZ9VqXW1g5VXjxpl0AdGoWxZhuGo2uCQW1anhmpoe/T13F/N+PplmTMLfLERFpUBTUasbX3iMboooKyz3v/cQ7i7L4wxlduHFYe7dLklriyc7n48VbmLUml5+ydmEtNAkLYnBqgje4JTSY6XrWWpZk7ea17zfwyU9bKCmroH9yHOMHtWNMt+aEBNVPON2yay9fLdvG1GXbWLDOWd/ZNi6CMd2ba33nMSioVcPKbXsY88S3PHJBDy7tr0/URERqk4Jazfjae2RDY63l/k+W88rc9fx6dEfuPLWT2yVJHdlVVMJ3nly+XZ3L7DU5bN1dDED7hEiGdXJC24CUeL9rQ7+3pJyPlzit9X/evJvIkEDOP6kV4we2c33rgtyCfUxbvp2py7Yxx+N0TG3WJNSZHqmOqb+goFYN1loGPzKd7q1imHyVfpcQEalNCmo142vvkQ3NP75axb+ne7hucAr3ndVF07MaCWstmTkFzFqdy7drcpi3dgfFpRUEBxrS28UxtFMCwzom0rVFE58d/cnMKeCNeRt5d9Em9hSX0blZNOMHteP8Pq2I8sGwuae4lOkrspm6dBszV2dTXFpB04hgTunSjLE9mjM4NaHRb7B9tPdH3/sv6hJjDCPSkvjox83sKytv9H9pREREGqJJszL593QPl/Zro5DWyBhjSE2KJjUpmuuHpFBcWk7G+p18uyaHWatz+PvUVfx96ioSokIY4p0mObRTAknR7i6JKSuvYNqK7bw+byPfeXIJDjSM6d6CKwe2o19yU5/+O9wkLJjz+rTivD6t2FtSzqzV2ZXNSN5ZlKUNto9BP40qRnVO4s35G1m4bidDOia4XY6IiIjUotfnbeCRL1ZyVs8WPHR+D5/+BVfqXlhwIEM6JjCkYwL3ntGF7D3FfLvGGW37dk0uHy7eAkBa82iGd0pkaMdE0pObEhZcPx/mb99TzJQFm3hrwUa27SmmZUwYd5/emYvT2/jlPmbhIYGM6d6CMd1bUFJWwdzMXKYeZoPtMd2ac0oXbbANmvp4kKKSMno/8DXjB7TjT2d3dbscEZEGQ1Mfa8YX3yP93Qc/ZnHn20sY1TmJSVf2JVhrZOQoKiosy7fuYfaaHL5dnUvGhjxKyy1hwQEMSIl31rd1TCA1KapWA7+1lu/X7uD1eRv4atl2yioswzolcuXAdoxKSyLQR6dknoiqG2x/uWwbW3cfvMH2qV2buT6qWZe0Rq0GrnppAVl5RUz/3Qi3SxERaTAU1GrGV98j/dXUpdu49c0fGJASx0vX9Ku3ERFpOAr3lTFv7Q6+XZPL7NU5rM0tBKBFTBjDvFMkh6QmEBtx7E2kD2dPcSnvL8ri9fkb8WQXEBsRzMXpbbi8f1uSEyJr81vxaYfbYDvAwJk9W3LTsPZ0bxXjdom1TmvUamBU50T+8sly1ucWNqr/MURERBqi2atz+PVbP9KzdQzPX5WukCbHJTI0iNFdmjG6SzMANuUVVU6T/HzpVv6XsQljoGfrWIZ3TGBop0R6t4k95sjtsi27eX3eRj78cTN7S8vp1SaWxy/qxVk9WzTKv6sBAYbebWLp3SaWe8Z0ZtX2fN7/YTNvzd/IJ0u2MDg1npuGdWBox4RGMXVZI2qH2LijiGGPzeBPZ3XluiEpbpcjItIgaEStZnz1PdLfLFyfx5UvziclIYopNw7UmhepE2XlFSzJ2s3s1Tl8uyaHxZt2UWEhOjSIQR32T5NMpG28s3dbcWk5Xyzdymvfb+CHjbsICw7g3F5Oa/0erRveiFFt2FNcylvzN/LSnHVs37OPLi2acNOw9pzZs4XfT2PW1McaGv2PmbSMDee16we4XYqISIOgoFYzvvwe6S9+ztrN5c/PI7FJKG/fNIiEKP9rviD+aXdRKXMyndG22atz2bxrLwDJ8RH0ahPLt2tyySssoX1CJFcMbMeFJ7XWhwjVVFJWwUeLNzN59lrWZBfQKjac64akcGm/Nn7bMVJTH2toZOckXv1+A4X7yvz2P7qIiEhjtWZ7Ple9NJ8m4cG8fv0AhTSpVzERwZzRowVn9GiBtZa1uYXe0TZnfduAlHiuHNSOkzvEN4rpe7UpJCiAi9LbMO6k1sxcnc2kWWv566fLeeqbNYwf2JarT05uUI1HlEIOY1RaEi98t445nlxO69bc7XJERESkmjbsKOSKF+YTHBjAmzcOoGVsuNslSSNmjKFDYhQdEqO4drCW1NSWgADDqLRmjEprxo8bdzJ59lqemZnJ89+uY9xJrbhhaHs6JEa5XeYJ8+9JnXUkPTmOqNAgZqzKdrsUERERqaatu/dyxQvzKSmv4PUbBtAuXk3BRBq6Pm2b8uz4vky/awQX9W3Nez9s5pR/zmLCqxks2rDT7fJOiEbUDiMkKIAhqQnMWJmDtVbD0iIiIj4ut2Af41+Yz66iUt68cQCdmkW7XZKI1KOUhEgeOr8Hd5zSiVe/X8+r32/gq+XbSW/XlJuGd2B0WhIBfrYPnUbUjmBUWhLb9hSzYmu+26WIiIjIUezeW8pVLy5g8669vHRNP3q2jnW7JBFxSWJ0KHed1pm5E0fx57O7snV3MTe+msGp/5rF/xZuZF9ZudslVpuC2hGMSEsE0PRHERERH1a4r4xrX17Amux8nrsynf4pcW6XJCI+IDI0iGsHpzDr7hE8eWlvwoIDuee9nxny6Ayemelh995St0s8JgW1I0iKDqNHqximr1RQExER8UXFpeXc+GoGS7J28+/L+jC8U6LbJYmIjwkKDODc3q349PYhvH79ANKaR/P3qas4+eFvePDT5Wzxbp/gi7RG7ShGdk7kPzM87CwsoWlkiNvliIiIiFdpeQW3vfkDczN38M+LezGmewu3SxIRH2aMYUjHBIZ0TGDZlt1Mnr2Wl+eu55W56zmnV0smDG9PWvMmbpd5EI2oHcXItCQqLMxek+N2KSIiIuJVXmG56+0lTFuRzV/P7cYFJ7V2uyQR8SPdWsbw5KV9mHX3CK4c1I6py7Yx5olvueblBczNzMVa63aJgILaUfVqHUt8ZIimP4qIiPgIay1/+OBnPl6yhYlj07hyULLbJYmIn2rdNII/n92NuRNH8bvTOrF0824uf34+5z49h09/2kJZeYWr9SmoHUVAgGF4p0Rmrc6hvMI3krWIiEhjZa3lwc9WMGXhJm4bmcrNwzu4XZKINACxESHcNqoj390zir+d34P84jJue/NHRv1jFq9+v569Je50iqxWUDPGjDHGrDLGeIwxEw/zfIwx5hNjzBJjzDJjzLW1X6o7RqYlsauolMWb/HvDPBEREX/35DdrePG7dVxzcjJ3ndbJ7XJEpIEJCw7k8gFtmXbncCaN70t8VAh/+mgZJz/yDf/6ejV5hSX1Ws8xg5oxJhB4GhgLdAUuM8Z0PeSwW4Hl1tpewAjgH8aYBtF9Y1inRAIDjKY/ioiIuOiFb9fyxLQ1XNS3NX86qyvG+NfGtSLiPwIDDGO6N+f9X53MOzcPom+7pjz5zRpOfuQb7vtwKRt2FNZLHdUZUesPeKy1a621JcAU4NxDjrFAtHH+1YwC8oCyWq3UJTHhwfRt15TpK9VQRERExA1vzt/Ig5+t4MweLXhkXE8CAhTSRKTuGWPolxzHC1f34+vfDuOcXi2ZsnAjIx+fya1v/MBPWbvq9PrVCWqtgE1V7md5H6vqP0AXYAvwM/Aba+0vVt8ZYyYYYzKMMRk5Of4TfEZ2TmLF1j1s213sdikiIiKNykeLN/OHD39mZOdE/nVJbwIV0kTEBR2bRfP3C3vx3T2jmDCsA7NX5/DcrLV1es3qBLXD/Yt4aGeN04HFQEugN/AfY8wvNiKw1k621qZba9MTE/1nU8pRaUkAzFil6Y8iIiL15evl27nz7SX0T47j2fF9CQlSDzQRcVezJmFMHJvG3HtHcd9Zh64Gq13V+RcvC2hT5X5rnJGzqq4F3rcOD7AOSKudEt3XqVkUrWLDtU5NRESknny3Jpdb3/iB7q1iePGafoQFB7pdkohIpeiwYJrHhNXpNaoT1BYCHY0xKd4GIZcCHx9yzEZgNIAxphnQGajbscB6ZIxhROdE5nhy2VfmTntOERGRxmLRhjxufDWD9omR/PfafkSFBrldkohIvTtmULPWlgG3AV8CK4C3rbXLjDE3G2Nu9h72V+BkY8zPwDfAPdba3Loq2g2j0pIoKilnwbo8t0sRERFpsJZu3s01Ly+keUwYr17fn9iIBtFEWkSkxqr1EZW19nPg80Mem1Tl6y3AabVbmm85uUMCIUEBTF+ZzdCO/rO+TkRExF94svO56qUFNAkL5vUbBpAUXbfTikREfJlW5VZTeEggg9rHM0Pr1EREGh1jzBhjzCpjjMcYM/Ewz8cYYz4xxiwxxiwzxlxb5bn1xpifjTGLjTEZ9Vu5/9iUV8T4FxYQYAyv3zCAVrHhbpckIuIqBbUaGJWWxPodRazLrZ9N7kRExH3GmEDgaWAs0BW4zBhzaKuvW4Hl1tpewAjgH9513fuNtNb2ttam10fN/mb7nmKueGE+e0vLef2G/qQkRLpdkoiI6xTUamB/m351fxQRaVT6Ax5r7VprbQkwBTj3kGMsEG2MMUAUkAeU1W+Z/imvsIQrXpjPjoJ9/Pe6/qQ1/8XuPiIijZKCWg20iYsgNSlK0x9FRBqXVsCmKvezvI9V9R+gC872NT8Dv7HWVnifs8BXxphFxpgJR7qIMWaCMSbDGJORk5NTe9X7sD3FpVz10nw25RXx4jX96N0m1u2SRER8hoJaDY3snMj8dTso3KcPSkVEGglzmMfsIfdPBxYDLYHewH+MMfuHhgZba0/CmTp5qzFm2OEuYq2dbK1Nt9amJyY2/KZVRSVlXPfyQlZty2fSlX0Z2D7e7ZJERHyKgloNjUxLorTc8p2nQe0+ICIiR5YFtKlyvzXOyFlV1wLvW4cHWAekQWVnZKy12cAHOFMpG7V9ZeXc9Noifti4kycv7cPIzklulyQi4nMU1GqoX3IcUaFBmv4oItJ4LAQ6GmNSvA1CLgU+PuSYjcBoAGNMM6AzsNYYE2mMifY+Homzlc3SeqvcB5WWV3D7mz/y7ZpcHh3XkzN6tHC7JBERn1StfdTkgODAAIZ2TGDGqmystTjrxkVEpKGy1pYZY24DvgQCgZestcuMMTd7n58E/BV4xRjzM85UyXustbnGmPbAB973iiDgTWvtVFe+ER9QUWG5+50lfLV8O/ef042L0tsc+yQRkUZKQe04jExL4oul21i+dQ/dWsa4XY6IiNQxa+3nwOeHPDapytdbcEbLDj1vLdCrzgv0E996cvlw8RbuPLUTV5+c7HY5IiI+TVMfj8OIzs4ib01/FBERqb4VW/cAKKSJiFSDgtpxSIoOo2frGO2nJiIiUgOe7AISo0OJCQ92uxQREZ+noHacRnRO4sdNu8grLHG7FBEREb/gyS4gNTHK7TJERPyCgtpxGpWWhLUwe3Xj2JRURETkRFhrycwuIDVJQU1EpDoU1I5Tz1YxxEeGaPqjiIhINWTn7yN/X5mCmohINSmoHaeAAMPwzonMWp1DeYV1uxwRERGf5skuAFBQExGpJgW1EzAqLYnde0v5ceNOt0sRERHxaQpqIiI1o6B2AoZ2TCQwwGj6o4iIyDF4sguIDg0iKTrU7VJERPyCgtoJiAkPJr1dUwU1ERGRY/BkF9AhKQpjjNuliIj4BQW1EzQyLYmV2/LZunuv26WIiIj4LE+OOj6KiNSEgtoJGpWWBMCMlWrTLyIicji795aSk79PQU1EpAYU1E5Qx6QoWsWGa/qjiIjIEVQ2EtFm1yIi1ebfQW1fvtsVYIxhZFoiczy57Csrd7scERERn5Opjo8iIjXmv0Etczr8Iw22LXW7EkalJbG3tJz5a/PcLkVERMTneHIKCAkKoE1chNuliIj4Df8Nai37gAmEmQ+7XQmD2icQGhSg6Y8iIiKH4ckuoH1CJIEB6vgoIlJd/hvUwpvCoFth5aewZbG7pYQEcnKHeGasysZa62otIiIivmZ/a34REak+/w1qAANvhrBYnxhVG5mWxIYdRazLLXS7FBEREZ9RXFrOpp1FaiQiIlJD/h3UwmLg5Nth9VTIWuRqKSM7O236Nf1RRETkgLU5hVirRiIiIjXl30ENYMBNEB4HM//mahlt4iLomBTFjFUKaiIiIvt5ctTxUUTkePh/UAuNhiF3gGcabJzvaikj05JYsC6Pgn1lrtYhIiLiKzzZBQQYSEmIdLsUERG/4v9BDaDfDRCZ6Pqo2sjOSZSWW75bk+tqHSIiIr4iM7uANnERhAUHul2KiIhfaRhBLSQShvwW1s6E9XNcKyM9uSnRYUHM0Do1ERERwBlRUyMREZGaaxhBDSD9OohqBjMeApda5AcHBjCsY6La9IuIiABl5RWsyy3U+jQRkePQcIJacDgMvQs2zIF1s10rY0TnRLLz97Fsyx7XahAREfEFm3bupaS8QnuoiYgch4YT1ABOuhqatIIZf3NtVG2Et02/pj+KiEhj58lWx0cRkePVsIJacJgzqrZpHmROd6WExOhQ+ifH8dq8Der+KCIijZqCmojI8WtYQQ2gz5UQ08bVtWq/P7MLOQX7eHLaaleuLyIi4gs82QUkRYfSJCzY7VJERPxOwwtqQSEw7G7YvAjWfOVKCb3bxHJpvza8NGc9q7blu1KDiIiI2zw5BXRQx0cRkePS8IIaQO/LIbadq6Nqd5+eRnRYEPd9tFQdIEVEpNGx1rI2u0DTHkVEjlPDDGqBwTD8Hti6BFZ97koJcZEh3DMmjQXr8vho8RZXahAREXFLdv4+8veVKaiJiBynhhnUAHpeAnEdYMbDUFHhSgmXpLehV5tYHvp8BXuKS12pQURExA1qJCIicmKqFdSMMWOMMauMMR5jzMTDPH+3MWax97bUGFNujImr/XJrIDAIRkyE7T/Dyk9cKSEgwPDXc7uRW7CPJ75e40oNIiIiblBQExE5MccMasaYQOBpYCzQFbjMGNO16jHW2sestb2ttb2Be4FZ1tq8Oqi3ZrqPg4RO3lG1cldK6Nk6lsv7t+W/369nxVZtgi0iIo2DJ7uA6NAgkqJD3S5FRMQvVWdErT/gsdautdaWAFOAc49y/GXAW7VR3AkLCHRG1XJWwLIPXCvj7tM7ExMezJ/UWERExC9VY2ZJjDHmE2PMEmPMMmPMtdU9t6HyZBfQISkKY4zbpYiI+KXqBLVWwKYq97O8j/2CMSYCGAO8d4TnJxhjMowxGTk5OTWt9fh0PR8Su8DMR1wbVYuNCGHimDQWrt/J+z9sdqUGERE5PtWZWQLcCiy31vYCRgD/MMaEVPPcBsmTo46PIiInojpB7XAfhR1pWOhsYM6Rpj1aaydba9OttemJiYnVrfHEBATAyHthxxr4+d36ueZhXNi3NX3axvLwFyvYvVeNRURE/Eh1ZpZYINo4w0dRQB5QVs1zG5zde0vJyd+noCYicgKqE9SygDZV7rcGjtRv/lJ8ZdpjVWlnQ/MeMOsRKC9zpQSnsUh38gpL+NfXq12pQUREjkt1Zpb8B+iC8/74M/Aba21FNc9tcCobiWizaxGR41adoLYQ6GiMSTHGhOCEsY8PPcgYEwMMBz6q3RJrQUAAjPg95K2Fn6a4Vkb3VjGMH9iOV79fz9LNu12rQ0REaqQ6M0tOBxYDLYHewH+MMU2qea5zETeWB9SRTHV8FBE5YccMatbaMuA24EtgBfC2tXaZMeZmY8zNVQ49H/jKWltYN6WeoM5joUVvmPUolLs39fCuUzvTNCKEP320lIoKNRYREfED1ZlZci3wvnV4gHVAWjXPBVxaHlBHPDkFhAQF0CYuwu1SRET8VrX2UbPWfm6t7WSt7WCtfcj72CRr7aQqx7xirb20rgo9YcbAyD/Aro2w+A3XyoiJCObeM7rww8ZdvPtDlmt1iIhItVVnZslGYDSAMaYZ0BlYW81zGxxPdgHtEyIJDFDHRxGR41WtoNZgdDwVWqXD7MehbJ9rZVzQpxXp7ZryyBcr2V2kxiIiIr6smjNL/gqcbIz5GfgGuMdam3ukc+v/u6hf+1vzi4jI8WtcQc0YGPUH2L0JfnzNtTICAgwPnNudXUUlPP7VKtfqEBGR6jnWzBJr7RZr7WnW2h7W2u7W2tePdm5DVlxazqadRWokIiJyghpXUANoPxLaDoLZ/4DSYtfK6NqyCVcNSub1+Rv4OUuNRUREpGFYm1OItWokIiJyohpfUDMGRv4e8rfAoldcLeXO0zoRHxnKH9VYREREGghPjjo+iojUhsYX1ABShkHyUPjun1BS5FoZTcKC+cOZaSzZtIu3MzYd+wQREREf58kuIMBASkKk26WIiPi1xhnUwBlVK9gOGS+5WsZ5vVvRPzmOR6euZGdhiau1iIiInKjM7ALaxEUQFhzodikiIn6t8Qa1dic769W++xeUuLf1mzGGB87rxp7iMv7+pRqLiIiIf/NkF6iRiIhILWi8QQ2cUbWiXFjwvKtlpDVvwjUnJzNl4UYWb9rlai0iIiLHq6y8gnW5hVqfJiJSCxp3UGvTH1JPhTlPwr58V0u545SOJEaF8qePllKuxiIiIuKHNu3cS0l5hfZQExGpBY07qAGMvBf25sH8Sa6WER0WzB/O7MJPWbuZsnCjq7WIiIgcD0+2Oj6KiNQWBbVWfaHTWJj7byh2dz+zc3q1ZGD7OP4+dRV5aiwiIiJ+RkFNRKT2KKiBM6pWvBvmPetqGcYY/npudwr3lfHoFytdrUVERKSmPNkFJEWH0iQs2O1SRET8noIaQIte0OVs+P5p2LvT1VI6Novm+iEp/C9jEz9sdLcWERGRmvDkFGg0TUSkliio7TfiXti3B+b+x+1KuH10R5o3CeO+D9VYRERE/IO1lsxsBTURkdqioLZfs27Q7XynqUjhDldLiQoN4o9ndWHZlj28OX+Dq7WIiIhUx/Y9+yjYV6agJiJSSxTUqho+0dn8eu5TblfCmT1aMDg1nse+XEVuwT63yxERETmqykYi2uxaRKRWKKhVlZQGPS6EBZOhIMfVUowx3H9Od/aWlvOIGouIiIiP82Q7+5FqRE1EpHYoqB1q+EQoK4Y5T7hdCalJUdwwtD3vLsoiY32e2+WIiIgckSengOiwIBKjQ90uRUSkQVBQO1RCKvS8FBa+APnb3K6G20el0jImjPs+WkZZeYXb5YiIiByWx9tIxBjjdikiIg2CgtrhDL8bykvhu3+5XQkRIUHcd1ZXVmzdw+vz1FhERER8kye7UOvTRERqkYLa4cS1h96XQ8bLsHuz29UwpntzhnZM4B9frSY7v9jtckRERA6yu6iU3IJ9Wp8mIlKLFNSOZNjdYMvhu3+6XYm3sUg39pVV8MjnaiwiIiK+xZOjRiIiIrVNQe1ImraDPlfCov/Crk1uV0P7xCgmDGvP+z9uZv5ad/d5ExERqaqyNb+CmohIrVFQO5phvwNj4NvH3a4EgFtHptIqNpw/fbSMUjUWERERH+HJLiAkKIDWTSPcLkVEpMFQUDuamNbQ9xr48XXIW+d2NYSHBPKns7uyans+r36vxiIiIuIbPNkFtE+IJDBAHR9FRGqLgtqxDLkTTCDM9o1RtdO6NmNE50T+9fVqtu9RYxEREXGfJ6dA0x5FRGqZgtqxNGkB/a6HJW/Bjky3q6lsLFJSXsHfPl/hdjkiItLIFZeWk7Vzr4KaiEgtU1CrjsF3QGAIzPq725UA0C4+kpuHd+CjxVv4PlONRURExD2ZOQVYq0YiIiK1TUGtOqKbQf8b4ee3IWe129UAcMuIDrRuGs6fPlqqxiIiIuIadXwUEakbCmrVNfg3EBQOsx5xuxIAwoID+cvZ3ViTXcDLc9xvdCIiIo1TZnYBAQZSEiLdLkVEpEFRUKuuyAQYcBMsfR+2L3e7GgBO6dqM0WlJPDFtDVt373W7HBERaYQ8OQW0jYsgNCjQ7VJERBoUBbWaOPl2CInymVE1gL+c043yCstDn6mxiIiI1D9Ptjo+iojUBQW1moiIg4G/guUfwbaf3a4GgDZxEdwyIpVPf9rKHE+u2+WIiEgjUlZewbrcQjooqImI1DoFtZoadAuExsBM3xlVu2l4e9rGRfCnj5ZSUqbGIiIiUj825hVRWm5JTVRQExGpbQpqNRXeFE6+DVZ+Clt+dLsawNtY5JyuZOYU8uJ3aiwiIiL1Qx0fRUTqjoLa8RhwM4TFwoyH3a6k0qi0ZpzatRlPfbOGLbvUWEREROqeJ8cJapr6KCJS+xTUjkdYExj8a1jzJWRluF1NpT+d1RWL5cHPfKMrpYhIQ2GMGWOMWWWM8RhjJh7m+buNMYu9t6XGmHJjTJz3ufXGmJ+9z/nOm0Yt8GQX0KxJKE3Cgt0uRUSkwVFQO179J0BEPMz4m9uVVGoTF8FtI1P5/OdtzF6d43Y5IiINgjEmEHgaGAt0BS4zxnSteoy19jFrbW9rbW/gXmCWtTavyiEjvc+n11fd9SFTHR9FROqMgtrxCo12NsHO/AY2znO7mko3DmtPcnwEf/54GfvKyt0uR0SkIegPeKy1a621JcAU4NyjHH8Z8Fa9VOYiay2ZOYVqJCIiUkcU1E5EvxshMsmnRtVCgwK5/9zurMst5IVv1VhERKQWtAI2Vbmf5X3sF4wxEcAY4L0qD1vgK2PMImPMhCNdxBgzwRiTYYzJyMnx/VkR2/YUU7CvTCNqIiJ1pFpB7Vhz873HjPDOv19mjJlVu2X6qJAIGPJbWDcL1n/ndjWVhndKZGz35vx7+hqydha5XY6IiL8zh3nMHuHYs4E5h0x7HGytPQln6uStxphhhzvRWjvZWpturU1PTEw8sYrrwf6Oj2okIiJSN44Z1KozN98YEws8A5xjre0GXFT7pfqo9GshqrkzqmaP9L5d//54VlcMhr9+qsYiIiInKAtoU+V+a2DLEY69lEOmPVprt3j/zAY+wJlK6ffUml9EpG5VZ0StOnPzLwfet9ZuhMo3o8YhOByG3gUb5jgjaz6iVWw4t49O5ctl25mxqvH85xARqQMLgY7GmBRjTAhOGPv40IOMMTHAcOCjKo9FGmOi938NnAYsrZeq65gnu4AmYUEkRoW6XYqISINUnaBWnbn5nYCmxpiZ3jn4Vx3uhfxt/n21nXQVNGnlc6NqNwxpT/vESP7y8TKKS9VYRETkeFhry4DbgC+BFcDb1tplxpibjTE3Vzn0fOAra21hlceaAd8ZY5YAC4DPrLVT66v2uuTxdnw05nAzQ0VE5ERVJ6hVZ25+ENAXOBM4HbjPGNPpFyf52fz7agsOg2G/g03znS6QPiIkKIAHzunOhh1FTJ691u1yRET8lrX2c2ttJ2ttB2vtQ97HJllrJ1U55hVr7aWHnLfWWtvLe+u2/9yGIDNHrflFROpSdYJadebmZwFTrbWF1tpcYDbQq3ZK9BO9x0NMW5j+kE+Nqg3pmMCZPVvw9AwPm/LUWERERE7crqIScgtKFNREROpQdYJadebmfwQMNcYEeVsTD8CZHtJ4BIXA8Lthyw+w+ku3qznIH8/sQmCA4f5P1FhEREROnBqJiIjUvWMGterMzbfWrgCmAj/hzMF/wVrbIBZL10ivy6BpMszwrVG1FjHh/GZ0R6at2M43K7a7XY6IiPi5yqCWGO1yJSIiDVe19lGr5tz8x6y1Xa213a21T9RRvb4tMBiG3wPbfoKVn7pdzUGuHZxCalIUf/lEjUVEROTEeLILCA0KoFXTcLdLERFpsKoV1KQGelwM8R3h8/+D/G1uV1MpJCiA+8/pxqa8vbw8Z73b5YiIiB/z5BTQPjGKwAB1fBQRqSsKarUtMAguehmKd8H/roSyfW5XVGlwagKj05J4ZoaHHQW+U5eIiPiX/a35RUSk7iio1YXmPeC8ZyFrAXx2p0+tV7v3jC4UlZbzxLQ1bpciIiJ+aG9JOZt37SU1UUFNRKQuKajVlW7nwbD/gx9fh/nPuV1NpdSkKC7v35Y3F2zEk53vdjkiIuJnMnMKsFYdH0VE6pqCWl0acS90PhO+/D2snel2NZXuOKUjEcGBPPLFSrdLERERP5OZo9b8IiL1QUGtLgUEwAXPQUIneOcayFvndkUAxEeFcsvIVKatyGZuZq7b5YiIiB/xZBcQYCA5IcLtUkREGjQFtboWGg2XvemsU3vrMtjnG9MNrx2cTKvYcB76bAUVFb6zhk5ERHybJ7uAdvGRhAYFul2KiEiDpqBWH+Law0WvQO5q+OBmqKhwuyLCggP5vzGdWbZlD+//uNntckRExE9k5hTQQY1ERETqnIJafekwEk5/yNkIe9ajblcDwNk9W9KrdQyPf7mKvSXaBFtERI6urLyCdbmFWp8mIlIPFNTq04CbofcVMOsRWP6R29UQEGD441ld2banmOe/Xet2OSIi4uM25hVRWm4V1ERE6oGCWn0yBs76F7Tu50yB3LbU7YrolxzHmG7NmTQrk+w9xW6XIyIiPsyTrY6PIiL1RUGtvgWFwiWvQ1gMTLkMCne4XRETx6ZRWl7BP79e7XYpIiLiwzze1vwdEiNdrkREpOFTUHNDdHO49A3I3w7vXA3lpa6Wk5wQyZUDk3k7YxMrt+1xtRYREfFdnuwCmjUJJTos2O1SREQaPAU1t7TqC+c8Beu/dTbEdtmvR6cSHRbM3z7XJtgiInJ4mdkFmvYoIlJPFNTc1OtSGHQbLJgMi/7raimxESHcPiqV2atzmLU6x9VaRETE91hrycwpJFWt+UVE6oWCmttOfQA6jILP7oKN81wt5apBybSLj+Bvn62gXJtgi4hIFdv2FFOwr0wjaiIi9URBzW0BgXDhSxDbFv43HnZnuVZKSFAAE8eksWp7Pm9nbHKtDhER8T37Oz52UFATEakXCmq+ILwpXPYWlBbDlMuhpMi1UsZ0b056u6b846vVFOwrc60OERHxLWrNLyJSvxTUfEViZxj3Amz9CT6+Haw7Uw+NMfzhzC7kFuzjuVmZrtQgIiK+x5NdQJOwIBKjQt0uRUSkUVBQ8yWdx8Do+2DpuzDnCdfK6NO2KWf3asnz365l6+69rtUhIiK+w+Pt+GiMcbsUEZFGQUHN1wy5E7pdANPuh9VfuVbG/53emQoLj325yrUaRETEd2TmqDW/iEh9UlDzNcbAuU9D8x7w3vWQs9qVMtrERXDt4GTe/2EzSzfvdqUGERHxDbuKSsgtKFFQExGpRwpqvigkAi59EwJDYMplsHeXK2XcOjKVuMgQHvxsOdalNXMiIuI+NRIREal/Cmq+KrYNXPIa7NzgjKxVlNd7CU3CgrnjlI7MW5vHNyuy6/36IiLiGyqDWmK0y5WIiDQeCmq+rN3JcMZj4JkG0/7iSgmX9W9L+8RI/vbFCkrLK1ypQURE3OXJLiA0KIBWTcPdLkVEpNFQUPN16ddC+vUw9yn46e16v3xwYAC/H9uFtTmFvLVgY71fX0RE3OfJKaB9YhSBAer4KCJSXxTU/MHYR6HdEGd/tc0/1PvlR3dJYlD7eJ6YtoY9xaX1fn0REXHX/tb8IiJSfxTU/EFgMFz8X4hMgilXQP72er38/k2wdxaV8PQMT71eW0RE3LW3pJzNu/aSmqigJiJSnxTU/EVkAlz2JhTvgv+Nh7J99Xr57q1iOL9PK17+bj2b8orq9doiIuKezJwCrFXHRxGR+qag5k+a94DznoGsBfDZnVDPLfPvPr0zAQHwd22CLSKNjDFmjDFmlTHGY4yZeJjn7zbGLPbelhpjyo0xcdU519dl5qg1v4iIGxTU/E2382HY3fDj67Bgcr1eukVMODcObc8nS7bw48ad9XptERG3GGMCgaeBsUBX4DJjTNeqx1hrH7PW9rbW9gbuBWZZa/Oqc66v82QXEGAgOSHC7VJERBoVBTV/NOL30PkMmHovrJ1Zr5e+aXgHEqJCefCzFdoEW0Qai/6Ax1q71lpbAkwBzj3K8ZcBbx3nuT7Hk11Au/hIQoMC3S5FRKRRUVDzRwEBcP5zkNAR3rkG8tbV26WjQoO467ROLNqwky+Wbqu364qIuKgVsKnK/SzvY79gjIkAxgDvHce5E4wxGcaYjJycnBMuurZ4sgvooEYiIiL1TkHNX4U1gcvectapTbkc9uXX26UvTm9D52bRPPLFSkrKtAm2iDR4h9s87EhTCs4G5lhr82p6rrV2srU23VqbnpiYeBxl1r6y8grW7yjU+jQRERcoqPmzuPZw0SuQsxI+uBkq6ic0BQYYfn9mFzbmFfHq9+vr5ZoiIi7KAtpUud8a2HKEYy/lwLTHmp7rczbkFVFabhXURERcoKDm7zqMhNMegpWfwqxH6+2ywzslMqxTIv+e7mFXUUm9XVdExAULgY7GmBRjTAhOGPv40IOMMTHAcOCjmp7rqzzZ6vgoIuIWBbWGYOCvoPcVMOsRWP7RsY+vJX84owv5xaU89Y02wRaRhstaWwbcBnwJrADettYuM8bcbIy5ucqh5wNfWWsLj3Vu/VV/YvYHtQ6JkS5XIiLS+AS5XYDUAmPgzH9Czir44FcQ1wGad6/zy3ZuHs3F6W14bd56rhrUjuQEvZGLSMNkrf0c+PyQxyYdcv8V4JXqnOsvMrMLaN4kjOiwYLdLERFpdDSi1lAEh8GlbzhNRqZcBoU76uWyd57WieDAAB75YmW9XE9EROqPJ6dA0x5FRFyioNaQRDeHS96A/O3wztVQXlrnl0yKDuPm4R2YumwbC9blHfsEERHxC9ZaMrMV1ERE3FKtoGaMGWOMWWWM8RhjJh7m+RHGmN3GmMXe259qv1SpltZ94ZynYP238OXv6+WSNw5tT/MmYTz02XIqKrQJtohIQ7B1dzGFJeV0UFATEXHFMYOaMSYQeBoYC3QFLjPGdD3Mod9aa3t7bw/Ucp1SE70uhUG3wYLJsOi/dX658JBAfnd6Z5Zk7eaTn/ym67SIiBxFZcdHbXYtIuKK6oyo9Qc81tq11toSYApwbt2WJSfslPuhwyj47C7YOK/OL3dBn1Z0a9mEv09dRXFpeZ1fT0RE6pZa84uIuKs6Qa0VsKnK/SzvY4caZIxZYoz5whjT7XAvZIyZYIzJMMZk5OTkHEe5Um2BQXDhSxDbBv43HnZn1enlAgIMfzizC5t37eXlOevr9FoiIlL3PDkFxIQHkxAV4nYpIiKNUnWCmjnMY4cuRPoBaGet7QX8G/jwcC9krZ1srU231qYnJibWqFA5DuFN4bIpUFoMUy6HkqI6vdzJHRI4pUsSz8zwsKNgX51eS0RE6pbH20jEmMP9GiAiInWtOkEtC2hT5X5r4KCFSNbaPdbaAu/XnwPBxpiEWqtSjl9iZxj3PGz9CT6+HWzdNvuYOLYLRaXlPDFtTZ1eR0RE6lZmdoHWp4mIuKg6QW0h0NEYk2KMCQEuBT6ueoAxprnxfuRmjOnvfd362chLjq3zWBj1R1j6Lsx5ok4vlZoUxeX92/Lmgo14svPr9FoiIlI3dhaWsKOwROvTRERcdMygZq0tA24DvgRWAG9ba5cZY242xtzsPexCYKkxZgnwFHCptXU8dCM1M/Qu6HYBTPsLTL3XmQ5ZR+44pSMRwYE8/Lk2wRYR8UeeHDUSERFxW1B1DvJOZ/z8kMcmVfn6P8B/arc0qVXGwHnPQmQCzHsG1s6CcS9As8PttHBi4qNCuWVkKo9OXclcTy4np2oWrIiIP1HHRxER91Vrw2tpIILD4IzH4PJ3oDAbJo+Aec9CRUWtX+rawcm0ig3nwc9WUK5NsEVE/Ionu4Cw4ABaxYa7XYqISKOloNYYdToNfvU9dBgJUyfCG+Mgf1utXiIsOJD/G9OZ5Vv38P4Pdbs1gIiI1C5PdgHtE6IICFDHRxERtyioNVZRiU7r/jP/ARu+h2cGwYpPa/US5/RqSa82sTz+1SqKSspq9bVFRKTu7G/NLyIi7lFQa8yMgX43wE2zvRtjXwEf/xpKCmvp5Q33ndmF7Xv28cK362rlNUVEpG4VlZSxeddeBTUREZcpqAkkdoLrp8HgO+CHV2HSUNi8qFZeOj05jrHdmzNpVibZe+qu06SIiNSOtTnOh3UKaiIi7lJQE0dQCJx6P1z9CZTtgxdPg9mPQUX5Cb/0xLFplJZX8M+vV9dCoSIiUpfU8VFExDcoqMnBUobCr76DLufA9AfhlTNh54YTesl28ZFcNSiZtzM2sXLbnloqVERE6oInu4DAAENyfKTbpYiINGoKavJL4U3hwpfg/Odg21KYNAR+evuEXvL2UalEhwXz0GcraqlIERGpC57sAtrFRRASpF8RRETcpH+F5fCMgV6XOqNrSV3h/Rvh3eth767jernYiBBuH5XKt2tymbkqu3ZrFRGRWuPJKaCDpj2KiLhOQU2OrmkyXPMZjPwjLPvAGV1bP+e4XuqqQcm0i4/gb5+voKy89jfZFhGRE1NaXsH63EKtTxMR8QEKanJsgUEw/G64/isIDHbWrU37C5SV1OhlQoICmDgmjdXbC3g7Q5tgi4j4mg07iiirsKQmKqiJiLhNQU2qr3U63PQt9BkP3/0LXjwVctfU6CXGdG9Ov+Sm/PPrVRTs0ybYIiK+RB0fRUR8h4Ka1ExoFJz7H7jkddi1wdlzbeGLYG21TjfG8Iczu5JbUMKkmZl1XKyIiNREZo4T1LRGTUTEfQpqcny6nA2/+h7aDoTP7oS3LoPC3Gqd2rtNLOf0asnz365l6+69dVyoiIhUlye7gBYxYUSFBrldiohIo6egJsevSQsY/z6c/jBkfgPPDII1X1fr1P8b0xkLPPblqrqtUUREqs2TXaBpjyIiPkJBTU5MQAAMugVunAGRCfDGhfD53VB69JGy1k0juG5wCu//sJmlm3fXU7EiInIkFRWWzJwCOqiRiIiIT1BQk9rRvLsT1gb8ChZMhskjYOtPRz3llpEdiIsM4cHPlmOrucZNRETqxtY9xRSVlGtETUTERyioSe0JDoOxjzjTIffuhBdGw9x/Q8Xh90xrEhbMHad0ZN7aPKat0CbYIiJuUsdHERHfoqAmtS91tNNopONp8NUf4bXzYM+Wwx56Wf+2tE+M5OHPV1CqTbBFRFyjoCYi4lsU1KRuRMY7LfzPfgqyFjqNRpZ9+IvDggMD+P3YLqzNLWT8C/N5eoaHhevzKC4tr/+aRUQaMU92AbERwcRHhrhdioiIAOq/K3XHGOh7NSQPgfdugHeuhjVXwNhHITS68rDRXZK445SOfPbT1soukCGBAfRsHUO/lDj6JTelb9s4YiKC3fpOREQavMzsAlITozDGuF2KiIigoCb1Ib4DXP8VzHwEvvsnbJgDF7wAbfoBzibYd5zSiTtO6UReYQmLNuxk4fo8Fq7P4/nZa3l2psUY6NwsmvTkpvRLjqNfchwtY8Nd/sZERBoOT04Bp3Vt5nYZIiLipaAm9SMwGEbf56xfe/8meOl0GP5/MPR3EHjgr2FcZAindm3Gqd5fFvaWlLN40y4y1uexcMNOPvxxC6/P2whAq9hw+iU3Jd0b3DomRREQoE+CRURqKq+whLzCEq1PExHxIQpqUr/anQy/+s7Za23mw+D5Bi6YDHEphz08PCSQQR3iGdQhHoCy8gpWbstn4fo8MtbvZE7mDj5c7DQqiQkPJr1d08rpkt1bxRAaFFhv31p92VdWzrbdxWTn76N5kzBaxYYroIrUMWPMGOBJIBB4wVr7yGGOGQE8AQQDudba4d7H1wP5QDlQZq1Nr5eia2B/I5EOCmoiIj5DQU3qX1iME846ngaf3gmThsDYv0Pvy511bUcRFBhA91YxdG8Vw7WDU7DWsjGviIXrd5KxPo8F6/P4ZqXT6j80KIBebWIrR936tmtKkzDfXudWUWHZUVjCll17ndvu4gNf79rL5l3F5BbsO+icyJBAOjaLJq15NJ32/9k8moSoUJe+C5GGxRgTCDwNnApkAQuNMR9ba5dXOSYWeAYYY63daIxJOuRlRlprc+ur5pqq7Pioza5FRHyGgpq4p8eF0GYAfHATfHQLLHsfTnsIktKq/RLGGNrFR9IuPpIL+7YGYEfBvsrgtnDDTibNWkv5jEyMgbTmTehfZbpk85iwuvruDqtwXxlbdzuBa2uV8LVl11627naCWUnZwdsUhAcH0jI2jJax4aQ1b0LL2HBaxoaRGB3Kll3FrN6ez6pt+Xy1fDtTFm6qPC8+MoTO3vDWuXl05ddRofrfXqSG+gMea+1aAGPMFOBcYHmVYy4H3rfWbgSw1vrV5pCZOQWEBwfSSmt/RUR8hn5jE3fFtoGrP4H5k2Dmo/DsydD3GhhxL0QlHtdLxkeFMqZ7c8Z0bw5AUUkZizfuYuF6p0nJO4uy+O/3GwBoExdOv3ZxpCfH0T+lKR1OoONZWXkF2fn7KoNY1ZGwLbuK2bJ7L7uKSg86J8BAsyZOCOvROpbTu4V5g5gTxlrGhBMbEVytmqy15BaUsHp7Piu35bN6Wz6rtufzdsYmikoObHfQKja8ctStszfEtU+MbJDTREVqSStgU5X7WcCAQ47pBAQbY2YC0cCT1tpXvc9Z4CtjjAWes9ZOPtxFjDETgAkAbdu2rb3qq8GTXUD7xEhNoxYR8SEKauK+gEAYdCv0vBRmPQILX4Sf34Ghd8GAmyH4xEa9IkKCODk1gZNTEwAnUC3fuqdy1G32mhze/3EzAE0jgr2jbc6oW/eWMYQEBWCtZU9x2S+mIW7dfSCIbdtTTHmFPejaTcKCaBkbTqvYcE5qF1v5dcvYcFrEhNGsSRjBgbWznaExhsToUBKjQxns/V7BmU65eddeVnmD26pt+azens/sNTmUljv1BgYYUhIinZG3ZgemULaJiyBQv7iJHO5/AnvI/SCgLzAaCAe+N8bMs9auBgZba7d4p0N+bYxZaa2d/YsXdALcZID09PRDX79OebILSE9uWp+XFBGRY1BQE98RGQ9nPAb9boSv74Npf4aMF+GUv0C3C465fq26ggID6Nk6lp6tY7l+iLPObf2OImdLgHV5ZGzYydfLtwMQFhxAy9hwtu8uprDk4E24gwMNLWKcka8BKXEHj4R5g1i0D6yJCwgwtImLoE1cBKdUab1dUlbB+h2FToDzhrifs3bz2U9bK48JCw6gY1L0gQDX3AlwSdGh2mtJGpMsoE2V+62BLYc5JtdaWwgUGmNmA72A1dbaLeBMhzTGfIAzlfIXQc0tRSVlbN61l0sT2xz7YBERqTcKauJ7EjvB5f+DtTPhyz/Au9fBvElw+t8q916rTcY4o0kpCZFcnO78opKdX8yi9TtZuH4nW3fvZXinxINGwlrFhpMQFerX04RCggLo5B09O7vXgceLSspYs73g4NG31Tm8uyir8piY8ODKaZOVUyibRWtTcmmoFgIdjTEpwGbgUpw1aVV9BPzHGBMEhOBMjfyXMSYSCLDW5nu/Pg14oP5KP7a1OYUAas0vIuJjFNTEd7UfATfNhsVvwvS/wounQPdxMPrP0LRdnV46KTqMsT1aMLZHizq9ji+KCAmiV5tYerWJPejxvEJn/VvVNXAfLt5MfnFZ5THNm4TRqXk0A1LiuKx/W+IiQ+q5epHaZ60tM8bcBnyJ057/JWvtMmPMzd7nJ1lrVxhjpgI/ARU4LfyXGmPaAx94R6CDgDettVPd+U4Or7Ljo4KaiIhPMdbW6zT4Sunp6TYjI8OVa4sf2lcAc56Euf8GWwGDboEhd0JYE7cra9SstWzdXcyq7d7mJdvyWbEtnxVb9xAaFMC4vq25bnCKfgEUjDGLfHH/MF9Vn++Rj3+5imdnZbLigTGEBNXOmlkREameo70/akRN/ENoFIz6A/S9Gr75K3z3L/jhNeexPldBoP4qu8EYU7k2b2TnA9tGrdmez0tz1vHuoizenL+RUWlJ3DAkhUEd4rW2TcTHeLILaBcfoZAmIuJj9K+y+JeY1nDBc3DjDEjsDJ/+FiYNhjXT3K5MqujYLJqHL+jJ3Imj+O0pnfgpaxeXvzCfM576jvcWZf1irzgRcY8np0AbXYuI+CAFNfFPrU6Caz6DS16Hsn3wxjh47QLYvvzY50q9SYgK5TendOS7e0bx93E9Ka+o4K53ljDk0ek8PcPDzsISt0sUadRKyytYn1uo6ckiIj5IQU38lzHQ5Wy4dYHTEXJzhjO69skdUJDtdnVSRVhwIBf3a8OXdwzj1ev6k9aiCY99uYpBj3zDHz/8mbU5BW6XKNIobdhRRFmFVVATEfFBWtgj/i8oxNkwu9dlMOtRWPgC/PwuDL0TBt5ywhtmS+0xxjCsUyLDOiWyals+L363lrcXZvHG/I2MTkvi+iHtGdg+TuvYROqJOj6KiPgujahJwxERB2MfhVvmQ8ow+OZ++E8/J7S51N1Ujqxz82j+fmEv5kwcxe2jOvLDxl1c9vw8zvr3d3zwo9axidSHTO9odnutURMR8TkKatLwJKTCZW/C1Z9AeAy8dz28cApsnO92ZXIYidGh3HlqJ+ZOHMXDF/SguLSc3/5vCcP+PoNnZ2ayu6jU7RJFGixPdgEtYsKICtUEGxERX6OgJg1XyjCYMAvOfQZ2Z8FLp8E718DO9W5XJocRFhzIZf3b8vVvh/Pytf1ITYri0akrGfjwN/z5o6Wszy10u0SRBseTXaBpjyIiPqpaQc0YM8YYs8oY4zHGTDzKcf2MMeXGmAtrr0SRExAQCH2ugF//AMMnwuovnemQX/8Jine7XZ0cRkCAYWTnJF6/YQBf/GYoZ/ZswZsLNjLyHzOZ8GoGC9blYTWVVeSEVVRYMnMK6KBpjyIiPumYQc0YEwg8DYwFugKXGWO6HuG4R4Eva7tIkRMWEgkj74XbF0GPi2DOU/BUH1jwPJSXuV2dHEGXFk14/KJezLlnFLeNTGXh+jwufu57zn16Dh8t3kxpudaxiRyvrXuKKSop14iaiIiPqs6IWn/AY61da60tAaYA5x7muNuB9wD1RRff1aQlnPcMTJgJSV3h89/BsyfD6q/UcMSHJTUJ467TOjN34mgePK87BcVl/GbKYob9fQbPzcpk916tYxOpKXV8FBHxbdUJaq2ATVXuZ3kfq2SMaQWcD0w62gsZYyYYYzKMMRk5OTk1rVWk9rTs7TQbufRNqCiDNy+C186H7cvcrkyOIjwkkPED2zHtzuG8eHU6yfGRPPzFSgY9/A1/+XgZG3cUuV2iiN9QUBMR8W3VCWqH29Do0KGHJ4B7rLXlR3sha+1ka226tTY9MTGxmiWK1BFjIO1MuGUejHkEtvwIk4bAx7+G/O1uVydHERBgGN2lGW9NGMintw9hTLfmvD5vAyMen8HNry0iY73WsYkciye7gNiIYOIjQ9wuRUREDqM6/XizgDZV7rcGthxyTDowxbtJbQJwhjGmzFr7YW0UKVKngkJg4K+g5yUw+3FYMBmWvgdD7oBBt0FwuNsVylF0bxXDPy/pzf+NSePV79fzxvyNTF22jd5tYrlhaApjujUnKFANbkUOlZldQGpilDaYFxHxUdX57WUh0NEYk2KMCQEuBT6ueoC1NsVam2ytTQbeBW5RSBO/ExEHY/4Gt86H9iNg+oPw73RY8j+oOOpgsfiA5jFh/N+YNL6/dxR/Pbcbu4pKuO3NHxn+2Exe+HYte4q1jk2kKk+OWvOLiPiyYwY1a20ZcBtON8cVwNvW2mXGmJuNMTfXdYEi9S6+A1z6BlzzGUTGwwcT4NnBsPxjNRzxAxEhQVw5KJlv7hrB81el07ppOA9+toKTH57OXz5exlfLtpG1s0hTI6VRyyssIa+wREFNRMSHVWfqI9baz4HPD3nssI1DrLXXnHhZIj4geQjcOBOWfwgz/gZvXwktesHIP0LHU501buKzAgMMp3Ztxqldm/Fz1m5e/G4tr8/bwCtz1wMQEx5M1xZN6NayCV29tw6JUQRrmqQ0AvsbiXRQUBMR8VnVCmoijVZAAHS/ALqcAz+/AzMfdjpEtu4Po/4I7Ye7XaFUQ4/WMTxxaR/+dkEPVm7LZ/mWPSzbsoflW/fw2rwN7Ctz9mMLCQqgc7PoA+GtRRO6tGhCZKj+qZSGpbLjoza7FhHxWfrtQ6Q6AoOg92XQ40L48XWY/Ri8eg4kD3UCW9uBblco1RAREsRJbZtyUtumlY+VlVewLreQ5Vu94W3LHr5cto0pC51dSYyB5PjIyuC2P8QlRYe59W2InDBPdgHhwYG0ilWzJBERX6WgJlITgcGQfi30ugwWvQLf/gNeOh1ST4VRf4CWfdyuUGooKDCAjs2i6dgsmnN7O1tEWmvZtqeYZZudUbflW/bwU9YuPvtpa+V5CVGhlaGtmzfEJcdHEhCgKbHi+zw5BbRP1N9XERFfpqAmcjyCw2DgzXDSlbDgeZjzBEweAWlnwcjfQ7NublcoJ8AYQ4uYcFrEhHNK12aVj+/eW8oKb3DbP3Vyzuy1lFU4jUkiQgLp0uLgkbdOzaIJCw5061sROazM7ALSk5se+0AREXGNgprIiQiJdPZbS78O5j0L3/8HVn4G3cfBiHshIdXtCqUWxYQHM7B9PAPbx1c+tq+snDXbCypH3pZv2cMHP27mtXkbAKepSWpi1EEjb11bNiE2QpsMizsK95WxeddeLk1sc+yDRUTENQpqIrUhrAmMuAf63+iEtXmTYNn7zhTJ4f8HTZPdrlDqSGhQIN1bxdC9VUzlYxUVlk07iw4aeZubmcsHP26uPKZVbDhdqoy8JUSFUmEtFRWWcmuxFsorv7aUV3DQ8xXWuU6FtZRXeI+v/Nr5s8J6zznK+eXe5yu8x1ee7z3HWsu9Y7sQExHsxo9X6sDanEIAteYXEfFxCmoitSkiDkb/CQb8Cr77Fyx8AX76H5x0FQz9HcS0crtCqQcBAYZ28ZG0i49kbI8WlY/nFuxzRt0qp0/u5puV213bni/AOCN+Aca5BQYYzC8eg9+e2okYFNQaCk9OPqCgJiLi6xTUROpCVCKM+RucfJvTcGTRf+HHN6Df9TDktxCV5HaF4oKEqFCGdUpkWKfEyseKSspYtS2fPcVlTnAyBuMNTYEBznq5QG9oCgigMlA5QapKqAowlecHeB8LNAYT4DxWGcLMgeOlcfJkFxDo/TBBRER8l4KaSF1q0hLO/Aec/GuY/XeY/5zTLXLATc5jEXFuVyguiwgJok9bNXWQ+uPJLqBdfAQhQdrcXUTEl+lfaZH60LQdnPs03LoA0s6E756AJ3vBzEegeI/b1YlII+LJLtBG1yIifkBBTaQ+JaTCuBfgV3Oh/XCY+TA82dNZz1ZS6HZ1ItLAlZZXsGFHkdaniYj4AQU1ETc06wqXvA4TZkLrfjDtL84I27xnobTY7epEpIHasKOQsgqroCYi4gcU1ETc1LIPXPEOXPcVJHWBqRPhqT6Q8RKUlbhdnYg0MJ7sAkAdH0VE/IGCmogvaDsArv4ErvoYYtvAp7+F/6TD4jehvMzt6kSkgdgf1DpojZqIiM9TUBPxJe2Hw3VfwhXvQngsfPgreGYgLH0PKircrk5E/Jwnu4CWMWFEhqrps4iIr1NQE/E1xkDHU2HCLGcdW0AQvHsdTBoCKz/Dtd2RRcTveXIK6KBpjyIifkFBTcRXGQNdzoZfzYFxL0JZMUy5HJ4fCWumKbCJ1CNjzBhjzCpjjMcYM/EIx4wwxiw2xiwzxsyqybn1oaLCkpldqPVpIiJ+QkFNxNcFBEKPC5092M59Ggp3wBvj4KUxsPgtKMpzu0KRBs0YEwg8DYwFugKXGWO6HnJMLPAMcI61thtwUXXPrS9bdu9lb2m5gpqIiJ/QJHURfxEYBH3GQ4+L4cdXnU2zP7wZTCC0OxnSzoK0MyC2rduVijQ0/QGPtXYtgDFmCnAusLzKMZcD71trNwJYa7NrcG69qOz4qEYiIiJ+QSNqIv4mKAT63QB3/Aw3zoAhv4XCXJh6DzzRAyYNhZmPwLafNT1SpHa0AjZVuZ/lfayqTkBTY8xMY8wiY8xVNTgXAGPMBGNMhjEmIycnp5ZKP0Ct+UVE/ItG1ET8lTHQ6iTnNvo+2JHpNBtZ9bkT1GY+7IyupZ0FaWdCm4HOqFxjUlEB2cthw1zYMAdyV0On0yH9Oo08Sk2Ywzx26KcgQUBfYDQQDnxvjJlXzXOdB62dDEwGSE9Pr/VPWTJzCmgaEUx8VGhtv7SIiNSBRvZbm0gDFt8BBv/auRVkw+qpTnBb+CLMewbC46DTGCe0dRgFIRFuV1z7ykth6xInlG2YCxu/h+LdznNNWkNcCsx50rl1Ggv9b4CUERCgyQVyVFlAmyr3WwNbDnNMrrW2ECg0xswGelXz3HrhyS7QaJqIiB9RUBNpiKKS4KSrnNu+Asj8BlZ+7oy2LXkTgsKdsJZ2phPeIuPdrvj4lBTB5gzY8L0TzrIWQmmR81x8R+h6LrQb7Kzh2z+CtmsTLHoZFv0XVn0G8anOVNJelzl714n80kKgozEmBdgMXIqzJq2qj4D/GGOCgBBgAPAvYGU1zq0XnuwCxnRv7salRUTkOCioiTR0oVFOYOl6rjPitGGuM9K28jMnqJgAaDvICW2dz3BGnXxV8W7YtODAiNnmH6CiFDDQvLsTTNsOcoJZVNLhXyO2DYz+Ewy/B5Z9CAufh6kT4ZsHoOfF0O9G57VEvKy1ZcaY24AvgUDgJWvtMmPMzd7nJ1lrVxhjpgI/ARXAC9bapQCHO7e+v4cdBfvYWVRKBzUSERHxG8a61GwgPT3dZmRkuHJtEcFpNLLtpwOhbftS5/Fm3Q+Etha9nLVwbinIgY1zD4yYbV8KtsLZBLzlSU4ga3cytBlwYqNhWxY7ge3nd5396tqe7EyLTDvbad4iJ8wYs8ham+52Hf6itt8j56/dwSWT5/HKtf0Y0fkIH2KIiEi9O9r7o0bURBorY5wg1qIXjPw95K1zpkau/AxmPwazHoWYNk5gSzvTCUSBwXVb065N3rVlc50/c1c7jweFQ5t+zihYu5OhVXrtrrFr2dvZo+7Uv8KPr0PGi/DudRDVDPpeA32vhSYtau96IvXMk6OOjyIi/kZBTUQccSkw6FbnVrjjQDOSH/4LC56DsFhvM5IzoMNoZ0rlibAWdni80xi/d4LZ7o3Oc6Ex0HYg9L7CWWPWolf9jGxFxDnNWAbdBp5pzijbrL/Dt/9wumf2v9Gpx81RRpHj4MkuIDw4kJYx4W6XIiIi1aSgJiK/FBkPfa5wbiWFkDnDCW2rp8JPUyAwFDqM9DYjGQtRicd+zYpy2L7s4BGzQu9eUZFJ0G4QnHybM2KW1BUCAuv2ezyagADodJpzy1vrdM788XVY/qFTW7/roeelJx5WReqJJ7uADkmRBAToQwYREX+hoCYiRxcSCV3Ocm7lZbBpnndd26dOcMM4o1/7p0jGd3DOKyuBrYsPjJhtnAf7vK3yY9tC6inexh+DnXN8dZQqrj2c/hCM/AMsfc8ZZfvsLvj6L9D7cqdjZGInt6sUOarM7AL6p8S5XYaIiNSAgpqIVF9gECQPcW6n/81p7rE/tH19n3NL7AKRCZCVAWV7nfMSOkP3C5zRsraDnM6L/iYkAk66EvqMd763BZOdNv8LnoOU4dB/gjM1tLFtKi4+r3BfGVt2F2t9moiIn9FvFCJyfIyB5j2c24iJsHMDrPrCCW378iH92gPBLDLB7WprjzFOY5M2/Zyw+sN/IeNl+N8Vzqba6dfCSVdXbzqoSD3IVCMRkQaptLSUrKwsiouL3S5FqiEsLIzWrVsTHFz9xmwKaiJSO5q2g4E3O7fGIioRhv0OBt8Bq7+ABc/D9L86HTO7nuc0H2ndz3endUqj4MlWUBNpiLKysoiOjiY5ORmj9xmfZq1lx44dZGVlkZJS/f1qFdRERE5UYBB0Odu55ayGhS/A4jfh57eheU9nWmT3cbW7pYBINXmyCwgKMLSLj3S7FBGpRcXFxQppfsIYQ3x8PDk5OTU6L6CO6hERaZwSO8EZf4e7VsCZ/4DyUvj4NvhnF/jyD04XSZF65MkuoF18BMGBessXaWgU0vzH8fy30r/aIiJ1ITTa6Qh5y/dwzWfQfgTMexaeOgneuAhWfwUVFW5XKY2AJ6dA0x5FRPyQpj6KiNQlYw50ytyzFRa94nSLfPMiaJoM6dc7nSQj1Dpdal9JWQUbdhQxtntzt0sREZEa0oiaiEh9adICRt4LdyyFC1+C6JbOlgb/7AIf3uK0/bfW7SqlAdmwo5DyCqsRNRGpdbt27eKZZ56p8XlnnHEGu3btqv2CGiCNqImI1LegEKe5SPdxsG2ps4n2T+/A4jec7Q76Xgs9L3amT4qcgMqOj4n6uyTSkN3/yTKWb9lTq6/ZtWUT/nx2tyM+vz+o3XLLLQc9Xl5eTmBg4BHP+/zzz2utxrpwrPrrk0bURETc1Lw7nP0k3LUSzvwnWOCzO+EfafDJb2DrErcrFD+2P6h1SFLHRxGpXRMnTiQzM5PevXvTr18/Ro4cyeWXX06PHj0AOO+88+jbty/dunVj8uTJleclJyeTm5vL+vXr6dKlCzfeeCPdunXjtNNOY+/evUe83vPPP0+/fv3o1asX48aNo6ioCIDt27dz/vnn06tXL3r16sXcuXMBePXVV+nZsye9evXiyiuvBOCaa67h3XffrXzNqChntsHMmTOrXf/UqVM56aST6NWrF6NHj6aiooKOHTtWdnSsqKggNTWV3NzcE/4Za0RNRMQXhDWBftdD+nWweRFkvARL/uesaWt5kvN49wsgRL9wS/V5cgpoFRtORIje7kUasqONfNWVRx55hKVLl7J48WJmzpzJmWeeydKlSyv3CXvppZeIi4tj79699OvXj3HjxhEfH3/Qa6xZs4a33nqL559/nosvvpj33nuP8ePHH/Z6F1xwATfeeCMAf/zjH3nxxRe5/fbb+fWvf83w4cP54IMPKC8vp6CggGXLlvHQQw8xZ84cEhISyMvLO+b3s2DBgmPWX1FRwY033sjs2bNJSUkhLy+PgIAAxo8fzxtvvMEdd9zBtGnT6NWrFwkJCSfy4wWqOaJmjBljjFlljPEYYyYe5vlzjTE/GWMWG2MyjDFDTrgyEZHGyBhonQ7nPeO0+B/zKJQWOS3+/5EGn98N25e7XaX4CU92AR20Pk1E6kH//v0P2sz5qaeeolevXgwcOJBNmzaxZs2aX5yTkpJC7969Aejbty/r168/4usvXbqUoUOH0qNHD9544w2WLVsGwPTp0/nVr34FQGBgIDExMUyfPp0LL7ywMizFxR27YVd16p83bx7Dhg2rPG7/61533XW8+uqrgBPwrr322mNerzqO+RGbMSYQeBo4FcgCFhpjPrbWVv1N4RvgY2utNcb0BN4G0mqlQhGRxiq8KQy8GQbcBBu/h4yXnRG2BZOhzUBIvxa6ngfBYW5XKj6oosKSmVPAgJT4Yx8sInKCIiMPzPiYOXMm06ZN4/vvvyciIoIRI0ZQXFz8i3NCQ0Mrvw4MDDzq1MdrrrmGDz/8kF69evHKK68wc+bMIx5rrT3svmVBQUFUeLfGsdZSUlJSo/qP9Lpt2rShWbNmTJ8+nfnz5/PGG28csbaaqM6IWn/AY61da60tAaYA51Y9wFpbYG1lq7JInFUWIiJSG4yBdifDuOfhzpVw2oNQmAMf3AT/THM20s795SeV0rht3rWX4tIKdXwUkToRHR1Nfn7+YZ/bvXs3TZs2JSIigpUrVzJv3rwTvl5+fj4tWrSgtLT0oCA0evRonn32WcBpBLJnzx5Gjx7N22+/zY4dOwAqpz4mJyezaNEiAD766CNKS0trVP+gQYOYNWsW69atO+h1AW644QbGjx/PxRdfXGvNSKoT1FoBm6rcz/I+dhBjzPnGmJXAZ8B1h3shY8wE79TIjP0L7kREpAYi4+Hk2+G2DLjqY0gZDvMnwX/S4ZWzYOl7UFZy7NeRBs+T4+34qKAmInUgPj6ewYMH0717d+6+++6DnhszZgxlZWX07NmT++67j4EDB57w9f76178yYMAATj31VNLSDkzce/LJJ5kxYwY9evSgb9++LFu2jG7duvGHP/yB4cOH06tXL+68804AbrzxRmbNmkX//v2ZP3/+QaNo1ak/MTGRyZMnc8EFF9Dr/9u79+CoyjSP49+HBMxFiUBQ0YCwSgkiJkjAC8WUiASYYWNRoIDgLLigoCDrDDuELW+Uo6JLoWuhy7IOlKKusDhQsytIEHG8zBYkwahcZriPxiAgDJdwG4LP/tEtEzS3bhpOd/L7VHVxztt93n76TeDh6fOe92RnM2zYsNPH5OfnU1FREbNpjwDmddyzx8zuBPq7+9jw/j1AT3efVMPrfwI85u6319Zvbm6uFxcXRxe1iIj8zeHdUPp6aFrkgS8hvTXkjITuo6Flh7qOPi/MrMTdc4OOI1HEIke+8tF2fv3OJtY92o+W6c1iFJmIxItNmzbRuXPnoMOQsOLiYh5++GE++uijGl9T3c+stvxYnzNqZUDbKvtZQHlNL3b3D4GrzOzslzoREZG6XXQp9P4lPPQZjHwbsnrCH16EF3NgwWDY9D9wqvrpHdJwbdtbQcv0ZirSRETOsRkzZjBkyBCeeeaZmPZbn/V6i4COZtYB+BoYDtxd9QVmdjWwLbyYyA1AM2BfTCMVEZHaNWkCHW8PPQ5+DZ8ugHWvwcJRcOFlcMPPQ4+L29bdlyS8rXsquLq1pj2KSGJ58MEH+eSTT85omzx5ckynFMZaQUEBBQU/Whj/rNVZqLl7pZlNBFYAScA8d99gZuPDz88BhgA/N7OTwDFgmNc1p1JERM6djCvg1gLoPQW2FELJfPjwX+GjmdAxD7qPgY79oElsLniW+LN1TwUDrmsTdBgiIhF56aWXgg4hbtTrDpjuvgxY9oO2OVW2nwWejW1oIiJy1pKSodNPQ4+//Dl0hm3da7D5XchoCzf8A3QbBc31H/qGZF/FCf5y9KQWEhERSWD1uuG1iIg0AC2uhL6Pwi82wl2vQaurYPWv4fkuoemRW1dB+P4ykti27tGKjyIiia5eZ9RERKQBSWoK194ReuzbFlotsvSN0KIjLdqHVovMGQUXtg44UImWluYXEUl8OqMmItKYtboK8p6EX2yCIb+B5lfAe0/ArM7w32Ngx0egS44TztY9FaQ1S+LyjJSgQxGRBurAgQO8/PLLUR37wgsvcPTo0RhH1PCoUBMREUi+ALoOhTHL4MG10GMsbFsFrw6CbzcHHZ1EaOueCq5qfSFmFnQoItJANZRCrbKyMugQaqSpjyIicqbW18DAGXD747D996F9SSiP/30XDh/XvfNEGo3lBfDNF7Ht87KuoVxQg4KCArZt20ZOTg79+vXjkksuYdGiRZw4cYLBgwczffp0jhw5wl133UVZWRmnTp3i0UcfZffu3ZSXl9OnTx8yMzNZvXp1tf1PmDCBoqIijh07xtChQ5k+fToARUVFTJ48mSNHjnDBBRewatUq0tLSmDp1KitWrMDMGDduHJMmTaJ9+/YUFxeTmZlJcXExU6ZM4YMPPuCJJ56gvLycnTt3kpmZydNPP80999zDkSNHAJg9eza33HILAM899xwLFiygSZMmDBw4kHHjxnHnnXeybt06ALZs2cLw4cMpKSmJ5egDKtRERKQmTVPhmgFBRyFR0LVpInKuzZgxg/Xr11NaWkphYSGLFy9m7dq1uDv5+fl8+OGH7N27l8svv5x33nkHgIMHD5KRkcGsWbNYvXo1mZmZNfb/1FNP0bJlS06dOkXfvn35/PPP6dSpE8OGDWPhwoX06NGDQ4cOkZqayty5c9mxYweffvopycnJ7N+/v874S0pK+Pjjj0lNTeXo0aOsXLmSlJQUtmzZwogRIyguLmb58uUsXbqUNWvWkJaWxv79+2nZsiUZGRmUlpaSk5PD/PnzGT16dKyG9Qwq1EREREREElktZ77Oh8LCQgoLC+nWrRsAFRUVbNmyhd69ezNlyhSmTp3KoEGD6N27d737XLRoEXPnzqWyspJdu3axceNGzIw2bdrQo0cPAJo3bw7Ae++9x/jx40lODpU2LVu2rLP//Px8UlNTATh58iQTJ06ktLSUpKQkNm/efLrfMWPGkJaWdka/Y8eOZf78+cyaNYuFCxeydu3aen+uSKhQExERERGRqLk706ZN4/777//RcyUlJSxbtoxp06aRl5fHY489Vmd/O3bsYObMmRQVFdGiRQtGjx7N8ePHcfdqr72tqT05OZnvwredOX78+BnPpaenn95+/vnnufTSS/nss8/47rvvSElJqbXfIUOGMH36dG677Ta6d+9Oq1at6vxM0dBiIiIiIiIiEpGLLrqIw4cPA9C/f3/mzZtHRUXo1iBff/01e/bsoby8nLS0NEaNGsWUKVNOX9dV9djqHDp0iPT0dDIyMti9ezfLly8HoFOnTpSXl1NUVATA4cOHqaysJC8vjzlz5pxeGOT7qY/t27c/fe3Y22+/XeP7HTx4kDZt2tCkSRMWLFjAqVOnAMjLy2PevHmnFz75vt+UlBT69+/PhAkTGDNmTBSjVz8q1EREROpgZgPM7E9mttXMCqp5/lYzO2hmpeHHY1We22lmX4Tbi89v5CIi50arVq3o1asX1113HStXruTuu+/m5ptvpmvXrgwdOpTDhw/zxRdf0LNnT3Jycnjqqad45JFHALjvvvsYOHAgffr0qbbv7OxsunXrRpcuXbj33nvp1asXAM2aNWPhwoVMmjSJ7Oxs+vXrx/Hjxxk7dizt2rXj+uuvJzs7mzfffBOAxx9/nMmTJ9O7d2+SkpJq/CwPPPAAr776KjfddBObN28+fbZtwIAB5Ofnk5ubS05ODjNnzjx9zMiRIzEz8vLyYjKe1TEP6P44ubm5XlysfCUi0hiYWYm75wYdRzTMLAnYDPQDyoAiYIS7b6zymluBKe4+qJrjdwK57v5tfd9TOVJE6rJp0yY6d+4cdBiN1syZMzl48CBPPvlkvY+p7mdWW37UNWoiIiK16wlsdfftAGb2FnAHsLHWo0REpEEaPHgw27Zt4/333z+n76NCTUREpHZXAF9V2S8DbqzmdTeb2WdAOaGzaxvC7Q4UmpkD/+Huc6t7EzO7D7gPoF27drGKXUQkrt14442cOHHijLYFCxbQtWvXgCKq25IlS87L+6hQExERqd2Pl/wKFV9VrQOudPcKM/spsBToGH6ul7uXm9klwEoz+6O7f/ijDkMF3FwITX2MWfQiInFszZo1QYcQt7SYiIiISO3KgLZV9rMInTU7zd0PuXtFeHsZ0NTMMsP75eE/9wBLCE2lFBE5a0GtNSGRi+ZnpUJNRESkdkVARzPrYGbNgOHA76q+wMwus/DNdsysJ6H8us/M0s3sonB7OpAHrD+v0YtIg5SSksK+fftUrCUAd2ffvn2n789WX5r6KCIiUgt3rzSzicAKIAmY5+4bzGx8+Pk5wFBggplVAseA4e7uZnYpsCRcwyUDb7r7u4F8EBFpULKysigrK2Pv3r1BhyL1kJKSQlZWVkTHqFATERGpQ3g647IftM2psj0bmF3NcduB7HMeoIg0Ok2bNqVDhw5BhyHnkKY+ioiIiIiIxBkVaiIiIiIiInFGhZqIiIiIiEicsaBWijGzvcCfz7KbTODbGITTmGjMIqcxi5zGLHINfcyudPfWQQeRKJQjA6Mxi5zGLHIas8g09PGqMT8GVqjFgpkVu3tu0HEkEo1Z5DRmkdOYRU5jJrGm36nIacwipzGLnMYsMo15vDT1UUREREREJM6oUBMREREREYkziV6ozQ06gASkMYucxixyGrPIacwk1vQ7FTmNWeQ0ZpHTmEWm0Y5XQl+jJiIiIiIi0hAl+hk1ERERERGRBkeFmoiIiIiISJxJ2ELNzAaY2Z/MbKuZFQQdT7wzs7ZmttrMNpnZBjObHHRMicDMkszsUzP736BjSRRmdrGZLTazP4Z/324OOqZ4ZmYPh/9Orjez/zKzlKBjksSm/BgZ5cfoKUdGRvkxco09RyZkoWZmScBLwEDgWmCEmV0bbFRxrxL4pbt3Bm4CHtSY1ctkYFPQQSSYfwPedfdOQDYavxqZ2RXAQ0Cuu18HJAHDg41KEpnyY1SUH6OnHBkZ5ccIKEcmaKEG9AS2uvt2d/8r8BZwR8AxxTV33+Xu68Lbhwn943BFsFHFNzPLAn4GvBJ0LInCzJoDPwF+A+Duf3X3A4EGFf+SgVQzSwbSgPKA45HEpvwYIeXH6ChHRkb5MWqNOkcmaqF2BfBVlf0y9I9qvZlZe6AbsCbgUOLdC8CvgO8CjiOR/B2wF5gfng7zipmlBx1UvHL3r4GZwJfALuCguxcGG5UkOOXHs6D8GJEXUI6MhPJjhJQjE7dQs2radJ+BejCzC4G3gX9y90NBxxOvzGwQsMfdS4KOJcEkAzcA/+7u3YAjgK6RqYGZtSB0tqMDcDmQbmajgo1KEpzyY5SUH+tPOTIqyo8RUo5M3EKtDGhbZT+LRnYqNBpm1pRQEnrD3X8bdDxxrheQb2Y7CU0dus3MXg82pIRQBpS5+/ffRi8mlJikercDO9x9r7ufBH4L3BJwTJLYlB+joPwYMeXIyCk/Rq7R58hELdSKgI5m1sHMmhG6sPB3AccU18zMCM2L3uTus4KOJ965+zR3z3L39oR+v95390b1LU403P0b4Cszuybc1BfYGGBI8e5L4CYzSwv/He2LLi6Xs6P8GCHlx8gpR0ZO+TEqjT5HJgcdQDTcvdLMJgIrCK0AM8/dNwQcVrzrBdwDfGFmpeG2f3H3ZcGFJA3UJOCN8H8StwNjAo4nbrn7GjNbDKwjtPLcp8DcYKOSRKb8GBXlRzlflB8joBwJ5q6p6yIiIiIiIvEkUac+ioiIiIiINFgq1EREREREROKMCjUREREREZE4o0JNREREREQkzqhQExERERERiTMq1EQiYGanzKy0yqMghn23N7P1sepPRETkfFF+FIm9hLyPmkiAjrl7TtBBiIiIxBnlR5EY0xk1kRgws51m9qyZrQ0/rg63X2lmq8zs8/Cf7cLtl5rZEjP7LPy4JdxVkpn9p5ltMLNCM0sNv/4hM9sY7uetgD6miIhIRJQfRaKnQk0kMqk/mNoxrMpzh9y9JzAbeCHcNht4zd2vB94AXgy3vwj83t2zgRuADeH2jsBL7t4FOAAMCbcXAN3C/Yw/Nx9NREQkasqPIjFm7h50DCIJw8wq3P3Catp3Are5+3Yzawp84+6tzOxboI27nwy373L3TDPbC2S5+4kqfbQHVrp7x/D+VKCpu//azN4FKoClwFJ3rzjHH1VERKTelB9FYk9n1ERix2vYruk11TlRZfsUf7uO9GfAS0B3oMTMdH2piIgkCuVHkSioUBOJnWFV/vy/8PYfgOHh7ZHAx+HtVcAEADNLMrPmNXVqZk2Atu6+GvgVcDHwo28tRURE4pTyo0gU9K2DSGRSzay0yv677v79EsQXmNkaQl+AjAi3PQTMM7N/BvYCY8Ltk4G5ZvaPhL4ZnADsquE9k4DXzSwDMOB5dz8Qo88jIiISC8qPIjGma9REYiA8Bz/X3b8NOhYREZF4ofwoEj1NfRQREREREYkzOqMmIiIiIiISZ3RGTUREREREJM6oUBMREREREYkzKtRERERERETijAo1ERERERGROKNCTUREREREJM78P+wofrsk6w6jAAAAAElFTkSuQmCC"
class="
jp-needs-light-background
"
>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woah!</p>
<p>Those are some nice looking loss curves.</p>
<p>It looks like our model is performing quite well and perhaps would benefit from a little longer training and potentially some <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data-augmentation">data augmentation</a> (to help prevent potential overfitting occurring from longer training).</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="35-saving-effnetb2-feature-extractor">3.5 Saving EffNetB2 feature extractor<a class="anchor-link" href="#35-saving-effnetb2-feature-extractor">&#182;</a></h3><p>Now we've got a well-performing trained model, let's save it to file so we can import and use it later.</p>
<p>To save our model we can use the <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/utils.py"><code>utils.save_model()</code></a> function we created in <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#5-creating-a-function-to-save-the-model-utilspy">05. PyTorch Going Modular section 5</a>.</p>
<p>We'll set the <code>target_dir</code> to <code>&quot;models&quot;</code> and the <code>model_name</code> to <code>&quot;09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</code> (a little comprehensive but at least we know what's going on).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-15">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="c1"># Save the model</span>
<span class="n">utils</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2</span><span class="p">,</span>
                 <span class="n">target_dir</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
                 <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-15" class="clipboard-copy-txt">from going_modular.going_modular import utils

# Save the model
utils.save_model(model=effnetb2,
                 target_dir="models",
                 model_name="09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Saving model to: models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="36-checking-the-size-of-effnetb2-feature-extractor">3.6 Checking the size of EffNetB2 feature extractor<a class="anchor-link" href="#36-checking-the-size-of-effnetb2-feature-extractor">&#182;</a></h3><p>Since one of our criteria for deploying a model to power FoodVision Mini is <strong>speed</strong> (~30FPS or better), let's check the size of our model.</p>
<p>Why check the size?</p>
<p>Well, while not always the case, the size of a model can influence its inference speed.</p>
<p>As in, if a model has more parameters, it generally performs more operations and each one of these operations requires some computing power.</p>
<p>And because we'd like our model to work on devices with limited computing power (e.g. on a mobile device or in a web browser), generally, the smaller the size the better (as long as it still performs well in terms of accuracy).</p>
<p>To check our model's size in bytes, we can use Python's <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path.stat"><code>pathlib.Path.stat(&quot;path_to_model&quot;).st_size</code></a> and then we can convert it (roughly) to megabytes by dividing it by <code>(1024*1024)</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-16">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Get the model size in bytes then convert to megabytes</span>
<span class="n">pretrained_effnetb2_model_size</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">stat</span><span class="p">()</span><span class="o">.</span><span class="n">st_size</span> <span class="o">//</span> <span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> <span class="c1"># division converts bytes to megabytes (roughly) </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pretrained EffNetB2 feature extractor model size: </span><span class="si">{</span><span class="n">pretrained_effnetb2_model_size</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-16" class="clipboard-copy-txt">from pathlib import Path

# Get the model size in bytes then convert to megabytes
pretrained_effnetb2_model_size = Path("models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth").stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) 
print(f"Pretrained EffNetB2 feature extractor model size: {pretrained_effnetb2_model_size} MB")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Pretrained EffNetB2 feature extractor model size: 29 MB
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="37-collecting-effnetb2-feature-extractor-stats">3.7 Collecting EffNetB2 feature extractor stats<a class="anchor-link" href="#37-collecting-effnetb2-feature-extractor-stats">&#182;</a></h3><p>We've got a few statistics about our EffNetB2 feature extractor model such as test loss, test accuracy and model size, how about we collect them all in a dictionary so we can compare them to the upcoming ViT feature extractor.</p>
<p>And we'll calculate an extra one for fun, total number of parameters.</p>
<p>We can do so by counting the number of elements (or patterns/weights) in <code>effnetb2.parameters()</code>. We'll access the number of elements in each parameter using the <a href="https://pytorch.org/docs/stable/generated/torch.numel.html"><code>torch.numel()</code></a> (short for &quot;number of elements&quot;) method.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[17]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-17">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Count number of parameters in EffNetB2</span>
<span class="n">effnetb2_total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">effnetb2_total_params</span>
</pre></div>
<div id="cell-17" class="clipboard-copy-txt"># Count number of parameters in EffNetB2
effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())
effnetb2_total_params</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[17]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>7705221</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Excellent!</p>
<p>Now let's put everything in a dictionary so we can make comparisons later on.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-18">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create a dictionary with EffNetB2 statistics</span>
<span class="n">effnetb2_stats</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;test_loss&quot;</span><span class="p">:</span> <span class="n">effnetb2_results</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                  <span class="s2">&quot;test_acc&quot;</span><span class="p">:</span> <span class="n">effnetb2_results</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                  <span class="s2">&quot;number_of_parameters&quot;</span><span class="p">:</span> <span class="n">effnetb2_total_params</span><span class="p">,</span>
                  <span class="s2">&quot;model_size (MB)&quot;</span><span class="p">:</span> <span class="n">pretrained_effnetb2_model_size</span><span class="p">}</span>
<span class="n">effnetb2_stats</span>
</pre></div>
<div id="cell-18" class="clipboard-copy-txt"># Create a dictionary with EffNetB2 statistics
effnetb2_stats = {"test_loss": effnetb2_results["test_loss"][-1],
                  "test_acc": effnetb2_results["test_acc"][-1],
                  "number_of_parameters": effnetb2_total_params,
                  "model_size (MB)": pretrained_effnetb2_model_size}
effnetb2_stats</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[18]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;test_loss&#39;: 0.28128674924373626,
 &#39;test_acc&#39;: 0.96875,
 &#39;number_of_parameters&#39;: 7705221,
 &#39;model_size (MB)&#39;: 29}</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Epic!</p>
<p>Looks like our EffNetB2 model is performing at over 95% accuracy!</p>
<p>Criteria number 1: perform at 95%+ accuracy, tick!</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="4-creating-a-vit-feature-extractor">4. Creating a ViT feature extractor<a class="anchor-link" href="#4-creating-a-vit-feature-extractor">&#182;</a></h2><p>Time to continue with our FoodVision Mini modelling experiments.</p>
<p>This time we're going to create a ViT feature extractor.</p>
<p>And we'll do it in much the same way as the EffNetB2 feature extractor except this time with <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#torchvision.models.vit_b_16"><code>torchvision.models.vit_b_16()</code></a> instead of <code>torchvision.models.efficientnet_b2()</code>.</p>
<p>We'll start by creating a function called <code>create_vit_model()</code> which will be very similar to <code>create_effnetb2_model()</code> except of course returning a ViT feature extractor model and transforms rather than EffNetB2.</p>
<p>Another slight difference is that <code>torchvision.models.vit_b_16()</code>'s output layer is called <code>heads</code> rather than <code>classifier</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[19]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-19">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Check out ViT heads layer</span>
<span class="n">vit</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vit_b_16</span><span class="p">()</span>
<span class="n">vit</span><span class="o">.</span><span class="n">heads</span>
</pre></div>
<div id="cell-19" class="clipboard-copy-txt"># Check out ViT heads layer
vit = torchvision.models.vit_b_16()
vit.heads</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[19]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>Sequential(
  (head): Linear(in_features=768, out_features=1000, bias=True)
)</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Knowing this, we've got all the pieces of the puzzle we need.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[20]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-20">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="k">def</span> <span class="nf">create_vit_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                     <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates a ViT-B/16 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of target classes. Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value for output layer. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): ViT-B/16 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): ViT-B/16 image transforms.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create ViT_B_16 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ViT_B_16_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vit_b_16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Freeze all layers in model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Change classifier head to suit our needs (this will be trainable)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="c1"># keep this the same as original model</span>
                                          <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">))</span> <span class="c1"># update to reflect target number of classes</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div id="cell-20" class="clipboard-copy-txt">def create_vit_model(num_classes:int=3, 
                     seed:int=42):
    """Creates a ViT-B/16 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of target classes. Defaults to 3.
        seed (int, optional): random seed value for output layer. Defaults to 42.

    Returns:
        model (torch.nn.Module): ViT-B/16 feature extractor model. 
        transforms (torchvision.transforms): ViT-B/16 image transforms.
    """
    # Create ViT_B_16 pretrained weights, transforms and model
    weights = torchvision.models.ViT_B_16_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.vit_b_16(weights=weights)

    # Freeze all layers in model
    for param in model.parameters():
        param.requires_grad = False

    # Change classifier head to suit our needs (this will be trainable)
    torch.manual_seed(seed)
    model.heads = nn.Sequential(nn.Linear(in_features=768, # keep this the same as original model
                                          out_features=num_classes)) # update to reflect target number of classes
    
    return model, transforms</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>ViT feature extraction model creation function ready!</p>
<p>Let's test it out.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[21]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-21">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create ViT model and transforms</span>
<span class="n">vit</span><span class="p">,</span> <span class="n">vit_transforms</span> <span class="o">=</span> <span class="n">create_vit_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                       <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
<div id="cell-21" class="clipboard-copy-txt"># Create ViT model and transforms
vit, vit_transforms = create_vit_model(num_classes=3,
                                       seed=42)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>No errors, lovely to see!</p>
<p>Now let's get a nice-looking summary of our ViT model using <code>torchinfo.summary()</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[22]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-22">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># # Print ViT feature extractor model summary (uncomment for full output)</span>
<span class="c1"># summary(vit, </span>
<span class="c1">#         input_size=(1, 3, 224, 224),</span>
<span class="c1">#         col_names=[&quot;input_size&quot;, &quot;output_size&quot;, &quot;num_params&quot;, &quot;trainable&quot;],</span>
<span class="c1">#         col_width=20,</span>
<span class="c1">#         row_settings=[&quot;var_names&quot;])</span>
</pre></div>
<div id="cell-22" class="clipboard-copy-txt">from torchinfo import summary

# # Print ViT feature extractor model summary (uncomment for full output)
# summary(vit, 
#         input_size=(1, 3, 224, 224),
#         col_names=["input_size", "output_size", "num_params", "trainable"],
#         col_width=20,
#         row_settings=["var_names"])</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-vit-feature-extractor-3-classes.png" width=900 alt="vit feature extractor with 3 output classes"/>
<p>Just like our EffNetB2 feature extractor model, our ViT model's base layers are frozen and the output layer is customized to our needs!</p>
<p>Do you notice the big difference though?</p>
<p>Our ViT model has <em>far</em> more parameters than our EffNetB2 model. Perhaps this will come into play when we compare are our models across speed and performance later on.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="41-create-dataloaders-for-vit">4.1 Create DataLoaders for ViT<a class="anchor-link" href="#41-create-dataloaders-for-vit">&#182;</a></h3><p>We've got our ViT model ready, now let's create some <code>DataLoader</code>s for it.</p>
<p>We'll do this in the same way we did for EffNetB2 except we'll use <code>vit_transforms</code> to transform our images into the same format the ViT model was trained on.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[23]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-23">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Setup ViT DataLoaders</span>
<span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span>
<span class="n">train_dataloader_vit</span><span class="p">,</span> <span class="n">test_dataloader_vit</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="n">data_setup</span><span class="o">.</span><span class="n">create_dataloaders</span><span class="p">(</span><span class="n">train_dir</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                                                                       <span class="n">test_dir</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                                                                       <span class="n">transform</span><span class="o">=</span><span class="n">vit_transforms</span><span class="p">,</span>
                                                                                       <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<div id="cell-23" class="clipboard-copy-txt"># Setup ViT DataLoaders
from going_modular.going_modular import data_setup
train_dataloader_vit, test_dataloader_vit, class_names = data_setup.create_dataloaders(train_dir=train_dir,
                                                                                       test_dir=test_dir,
                                                                                       transform=vit_transforms,
                                                                                       batch_size=32)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="42-training-vit-feature-extractor">4.2 Training ViT feature extractor<a class="anchor-link" href="#42-training-vit-feature-extractor">&#182;</a></h3><p>You know what time it is...</p>
<p>...it's traininggggggg time (sung in the same tune as the song <a href="https://youtu.be/xGytDsqkQY8">Closing Time</a>).</p>
<p>Let's train our ViT feature extractor model for 10 epochs using our <code>engine.train()</code> function with <code>torch.optim.Adam()</code> and a learning rate of <code>1e-3</code> as our optimizer and <code>torch.nn.CrossEntropyLoss()</code> as our loss function.</p>
<p>We'll use our <code>set_seeds()</code> function before training to try and make our results as reproducible as possible.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[24]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-24">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">engine</span>

<span class="c1"># Setup optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">vit</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                             <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="c1"># Setup loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Train ViT model with seeds set for reproducibility</span>
<span class="n">set_seeds</span><span class="p">()</span>
<span class="n">vit_results</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">vit</span><span class="p">,</span>
                           <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader_vit</span><span class="p">,</span>
                           <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader_vit</span><span class="p">,</span>
                           <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                           <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                           <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
                           <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
<div id="cell-24" class="clipboard-copy-txt">from going_modular.going_modular import engine

# Setup optimizer
optimizer = torch.optim.Adam(params=vit.parameters(),
                             lr=1e-3)
# Setup loss function
loss_fn = torch.nn.CrossEntropyLoss()

# Train ViT model with seeds set for reproducibility
set_seeds()
vit_results = engine.train(model=vit,
                           train_dataloader=train_dataloader_vit,
                           test_dataloader=test_dataloader_vit,
                           epochs=10,
                           optimizer=optimizer,
                           loss_fn=loss_fn,
                           device=device)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre>
</div>

</div>
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch: 1 | train_loss: 0.7023 | train_acc: 0.7500 | test_loss: 0.2714 | test_acc: 0.9290
Epoch: 2 | train_loss: 0.2531 | train_acc: 0.9104 | test_loss: 0.1669 | test_acc: 0.9602
Epoch: 3 | train_loss: 0.1766 | train_acc: 0.9542 | test_loss: 0.1270 | test_acc: 0.9693
Epoch: 4 | train_loss: 0.1277 | train_acc: 0.9625 | test_loss: 0.1072 | test_acc: 0.9722
Epoch: 5 | train_loss: 0.1163 | train_acc: 0.9646 | test_loss: 0.0950 | test_acc: 0.9784
Epoch: 6 | train_loss: 0.1270 | train_acc: 0.9375 | test_loss: 0.0830 | test_acc: 0.9722
Epoch: 7 | train_loss: 0.0899 | train_acc: 0.9771 | test_loss: 0.0844 | test_acc: 0.9784
Epoch: 8 | train_loss: 0.0928 | train_acc: 0.9812 | test_loss: 0.0759 | test_acc: 0.9722
Epoch: 9 | train_loss: 0.0933 | train_acc: 0.9792 | test_loss: 0.0729 | test_acc: 0.9784
Epoch: 10 | train_loss: 0.0662 | train_acc: 0.9833 | test_loss: 0.0642 | test_acc: 0.9847
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="43-inspecting-vit-loss-curves">4.3 Inspecting ViT loss curves<a class="anchor-link" href="#43-inspecting-vit-loss-curves">&#182;</a></h3><p>Alright, alright, alright, ViT model trained, let's get visual and see some loss curves.</p>
<blockquote>
<p><strong>Note:</strong> Don't forget you can see what an ideal set of loss curves should look like in <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#8-what-should-an-ideal-loss-curve-look-like">04. PyTorch Custom Datasets section 8</a>.</p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[25]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-25">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">plot_loss_curves</span>

<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">vit_results</span><span class="p">)</span>
</pre></div>
<div id="cell-25" class="clipboard-copy-txt">from helper_functions import plot_loss_curves

plot_loss_curves(vit_results)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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"
class="
jp-needs-light-background
"
>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Ohh yeah!</p>
<p>Those are some nice looking loss curves. Just like our EffNetB2 feature extractor model, it looks our ViT model might benefit from a little longer training time and perhaps some <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data-augmentation">data augmentation</a> (to help prevent overfitting).</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="44-saving-vit-feature-extractor">4.4 Saving ViT feature extractor<a class="anchor-link" href="#44-saving-vit-feature-extractor">&#182;</a></h3><p>Our ViT model is performing outstanding!</p>
<p>So let's save it to file so we can import it and use it later if we wish.</p>
<p>We can do so using the <code>utils.save_model()</code> function we created in <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#5-creating-a-function-to-save-the-model-utilspy">05. PyTorch Going Modular section 5</a>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[26]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-26">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Save the model</span>
<span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="n">utils</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">vit</span><span class="p">,</span>
                 <span class="n">target_dir</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
                 <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-26" class="clipboard-copy-txt"># Save the model
from going_modular.going_modular import utils

utils.save_model(model=vit,
                 target_dir="models",
                 model_name="09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Saving model to: models/09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="45-checking-the-size-of-vit-feature-extractor">4.5 Checking the size of ViT feature extractor<a class="anchor-link" href="#45-checking-the-size-of-vit-feature-extractor">&#182;</a></h3><p>And since we want to compare our EffNetB2 model to our ViT model across a number of characteristics, let's find out its size.</p>
<p>To check our model's size in bytes, we can use Python's <code>pathlib.Path.stat(&quot;path_to_model&quot;).st_size</code> and then we can convert it (roughly) to megabytes by dividing it by <code>(1024*1024)</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[27]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-27">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Get the model size in bytes then convert to megabytes</span>
<span class="n">pretrained_vit_model_size</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;models/09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">stat</span><span class="p">()</span><span class="o">.</span><span class="n">st_size</span> <span class="o">//</span> <span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> <span class="c1"># division converts bytes to megabytes (roughly) </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pretrained ViT feature extractor model size: </span><span class="si">{</span><span class="n">pretrained_vit_model_size</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-27" class="clipboard-copy-txt">from pathlib import Path

# Get the model size in bytes then convert to megabytes
pretrained_vit_model_size = Path("models/09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth").stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) 
print(f"Pretrained ViT feature extractor model size: {pretrained_vit_model_size} MB")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Pretrained ViT feature extractor model size: 327 MB
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Hmm, how does the ViT feature extractor model size compare to our EffNetB2 model size?</p>
<p>We'll find this out shortly when we compare all of our model's characteristics.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="46-collecting-vit-feature-extractor-stats">4.6 Collecting ViT feature extractor stats<a class="anchor-link" href="#46-collecting-vit-feature-extractor-stats">&#182;</a></h3><p>Let's put together all of our ViT feature extractor model statistics.</p>
<p>We saw it in the summary output above but we'll calculate its total number of parameters.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[28]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-28">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Count number of parameters in ViT</span>
<span class="n">vit_total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">vit</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">vit_total_params</span>
</pre></div>
<div id="cell-28" class="clipboard-copy-txt"># Count number of parameters in ViT
vit_total_params = sum(torch.numel(param) for param in vit.parameters())
vit_total_params</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[28]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>85800963</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woah, that looks like a fair bit more than our EffNetB2!</p>
<blockquote>
<p><strong>Note:</strong> A larger number of parameters (or weights/patterns) generally means a model has a higher <em>capacity</em> to learn, whether it actually uses this extra capacity is another story. In light of this, our EffNetB2 model has 7,705,221 parameters where as our ViT model has 85,800,963 (11.1x more) so we could assume that our ViT model has more of a capacity to learn, if given more data (more opportunities to learn). However, this larger capacity to learn ofen comes with an  increased model filesize and a longer time to perform inference.</p>
</blockquote>
<p>Now let's create a dictionary with some important characteristics of our ViT model.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[29]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-29">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create ViT statistics dictionary</span>
<span class="n">vit_stats</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;test_loss&quot;</span><span class="p">:</span> <span class="n">vit_results</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
             <span class="s2">&quot;test_acc&quot;</span><span class="p">:</span> <span class="n">vit_results</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
             <span class="s2">&quot;number_of_parameters&quot;</span><span class="p">:</span> <span class="n">vit_total_params</span><span class="p">,</span>
             <span class="s2">&quot;model_size (MB)&quot;</span><span class="p">:</span> <span class="n">pretrained_vit_model_size</span><span class="p">}</span>

<span class="n">vit_stats</span>
</pre></div>
<div id="cell-29" class="clipboard-copy-txt"># Create ViT statistics dictionary
vit_stats = {"test_loss": vit_results["test_loss"][-1],
             "test_acc": vit_results["test_acc"][-1],
             "number_of_parameters": vit_total_params,
             "model_size (MB)": pretrained_vit_model_size}

vit_stats</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[29]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;test_loss&#39;: 0.06418210905976593,
 &#39;test_acc&#39;: 0.984659090909091,
 &#39;number_of_parameters&#39;: 85800963,
 &#39;model_size (MB)&#39;: 327}</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Nice! Looks like our ViT model achieves over 95% accuracy too.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="5-making-predictions-with-our-trained-models-and-timing-them">5. Making predictions with our trained models and timing them<a class="anchor-link" href="#5-making-predictions-with-our-trained-models-and-timing-them">&#182;</a></h2><p>We've got a couple of trained models, both performing pretty well.</p>
<p>Now how about we test them out doing what we'd like them to do?</p>
<p>As in, let's see how they go making predictions (performing inference).</p>
<p>We know both of our models are performing at over 95% accuracy on the test dataset, but how fast are they?</p>
<p>Ideally, if we're deploying our FoodVision Mini model to a mobile device so people can take photos of their food and identify it, we'd like the predictions to happen at real-time (~30 frames per second).</p>
<p>That's why our second criteria is: a fast model.</p>
<p>To find out how long each of our models take to performance inference, let's create a function called <code>pred_and_store()</code> to iterate over each of the test dataset images one by one and perform a prediction.</p>
<p>We'll time each of the predictions as well as store the results in a common prediction format: a list of dictionaries (where each element in the list is a single prediction and each sinlge prediction is a dictionary).</p>
<blockquote>
<p><strong>Note:</strong> We time the predictions one by one rather than by batch because when our model is deployed, it will likely only be making a prediction on one image at a time. As in, someone takes a photo and our model predicts on that single image.</p>
</blockquote>
<p>Since we'd like to make predictions across all the images in the test set, let's first get a list of all of the test image paths so we can iterate over them.</p>
<p>To do so, we'll use Python's <a href="https://docs.python.org/3/library/pathlib.html#basic-use"><code>pathlib.Path(&quot;target_dir&quot;).glob(&quot;*/*.jpg&quot;))</code></a> to find all of the filepaths in a target directory with the extension <code>.jpg</code> (all of our test images).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[30]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-30">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Get all test data paths</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Finding all filepaths ending with &#39;.jpg&#39; in directory: </span><span class="si">{</span><span class="n">test_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">test_data_paths</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">test_dir</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*/*.jpg&quot;</span><span class="p">))</span>
<span class="n">test_data_paths</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
<div id="cell-30" class="clipboard-copy-txt">from pathlib import Path

# Get all test data paths
print(f"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}")
test_data_paths = list(Path(test_dir).glob("*/*.jpg"))
test_data_paths[:5]</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Finding all filepaths ending with &#39;.jpg&#39; in directory: data/pizza_steak_sushi_20_percent/test
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[30]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/831681.jpg&#39;),
 PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/3100563.jpg&#39;),
 PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/2752603.jpg&#39;),
 PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/39461.jpg&#39;),
 PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/730464.jpg&#39;)]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="51-creating-a-function-to-make-predictions-across-the-test-dataset">5.1 Creating a function to make predictions across the test dataset<a class="anchor-link" href="#51-creating-a-function-to-make-predictions-across-the-test-dataset">&#182;</a></h3><p>Now we've got a list of our test image paths, let's get to work on our <code>pred_and_store()</code> function:</p>
<ol>
<li>Create a function that takes a list of paths, a trained PyTorch model, a series of transforms (to prepare images), a list of target class names and a target device.</li>
<li>Create an empty list to store prediction dictionaries (we want the function to return a list of dictionaries, one for each prediction).</li>
<li>Loop through the target input paths (steps 4-14 will happen inside the loop).</li>
<li>Create an empty dictionary for each iteration in the loop to store prediction values per sample.</li>
<li>Get the sample path and ground truth class name (we can do this by infering the class from the path).</li>
<li>Start the prediction timer using Python's <a href="https://docs.python.org/3/library/timeit.html#timeit.default_timer"><code>timeit.default_timer()</code></a>.</li>
<li>Open the image using <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#functions"><code>PIL.Image.open(path)</code></a>.</li>
<li>Transform the image so it's capable of being using with the target model as well as add a batch dimension and send the image to the target device.</li>
<li>Prepare the model for inference by sending it to the target device and turning on <code>eval()</code> mode.</li>
<li>Turn on <a href="https://pytorch.org/docs/stable/generated/torch.inference_mode.html"><code>torch.inference_mode()</code></a> and pass the target transformed image to the model and calculate the prediction probability using <code>torch.softmax()</code> and the target label using <code>torch.argmax()</code>.</li>
<li>Add the prediction probability and prediction class to the prediction dictionary created in step 4. Also make sure the prediction probability is on the CPU so it can be used with non-GPU libraries such as NumPy and pandas for later inspection.</li>
<li>End the prediction timer started in step 6 and add the time to the prediction dictionary created in step 4.</li>
<li>See if the predicted class matches the ground truth class from step 5 and add the result to the prediction dictionary created in step 4.</li>
<li>Append the updated prediction dictionary to the empty list of predictions created in step 2.</li>
<li>Return the list of prediction dictionaries.</li>
</ol>
<p>A bunch of steps, but nothing we can't handle!</p>
<p>Let's do it.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[31]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-31">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span> 
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>

<span class="c1"># 1. Create a function to return a list of dictionaries with sample, truth label, prediction, prediction probability and prediction time</span>
<span class="k">def</span> <span class="nf">pred_and_store</span><span class="p">(</span><span class="n">paths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">],</span> 
                   <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                   <span class="n">transform</span><span class="p">:</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="p">,</span> 
                   <span class="n">class_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> 
                   <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
    
    <span class="c1"># 2. Create an empty list to store prediction dictionaires</span>
    <span class="n">pred_list</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># 3. Loop through target paths</span>
    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">paths</span><span class="p">):</span>
        
        <span class="c1"># 4. Create empty dictionary to store prediction information for each sample</span>
        <span class="n">pred_dict</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># 5. Get the sample path and ground truth class name</span>
        <span class="n">pred_dict</span><span class="p">[</span><span class="s2">&quot;image_path&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span>
        <span class="n">class_name</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">stem</span>
        <span class="n">pred_dict</span><span class="p">[</span><span class="s2">&quot;class_name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_name</span>
        
        <span class="c1"># 6. Start the prediction timer</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
        
        <span class="c1"># 7. Open image path</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        
        <span class="c1"># 8. Transform the image, add batch dimension and put image on target device</span>
        <span class="n">transformed_image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
        
        <span class="c1"># 9. Prepare model for inference by sending it to target device and turning on eval() mode</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># 10. Get prediction probability, predicition label and prediction class</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
            <span class="n">pred_logit</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">)</span> <span class="c1"># perform inference on target sample </span>
            <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred_logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># turn logits into prediction probabilities</span>
            <span class="n">pred_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># turn prediction probabilities into prediction label</span>
            <span class="n">pred_class</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="n">pred_label</span><span class="o">.</span><span class="n">cpu</span><span class="p">()]</span> <span class="c1"># hardcode prediction class to be on CPU</span>

            <span class="c1"># 11. Make sure things in the dictionary are on CPU (required for inspecting predictions later on) </span>
            <span class="n">pred_dict</span><span class="p">[</span><span class="s2">&quot;pred_prob&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">pred_prob</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">pred_dict</span><span class="p">[</span><span class="s2">&quot;pred_class&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_class</span>
            
            <span class="c1"># 12. End the timer and calculate time per pred</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
            <span class="n">pred_dict</span><span class="p">[</span><span class="s2">&quot;time_for_pred&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">end_time</span><span class="o">-</span><span class="n">start_time</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

        <span class="c1"># 13. Does the pred match the true label?</span>
        <span class="n">pred_dict</span><span class="p">[</span><span class="s2">&quot;correct&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_name</span> <span class="o">==</span> <span class="n">pred_class</span>

        <span class="c1"># 14. Add the dictionary to the list of preds</span>
        <span class="n">pred_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_dict</span><span class="p">)</span>
    
    <span class="c1"># 15. Return list of prediction dictionaries</span>
    <span class="k">return</span> <span class="n">pred_list</span>
</pre></div>
<div id="cell-31" class="clipboard-copy-txt">import pathlib
import torch

from PIL import Image
from timeit import default_timer as timer 
from tqdm.auto import tqdm
from typing import List, Dict

# 1. Create a function to return a list of dictionaries with sample, truth label, prediction, prediction probability and prediction time
def pred_and_store(paths: List[pathlib.Path], 
                   model: torch.nn.Module,
                   transform: torchvision.transforms, 
                   class_names: List[str], 
                   device: str = "cuda" if torch.cuda.is_available() else "cpu") -> List[Dict]:
    
    # 2. Create an empty list to store prediction dictionaires
    pred_list = []
    
    # 3. Loop through target paths
    for path in tqdm(paths):
        
        # 4. Create empty dictionary to store prediction information for each sample
        pred_dict = {}

        # 5. Get the sample path and ground truth class name
        pred_dict["image_path"] = path
        class_name = path.parent.stem
        pred_dict["class_name"] = class_name
        
        # 6. Start the prediction timer
        start_time = timer()
        
        # 7. Open image path
        img = Image.open(path)
        
        # 8. Transform the image, add batch dimension and put image on target device
        transformed_image = transform(img).unsqueeze(0).to(device) 
        
        # 9. Prepare model for inference by sending it to target device and turning on eval() mode
        model.to(device)
        model.eval()
        
        # 10. Get prediction probability, predicition label and prediction class
        with torch.inference_mode():
            pred_logit = model(transformed_image) # perform inference on target sample 
            pred_prob = torch.softmax(pred_logit, dim=1) # turn logits into prediction probabilities
            pred_label = torch.argmax(pred_prob, dim=1) # turn prediction probabilities into prediction label
            pred_class = class_names[pred_label.cpu()] # hardcode prediction class to be on CPU

            # 11. Make sure things in the dictionary are on CPU (required for inspecting predictions later on) 
            pred_dict["pred_prob"] = round(pred_prob.unsqueeze(0).max().cpu().item(), 4)
            pred_dict["pred_class"] = pred_class
            
            # 12. End the timer and calculate time per pred
            end_time = timer()
            pred_dict["time_for_pred"] = round(end_time-start_time, 4)

        # 13. Does the pred match the true label?
        pred_dict["correct"] = class_name == pred_class

        # 14. Add the dictionary to the list of preds
        pred_list.append(pred_dict)
    
    # 15. Return list of prediction dictionaries
    return pred_list</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Ho, ho!</p>
<p>What a good looking function!</p>
<p>And you know what, since our <code>pred_and_store()</code> is a pretty good utility function for making and storing predictions, it could be stored to <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/predictions.py"><code>going_modular.going_modular.predictions.py</code></a> for later use. That might be an extension you'd like to try, check out <a href="https://www.learnpytorch.io/05_pytorch_going_modular/">05. PyTorch Going Modular</a> for ideas.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="52-making-and-timing-predictions-with-effnetb2">5.2 Making and timing predictions with EffNetB2<a class="anchor-link" href="#52-making-and-timing-predictions-with-effnetb2">&#182;</a></h3><p>Time to test out our <code>pred_and_store()</code> function!</p>
<p>Let's start by using it to make predictions across the test dataset with our EffNetB2 model, paying attention to two details:</p>
<ol>
<li><strong>Device</strong> - We'll hard code the <code>device</code> parameter to use <code>&quot;cpu&quot;</code> because when we deploy our model, we won't always have access to a <code>&quot;cuda&quot;</code> (GPU) device.<ul>
<li>Making the predictions on CPU will be a good indicator of speed of inference too because generally predictions on CPU devices are slower than GPU devices.</li>
</ul>
</li>
<li><strong>Transforms</strong> - We'll also be sure to set the <code>transform</code> parameter to <code>effnetb2_transforms</code> to make sure the images are opened and transformed in the same way our <code>effnetb2</code> model has been trained on.</li>
</ol>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[32]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-32">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Make predictions across test dataset with EffNetB2</span>
<span class="n">effnetb2_test_pred_dicts</span> <span class="o">=</span> <span class="n">pred_and_store</span><span class="p">(</span><span class="n">paths</span><span class="o">=</span><span class="n">test_data_paths</span><span class="p">,</span>
                                          <span class="n">model</span><span class="o">=</span><span class="n">effnetb2</span><span class="p">,</span>
                                          <span class="n">transform</span><span class="o">=</span><span class="n">effnetb2_transforms</span><span class="p">,</span>
                                          <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
                                          <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span> <span class="c1"># make predictions on CPU</span>
</pre></div>
<div id="cell-32" class="clipboard-copy-txt"># Make predictions across test dataset with EffNetB2
effnetb2_test_pred_dicts = pred_and_store(paths=test_data_paths,
                                          model=effnetb2,
                                          transform=effnetb2_transforms,
                                          class_names=class_names,
                                          device="cpu") # make predictions on CPU </div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>  0%|          | 0/150 [00:00&lt;?, ?it/s]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Nice! Look at those predictions fly!</p>
<p>Let's inspect the first couple and see what they look like.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[33]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-33">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Inspect the first 2 prediction dictionaries</span>
<span class="n">effnetb2_test_pred_dicts</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
<div id="cell-33" class="clipboard-copy-txt"># Inspect the first 2 prediction dictionaries
effnetb2_test_pred_dicts[:2]</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[33]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[{&#39;image_path&#39;: PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/831681.jpg&#39;),
  &#39;class_name&#39;: &#39;steak&#39;,
  &#39;pred_prob&#39;: 0.9293,
  &#39;pred_class&#39;: &#39;steak&#39;,
  &#39;time_for_pred&#39;: 0.0494,
  &#39;correct&#39;: True},
 {&#39;image_path&#39;: PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/3100563.jpg&#39;),
  &#39;class_name&#39;: &#39;steak&#39;,
  &#39;pred_prob&#39;: 0.9534,
  &#39;pred_class&#39;: &#39;steak&#39;,
  &#39;time_for_pred&#39;: 0.0264,
  &#39;correct&#39;: True}]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woohoo!</p>
<p>It looks like our <code>pred_and_store()</code> function worked nicely.</p>
<p>Thanks to our list of dictionaries data structure, we've got plenty of useful information we can further inspect.</p>
<p>To do so, let's turn our list of dictionaries into a pandas DataFrame.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[34]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-34">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Turn the test_pred_dicts into a DataFrame</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">effnetb2_test_pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">effnetb2_test_pred_dicts</span><span class="p">)</span>
<span class="n">effnetb2_test_pred_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
<div id="cell-34" class="clipboard-copy-txt"># Turn the test_pred_dicts into a DataFrame
import pandas as pd
effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred_dicts)
effnetb2_test_pred_df.head()</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[34]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image_path</th>
      <th>class_name</th>
      <th>pred_prob</th>
      <th>pred_class</th>
      <th>time_for_pred</th>
      <th>correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/8...</td>
      <td>steak</td>
      <td>0.9293</td>
      <td>steak</td>
      <td>0.0494</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/3...</td>
      <td>steak</td>
      <td>0.9534</td>
      <td>steak</td>
      <td>0.0264</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/2...</td>
      <td>steak</td>
      <td>0.7532</td>
      <td>steak</td>
      <td>0.0256</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/3...</td>
      <td>steak</td>
      <td>0.5935</td>
      <td>steak</td>
      <td>0.0263</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/7...</td>
      <td>steak</td>
      <td>0.8959</td>
      <td>steak</td>
      <td>0.0269</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Beautiful!</p>
<p>Look how easily those prediction dictionaries turn into a structured format we can perform analysis on.</p>
<p>Such as finding how many predictions our EffNetB2 model got wrong...</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[35]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-35">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Check number of correct predictions</span>
<span class="n">effnetb2_test_pred_df</span><span class="o">.</span><span class="n">correct</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
<div id="cell-35" class="clipboard-copy-txt"># Check number of correct predictions
effnetb2_test_pred_df.correct.value_counts()</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[35]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>True     145
False      5
Name: correct, dtype: int64</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Five wrong predictions out of 150 total, not bad!</p>
<p>And how about the average prediction time?</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[36]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-36">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Find the average time per prediction </span>
<span class="n">effnetb2_average_time_per_pred</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">effnetb2_test_pred_df</span><span class="o">.</span><span class="n">time_for_pred</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;EffNetB2 average time per prediction: </span><span class="si">{</span><span class="n">effnetb2_average_time_per_pred</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-36" class="clipboard-copy-txt"># Find the average time per prediction 
effnetb2_average_time_per_pred = round(effnetb2_test_pred_df.time_for_pred.mean(), 4)
print(f"EffNetB2 average time per prediction: {effnetb2_average_time_per_pred} seconds")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>EffNetB2 average time per prediction: 0.0269 seconds
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Hmm, how does that average prediction time live up to our criteria of our model performing at real-time (~30FPS or 0.03 seconds per prediction)?</p>
<blockquote>
<p><strong>Note:</strong> Prediction times will be different across different hardware types (e.g. a local Intel i9 vs Google Colab CPU). The better and faster the hardware, generally, the faster the prediction. For example, on my local deep learning PC with an Intel i9 chip, my average prediction time with EffNetB2 is around 0.031 seconds (just under real-time). However, on Google Colab (I'm not sure what CPU hardware Colab uses but it looks like it might be an <a href="https://stackoverflow.com/questions/47805170/whats-the-hardware-spec-for-google-colaboratory">Intel(R) Xeon(R)</a>), my average prediction time with EffNetB2 is about 0.1396 seconds (3-4x slower).</p>
</blockquote>
<p>Let's add our EffNetB2 average time per prediction to our <code>effnetb2_stats</code> dictionary.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[37]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-37">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Add EffNetB2 average prediction time to stats dictionary </span>
<span class="n">effnetb2_stats</span><span class="p">[</span><span class="s2">&quot;time_per_pred_cpu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">effnetb2_average_time_per_pred</span>
<span class="n">effnetb2_stats</span>
</pre></div>
<div id="cell-37" class="clipboard-copy-txt"># Add EffNetB2 average prediction time to stats dictionary 
effnetb2_stats["time_per_pred_cpu"] = effnetb2_average_time_per_pred
effnetb2_stats</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[37]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;test_loss&#39;: 0.28128674924373626,
 &#39;test_acc&#39;: 0.96875,
 &#39;number_of_parameters&#39;: 7705221,
 &#39;model_size (MB)&#39;: 29,
 &#39;time_per_pred_cpu&#39;: 0.0269}</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="53-making-and-timing-predictions-with-vit">5.3 Making and timing predictions with ViT<a class="anchor-link" href="#53-making-and-timing-predictions-with-vit">&#182;</a></h3><p>We've made predictions with our EffNetB2 model, now let's do the same for our ViT model.</p>
<p>To do so, we can use the <code>pred_and_store()</code> function we created above except this time we'll pass in our <code>vit</code> model as well as the <code>vit_transforms</code>.</p>
<p>And we'll keep the predictions on the CPU via <code>device=&quot;cpu&quot;</code> (a natural extension here would be to test the prediction times on CPU and on GPU).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[38]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-38">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Make list of prediction dictionaries with ViT feature extractor model on test images</span>
<span class="n">vit_test_pred_dicts</span> <span class="o">=</span> <span class="n">pred_and_store</span><span class="p">(</span><span class="n">paths</span><span class="o">=</span><span class="n">test_data_paths</span><span class="p">,</span>
                                     <span class="n">model</span><span class="o">=</span><span class="n">vit</span><span class="p">,</span>
                                     <span class="n">transform</span><span class="o">=</span><span class="n">vit_transforms</span><span class="p">,</span>
                                     <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
                                     <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-38" class="clipboard-copy-txt"># Make list of prediction dictionaries with ViT feature extractor model on test images
vit_test_pred_dicts = pred_and_store(paths=test_data_paths,
                                     model=vit,
                                     transform=vit_transforms,
                                     class_names=class_names,
                                     device="cpu")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>  0%|          | 0/150 [00:00&lt;?, ?it/s]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Predictions made!</p>
<p>Now let's check out the first couple.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[39]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-39">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Check the first couple of ViT predictions on the test dataset</span>
<span class="n">vit_test_pred_dicts</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
<div id="cell-39" class="clipboard-copy-txt"># Check the first couple of ViT predictions on the test dataset
vit_test_pred_dicts[:2]</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[39]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[{&#39;image_path&#39;: PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/831681.jpg&#39;),
  &#39;class_name&#39;: &#39;steak&#39;,
  &#39;pred_prob&#39;: 0.9933,
  &#39;pred_class&#39;: &#39;steak&#39;,
  &#39;time_for_pred&#39;: 0.1313,
  &#39;correct&#39;: True},
 {&#39;image_path&#39;: PosixPath(&#39;data/pizza_steak_sushi_20_percent/test/steak/3100563.jpg&#39;),
  &#39;class_name&#39;: &#39;steak&#39;,
  &#39;pred_prob&#39;: 0.9893,
  &#39;pred_class&#39;: &#39;steak&#39;,
  &#39;time_for_pred&#39;: 0.0638,
  &#39;correct&#39;: True}]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Wonderful!</p>
<p>And just like before, since our ViT model's predictions are in the form of a list of dictionaries, we can easily turn them into a pandas DataFrame for further inspection.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[40]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-40">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Turn vit_test_pred_dicts into a DataFrame</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">vit_test_pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vit_test_pred_dicts</span><span class="p">)</span>
<span class="n">vit_test_pred_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
<div id="cell-40" class="clipboard-copy-txt"># Turn vit_test_pred_dicts into a DataFrame
import pandas as pd
vit_test_pred_df = pd.DataFrame(vit_test_pred_dicts)
vit_test_pred_df.head()</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image_path</th>
      <th>class_name</th>
      <th>pred_prob</th>
      <th>pred_class</th>
      <th>time_for_pred</th>
      <th>correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/8...</td>
      <td>steak</td>
      <td>0.9933</td>
      <td>steak</td>
      <td>0.1313</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/3...</td>
      <td>steak</td>
      <td>0.9893</td>
      <td>steak</td>
      <td>0.0638</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/2...</td>
      <td>steak</td>
      <td>0.9971</td>
      <td>steak</td>
      <td>0.0627</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/3...</td>
      <td>steak</td>
      <td>0.7685</td>
      <td>steak</td>
      <td>0.0632</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>data/pizza_steak_sushi_20_percent/test/steak/7...</td>
      <td>steak</td>
      <td>0.9499</td>
      <td>steak</td>
      <td>0.0641</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>How many predictions did our ViT model get correct?</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[41]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-41">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Count the number of correct predictions</span>
<span class="n">vit_test_pred_df</span><span class="o">.</span><span class="n">correct</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
<div id="cell-41" class="clipboard-copy-txt"># Count the number of correct predictions
vit_test_pred_df.correct.value_counts()</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[41]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>True     148
False      2
Name: correct, dtype: int64</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woah!</p>
<p>Our ViT model did a little better than our EffNetB2 model in terms of correct predictions, only two samples wrong across the whole test dataset.</p>
<p>As an extension you might want to visualize the ViT model's wrong predictions and see if there's any reason why it might've got them wrong.</p>
<p>How about we calculate how long the ViT model took per prediction?</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[42]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-42">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Calculate average time per prediction for ViT model</span>
<span class="n">vit_average_time_per_pred</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">vit_test_pred_df</span><span class="o">.</span><span class="n">time_for_pred</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ViT average time per prediction: </span><span class="si">{</span><span class="n">vit_average_time_per_pred</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-42" class="clipboard-copy-txt"># Calculate average time per prediction for ViT model
vit_average_time_per_pred = round(vit_test_pred_df.time_for_pred.mean(), 4)
print(f"ViT average time per prediction: {vit_average_time_per_pred} seconds")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>ViT average time per prediction: 0.0641 seconds
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Well, that looks a little slower than our EffNetB2 model's average time per prediction but how does it look in terms of our second criteria: speed?</p>
<p>For now, let's add the value to our <code>vit_stats</code> dictionary so we can compare it to our EffNetB2 model's stats.</p>
<blockquote>
<p><strong>Note:</strong> The average time per prediction values will be highly dependent on the hardware you make them on. For example, for the ViT model, my average time per prediction (on the CPU) was 0.0693-0.0777 seconds on my local deep learning PC with an Intel i9 CPU. Where as on Google Colab, my average time per prediction with the ViT model was 0.6766-0.7113 seconds.</p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[43]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-43">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Add average prediction time for ViT model on CPU</span>
<span class="n">vit_stats</span><span class="p">[</span><span class="s2">&quot;time_per_pred_cpu&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vit_average_time_per_pred</span>
<span class="n">vit_stats</span>
</pre></div>
<div id="cell-43" class="clipboard-copy-txt"># Add average prediction time for ViT model on CPU
vit_stats["time_per_pred_cpu"] = vit_average_time_per_pred
vit_stats</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[43]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>{&#39;test_loss&#39;: 0.06418210905976593,
 &#39;test_acc&#39;: 0.984659090909091,
 &#39;number_of_parameters&#39;: 85800963,
 &#39;model_size (MB)&#39;: 327,
 &#39;time_per_pred_cpu&#39;: 0.0641}</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="6-comparing-model-results-prediction-times-and-size">6. Comparing model results, prediction times and size<a class="anchor-link" href="#6-comparing-model-results-prediction-times-and-size">&#182;</a></h2><p>Our two best model contenders have been trained and evaluated.</p>
<p>Now let's put them head to head and compare across their different statistics.</p>
<p>To do so, let's turn our <code>effnetb2_stats</code> and <code>vit_stats</code> dictionaries into a pandas DataFrame.</p>
<p>We'll add a column to view the model names as well as the convert the test accuracy to a whole percentage rather than decimal.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[44]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-44">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Turn stat dictionaries into DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">effnetb2_stats</span><span class="p">,</span> <span class="n">vit_stats</span><span class="p">])</span>

<span class="c1"># Add column for model names</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;EffNetB2&quot;</span><span class="p">,</span> <span class="s2">&quot;ViT&quot;</span><span class="p">]</span>

<span class="c1"># Convert accuracy to percentages</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">df</span>
</pre></div>
<div id="cell-44" class="clipboard-copy-txt"># Turn stat dictionaries into DataFrame
df = pd.DataFrame([effnetb2_stats, vit_stats])

# Add column for model names
df["model"] = ["EffNetB2", "ViT"]

# Convert accuracy to percentages
df["test_acc"] = round(df["test_acc"] * 100, 2)

df</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[44]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>test_loss</th>
      <th>test_acc</th>
      <th>number_of_parameters</th>
      <th>model_size (MB)</th>
      <th>time_per_pred_cpu</th>
      <th>model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.281287</td>
      <td>96.88</td>
      <td>7705221</td>
      <td>29</td>
      <td>0.0269</td>
      <td>EffNetB2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.064182</td>
      <td>98.47</td>
      <td>85800963</td>
      <td>327</td>
      <td>0.0641</td>
      <td>ViT</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Wonderful!</p>
<p>It seems our models are quite close in terms of overall test accuracy but how do they look across the other fields?</p>
<p>One way to find out would be to divide the ViT model statistics by the EffNetB2 model statistics to find out the different ratios between the models.</p>
<p>Let's create another DataFrame to do so.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[45]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-45">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Compare ViT to EffNetB2 across different characteristics</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;ViT&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;EffNetB2&quot;</span><span class="p">]),</span> <span class="c1"># divide ViT statistics by EffNetB2 statistics</span>
             <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;ViT to EffNetB2 ratios&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</pre></div>
<div id="cell-45" class="clipboard-copy-txt"># Compare ViT to EffNetB2 across different characteristics
pd.DataFrame(data=(df.set_index("model").loc["ViT"] / df.set_index("model").loc["EffNetB2"]), # divide ViT statistics by EffNetB2 statistics
             columns=["ViT to EffNetB2 ratios"]).T</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[45]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>test_loss</th>
      <th>test_acc</th>
      <th>number_of_parameters</th>
      <th>model_size (MB)</th>
      <th>time_per_pred_cpu</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ViT to EffNetB2 ratios</th>
      <td>0.228173</td>
      <td>1.016412</td>
      <td>11.135432</td>
      <td>11.275862</td>
      <td>2.3829</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>It seems our ViT model outperforms the EffNetB2 model across the performance metrics (test loss, where lower is better and test accuracy, where higher is better) but at the expense of having:</p>
<ul>
<li>11x+ the number of parameters.</li>
<li>11x+ the model size.</li>
<li>2.5x+ the prediction time per image.</li>
</ul>
<p>Are these tradeoffs worth it?</p>
<p>Perhaps if we had unlimited compute power but for our use case of deploying the FoodVision Mini model to a smaller device (e.g. a mobile phone), we'd likely start out with the EffNetB2 model for faster predictions at a slightly reduced performance but dramatically smaller</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="61-visualizing-the-speed-vs-performance-tradeoff">6.1 Visualizing the speed vs. performance tradeoff<a class="anchor-link" href="#61-visualizing-the-speed-vs-performance-tradeoff">&#182;</a></h3><p>We've seen that our ViT model outperforms our EffNetB2 model in terms of performance metrics such as test loss and test accuracy.</p>
<p>However, our EffNetB2 model makes performs predictions faster and has a much small model size.</p>
<blockquote>
<p><strong>Note:</strong> Performance or inference time is also often referred to as &quot;latency&quot;.</p>
</blockquote>
<p>How about we make this fact visual?</p>
<p>We can do so by creating a plot with matplotlib:</p>
<ol>
<li>Create a scatter plot from the comparison DataFrame to compare EffNetB2 and ViT <code>time_per_pred_cpu</code> and <code>test_acc</code> values.</li>
<li>Add titles and labels respective of the data and customize the fontsize for aesthetics.</li>
<li>Annotate the samples on the scatter plot from step 1 with their appropriate labels (the model names).</li>
<li>Create a legend based on the model sizes (<code>model_size (MB)</code>).</li>
</ol>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[46]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-46">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># 1. Create a plot from model comparison DataFrame</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> 
                     <span class="n">x</span><span class="o">=</span><span class="s2">&quot;time_per_pred_cpu&quot;</span><span class="p">,</span> 
                     <span class="n">y</span><span class="o">=</span><span class="s2">&quot;test_acc&quot;</span><span class="p">,</span> 
                     <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">],</span> <span class="c1"># what colours to use?</span>
                     <span class="n">s</span><span class="o">=</span><span class="s2">&quot;model_size (MB)&quot;</span><span class="p">)</span> <span class="c1"># size the dots by the model sizes</span>

<span class="c1"># 2. Add titles, labels and customize fontsize for aesthetics</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;FoodVision Mini Inference Speed vs Performance&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Prediction time per image (seconds)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Test accuracy (%)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 3. Annotate with model names</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span> <span class="c1"># note: depending on your version of Matplotlib, you may need to use &quot;s=...&quot; or &quot;text=...&quot;, see: https://github.com/faustomorales/keras-ocr/issues/183#issuecomment-977733270 </span>
                <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;time_per_pred_cpu&quot;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.0006</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]</span><span class="o">+</span><span class="mf">0.03</span><span class="p">),</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># 4. Create a legend based on model sizes</span>
<span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(</span><span class="n">prop</span><span class="o">=</span><span class="s2">&quot;sizes&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">model_size_legend</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="p">,</span> 
                              <span class="n">labels</span><span class="p">,</span> 
                              <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">,</span> 
                              <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Model size (MB)&quot;</span><span class="p">,</span>
                              <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># Save the figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;images/09-foodvision-mini-inference-speed-vs-performance.jpg&quot;</span><span class="p">)</span>

<span class="c1"># Show the figure</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<div id="cell-46" class="clipboard-copy-txt"># 1. Create a plot from model comparison DataFrame
fig, ax = plt.subplots(figsize=(12, 8))
scatter = ax.scatter(data=df, 
                     x="time_per_pred_cpu", 
                     y="test_acc", 
                     c=["blue", "orange"], # what colours to use?
                     s="model_size (MB)") # size the dots by the model sizes

# 2. Add titles, labels and customize fontsize for aesthetics
ax.set_title("FoodVision Mini Inference Speed vs Performance", fontsize=18)
ax.set_xlabel("Prediction time per image (seconds)", fontsize=14)
ax.set_ylabel("Test accuracy (%)", fontsize=14)
ax.tick_params(axis='both', labelsize=12)
ax.grid(True)

# 3. Annotate with model names
for index, row in df.iterrows():
    ax.annotate(text=row["model"], # note: depending on your version of Matplotlib, you may need to use "s=..." or "text=...", see: https://github.com/faustomorales/keras-ocr/issues/183#issuecomment-977733270 
                xy=(row["time_per_pred_cpu"]+0.0006, row["test_acc"]+0.03),
                size=12)

# 4. Create a legend based on model sizes
handles, labels = scatter.legend_elements(prop="sizes", alpha=0.5)
model_size_legend = ax.legend(handles, 
                              labels, 
                              loc="lower right", 
                              title="Model size (MB)",
                              fontsize=12)

# Save the figure
plt.savefig("images/09-foodvision-mini-inference-speed-vs-performance.jpg")

# Show the figure
plt.show()</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,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"
class="
jp-needs-light-background
"
>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woah!</p>
<p>The plot really visualizes the <strong>speed vs. performance tradeoff</strong>, in other words, when you have a larger, better performing deep model (like our ViT model), it <em>generally</em> takes longer to perform inference (higher latency).</p>
<p>There are exceptions to the rule and new research is being published all the time to help make larger models perform faster.</p>
<p>And it can be tempting to just deploy the <em>best</em> performing model but it's also good to take into considersation where the model is going to be performing.</p>
<p>In our case, the differences between our model's performance levels (on the test loss and test accuracy) aren't too extreme.</p>
<p>But since we'd like to put an emphasis on speed to begin with, we're going to stick with deploying EffNetB2 since it's faster and has a much smaller footprint.</p>
<blockquote>
<p><strong>Note:</strong> Prediction times will be different across different hardware types (e.g. Intel i9 vs Google Colab CPU vs GPU) so it's important to think about and test where your model is going to end up. Asking questions like &quot;where is the model going to be run?&quot; or &quot;what is the ideal scenario for running the model?&quot; and then running experiments to try and provide answers on your way to deployment is very helpful.</p>
</blockquote>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="7-bringing-foodvision-mini-to-life-by-creating-a-gradio-demo">7. Bringing FoodVision Mini to life by creating a Gradio demo<a class="anchor-link" href="#7-bringing-foodvision-mini-to-life-by-creating-a-gradio-demo">&#182;</a></h2><p>We've decided we'd like to deploy the EffNetB2 model (to begin with, this could always be changed later).</p>
<p>So how can we do that?</p>
<p>There are several ways to deploy a machine learning model each with specific use cases (as discussed above).</p>
<p>We're going to be focused on perhaps the quickest and certainly one of the most fun ways to get a model deployed to the internet.</p>
<p>And that's by using <a href="https://gradio.app/">Gradio</a>.</p>
<p>What's Gradio?</p>
<p>The homepage describes it beautifully:</p>
<blockquote>
<p>Gradio is the fastest way to demo your machine learning model with a friendly web interface so that anyone can use it, anywhere!</p>
</blockquote>
<p>Why create a demo of your models?</p>
<p>Because metrics on the test set look nice but you never really know how you're model performs until you use it in the wild.</p>
<p>So let's get deploying!</p>
<p>We'll start by importing Gradio with the common alias <code>gr</code> and if it's not present, we'll install it.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[47]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-47">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Import/install Gradio </span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
<span class="k">except</span><span class="p">:</span> 
    <span class="err">!</span><span class="n">pip</span> <span class="o">-</span><span class="n">q</span> <span class="n">install</span> <span class="n">gradio</span>
    <span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
    
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Gradio version: </span><span class="si">{</span><span class="n">gr</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-47" class="clipboard-copy-txt"># Import/install Gradio 
try:
    import gradio as gr
except: 
    !pip -q install gradio
    import gradio as gr
    
print(f"Gradio version: {gr.__version__}")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Gradio version: 3.1.4
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Gradio ready!</p>
<p>Let's turn FoodVision Mini into a demo application.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="71-gradio-overview">7.1 Gradio overview<a class="anchor-link" href="#71-gradio-overview">&#182;</a></h3><p>The overall premise of Gradio is very similar to what we've been repeating throughout the course.</p>
<p>What are our <strong>inputs</strong> and <strong>outputs</strong>?</p>
<p>And how should we get there?</p>
<p>Well that's what our machine learning model does.</p>
<pre><code>inputs -&gt; ML model -&gt; outputs
</code></pre>
<p>In our case, for FoodVision Mini, our inputs are images of food, our ML model is EffNetB2 and our outputs are classes of food (pizza, steak or sushi).</p>
<pre><code>images of food -&gt; EffNetB2 -&gt; outputs
</code></pre>
<p>Though the concepts of inputs and outputs can be bridged to almost any other kind of ML problem.</p>
<p>Your inputs and outputs might be any combination of the following:</p>
<ul>
<li>Images</li>
<li>Text</li>
<li>Video</li>
<li>Tabular data</li>
<li>Audio</li>
<li>Numbers</li>
<li>&amp; more</li>
</ul>
<p>And the ML model you build will depend on your inputs and outputs.</p>
<p>Gradio emulates this paradigm by creating an interface (<a href="https://gradio.app/docs/#interface-header"><code>gradio.Interface()</code></a>) to from inputs to outputs.</p>
<pre><code>gradio.Interface(fn, inputs, outputs)
</code></pre>
<p>Where, <code>fn</code> is a Python function to map the <code>inputs</code> to the <code>outputs</code>.</p>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-gradio-workflow.png" alt="gradio workflow of inputs flowing into some kind of model or function and then producing outputs" width=900/>
<p><em>Gradio provides a very helpful <code>Interface</code> class to easily create an inputs -&gt; model/function -&gt; outputs workflow where the inputs and outputs could be almost anything you want. For example, you might input Tweets (text) to see if they're about machine learning or not or <a href="https://huggingface.co/blog/stable_diffusion">input a text prompt to generate images</a>.</em></p>
<blockquote>
<p><strong>Note:</strong> Gradio has a vast number of possible <code>inputs</code> and <code>outputs</code> options known as &quot;Components&quot; from images to text to numbers to audio to videos and more. You can see all of these in the <a href="https://gradio.app/docs/#components">Gradio Components documentation</a>.</p>
</blockquote>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="72-creating-a-function-to-map-our-inputs-and-outputs">7.2 Creating a function to map our inputs and outputs<a class="anchor-link" href="#72-creating-a-function-to-map-our-inputs-and-outputs">&#182;</a></h3><p>To create our FoodVision Mini demo with Gradio, we'll need a function to map our inputs to our outputs.</p>
<p>We created a function earlier called <code>pred_and_store()</code> to make predictions with a given model across a list of target files and store them in a list of dictionaries.</p>
<p>How about we create a similar function but this time focusing on a making a prediction on a single image with our EffNetB2 model?</p>
<p>More specifically, we want a function that takes an image as input, preprocesses (transforms) it, makes a prediction with EffNetB2 and then returns the prediction (pred or pred label for short) as well as the prediction probability (pred prob).</p>
<p>And while we're here, let's return the time it took to do so too:</p>
<pre><code>input: image -&gt; transform -&gt; predict with EffNetB2 -&gt; output: pred, pred prob, time taken
</code></pre>
<p>This will be our <code>fn</code> parameter for our Gradio interface.</p>
<p>First, let's make sure our EffNetB2 model is on the CPU (since we're sticking with CPU-only predictions, however you could change this if you have access to a GPU).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[48]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-48">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Put EffNetB2 on CPU</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span> 

<span class="c1"># Check the device</span>
<span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span><span class="o">.</span><span class="n">device</span>
</pre></div>
<div id="cell-48" class="clipboard-copy-txt"># Put EffNetB2 on CPU
effnetb2.to("cpu") 

# Check the device
next(iter(effnetb2.parameters())).device</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[48]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>device(type=&#39;cpu&#39;)</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>And now let's create a function called <code>predict()</code> to replicate the workflow above.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[49]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-49">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms and performs a prediction on img and returns prediction and time taken.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Start the timer</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    
    <span class="c1"># Transform the target image and add a batch dimension</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">effnetb2_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Put model into evaluation mode and turn on inference mode</span>
    <span class="n">effnetb2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
        <span class="c1"># Pass the transformed image through the model and turn the prediction logits into prediction probabilities</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">effnetb2</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio&#39;s output parameter)</span>
    <span class="n">pred_labels_and_probs</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))}</span>
    
    <span class="c1"># Calculate the prediction time</span>
    <span class="n">pred_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># Return the prediction dictionary and prediction time </span>
    <span class="k">return</span> <span class="n">pred_labels_and_probs</span><span class="p">,</span> <span class="n">pred_time</span>
</pre></div>
<div id="cell-49" class="clipboard-copy-txt">from typing import Tuple, Dict

def predict(img) -> Tuple[Dict, float]:
    """Transforms and performs a prediction on img and returns prediction and time taken.
    """
    # Start the timer
    start_time = timer()
    
    # Transform the target image and add a batch dimension
    img = effnetb2_transforms(img).unsqueeze(0)
    
    # Put model into evaluation mode and turn on inference mode
    effnetb2.eval()
    with torch.inference_mode():
        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities
        pred_probs = torch.softmax(effnetb2(img), dim=1)
    
    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)
    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}
    
    # Calculate the prediction time
    pred_time = round(timer() - start_time, 5)
    
    # Return the prediction dictionary and prediction time 
    return pred_labels_and_probs, pred_time</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Beautiful!</p>
<p>Now let's see our function in action by performing a prediction on a random image from the test dataset.</p>
<p>We'll start by getting a list of all the image paths from the test directory and then randomly selecting one.</p>
<p>Then we'll open the randomly selected image with <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#functions"><code>PIL.Image.open()</code></a>.</p>
<p>Finally, we'll pass the image to our <code>predict()</code> function.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[50]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-50">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Get a list of all test image filepaths</span>
<span class="n">test_data_paths</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">test_dir</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*/*.jpg&quot;</span><span class="p">))</span>

<span class="c1"># Randomly select a test image path</span>
<span class="n">random_image_path</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">test_data_paths</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Open the target image</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">random_image_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Predicting on image at path: </span><span class="si">{</span><span class="n">random_image_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Predict on the target image and print out the outputs</span>
<span class="n">pred_dict</span><span class="p">,</span> <span class="n">pred_time</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">img</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction label and probability dictionary: </span><span class="se">\n</span><span class="si">{</span><span class="n">pred_dict</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction time: </span><span class="si">{</span><span class="n">pred_time</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-50" class="clipboard-copy-txt">import random
from PIL import Image

# Get a list of all test image filepaths
test_data_paths = list(Path(test_dir).glob("*/*.jpg"))

# Randomly select a test image path
random_image_path = random.sample(test_data_paths, k=1)[0]

# Open the target image
image = Image.open(random_image_path)
print(f"[INFO] Predicting on image at path: {random_image_path}\n")

# Predict on the target image and print out the outputs
pred_dict, pred_time = predict(img=image)
print(f"Prediction label and probability dictionary: \n{pred_dict}")
print(f"Prediction time: {pred_time} seconds")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Predicting on image at path: data/pizza_steak_sushi_20_percent/test/pizza/3770514.jpg

Prediction label and probability dictionary: 
{&#39;pizza&#39;: 0.9785208702087402, &#39;steak&#39;: 0.01169557310640812, &#39;sushi&#39;: 0.009783552028238773}
Prediction time: 0.027 seconds
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Nice!</p>
<p>Running the cell above a few times we can see different prediction probabilities for each label from our EffNetB2 model as well as the time it took per prediction.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="73-creating-a-list-of-example-images">7.3 Creating a list of example images<a class="anchor-link" href="#73-creating-a-list-of-example-images">&#182;</a></h3><p>Our <code>predict()</code> function enables us to go from inputs -&gt; transform -&gt; ML model -&gt; outputs.</p>
<p>Which is exactly what we need for our Graido demo.</p>
<p>But before we create the demo, let's create one more thing: a list of examples.</p>
<p>Gradio's <a href="https://gradio.app/docs/#interface"><code>Interface</code></a> class takes a list of <code>examples</code> of as an optional parameter (<code>gradio.Interface(examples=List[Any])</code>).</p>
<p>And the format for the <code>examples</code> parameter is a list of lists.</p>
<p>So let's create a list of lists containing random filepaths to our test images.</p>
<p>Three examples should be enough.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[51]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-51">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create a list of example inputs to our Gradio demo</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">str</span><span class="p">(</span><span class="n">filepath</span><span class="p">)]</span> <span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">test_data_paths</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">example_list</span>
</pre></div>
<div id="cell-51" class="clipboard-copy-txt"># Create a list of example inputs to our Gradio demo
example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]
example_list</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[51]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[[&#39;data/pizza_steak_sushi_20_percent/test/sushi/804460.jpg&#39;],
 [&#39;data/pizza_steak_sushi_20_percent/test/steak/746921.jpg&#39;],
 [&#39;data/pizza_steak_sushi_20_percent/test/steak/2117351.jpg&#39;]]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Perfect!</p>
<p>Our Gradio demo will showcase these as example inputs to our demo so people can try it out and see what it does without uploading any of their own data.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="74-building-a-gradio-interface">7.4 Building a Gradio interface<a class="anchor-link" href="#74-building-a-gradio-interface">&#182;</a></h3><p>Time to put everything together and bring our FoodVision Mini demo to life!</p>
<p>Let's create a Gradio interface to replicate the workflow:</p>
<pre><code>input: image -&gt; transform -&gt; predict with EffNetB2 -&gt; output: pred, pred prob, time taken
</code></pre>
<p>We can do with the <a href="https://gradio.app/docs/#interface"><code>gradio.Interface()</code></a> class with the following parameters:</p>
<ul>
<li><code>fn</code> - a Python function to map <code>inputs</code> to <code>outputs</code>, in our case, we'll use our <code>predict()</code> function.</li>
<li><code>inputs</code> - the input to our interface, such as an image using <a href="https://gradio.app/docs/#image"><code>gradio.Image()</code></a> or <code>&quot;image&quot;</code>.</li>
<li><code>outputs</code> - the output of our interface once the <code>inputs</code> have gone through the <code>fn</code>, such as a label using <a href="https://gradio.app/docs/#label"><code>gradio.Label()</code></a> (for our model's predicted labels) or number using <a href="https://gradio.app/docs/#number"><code>gradio.Number()</code></a> (for our model's prediction time).<ul>
<li><strong>Note:</strong> Gradio comes with many in-built <code>inputs</code> and <code>outputs</code> options known as <a href="https://gradio.app/docs/#components">&quot;Components&quot;</a>.</li>
</ul>
</li>
<li><code>examples</code> - a list of examples to showcase for the demo.</li>
<li><code>title</code> - a string title of the demo.</li>
<li><code>description</code> - a string description of the demo.</li>
<li><code>article</code> - a reference note at the bottom of the demo.</li>
</ul>
<p>Once we've created our demo instance of <code>gr.Interface()</code>, we can bring it to life using <a href="https://gradio.app/docs/#launch-header"><code>gradio.Interface().launch()</code></a> or <code>demo.launch()</code> command.</p>
<p>Easy!</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[52]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-52">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>

<span class="c1"># Create title, description and article strings</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;FoodVision Mini &quot;</span>
<span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi.&quot;</span>
<span class="n">article</span> <span class="o">=</span> <span class="s2">&quot;Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/).&quot;</span>

<span class="c1"># Create the Gradio demo</span>
<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span> <span class="c1"># mapping function from input to output</span>
                    <span class="n">inputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;pil&quot;</span><span class="p">),</span> <span class="c1"># what are the inputs?</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">gr</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">num_top_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predictions&quot;</span><span class="p">),</span> <span class="c1"># what are the outputs?</span>
                             <span class="n">gr</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prediction time (s)&quot;</span><span class="p">)],</span> <span class="c1"># our fn has two outputs, therefore we have two outputs</span>
                    <span class="n">examples</span><span class="o">=</span><span class="n">example_list</span><span class="p">,</span> 
                    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
                    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
                    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">)</span>

<span class="c1"># Launch the demo!</span>
<span class="n">demo</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># print errors locally?</span>
            <span class="n">share</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># generate a publically shareable URL?</span>
</pre></div>
<div id="cell-52" class="clipboard-copy-txt">import gradio as gr

# Create title, description and article strings
title = "FoodVision Mini "
description = "An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi."
article = "Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."

# Create the Gradio demo
demo = gr.Interface(fn=predict, # mapping function from input to output
                    inputs=gr.Image(type="pil"), # what are the inputs?
                    outputs=[gr.Label(num_top_classes=3, label="Predictions"), # what are the outputs?
                             gr.Number(label="Prediction time (s)")], # our fn has two outputs, therefore we have two outputs
                    examples=example_list, 
                    title=title,
                    description=description,
                    article=article)

# Launch the demo!
demo.launch(debug=False, # print errors locally?
            share=True) # generate a publically shareable URL?</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Running on local URL:  http://127.0.0.1:7860/
Running on public URL: https://27541.gradio.app

This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">
<div><iframe src="https://27541.gradio.app" width="900" height="500" allow="autoplay; camera; microphone;" frameborder="0" allowfullscreen></iframe></div>
</div>

</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[52]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>(&lt;gradio.routes.App at 0x7f122dd0f0d0&gt;,
 &#39;http://127.0.0.1:7860/&#39;,
 &#39;https://27541.gradio.app&#39;)</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<img src="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/09-gradio-running-in-google-colab-and-in-browser.gif" alt="Gradio demo running in Google Colab and on the web" width=750/>
<p><em>FoodVision Mini Gradio demo running in Google Colab and in the browser (the link when running from Google Colab only lasts for 72 hours). You can see the <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">permanent live demo on Hugging Face Spaces</a>.</em></p>
<p>Woohoo!!! What an epic demo!!!</p>
<p>FoodVision Mini has officially come to life in an interface someone could use and try out.</p>
<p>If you set the parameter <code>share=True</code> in the <code>launch()</code> method, Gradio also provides you with a shareable link such as <code>https://123XYZ.gradio.app</code> (this link is an example only and likely expired) which is valid for 72-hours.</p>
<p>The link provides a proxy back to the Gradio interface you launched.</p>
<p>For more permanent hosting, you can upload your Gradio app to <a href="https://huggingface.co/spaces">Hugging Face Spaces</a> or anywhere that runs Python code.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="8-turning-our-foodvision-mini-gradio-demo-into-a-deployable-app">8. Turning our FoodVision Mini Gradio Demo into a deployable app<a class="anchor-link" href="#8-turning-our-foodvision-mini-gradio-demo-into-a-deployable-app">&#182;</a></h2><p>We've seen our FoodVision Mini model come to life through a Gradio demo.</p>
<p>But what if we wanted to share it with our friends?</p>
<p>Well, we could use the provided Gradio link, however, the shared link only lasts for 72-hours.</p>
<p>To make our FoodVision Mini demo more permanent, we can package it into an app and upload it to <a href="https://huggingface.co/spaces/launch">Hugging Face Spaces</a>.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="81-what-is-hugging-face-spaces">8.1 What is Hugging Face Spaces?<a class="anchor-link" href="#81-what-is-hugging-face-spaces">&#182;</a></h3><p>Hugging Face Spaces is a resource that allows you to host and share machine learning apps.</p>
<p>Building a demo is one of the best ways to showcase and test what you've done.</p>
<p>And Spaces allows you to do just that.</p>
<p>You can think of Hugging Face as the GitHub of machine learning.</p>
<p>If having a good GitHub portfolio showcases your coding abilities, having a good Hugging Face portfolio can showcase your machine learning abilities.</p>
<blockquote>
<p><strong>Note:</strong> There are many other places we could upload and host our Gradio app such as, Google Cloud, AWS (Amazon Web Services) or other cloud vendors, however, we're going to use Hugging Face Spaces due to the ease of use and wide adoption by the machine learning community.</p>
</blockquote>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="82-deployed-gradio-app-structure">8.2 Deployed Gradio app structure<a class="anchor-link" href="#82-deployed-gradio-app-structure">&#182;</a></h3><p>To upload our demo Gradio app, we'll want to put everything relating to it into a single directory.</p>
<p>For example, our demo might live at the path <code>demos/foodvision_mini/</code> with the file structure:</p>
<pre><code>demos/
 foodvision_mini/
     09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth
     app.py
     examples/
        example_1.jpg
        example_2.jpg
        example_3.jpg
     model.py
     requirements.txt
</code></pre>
<p>Where:</p>
<ul>
<li><code>09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth</code> is our trained PyTorch model file.</li>
<li><code>app.py</code> contains our Gradio app (similar to the code that launched the app).<ul>
<li><strong>Note:</strong> <code>app.py</code> is the default filename used for Hugging Face Spaces, if you deploy your app there, Spaces will by default look for a file called <code>app.py</code> to run. This is changable in settings.</li>
</ul>
</li>
<li><code>examples/</code> contains example images to use with our Gradio app.</li>
<li><code>model.py</code> contains the model defintion as well as any transforms assosciated with the model.</li>
<li><code>requirements.txt</code> contains the dependencies to run our app such as <code>torch</code>, <code>torchvision</code> and <code>gradio</code>.</li>
</ul>
<p>Why this way?</p>
<p>Because it's one of the simplest layouts we could begin with.</p>
<p>Our focus is: <em>experiment, experiment, experiment!</em></p>
<p>The quicker we can run smaller experiments, the better our bigger ones will be.</p>
<p>We're going to work towards recreating the structure above but you can see a live demo app running on Hugging Face Spaces as well as the file structure:</p>
<ul>
<li><a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">Live Gradio demo of FoodVision Mini </a>.</li>
<li><a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini/tree/main">FoodVision Mini file structure on Hugging Face Spaces</a>.</li>
</ul>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="83-creating-a-demos-folder-to-store-our-foodvision-mini-app-files">8.3 Creating a <code>demos</code> folder to store our FoodVision Mini app files<a class="anchor-link" href="#83-creating-a-demos-folder-to-store-our-foodvision-mini-app-files">&#182;</a></h3><p>To begin, let's first create a <code>demos/</code> directory to store all of our FoodVision Mini app files.</p>
<p>We can do with Python's <a href="https://docs.python.org/3/library/pathlib.html#basic-use"><code>pathlib.Path(&quot;path_to_dir&quot;)</code></a> to establish the directory path and <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir"><code>pathlib.Path(&quot;path_to_dir&quot;).mkdir()</code></a> to create it.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[53]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-53">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Create FoodVision mini demo path</span>
<span class="n">foodvision_mini_demo_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;demos/foodvision_mini/&quot;</span><span class="p">)</span>

<span class="c1"># Remove files that might already exist there and create new directory</span>
<span class="k">if</span> <span class="n">foodvision_mini_demo_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">foodvision_mini_demo_path</span><span class="p">)</span>
    <span class="n">foodvision_mini_demo_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># make the parent folders?</span>
                                    <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># create it even if it already exists?</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># If the file doesn&#39;t exist, create it anyway</span>
    <span class="n">foodvision_mini_demo_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                    <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="c1"># Check what&#39;s in the folder</span>
<span class="err">!</span><span class="n">ls</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span>
</pre></div>
<div id="cell-53" class="clipboard-copy-txt">import shutil
from pathlib import Path

# Create FoodVision mini demo path
foodvision_mini_demo_path = Path("demos/foodvision_mini/")

# Remove files that might already exist there and create new directory
if foodvision_mini_demo_path.exists():
    shutil.rmtree(foodvision_mini_demo_path)
    foodvision_mini_demo_path.mkdir(parents=True, # make the parent folders?
                                    exist_ok=True) # create it even if it already exists?
else:
    # If the file doesn't exist, create it anyway
    foodvision_mini_demo_path.mkdir(parents=True, 
                                    exist_ok=True)
    
# Check what's in the folder
!ls demos/foodvision_mini/</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="84-creating-a-folder-of-example-images-to-use-with-our-foodvision-mini-demo">8.4 Creating a folder of example images to use with our FoodVision Mini demo<a class="anchor-link" href="#84-creating-a-folder-of-example-images-to-use-with-our-foodvision-mini-demo">&#182;</a></h3><p>Now we've got a directory to store our FoodVision Mini demo files, let's add some examples to it.</p>
<p>Three example images from the test dataset should be enough.</p>
<p>To do so we'll:</p>
<ol>
<li>Create an <code>examples/</code> directory within the <code>demos/foodvision_mini</code> directory.</li>
<li>Choose three random images from the test dataset and collect their filepaths in a list.</li>
<li>Copy the three random images from the test dataset to the <code>demos/foodvision_mini/examples/</code> directory.</li>
</ol>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[54]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-54">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># 1. Create an examples directory</span>
<span class="n">foodvision_mini_examples_path</span> <span class="o">=</span> <span class="n">foodvision_mini_demo_path</span> <span class="o">/</span> <span class="s2">&quot;examples&quot;</span>
<span class="n">foodvision_mini_examples_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 2. Collect three random test dataset image paths</span>
<span class="n">foodvision_mini_examples</span> <span class="o">=</span> <span class="p">[</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg&#39;</span><span class="p">),</span>
                            <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg&#39;</span><span class="p">),</span>
                            <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg&#39;</span><span class="p">)]</span>

<span class="c1"># 3. Copy the three random images to the examples directory</span>
<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">foodvision_mini_examples</span><span class="p">:</span>
    <span class="n">destination</span> <span class="o">=</span> <span class="n">foodvision_mini_examples_path</span> <span class="o">/</span> <span class="n">example</span><span class="o">.</span><span class="n">name</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Copying </span><span class="si">{</span><span class="n">example</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">destination</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">copy2</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">example</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="n">destination</span><span class="p">)</span>
</pre></div>
<div id="cell-54" class="clipboard-copy-txt">import shutil
from pathlib import Path

# 1. Create an examples directory
foodvision_mini_examples_path = foodvision_mini_demo_path / "examples"
foodvision_mini_examples_path.mkdir(parents=True, exist_ok=True)

# 2. Collect three random test dataset image paths
foodvision_mini_examples = [Path('data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg'),
                            Path('data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg'),
                            Path('data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg')]

# 3. Copy the three random images to the examples directory
for example in foodvision_mini_examples:
    destination = foodvision_mini_examples_path / example.name
    print(f"[INFO] Copying {example} to {destination}")
    shutil.copy2(src=example, dst=destination)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Copying data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg to demos/foodvision_mini/examples/592799.jpg
[INFO] Copying data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg to demos/foodvision_mini/examples/3622237.jpg
[INFO] Copying data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg to demos/foodvision_mini/examples/2582289.jpg
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Now to verify our examples are present, let's list the contents of our <code>demos/foodvision_mini/examples/</code> directory with <a href="https://docs.python.org/3/library/os.html#os.listdir"><code>os.listdir()</code></a> and then format the filepaths into a list of lists (so it's compatible with Gradio's <a href="https://gradio.app/docs/#interface"><code>gradio.Interface()</code></a> <code>example</code> parameter).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[55]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-55">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Get example filepaths in a list of lists</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;examples/&quot;</span> <span class="o">+</span> <span class="n">example</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">foodvision_mini_examples_path</span><span class="p">)]</span>
<span class="n">example_list</span>
</pre></div>
<div id="cell-55" class="clipboard-copy-txt">import os

# Get example filepaths in a list of lists
example_list = [["examples/" + example] for example in os.listdir(foodvision_mini_examples_path)]
example_list</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[55]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[[&#39;examples/3622237.jpg&#39;], [&#39;examples/592799.jpg&#39;], [&#39;examples/2582289.jpg&#39;]]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="85-moving-our-trained-effnetb2-model-to-our-foodvision-mini-demo-directory">8.5 Moving our trained EffNetB2 model to our FoodVision Mini demo directory<a class="anchor-link" href="#85-moving-our-trained-effnetb2-model-to-our-foodvision-mini-demo-directory">&#182;</a></h3><p>We previously saved our FoodVision Mini EffNetB2 feature extractor model under <code>models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth</code>.</p>
<p>And rather double up on saved model files, let's move our model to our <code>demos/foodvision_mini</code> directory.</p>
<p>We can do so using Python's <a href="https://docs.python.org/3/library/shutil.html#shutil.move"><code>shutil.move()</code></a> method and passing in <code>src</code> (the source path of the target file) and <code>dst</code> (the destination path of the target file to be moved to) parameters.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[56]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-56">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>

<span class="c1"># Create a source path for our target model</span>
<span class="n">effnetb2_foodvision_mini_model_path</span> <span class="o">=</span> <span class="s2">&quot;models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</span>

<span class="c1"># Create a destination path for our target model </span>
<span class="n">effnetb2_foodvision_mini_model_destination</span> <span class="o">=</span> <span class="n">foodvision_mini_demo_path</span> <span class="o">/</span> <span class="n">effnetb2_foodvision_mini_model_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Try to move the file</span>
<span class="k">try</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Attempting to move </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_path</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Move the model</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">effnetb2_foodvision_mini_model_path</span><span class="p">,</span> 
                <span class="n">dst</span><span class="o">=</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Model move complete.&quot;</span><span class="p">)</span>

<span class="c1"># If the model has already been moved, check if it exists</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] No model found at </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_path</span><span class="si">}</span><span class="s2">, perhaps its already been moved?&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Model exists at </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-56" class="clipboard-copy-txt">import shutil

# Create a source path for our target model
effnetb2_foodvision_mini_model_path = "models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"

# Create a destination path for our target model 
effnetb2_foodvision_mini_model_destination = foodvision_mini_demo_path / effnetb2_foodvision_mini_model_path.split("/")[1]

# Try to move the file
try:
    print(f"[INFO] Attempting to move {effnetb2_foodvision_mini_model_path} to {effnetb2_foodvision_mini_model_destination}")
    
    # Move the model
    shutil.move(src=effnetb2_foodvision_mini_model_path, 
                dst=effnetb2_foodvision_mini_model_destination)
    
    print(f"[INFO] Model move complete.")

# If the model has already been moved, check if it exists
except:
    print(f"[INFO] No model found at {effnetb2_foodvision_mini_model_path}, perhaps its already been moved?")
    print(f"[INFO] Model exists at {effnetb2_foodvision_mini_model_destination}: {effnetb2_foodvision_mini_model_destination.exists()}")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Attempting to move models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth to demos/foodvision_mini/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth
[INFO] Model move complete.
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="86-turning-our-effnetb2-model-into-a-python-script-modelpy">8.6 Turning our EffNetB2 model into a Python script (<code>model.py</code>)<a class="anchor-link" href="#86-turning-our-effnetb2-model-into-a-python-script-modelpy">&#182;</a></h3><p>Our current model's <code>state_dict</code> is saved to <code>demos/foodvision_mini/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth</code>.</p>
<p>To load it in we can use <code>model.load_state_dict()</code> along with <code>torch.load()</code>.</p>
<blockquote>
<p><strong>Note:</strong> For a refresh on saving and loading a model (or a model's <code>state_dict</code> in PyTorch, see <a href="https://www.learnpytorch.io/01_pytorch_workflow/#5-saving-and-loading-a-pytorch-model">01. PyTorch Workflow Fundamentals section 5: Saving and loading a PyTorch model</a> or see the PyTorch recipe for <a href="https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html">What is a <code>state_dict</code> in PyTorch?</a></p>
</blockquote>
<p>But before we can do this, we first need a way to instantiate a <code>model</code>.</p>
<p>To do this in a modular fashion we'll create a script called <code>model.py</code> which contains our <code>create_effnetb2_model()</code> function we created in <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#31-creating-a-function-to-make-an-effnetb2-feature-extractor">section 3.1: <em>Creating a function to make an EffNetB2 feature extractor</em></a>.</p>
<p>That way we can import the function in <em>another</em> script (see <code>app.py</code> below) and then use it to create our EffNetB2 <code>model</code> instance as well as get its appropriate transforms.</p>
<p>Just like in <a href="https://www.learnpytorch.io/05_pytorch_going_modular/">05. PyTorch Going Modular</a>, we'll use the <code>%%writefile path/to/file</code> magic command to turn a cell of code into a file.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[57]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-57">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">py</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">def</span> <span class="nf">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                          <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates an EfficientNetB2 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of classes in the classifier head. </span>
<span class="sd">            Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): EffNetB2 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): EffNetB2 image transforms.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create EffNetB2 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Freeze all layers in base model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Change classifier head with random seed for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div id="cell-57" class="clipboard-copy-txt">%%writefile demos/foodvision_mini/model.py
import torch
import torchvision

from torch import nn


def create_effnetb2_model(num_classes:int=3, 
                          seed:int=42):
    """Creates an EfficientNetB2 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of classes in the classifier head. 
            Defaults to 3.
        seed (int, optional): random seed value. Defaults to 42.

    Returns:
        model (torch.nn.Module): EffNetB2 feature extractor model. 
        transforms (torchvision.transforms): EffNetB2 image transforms.
    """
    # Create EffNetB2 pretrained weights, transforms and model
    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.efficientnet_b2(weights=weights)

    # Freeze all layers in base model
    for param in model.parameters():
        param.requires_grad = False

    # Change classifier head with random seed for reproducibility
    torch.manual_seed(seed)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.3, inplace=True),
        nn.Linear(in_features=1408, out_features=num_classes),
    )
    
    return model, transforms</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing demos/foodvision_mini/model.py
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="87-turning-our-foodvision-mini-gradio-app-into-a-python-script-apppy">8.7 Turning our FoodVision Mini Gradio app into a Python script (<code>app.py</code>)<a class="anchor-link" href="#87-turning-our-foodvision-mini-gradio-app-into-a-python-script-apppy">&#182;</a></h3><p>We've now got a <code>model.py</code> script as well as a path to a saved model <code>state_dict</code> that we can load in.</p>
<p>Time to construct <code>app.py</code>.</p>
<p>We call it <code>app.py</code> because by default when you create a HuggingFace Space, it looks for a file called <code>app.py</code> to run and host (though you can change this in settings).</p>
<p>Our <code>app.py</code> script will put together all of the pieces of the puzzle to create our Gradio demo and will have four main parts:</p>
<ol>
<li><strong>Imports and class names setup</strong> - Here we'll import the various dependencies for our demo including the <code>create_effnetb2_model()</code> function from <code>model.py</code> as well as setup the different class names for our FoodVision Mini app.</li>
<li><strong>Model and transforms preparation</strong> - Here we'll create an EffNetB2 model instance along with the transforms to go with it and then we'll load in the saved model weights/<code>state_dict</code>. When we load the model we'll also set <code>map_location=torch.device(&quot;cpu&quot;)</code> in <a href="https://pytorch.org/docs/stable/generated/torch.load.html"><code>torch.load()</code></a> so our model gets loaded onto the CPU regardless of the device it trained on (we do this because we won't necessarily have a GPU when we deploy and we'll get an error if our model is trained on GPU but we try to deploy it to CPU without explicitly saying so).</li>
<li><strong>Predict function</strong> - Gradio's <code>gradio.Interface()</code> takes a <code>fn</code> parameter to map inputs to outputs, our <code>predict()</code> function will be the same as the one we defined above in <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#72-creating-a-function-to-map-our-inputs-and-outputs">section 7.2: <em>Creating a function to map our inputs and outputs</em></a>, it will take in an image and then use the loaded transforms to preprocess it before using the loaded model to make a prediction on it.<ul>
<li><strong>Note:</strong> We'll have to create the example list on the fly via the <code>examples</code> parameter. We can do so by creating a list of the files inside the <code>examples/</code> directory with: <code>[[&quot;examples/&quot; + example] for example in os.listdir(&quot;examples&quot;)]</code>.</li>
</ul>
</li>
<li><strong>Gradio app</strong> - This is where the main logic of our demo will live, we'll create a <code>gradio.Interface()</code> instance called <code>demo</code> to put together our inputs, <code>predict()</code> function and outputs. And we'll finish the script by calling <code>demo.launch()</code> to launch our FoodVision Mini demo!</li>
</ol>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[58]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-58">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span><span class="n">app</span><span class="o">.</span><span class="n">py</span>
<span class="c1">### 1. Imports and class names setup ### </span>
<span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">create_effnetb2_model</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>

<span class="c1"># Setup class names</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;pizza&quot;</span><span class="p">,</span> <span class="s2">&quot;steak&quot;</span><span class="p">,</span> <span class="s2">&quot;sushi&quot;</span><span class="p">]</span>

<span class="c1">### 2. Model and transforms preparation ###</span>

<span class="c1"># Create EffNetB2 model</span>
<span class="n">effnetb2</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="c1"># len(class_names) would also work</span>
<span class="p">)</span>

<span class="c1"># Load saved weights</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">f</span><span class="o">=</span><span class="s2">&quot;09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</span><span class="p">,</span>
        <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>  <span class="c1"># load to CPU</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1">### 3. Predict function ###</span>

<span class="c1"># Create predict function</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms and performs a prediction on img and returns prediction and time taken.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Start the timer</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    
    <span class="c1"># Transform the target image and add a batch dimension</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">effnetb2_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Put model into evaluation mode and turn on inference mode</span>
    <span class="n">effnetb2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
        <span class="c1"># Pass the transformed image through the model and turn the prediction logits into prediction probabilities</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">effnetb2</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio&#39;s output parameter)</span>
    <span class="n">pred_labels_and_probs</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))}</span>
    
    <span class="c1"># Calculate the prediction time</span>
    <span class="n">pred_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># Return the prediction dictionary and prediction time </span>
    <span class="k">return</span> <span class="n">pred_labels_and_probs</span><span class="p">,</span> <span class="n">pred_time</span>

<span class="c1">### 4. Gradio app ###</span>

<span class="c1"># Create title, description and article strings</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;FoodVision Mini &quot;</span>
<span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi.&quot;</span>
<span class="n">article</span> <span class="o">=</span> <span class="s2">&quot;Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/).&quot;</span>

<span class="c1"># Create examples list from &quot;examples/&quot; directory</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;examples/&quot;</span> <span class="o">+</span> <span class="n">example</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;examples&quot;</span><span class="p">)]</span>

<span class="c1"># Create the Gradio demo</span>
<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span> <span class="c1"># mapping function from input to output</span>
                    <span class="n">inputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;pil&quot;</span><span class="p">),</span> <span class="c1"># what are the inputs?</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">gr</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">num_top_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predictions&quot;</span><span class="p">),</span> <span class="c1"># what are the outputs?</span>
                             <span class="n">gr</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prediction time (s)&quot;</span><span class="p">)],</span> <span class="c1"># our fn has two outputs, therefore we have two outputs</span>
                    <span class="c1"># Create examples list from &quot;examples/&quot; directory</span>
                    <span class="n">examples</span><span class="o">=</span><span class="n">example_list</span><span class="p">,</span> 
                    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
                    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
                    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">)</span>

<span class="c1"># Launch the demo!</span>
<span class="n">demo</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</pre></div>
<div id="cell-58" class="clipboard-copy-txt">%%writefile demos/foodvision_mini/app.py
### 1. Imports and class names setup ### 
import gradio as gr
import os
import torch

from model import create_effnetb2_model
from timeit import default_timer as timer
from typing import Tuple, Dict

# Setup class names
class_names = ["pizza", "steak", "sushi"]

### 2. Model and transforms preparation ###

# Create EffNetB2 model
effnetb2, effnetb2_transforms = create_effnetb2_model(
    num_classes=3, # len(class_names) would also work
)

# Load saved weights
effnetb2.load_state_dict(
    torch.load(
        f="09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth",
        map_location=torch.device("cpu"),  # load to CPU
    )
)

### 3. Predict function ###

# Create predict function
def predict(img) -> Tuple[Dict, float]:
    """Transforms and performs a prediction on img and returns prediction and time taken.
    """
    # Start the timer
    start_time = timer()
    
    # Transform the target image and add a batch dimension
    img = effnetb2_transforms(img).unsqueeze(0)
    
    # Put model into evaluation mode and turn on inference mode
    effnetb2.eval()
    with torch.inference_mode():
        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities
        pred_probs = torch.softmax(effnetb2(img), dim=1)
    
    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)
    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}
    
    # Calculate the prediction time
    pred_time = round(timer() - start_time, 5)
    
    # Return the prediction dictionary and prediction time 
    return pred_labels_and_probs, pred_time

### 4. Gradio app ###

# Create title, description and article strings
title = "FoodVision Mini "
description = "An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi."
article = "Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."

# Create examples list from "examples/" directory
example_list = [["examples/" + example] for example in os.listdir("examples")]

# Create the Gradio demo
demo = gr.Interface(fn=predict, # mapping function from input to output
                    inputs=gr.Image(type="pil"), # what are the inputs?
                    outputs=[gr.Label(num_top_classes=3, label="Predictions"), # what are the outputs?
                             gr.Number(label="Prediction time (s)")], # our fn has two outputs, therefore we have two outputs
                    # Create examples list from "examples/" directory
                    examples=example_list, 
                    title=title,
                    description=description,
                    article=article)

# Launch the demo!
demo.launch()</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing demos/foodvision_mini/app.py
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="88-creating-a-requirements-file-for-foodvision-mini-requirementstxt">8.8 Creating a requirements file for FoodVision Mini (<code>requirements.txt</code>)<a class="anchor-link" href="#88-creating-a-requirements-file-for-foodvision-mini-requirementstxt">&#182;</a></h3><p>The last file we need to create for our FoodVision Mini app is a <a href="https://learnpython.com/blog/python-requirements-file/"><code>requirements.txt</code> file</a>.</p>
<p>This will be a text file containing all of the required dependencies for our demo.</p>
<p>When we deploy our demo app to Hugging Face Spaces, it will search through this file and install the dependencies we define so our app can run.</p>
<p>The good news is, there's only three!</p>
<ol>
<li><code>torch==1.12.0</code></li>
<li><code>torchvision==0.13.0</code></li>
<li><code>gradio==3.1.4</code></li>
</ol>
<p>The &quot;<code>==1.12.0</code>&quot; states the version number to install.</p>
<p>Defining the version number is not 100% required but we will for now so if any breaking updates occur in future releases, our app still runs (PS if you find any errors, feel free to post on the course <a href="https://github.com/mrdbourke/pytorch-deep-learning/issues">GitHub Issues</a>).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[59]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-59">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span><span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">torch</span><span class="o">==</span><span class="mf">1.12.0</span>
<span class="n">torchvision</span><span class="o">==</span><span class="mf">0.13.0</span>
<span class="n">gradio</span><span class="o">==</span><span class="mf">3.1.4</span>
</pre></div>
<div id="cell-59" class="clipboard-copy-txt">%%writefile demos/foodvision_mini/requirements.txt
torch==1.12.0
torchvision==0.13.0
gradio==3.1.4</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing demos/foodvision_mini/requirements.txt
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Nice!</p>
<p>We've officially got all the files we need to deploy our FoodVision Mini demo!</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="9-deploying-our-foodvision-mini-app-to-huggingface-spaces">9. Deploying our FoodVision Mini app to HuggingFace Spaces<a class="anchor-link" href="#9-deploying-our-foodvision-mini-app-to-huggingface-spaces">&#182;</a></h2><p>We've got a file containing our FoodVision Mini demo, now how do we get it to run on Hugging Face Spaces?</p>
<p>There are two main options for uploading to a Hugging Face Space (also called a <a href="https://huggingface.co/docs/hub/repositories-getting-started#getting-started-with-repositories">Hugging Face Repository</a>, similar to a git repository):</p>
<ol>
<li><a href="https://huggingface.co/docs/hub/repositories-getting-started#adding-files-to-a-repository-web-ui">Uploading via the Hugging Face Web interface (easiest)</a>.</li>
<li><a href="https://huggingface.co/docs/hub/repositories-getting-started#terminal">Uploading via the command line or terminal</a>.<ul>
<li><strong>Bonus:</strong> You can also use the <a href="https://huggingface.co/docs/huggingface_hub/index"><code>huggingface_hub</code> library</a> to interact with Hugging Face, this would be a good extension to the above two options.</li>
</ul>
</li>
</ol>
<p>Feel free to read the documentation on both options but we're going to go with option two.</p>
<blockquote>
<p><strong>Note:</strong> To host anything on Hugging Face, you will to <a href="https://huggingface.co/join">sign up for a free Hugging Face account</a>.</p>
</blockquote>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="91-downloading-our-foodvision-mini-app-files">9.1 Downloading our FoodVision Mini app files<a class="anchor-link" href="#91-downloading-our-foodvision-mini-app-files">&#182;</a></h3><p>Let's check out the demo files we've got inside <code>demos/foodvision_mini</code>.</p>
<p>To do so we can use the <code>!ls</code> command followed by the target filepath.</p>
<p><code>ls</code> stands for &quot;list&quot; and the <code>!</code> means we want to execute the command at the shell level.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[60]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-60">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="err">!</span><span class="n">ls</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span>
</pre></div>
<div id="cell-60" class="clipboard-copy-txt">!ls demos/foodvision_mini</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth
app.py
examples
model.py
requirements.txt
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>These are all files that we've created!</p>
<p>To begin uploading our files to Hugging Face, let's now download them from Google Colab (or wherever you're running this notebook).</p>
<p>To do so, we'll first compress the files into a single zip folder via the command:</p>
<pre><code>zip -r ../foodvision_mini.zip * -x &quot;*.pyc&quot; &quot;*.ipynb&quot; &quot;*__pycache__*&quot; &quot;*ipynb_checkpoints*&quot;
</code></pre>
<p>Where:</p>
<ul>
<li><code>zip</code> stands for &quot;zip&quot; as in &quot;please zip together the files in the following directory&quot;.</li>
<li><code>-r</code> stands for &quot;recursive&quot; as in, &quot;go through all of the files in the target directory&quot;.</li>
<li><code>../foodvision_mini.zip</code> is the target directory we'd like our files to be zipped to.</li>
<li><code>*</code> stands for &quot;all the files in the current directory&quot;.</li>
<li><code>-x</code> stands for &quot;exclude these files&quot;.</li>
</ul>
<p>We can download our zip file from Google Colab using <a href="https://colab.research.google.com/notebooks/io.ipynb"><code>google.colab.files.download(&quot;demos/foodvision_mini.zip&quot;)</code></a> (we'll put this inside a <code>try</code> and <code>except</code> block just in case we're not running the code inside Google Colab, and if so we'll print a message saying to manually download the files).</p>
<p>Let's try it out!</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[61]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-61">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Change into and then zip the foodvision_mini folder but exclude certain files</span>
<span class="err">!</span><span class="n">cd</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span> <span class="o">&amp;&amp;</span> <span class="nb">zip</span> <span class="o">-</span><span class="n">r</span> <span class="o">../</span><span class="n">foodvision_mini</span><span class="o">.</span><span class="n">zip</span> <span class="o">*</span> <span class="o">-</span><span class="n">x</span> <span class="s2">&quot;*.pyc&quot;</span> <span class="s2">&quot;*.ipynb&quot;</span> <span class="s2">&quot;*__pycache__*&quot;</span> <span class="s2">&quot;*ipynb_checkpoints*&quot;</span>

<span class="c1"># Download the zipped FoodVision Mini app (if running in Google Colab)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;demos/foodvision_mini.zip&quot;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Not running in Google Colab, can&#39;t use google.colab.files.download(), please manually download.&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-61" class="clipboard-copy-txt"># Change into and then zip the foodvision_mini folder but exclude certain files
!cd demos/foodvision_mini && zip -r ../foodvision_mini.zip * -x "*.pyc" "*.ipynb" "*__pycache__*" "*ipynb_checkpoints*"

# Download the zipped FoodVision Mini app (if running in Google Colab)
try:
    from google.colab import files
    files.download("demos/foodvision_mini.zip")
except:
    print("Not running in Google Colab, can't use google.colab.files.download(), please manually download.")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>updating: 09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth (deflated 8%)
updating: app.py (deflated 57%)
updating: examples/ (stored 0%)
updating: examples/3622237.jpg (deflated 0%)
updating: examples/592799.jpg (deflated 1%)
updating: examples/2582289.jpg (deflated 17%)
updating: model.py (deflated 56%)
updating: requirements.txt (deflated 4%)
Not running in Google Colab, can&#39;t use google.colab.files.download(), please manually download.
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woohoo!</p>
<p>Looks like our <code>zip</code> command was successful.</p>
<p>If you're running this notebook in Google Colab, you should see a file start to download in your browser.</p>
<p>Otherwise, you can see the <code>foodvision_mini.zip</code> folder (and more) on the <a href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/demos">course GitHub under the <code>demos/</code> directory</a>.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="92-running-our-foodvision-mini-demo-locally">9.2 Running our FoodVision Mini demo locally<a class="anchor-link" href="#92-running-our-foodvision-mini-demo-locally">&#182;</a></h3><p>If you download the <code>foodvision_mini.zip</code> file, you can test it locally by:</p>
<ol>
<li>Unzipping the file.</li>
<li>Opening terminal or a command line prompt.</li>
<li>Changing into the <code>foodvision_mini</code> directory (<code>cd foodvision_mini</code>).</li>
<li>Creating an environment (<code>python3 -m venv env</code>).</li>
<li>Activating the environment (<code>source env/bin/activate</code>).</li>
<li>Installing the requirements (<code>pip install -r requirements.txt</code>, the &quot;<code>-r</code>&quot; is for recursive).<ul>
<li><strong>Note:</strong> This step may take 5-10 minutes depending on your internet connection. And if you're facing errors, you may need to upgrade <code>pip</code> first: <code>pip install --upgrade pip</code>.</li>
</ul>
</li>
<li>Run the app (<code>python3 app.py</code>).</li>
</ol>
<p>This should result in a Gradio demo just like the one we built above running locally on your machine at a URL such as <code>http://127.0.0.1:7860/</code>.</p>
<blockquote>
<p><strong>Note:</strong> If you run the app locally and you notice a <code>flagged/</code> directory appear, it contains samples that have been &quot;flagged&quot;.</p>
<p>For example, if someone tries the demo and the model produces an incorrect result, the sample can be &quot;flagged&quot; and reviewed for later.</p>
<p>For more on flagging in Gradio, see the <a href="https://gradio.app/docs/#flagging">flagging documentation</a>.</p>
</blockquote>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="93-uploading-to-hugging-face">9.3 Uploading to Hugging Face<a class="anchor-link" href="#93-uploading-to-hugging-face">&#182;</a></h3><p>We've verfied our FoodVision Mini app works locally, however, the fun of creating a machine learning demo is to show it to other people and allow them to use it.</p>
<p>To do so, we're going to upload our FoodVision Mini demo to Hugging Face.</p>
<blockquote>
<p><strong>Note:</strong> The following series of steps uses a Git (a file tracking system) workflow. For more on how Git works, I'd recommend going through the <a href="https://youtu.be/RGOj5yH7evk">Git and GitHub for Beginners tutorial</a> on freeCodeCamp.</p>
</blockquote>
<ol>
<li><a href="https://huggingface.co/join">Sign up</a> for a Hugging Face account.</li>
<li>Start a new Hugging Face Space by going to your profile and then <a href="https://huggingface.co/new-space">clicking &quot;New Space&quot;</a>.<ul>
<li><strong>Note:</strong> A Space in Hugging Face is also known as a &quot;code repository&quot; (a place to store your code/files) or &quot;repo&quot; for short.</li>
</ul>
</li>
<li>Give the Space a name, for example, mine is called <code>mrdbourke/foodvision_mini</code>, you can see it here: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">https://huggingface.co/spaces/mrdbourke/foodvision_mini</a></li>
<li>Select a license (I used <a href="https://opensource.org/licenses/MIT">MIT</a>).</li>
<li>Select Gradio as the Space SDK (software development kit).<ul>
<li><strong>Note:</strong> You can use other options such as Streamlit but since our app is built with Gradio, we'll stick with that.</li>
</ul>
</li>
<li>Choose whether your Space is it's public or private (I selected public since I'd like my Space to be available to others).</li>
<li>Click &quot;Create Space&quot;.</li>
<li>Clone the repo locally by running something like: <code>git clone https://huggingface.co/spaces/[YOUR_USERNAME]/[YOUR_SPACE_NAME]</code> in terminal or command prompt.<ul>
<li><strong>Note:</strong> You can also add files via uploading them under the &quot;Files and versions&quot; tab.</li>
</ul>
</li>
<li>Copy/move the contents of the downloaded <code>foodvision_mini</code> folder to the cloned repo folder.</li>
<li>To upload and track larger files (e.g. files over 10MB or in our case, our PyTorch model file) you'll need to <a href="https://git-lfs.github.com/">install Git LFS</a> (which stands for &quot;git large file storage&quot;).</li>
<li>After you've installed Git LFS, you can activate it by running <code>git lfs install</code>.</li>
<li>In the <code>foodvision_mini</code> directory, track the files over 10MB with Git LFS with <code>git lfs track &quot;*.file_extension&quot;</code>.<ul>
<li>Track EffNetB2 PyTorch model file with <code>git lfs track &quot;09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth&quot;</code>.</li>
</ul>
</li>
<li>Track <code>.gitattributes</code> (automatically created when cloning from HuggingFace, this file will help ensure our larger files are tracked with Git LFS). You can see an example <code>.gitattributes</code> file on the <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini/blob/main/.gitattributes">FoodVision Mini Hugging Face Space</a>.<ul>
<li><code>git add .gitattributes</code></li>
</ul>
</li>
<li>Add the rest of the <code>foodvision_mini</code> app files and commit them with:<ul>
<li><code>git add *</code></li>
<li><code>git commit -m &quot;first commit&quot;</code></li>
</ul>
</li>
<li>Push (upload) the files to Hugging Face:<ul>
<li><code>git push</code></li>
</ul>
</li>
<li>Wait 3-5 minutes for the build to happen (future builds are faster) and your app to become live!</li>
</ol>
<p>If everything worked, you should see a live running example of our FoodVision Mini Gradio demo like the one here: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">https://huggingface.co/spaces/mrdbourke/foodvision_mini</a></p>
<p>And we can even embed our FoodVision Mini Gradio demo into our notebook as an <a href="https://gradio.app/sharing_your_app/#embedding-with-iframes">iframe</a> with <a href="https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.IFrame"><code>IPython.display.IFrame</code></a> and a link to our space in the format <code>https://hf.space/embed/[YOUR_USERNAME]/[YOUR_SPACE_NAME]/+</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[62]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-62">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># IPython is a library to help make Python interactive</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>

<span class="c1"># Embed FoodVision Mini Gradio demo</span>
<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://hf.space/embed/mrdbourke/foodvision_mini/+&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">)</span>
</pre></div>
<div id="cell-62" class="clipboard-copy-txt"># IPython is a library to help make Python interactive
from IPython.display import IFrame

# Embed FoodVision Mini Gradio demo
IFrame(src="https://hf.space/embed/mrdbourke/foodvision_mini/+", width=900, height=750)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[62]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">

        <iframe
            width="900"
            height="750"
            src="https://hf.space/embed/mrdbourke/foodvision_mini/+"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="10-creating-foodvision-big">10. Creating FoodVision Big<a class="anchor-link" href="#10-creating-foodvision-big">&#182;</a></h2><p>We've spent the past few sections and chapters working on bringing FoodVision Mini to life.</p>
<p>And now we've seen it working in a live demo, how about we step things up a notch?</p>
<p>How?</p>
<p>FoodVision Big!</p>
<p>Since FoodVision Mini is trained on pizza, steak and sushi images from the <a href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html">Food101 dataset</a> (101 classes of food x 1000 images each), how about we make FoodVision Big by training a model on all 101 classes!</p>
<p>We'll go from three classes to 101!</p>
<p>From pizza, steak, sushi to pizza, steak, sushi, hot dog, apple pie, carrot cake, chocolate cake, french fires, garlic bread, ramen, nachos, tacos and more!</p>
<p>How?</p>
<p>Well, we've got all the steps in place, all we have to do is alter our EffNetB2 model slightly as well as prepare a different dataset.</p>
<p>To finish Milestone Project 3, let's recreate a Gradio demo similar to FoodVision Mini (three classes) but for FoodVision Big (101 classes).</p>
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployment-foodvision-mini-to-foodvision-big.png" alt="foodvision mini model on three classes: pizza, steak, sushi and foodvision big on all of the 101 classes in the food101 dataset" width=900/>
<p><em>FoodVision Mini works with three food classes: pizza, steak and sushi. And FoodVision Big steps it up a notch to work across 101 food classes: all of the <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names.txt">classes in the Food101 dataset</a>.</em></p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="101-creating-a-model-and-transforms-for-foodvision-big">10.1 Creating a model and transforms for FoodVision Big<a class="anchor-link" href="#101-creating-a-model-and-transforms-for-foodvision-big">&#182;</a></h3><p>When creating FoodVision Mini we saw that the EffNetB2 model was a good tradeoff between speed and performance (it performed well with a fast speed).</p>
<p>So we'll continue using the same model for FoodVision Big.</p>
<p>We can create an EffNetB2 feature extractor for Food101 by using our <code>create_effnetb2_model()</code> function we created above, in <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#31-creating-a-function-to-make-an-effnetb2-feature-extractor">section 3.1</a>, and passing it the parameter <code>num_classes=101</code> (since Food101 has 101 classes).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[63]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-63">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create EffNetB2 model capable of fitting to 101 classes for Food101</span>
<span class="n">effnetb2_food101</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
</pre></div>
<div id="cell-63" class="clipboard-copy-txt"># Create EffNetB2 model capable of fitting to 101 classes for Food101
effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Beautiful!</p>
<p>Let's now get a summary of our model.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[64]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-64">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># # Get a summary of EffNetB2 feature extractor for Food101 with 101 output classes (uncomment for full output)</span>
<span class="c1"># summary(effnetb2_food101, </span>
<span class="c1">#         input_size=(1, 3, 224, 224),</span>
<span class="c1">#         col_names=[&quot;input_size&quot;, &quot;output_size&quot;, &quot;num_params&quot;, &quot;trainable&quot;],</span>
<span class="c1">#         col_width=20,</span>
<span class="c1">#         row_settings=[&quot;var_names&quot;])</span>
</pre></div>
<div id="cell-64" class="clipboard-copy-txt">from torchinfo import summary

# # Get a summary of EffNetB2 feature extractor for Food101 with 101 output classes (uncomment for full output)
# summary(effnetb2_food101, 
#         input_size=(1, 3, 224, 224),
#         col_names=["input_size", "output_size", "num_params", "trainable"],
#         col_width=20,
#         row_settings=["var_names"])</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<img src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-effnetb2-feature-extractor-101-classes.png" width=900 alt="effnetb2 feature extractor with 100 output classes model summary"/>
<p>Nice!</p>
<p>See how just like our EffNetB2 model for FoodVision Mini the base layers are frozen (these are pretrained on ImageNet) and the outer layers (the <code>classifier</code> layers) are trainble with an ouput shape of <code>[batch_size, 101]</code> (<code>101</code> for 101 classes in Food101).</p>
<p>Now since we're going to be dealing with a fair bit more data than usual, how about we add a little data augmentation to our transforms (<code>effnetb2_transforms</code>) to augment the training data.</p>
<blockquote>
<p><strong>Note:</strong> Data augmentation is a technique used to alter the appearance of an input training sample (e.g. rotating an image or slightly skewing it) to artificially increase the diversity of a training dataset to hopefully prevent overfitting. You can see more on data augmentation in <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data-augmentation">04. PyTorch Custom Datasets section 6</a>.</p>
</blockquote>
<p>Let's compose a <code>torchvision.transforms</code> pipeline to use <a href="https://pytorch.org/vision/main/generated/torchvision.transforms.TrivialAugmentWide.html"><code>torchvision.transforms.TrivialAugmentWide()</code></a> (the same data augmentation used by the PyTorch team in their <a href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#break-down-of-key-accuracy-improvements">computer vision recipes</a>) as well as the <code>effnetb2_transforms</code> to transform our training images.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[65]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-65">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create Food101 training data transforms (only perform data augmentation on the training images)</span>
<span class="n">food101_train_transforms</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">TrivialAugmentWide</span><span class="p">(),</span>
    <span class="n">effnetb2_transforms</span><span class="p">,</span>
<span class="p">])</span>
</pre></div>
<div id="cell-65" class="clipboard-copy-txt"># Create Food101 training data transforms (only perform data augmentation on the training images)
food101_train_transforms = torchvision.transforms.Compose([
    torchvision.transforms.TrivialAugmentWide(),
    effnetb2_transforms,
])</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Epic!</p>
<p>Now let's compare <code>food101_train_transforms</code> (for the training data) and <code>effnetb2_transforms</code> (for the testing/inference data).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[66]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-66">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training transforms:</span><span class="se">\n</span><span class="si">{</span><span class="n">food101_train_transforms</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Testing transforms:</span><span class="se">\n</span><span class="si">{</span><span class="n">effnetb2_transforms</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-66" class="clipboard-copy-txt">print(f"Training transforms:\n{food101_train_transforms}\n") 
print(f"Testing transforms:\n{effnetb2_transforms}")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Training transforms:
Compose(
    TrivialAugmentWide(num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)
    ImageClassification(
    crop_size=[288]
    resize_size=[288]
    mean=[0.485, 0.456, 0.406]
    std=[0.229, 0.224, 0.225]
    interpolation=InterpolationMode.BICUBIC
)
)

Testing transforms:
ImageClassification(
    crop_size=[288]
    resize_size=[288]
    mean=[0.485, 0.456, 0.406]
    std=[0.229, 0.224, 0.225]
    interpolation=InterpolationMode.BICUBIC
)
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="102-getting-data-for-foodvision-big">10.2 Getting data for FoodVision Big<a class="anchor-link" href="#102-getting-data-for-foodvision-big">&#182;</a></h3><p>For FoodVision Mini, we made our own <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb">custom data splits</a> of the entire Food101 dataset.</p>
<p>To get the whole Food101 dataset, we can use <a href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html"><code>torchvision.datasets.Food101()</code></a>.</p>
<p>We'll first setup a path to directory <code>data/</code> to store the images.</p>
<p>Then we'll download and transform the training and testing dataset splits using <code>food101_train_transforms</code> and <code>effnetb2_transforms</code> to transform each dataset respectively.</p>
<blockquote>
<p><strong>Note:</strong> If you're using Google Colab, the cell below will take ~3-5 minutes to fully run and download the Food101 images from PyTorch.</p>
<p>This is because there is over 100,000 images being downloaded (101 classes x 1000 images per class). If you restart your Google Colab runtime and come back to this cell, the images will have to redownload. Alternatively, if you're running this notebook locally, the images will be cached and stored in the directory specified by the <code>root</code> parameter of <code>torchvision.datasets.Food101()</code>.</p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[67]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-67">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="c1"># Setup data directory</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>

<span class="c1"># Get training data (~750 images x 101 food classes)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Food101</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="c1"># path to download data to</span>
                              <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="c1"># dataset split to get</span>
                              <span class="n">transform</span><span class="o">=</span><span class="n">food101_train_transforms</span><span class="p">,</span> <span class="c1"># perform data augmentation on training data</span>
                              <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># want to download?</span>

<span class="c1"># Get testing data (~250 images x 101 food classes)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Food101</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>
                             <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span>
                             <span class="n">transform</span><span class="o">=</span><span class="n">effnetb2_transforms</span><span class="p">,</span> <span class="c1"># perform normal EffNetB2 transforms on test data</span>
                             <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<div id="cell-67" class="clipboard-copy-txt">from torchvision import datasets

# Setup data directory
from pathlib import Path
data_dir = Path("data")

# Get training data (~750 images x 101 food classes)
train_data = datasets.Food101(root=data_dir, # path to download data to
                              split="train", # dataset split to get
                              transform=food101_train_transforms, # perform data augmentation on training data
                              download=True) # want to download?

# Get testing data (~250 images x 101 food classes)
test_data = datasets.Food101(root=data_dir,
                             split="test",
                             transform=effnetb2_transforms, # perform normal EffNetB2 transforms on test data
                             download=True)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Data downloaded!</p>
<p>Now we can get a list of all the class names using <code>train_data.classes</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[68]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-68">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Get Food101 class names</span>
<span class="n">food101_class_names</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">classes</span>

<span class="c1"># View the first 10</span>
<span class="n">food101_class_names</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
<div id="cell-68" class="clipboard-copy-txt"># Get Food101 class names
food101_class_names = train_data.classes

# View the first 10
food101_class_names[:10]</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[68]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[&#39;apple_pie&#39;,
 &#39;baby_back_ribs&#39;,
 &#39;baklava&#39;,
 &#39;beef_carpaccio&#39;,
 &#39;beef_tartare&#39;,
 &#39;beet_salad&#39;,
 &#39;beignets&#39;,
 &#39;bibimbap&#39;,
 &#39;bread_pudding&#39;,
 &#39;breakfast_burrito&#39;]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Ho ho! Those are some delicious sounding foods (although I've never heard of &quot;beignets&quot;... update: after a quick Google search, beignets also look delicious).</p>
<p>You can see a full list of the Food101 class names on the course GitHub under <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names.txt"><code>extras/food101_class_names.txt</code></a>.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="103-creating-a-subset-of-the-food101-dataset-for-faster-experimenting">10.3 Creating a subset of the Food101 dataset for faster experimenting<a class="anchor-link" href="#103-creating-a-subset-of-the-food101-dataset-for-faster-experimenting">&#182;</a></h3><p>This is optional.</p>
<p>We don't <em>need</em> to create another subset of the Food101 dataset, we could train and evaluate a model across the whole 101,000 images.</p>
<p>But to keep training fast, let's create a 20% split of the training and test datasets.</p>
<p>Our goal will be to see if we can beat the original <a href="https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/">Food101 paper's</a> best results with only 20% of the data.</p>
<p>To breakdown the datasets we've used/will use:</p>
<table>
<thead>
<tr>
  <th><strong>Notebook(s)</strong></th>
  <th><strong>Project name</strong></th>
  <th><strong>Dataset</strong></th>
  <th><strong>Number of classes</strong></th>
  <th><strong>Training images</strong></th>
  <th><strong>Testing images</strong></th>
</tr>
</thead>
<tbody>
<tr>
  <td>04, 05, 06, 07, 08</td>
  <td>FoodVision Mini (10% data)</td>
  <td>Food101 custom split</td>
  <td>3 (pizza, steak, sushi)</td>
  <td>225</td>
  <td>75</td>
</tr>
<tr>
  <td>07, 08, 09</td>
  <td>FoodVision Mini (20% data)</td>
  <td>Food101 custom split</td>
  <td>3 (pizza, steak, sushi)</td>
  <td>450</td>
  <td>150</td>
</tr>
<tr>
  <td><strong>09 (this one)</strong></td>
  <td>FoodVision Big (20% data)</td>
  <td>Food101 custom split</td>
  <td>101 (all Food101 classes)</td>
  <td>15150</td>
  <td>5050</td>
</tr>
<tr>
  <td>Extension</td>
  <td>FoodVision Big</td>
  <td>Food101 all data</td>
  <td>101</td>
  <td>75750</td>
  <td>25250</td>
</tr>
</tbody>
</table>
<p>Can you see the trend?</p>
<p>Just like our model size slowly increased overtime, so has the size of the dataset we've been using for experiments.</p>
<blockquote>
<p><strong>Note:</strong> To truly beat the original Food101 paper's results with 20% of the data, we'd have to train a model on 20% of the training data and then evaluate our model on the <em>whole</em> test set rather than the split we created. I'll leave this as an extension exercise for you to try. I'd also encourage you to try training a model on the entire Food101 training dataset.</p>
</blockquote>
<p>To make our FoodVision Big (20% data) split, let's create a function called <code>split_dataset()</code> to split a given dataset into certain proportions.</p>
<p>We can use <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split"><code>torch.utils.data.random_split()</code></a> to create splits of given sizes using the <code>lengths</code> parameter.</p>
<p>The <code>lengths</code> parameter accepts a list of desired split lengths where the total of the list must equal the overall length of the dataset.</p>
<p>For example, with a dataset of size 100, you could pass in <code>lengths=[20, 80]</code> to receive a 20% and 80% split.</p>
<p>We'll want our function to return two splits, one with the target length (e.g. 20% of the training data) and the other with the remaining length (e.g. the remaining 80% of the training data).</p>
<p>Finally, we'll set <code>generator</code> parameter to a <code>torch.manual_seed()</code> value for reproducibility.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[69]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-69">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="k">def</span> <span class="nf">split_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="n">split_size</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Randomly splits a given dataset into two proportions based on split_size and seed.</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset (torchvision.datasets): A PyTorch Dataset, typically one from torchvision.datasets.</span>
<span class="sd">        split_size (float, optional): How much of the dataset should be split? </span>
<span class="sd">            E.g. split_size=0.2 means there will be a 20% split and an 80% split. Defaults to 0.2.</span>
<span class="sd">        seed (int, optional): Seed for random generator. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: (random_split_1, random_split_2) where random_split_1 is of size split_size*len(dataset) and </span>
<span class="sd">            random_split_2 is of size (1-split_size)*len(dataset).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create split lengths based on original dataset length</span>
    <span class="n">length_1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">split_size</span><span class="p">)</span> <span class="c1"># desired length</span>
    <span class="n">length_2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">length_1</span> <span class="c1"># remaining length</span>
        
    <span class="c1"># Print out info</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Splitting dataset of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> into splits of size: </span><span class="si">{</span><span class="n">length_1</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">split_size</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">%), </span><span class="si">{</span><span class="n">length_2</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">int</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">split_size</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>
    
    <span class="c1"># Create splits with given random seed</span>
    <span class="n">random_split_1</span><span class="p">,</span> <span class="n">random_split_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                                                                   <span class="n">lengths</span><span class="o">=</span><span class="p">[</span><span class="n">length_1</span><span class="p">,</span> <span class="n">length_2</span><span class="p">],</span>
                                                                   <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">))</span> <span class="c1"># set the random seed for reproducible splits</span>
    <span class="k">return</span> <span class="n">random_split_1</span><span class="p">,</span> <span class="n">random_split_2</span>
</pre></div>
<div id="cell-69" class="clipboard-copy-txt">def split_dataset(dataset:torchvision.datasets, split_size:float=0.2, seed:int=42):
    """Randomly splits a given dataset into two proportions based on split_size and seed.

    Args:
        dataset (torchvision.datasets): A PyTorch Dataset, typically one from torchvision.datasets.
        split_size (float, optional): How much of the dataset should be split? 
            E.g. split_size=0.2 means there will be a 20% split and an 80% split. Defaults to 0.2.
        seed (int, optional): Seed for random generator. Defaults to 42.

    Returns:
        tuple: (random_split_1, random_split_2) where random_split_1 is of size split_size*len(dataset) and 
            random_split_2 is of size (1-split_size)*len(dataset).
    """
    # Create split lengths based on original dataset length
    length_1 = int(len(dataset) * split_size) # desired length
    length_2 = len(dataset) - length_1 # remaining length
        
    # Print out info
    print(f"[INFO] Splitting dataset of length {len(dataset)} into splits of size: {length_1} ({int(split_size*100)}%), {length_2} ({int((1-split_size)*100)}%)")
    
    # Create splits with given random seed
    random_split_1, random_split_2 = torch.utils.data.random_split(dataset, 
                                                                   lengths=[length_1, length_2],
                                                                   generator=torch.manual_seed(seed)) # set the random seed for reproducible splits
    return random_split_1, random_split_2</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Dataset split function created!</p>
<p>Now let's test it out by creating a 20% training and testing dataset split of Food101.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[70]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-70">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create training 20% split of Food101</span>
<span class="n">train_data_food101_20_percent</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                                                 <span class="n">split_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Create testing 20% split of Food101</span>
<span class="n">test_data_food101_20_percent</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                                                <span class="n">split_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">train_data_food101_20_percent</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data_food101_20_percent</span><span class="p">)</span>
</pre></div>
<div id="cell-70" class="clipboard-copy-txt"># Create training 20% split of Food101
train_data_food101_20_percent, _ = split_dataset(dataset=train_data,
                                                 split_size=0.2)

# Create testing 20% split of Food101
test_data_food101_20_percent, _ = split_dataset(dataset=test_data,
                                                split_size=0.2)

len(train_data_food101_20_percent), len(test_data_food101_20_percent)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Splitting dataset of length 75750 into splits of size: 15150 (20%), 60600 (80%)
[INFO] Splitting dataset of length 25250 into splits of size: 5050 (20%), 20200 (80%)
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[70]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>(15150, 5050)</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Excellent!</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="104-turning-our-food101-datasets-into-dataloaders">10.4 Turning our Food101 datasets into <code>DataLoader</code>s<a class="anchor-link" href="#104-turning-our-food101-datasets-into-dataloaders">&#182;</a></h3><p>Now let's turn our Food101 20% dataset splits into <code>DataLoader</code>'s using <code>torch.utils.data.DataLoader()</code>.</p>
<p>We'll set <code>shuffle=True</code> for the training data only and the batch size to <code>32</code> for both datasets.</p>
<p>And we'll set <code>num_workers</code> to <code>4</code> if the CPU count is available or <code>2</code> if it's not (though the value of <code>num_workers</code> is very experimental and will depend on the hardware you're using, there's an <a href="https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813">active discussion thread about this on the PyTorch forums</a>).</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[71]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-71">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">4</span> <span class="k">else</span> <span class="mi">4</span> <span class="c1"># this value is very experimental and will depend on the hardware you have available, Google Colab generally provides 2x CPUs</span>

<span class="c1"># Create Food101 20 percent training DataLoader</span>
<span class="n">train_dataloader_food101_20_percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data_food101_20_percent</span><span class="p">,</span>
                                                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                  <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
<span class="c1"># Create Food101 20 percent testing DataLoader</span>
<span class="n">test_dataloader_food101_20_percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data_food101_20_percent</span><span class="p">,</span>
                                                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                                 <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
</pre></div>
<div id="cell-71" class="clipboard-copy-txt">import os
import torch

BATCH_SIZE = 32
NUM_WORKERS = 2 if os.cpu_count() <= 4 else 4 # this value is very experimental and will depend on the hardware you have available, Google Colab generally provides 2x CPUs

# Create Food101 20 percent training DataLoader
train_dataloader_food101_20_percent = torch.utils.data.DataLoader(train_data_food101_20_percent,
                                                                  batch_size=BATCH_SIZE,
                                                                  shuffle=True,
                                                                  num_workers=NUM_WORKERS)
# Create Food101 20 percent testing DataLoader
test_dataloader_food101_20_percent = torch.utils.data.DataLoader(test_data_food101_20_percent,
                                                                 batch_size=BATCH_SIZE,
                                                                 shuffle=False,
                                                                 num_workers=NUM_WORKERS)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="105-training-foodvision-big-model">10.5 Training FoodVision Big model<a class="anchor-link" href="#105-training-foodvision-big-model">&#182;</a></h3><p>FoodVision Big model and <code>DataLoader</code>s ready!</p>
<p>Time for training.</p>
<p>We'll create an optimizer using <code>torch.optim.Adam()</code> and a learning rate of <code>1e-3</code>.</p>
<p>And because we've got so many classes, we'll also setup a loss function using <code>torch.nn.CrossEntropyLoss()</code> with <code>label_smoothing=0.1</code>, inline with <a href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#label-smoothing"><code>torchvision</code>'s state-of-the-art training recipe</a>.</p>
<p>What's <a href="https://paperswithcode.com/method/label-smoothing"><strong>label smoothing</strong></a>?</p>
<p>Label smoothing is a regularization technique (regularization is another word to describe the process of <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#81-how-to-deal-with-overfitting">preventing overfitting</a>) that reduces the value a model gives to anyone label and spreads it across the other labels.</p>
<p>In essence, rather than a model getting <em>too confident</em> on a single label, label smoothing gives a non-zero value to other labels to help aid in generalization.</p>
<p>For example, if a model <em>without</em> label smoothing had the following outputs for 5 classes:</p>
<pre><code>[0, 0, 0.99, 0.01, 0]
</code></pre>
<p>A model <em>with</em> label smoothing may have the following outputs:</p>
<pre><code>[0.01, 0.01, 0.96, 0.01, 0.01]
</code></pre>
<p>The model is still confident on its prediction of class 3 but giving small values to the other labels forces the model to at least consider other options.</p>
<p>Finally, to keep things quick, we'll train our model for five epochs using the <code>engine.train()</code> function we created in <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them">05. PyTorch Going Modular section 4</a> with the goal of beating the original Food101 paper's result of 56.4% accuracy on the test set.</p>
<p>Let's train our biggest model yet!</p>
<blockquote>
<p><strong>Note:</strong> Running the cell below will take ~15-20 minutes to run on Google Colab. This is because it's training the biggest model with the largest amount of data we've used so far (15,150 training images, 5050 testing images). And it's a reason we decided to split 20% of the full Food101 dataset off before (so training didn't take over an hour).</p>
</blockquote>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[72]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-72">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">engine</span>

<span class="c1"># Setup optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">effnetb2_food101</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                             <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># Setup loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">label_smoothing</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># throw in a little label smoothing because so many classes</span>

<span class="c1"># Want to beat original Food101 paper with 20% of data, need 56.4%+ acc on test dataset</span>
<span class="n">set_seeds</span><span class="p">()</span>    
<span class="n">effnetb2_food101_results</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2_food101</span><span class="p">,</span>
                                        <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader_food101_20_percent</span><span class="p">,</span>
                                        <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader_food101_20_percent</span><span class="p">,</span>
                                        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                                        <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
                                        <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
<div id="cell-72" class="clipboard-copy-txt">from going_modular.going_modular import engine

# Setup optimizer
optimizer = torch.optim.Adam(params=effnetb2_food101.parameters(),
                             lr=1e-3)

# Setup loss function
loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1) # throw in a little label smoothing because so many classes

# Want to beat original Food101 paper with 20% of data, need 56.4%+ acc on test dataset
set_seeds()    
effnetb2_food101_results = engine.train(model=effnetb2_food101,
                                        train_dataloader=train_dataloader_food101_20_percent,
                                        test_dataloader=test_dataloader_food101_20_percent,
                                        optimizer=optimizer,
                                        loss_fn=loss_fn,
                                        epochs=5,
                                        device=device)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>  0%|          | 0/5 [00:00&lt;?, ?it/s]</pre>
</div>

</div>
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Epoch: 1 | train_loss: 3.6317 | train_acc: 0.2869 | test_loss: 2.7670 | test_acc: 0.4937
Epoch: 2 | train_loss: 2.8615 | train_acc: 0.4388 | test_loss: 2.4653 | test_acc: 0.5387
Epoch: 3 | train_loss: 2.6585 | train_acc: 0.4844 | test_loss: 2.3547 | test_acc: 0.5649
Epoch: 4 | train_loss: 2.5494 | train_acc: 0.5116 | test_loss: 2.3038 | test_acc: 0.5755
Epoch: 5 | train_loss: 2.5006 | train_acc: 0.5239 | test_loss: 2.2805 | test_acc: 0.5810
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Woohoo!!!!</p>
<p>Looks like we beat the original Food101 paper's results of 56.4% accuracy with only 20% of the training data (though we only evaluated on 20% of the testing data too, to fully replicate the results, we could evaluate on 100% of the testing data).</p>
<p>That's the power of transfer learning!</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="106-inspecting-loss-curves-of-foodvision-big-model">10.6 Inspecting loss curves of FoodVision Big model<a class="anchor-link" href="#106-inspecting-loss-curves-of-foodvision-big-model">&#182;</a></h3><p>Let's make our FoodVision Big loss curves visual.</p>
<p>We can do so with the <code>plot_loss_curves()</code> function from <code>helper_functions.py</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[73]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-73">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">plot_loss_curves</span>

<span class="c1"># Check out the loss curves for FoodVision Big</span>
<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">effnetb2_food101_results</span><span class="p">)</span>
</pre></div>
<div id="cell-73" class="clipboard-copy-txt">from helper_functions import plot_loss_curves

# Check out the loss curves for FoodVision Big
plot_loss_curves(effnetb2_food101_results)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedImage jp-OutputArea-output ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2oAAAG5CAYAAAD/HsejAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAB+3ElEQVR4nOzdd3xUVeL+8c9J74F0SAgJvfcOUkQRsCCi2BWxrHV1V/3p162uu67uqqu7WJZV7F1ELBRROiJVOkhLgNBbICRA2vn9cQcIMUCAJHcmed6v17xIZu5MntyEzDxzzj3XWGsRERERERER7+HndgARERERERE5mYqaiIiIiIiIl1FRExERERER8TIqaiIiIiIiIl5GRU1ERERERMTLqKiJiIiIiIh4GRU1ERERERERL6OiJnIejDGZxpiL3M4hIiJS2Ywx040x+40xwW5nEakJVNRERERE5LSMMWnABYAFrqjCrxtQVV9LxNuoqIlUMGNMsDHmRWPMNs/lxWPvPhpj4owxXxtjso0x+4wxs4wxfp7bHjPGbDXG5BhjfjbG9Hf3OxERETnuFuBH4C3g1mNXGmPqGWM+N8bsNsbsNcaMKnHbncaY1Z7ntVXGmA6e660xplGJ7d4yxvzV83FfY0yW5zlxB/CmMaa257lzt2dE72tjTEqJ+8cYY970POfuN8Z84bl+hTHm8hLbBRpj9hhj2lXSPhKpUCpqIhXvd0A3oB3QFugC/N5z28NAFhAPJAJPANYY0xS4H+hsrY0ELgEyqzS1iIjIqd0CvO+5XGKMSTTG+ANfA5uANCAZ+AjAGHMN8GfP/aJwRuH2lvNrJQExQH3gLpzXq296Pk8FDgOjSmz/LhAGtAQSgH95rn8HuKnEdoOB7dbaJeXMIeIqDSeLVLwbgQestbsAjDFPAv8F/gAUAHWA+tba9cAszzZFQDDQwhiz21qb6UZwERGR0owxvXBK0ifW2j3GmA3ADTgjbHWBR621hZ7NZ3v+vQP4h7V2gefz9WfxJYuBP1lrj3o+PwyMLZHnb8A0z8d1gEFArLV2v2eTGZ5/3wP+YIyJstYeBG7GKXUiPkEjaiIVry7Ou4vHbPJcB/BPnCerb40xG40xjwN4SttDOO8+7jLGfGSMqYuIiIj7bgW+tdbu8Xz+gee6esCmEiWtpHrAhnP8eruttUeOfWKMCTPG/NcYs8kYcxCYCdTyjOjVA/aVKGnHWWu3AXOAYcaYWjiF7v1zzCRS5VTURCreNpx3Ho9J9VyHtTbHWvuwtbYBcDnw22PHollrP7DWHnvX0gLPVm1sERGRkxljQoHhQB9jzA7PcWO/wZnavxNIPcWCH1uAhqd42DycqYrHJJW63Zb6/GGgKdDVWhsF9D4Wz/N1YjxFrCxv40x/vAaYa63deortRLyOiprI+Qs0xoQcuwAfAr83xsQbY+KAP+JMv8AYc5kxppExxgAHgSKgyBjT1BhzoWfRkSM40zyK3Pl2REREjrsS5/moBc6x1+2A5jhT968EtgPPGGPCPc+DPT33ex14xBjT0TgaGWOOvYm5BLjBGONvjBkI9DlDhkic58VsY0wM8KdjN1hrtwMTgVc8i44EGmN6l7jvF0AH4EGcY9ZEfIaKmsj5m4DzBHLsEgIsBJYBy4HFwF892zYGvgMOAXOBV6y103GOT3sG2APswDkY+okq+w5ERETKdivwprV2s7V2x7ELzmIe1+PMDmkEbMZZLOtaAGvtp8DfcKZJ5uAUphjPYz7ouV82znHdX5whw4tAKM5z5I/ApFK334xzDPgaYBfOoQR4chw7vi0d+Lz837aI+4y1pUeXRURERESqB2PMH4Em1tqbzrixiBfRqo8iIiIiUi15pkrejjPqJuJTNPVRRERERKodY8ydOIuNTLTWznQ7j8jZ0tRHERERERERL6MRNRERERERES/j2jFqcXFxNi0tza0vLyIiVWjRokV7rLXxbufwFXqOFBGpGU73/OhaUUtLS2PhwoVufXkREalCxphNbmfwJXqOFBGpGU73/KipjyIiIiIiIl5GRU1ERERERMTLqKiJiIiIiIh4GZ3wWkRqvIKCArKysjhy5IjbUXxeSEgIKSkpBAYGuh2l2tHvqW/R/wUROV8qaiJS42VlZREZGUlaWhrGGLfj+CxrLXv37iUrK4v09HS341Q7+j31Hfq/ICIVQVMfRaTGO3LkCLGxsXrxe56MMcTGxmrEp5Lo99R36P+CiFQEFTUREdCL3wqi/Vi5tH99h35WInK+VNRERERERES8jIqaiIiIiIiIl1FRExFxWXZ2Nq+88spZ32/w4MFkZ2ef9f1GjBjBZ599dtb3k5qtqn9PRURqOhU1ERGXneoFcFFR0WnvN2HCBGrVqlVJqUROVl1/T8+UX0TELVqeX0SkhCe/WsmqbQcr9DFb1I3iT5e3POXtjz/+OBs2bKBdu3YEBgYSERFBnTp1WLJkCatWreLKK69ky5YtHDlyhAcffJC77roLgLS0NBYuXMihQ4cYNGgQvXr14ocffiA5OZnx48cTGhp6xmzff/89jzzyCIWFhXTu3JlXX32V4OBgHn/8cb788ksCAgIYMGAAzz33HJ9++ilPPvkk/v7+REdHM3PmzArbR3J2asLv6f/+9z9Gjx5Nfn4+jRo14t133yUsLIydO3dy9913s3HjRgBeffVVevTowTvvvMNzzz2HMYY2bdrw7rvvMmLECC677DKuvvpqACIiIjh06BDTp0/nySefLFf+SZMm8cQTT1BUVERcXBxTpkyhadOm/PDDD8THx1NcXEyTJk348ccfiYuLq8gfiYjUcCpqIiIue+aZZ1ixYgVLlixh+vTpXHrppaxYseL4+ZfGjBlDTEwMhw8fpnPnzgwbNozY2NiTHmPdunV8+OGH/O9//2P48OGMHTuWm2666bRf98iRI4wYMYLvv/+eJk2acMstt/Dqq69yyy23MG7cONasWYMx5vi0tb/85S9MnjyZ5ORkTWWrgar69/Sqq67izjvvBOD3v/89b7zxBg888AC//vWv6dOnD+PGjaOoqIhDhw6xcuVK/va3vzFnzhzi4uLYt2/fGb+f+fPnnzF/cXExd955JzNnziQ9PZ19+/bh5+fHTTfdxPvvv89DDz3Ed999R9u2bVXSRKTCqaiJiJRwuhGFqtKlS5eTTpL773//m3HjxgGwZcsW1q1b94sXwOnp6bRr1w6Ajh07kpmZecav8/PPP5Oenk6TJk0AuPXWW3n55Ze5//77CQkJ4Y477uDSSy/lsssuA6Bnz56MGDGC4cOHc9VVV1XAdyrnqib8nq5YsYLf//73ZGdnc+jQIS655BIApk6dyjvvvANwfHT3nXfe4eqrrz5elmJiYiok/+7du+ndu/fx7Y497siRIxkyZAgPPfQQY8aM4bbbbjvj1xMROVs+e4yatZZFm/ZRXGzdjiIiUqHCw8OPfzx9+nS+++475s6dy9KlS2nfvn2ZJ9ENDg4+/rG/vz+FhYVn/DrWlv33MyAggPnz5zNs2DC++OILBg4cCMBrr73GX//6V7Zs2UK7du3Yu3fv2X5rUo1U9u/piBEjGDVqFMuXL+dPf/rTaU8eba0t87xlAQEBFBcXH98mPz//rPKf6nHr1atHYmIiU6dOZd68eQwaNOiU2USkmikuhrx9sGc97N9UqV/KZ0fUvl21k1+9u4i3R3ahT5N4t+OIiJyzyMhIcnJyyrztwIED1K5dm7CwMNasWcOPP/5YYV+3WbNmZGZmsn79+uPHAPXp04dDhw6Rl5fH4MGD6datG40aNQJgw4YNdO3ala5du/LVV1+xZcuWX4yYSPVV1b+nOTk51KlTh4KCAt5//32Sk5MB6N+/P6+++ioPPfQQRUVF5Obm0r9/f4YOHcpvfvMbYmNj2bdvHzExMaSlpbFo0SKGDx/O+PHjKSgoOKv83bt357777iMjI+P41Mdjo2p33HEHN910EzfffDP+/v7n/f2KiAuKCpzSdXif82/e3lIf7y9x+17n4yPZYJ03gGg1DK4eU2nxfLao9WuaQHxkMGNmZ6ioiYhPi42NpWfPnrRq1YrQ0FASExOP3zZw4EBee+012rRpQ9OmTenWrVuFfd2QkBDefPNNrrnmmuOLidx9993s27ePIUOGHB9R+Ne//gXAo48+yrp167DW0r9/f9q2bVthWcT7VfXv6VNPPUXXrl2pX78+rVu3Pl4SX3rpJe666y7eeOMN/P39efXVV+nevTu/+93v6NOnD/7+/rRv35633nqLO++8kyFDhtClSxf69+9/0ihaSafKHx8fz+jRo7nqqqsoLi4mISGBKVOmAHDFFVdw2223adqjiLfIzztF4SpRxEoWrsP74ehpFmUKCIGwWAiNgbDakNTa83HMievjGlXqt2RONfWlsnXq1MkuXLjwvB7jP9+v4/kpa/nut71plBBZQclEpKZZvXo1zZs3dztGtVHW/jTGLLLWdnIpks8p6zlSv6feZeHChfzmN79h1qxZp9xGPzORc2CtU6Dy9kLe/rLL1/HCtf/Ex4Wnnh5NcBSE1nYKVlhMqcJV++Tydez2oLAq+XZP9/zosyNqADd0TeU/09YzZk4mTw9t7XYcERERqQGeeeYZXn31Vd5//323o4h4t+KiUtMHyzG98PB+KD7F8avGD0JqnShc0SlQp00Z5atE4QqtDQFBVfptVxSfLmqxEcEMbZfM54uzeHRAU2qH++YPQUSkMtx3333MmTPnpOsefPBBTdUSr+KLv6ePP/44jz/+uNsxRKpW4dEypg+eYXrhkQPAKWbv+QWePMIV1+T0hSssxilpfj67FuJZ8+miBnBbrzQ+XriFDxds5t6+lTtPVETEl7z88stuRxA5I/2eilQxayE/95fHa5U52rXvxPTC/EOnfszAcE+h8kwvrJVaRuGqfXL5CoqAMlZVlRPOWNSMMSHATCDYs/1n1to/lbFdX+BFIBDYY63tU5FBT6VZUhS9GsXxzg+buPOCBgT615yWLSIiIiJynLWQsx32boB9G2HfBmcJ+ZNGwPZCUf6pHyMk2lOmYiEiEeKbe0a+ap96tCswpOq+xxqkPCNqR4ELrbWHjDGBwGxjzERr7fG1d40xtYBXgIHW2s3GmITKiVu2kb3SGPnWQiYs386QdslV+aVFRERERKqOtXBop6eMbShRyjyXgrwT2/oHOaNb4fFQOw2SO5x6emFYrDO10N/nJ9xVG2f8SVhnWchjY52BnkvpyaY3AJ9bazd77rOrIkOeSd8mCaTHhTNmdgZXtK1b5skpRURERER8grWQu7tUGTtWyDJOnoboF+iUsJgGkN7b+Te2IcQ0dBbb8NN5/nxVuSqzMcYfWAQ0Al621s4rtUkTINAYMx2IBF6y1r5TxuPcBdwFkJqaeh6xT+bnZ7itZxp/HL+SxZuz6Vi/doU9toiIiEB2djYffPAB995771nf98UXX+Suu+4iLKxqlrsW8QnWQu6eE1MUTyplGZBf4gTzfgFQq75TwOr38pSxBp4yVk+jYNVUuX6q1toioJ1niuM4Y0wra+2KUo/TEegPhAJzjTE/WmvXlnqc0cBocM4RUwH5jxvWIYXnJv/MmDkZKmoi4lMq+wVwWloaCxcuJC4u7nxiSg2XnZ3NK6+8cs6/pzfddJNXFLXCwkICAvSiVqqItc6xYcdGw0pPVyx5wmXj70xTjG0Iqd09o2INnEutVPAPdO/7EFec1V8qa222Z9RsIFCyqGXhLCCSC+QaY2YCbYG1v3yUyhEeHMD1XVJ5fXYGW7MPk1wrtKq+tIjIeakuL4Clenv88cfZsGED7dq14+KLLyYhIYFPPvmEo0ePMnToUJ588klyc3MZPnw4WVlZFBUV8Yc//IGdO3eybds2+vXrR1xcHNOmTSvz8e+55x4WLFjA4cOHufrqq3nyyScBWLBgAQ8++CC5ubkEBwfz/fffExYWxmOPPcbkyZMxxnDnnXfywAMPnPSmxMKFC3nkkUeYPn06f/7zn9m2bRuZmZnExcXx9NNPc/PNN5ObmwvAqFGj6NGjBwD/+Mc/ePfdd/Hz82PQoEHceeedXHPNNSxevBiAdevWcd1117Fo0aIq2OviM/L2lShipUbIjhw4sZ3xc0bAYhtCSucTUxRjG6qMyS+UZ9XHeKDAU9JCgYuAZ0ttNh4YZYwJAIKArsC/KjrsmdzSI43XZ2fwzg+Z/N/g5lX95UWkOpj4OOxYXrGPmdQaBj1zypsr+wVwSS+88AJjxowB4I477uChhx4q87GvvfZaHn/8cb788ksCAgIYMGAAzz33XIXtEjlPLvyePvPMM6xYsYIlS5bw7bff8tlnnzF//nystVxxxRXMnDmT3bt3U7duXb755hsADhw4QHR0NC+88ALTpk077aju3/72N2JiYigqKqJ///4sW7aMZs2ace211/Lxxx/TuXNnDh48SGhoKKNHjyYjI4OffvqJgIAA9u3bd8Zvb9GiRcyePZvQ0FDy8vKYMmUKISEhrFu3juuvv56FCxcyceJEvvjiC+bNm0dYWBj79u0jJiaG6OholixZQrt27XjzzTcZMWLEWe9eqQYOZ3sK2MZSi3hscJa3P85ArXpOAWt1dakyVt9nT74sVa88I2p1gLc9x6n5AZ9Ya782xtwNYK19zVq72hgzCVgGFAOvl5oaWSWSa4UysGUSH87fzK/7NyY8WFMbRMT7VfYL4GMWLVrEm2++ybx587DW0rVrV/r06cPGjRt/8dj79u1j3LhxrFmzBmMM2dnZlbkLxMd8++23fPvtt7Rv3x6AQ4cOsW7dOi644AIeeeQRHnvsMS677DIuuOCCcj/mJ598wujRoyksLGT79u2sWrUKYwx16tShc+fOAERFRQHw3Xffcffddx+fwhgTE3PGx7/iiisIDXVm2xQUFHD//fezZMkS/P39Wbt27fHHve22246PUB973DvuuIM333yTF154gY8//pj58+eX+/sSH3Pk4MklrOQiHnl7S2xonIU6YhpAy6GeKYqeMlY7DQKC3foOpBopz6qPy4D2ZVz/WqnP/wn8s+KinZuRvdL5Zvl2Pl+cxc3d09yOIyK+5jQjClWhMl4AHzN79myGDh1KeHg4AFdddRWzZs1i4MCBv3jswsJCQkJCuOOOO7j00ku57LLLKvT7lPPk8u+ptZb/+7//41e/+tUvblu0aBETJkzg//7v/xgwYAB//OMfz/h4GRkZPPfccyxYsIDatWszYsQIjhw5grW2zJWcT3V9QEAAxcXFABw5cuSk24793gP861//IjExkaVLl1JcXExISMhpH3fYsGE8+eSTXHjhhXTs2JHY2Ngzfk/ixY7mlJqiWGKELG/PydtGJTslrPnlJ4pYTAOona5zh0mlq3ZDTh1Sa9G2Xi3GzMnkxq718fPTUv0i4jsq+gVw6ccuS5MmTcp87Pnz5/P999/z0UcfMWrUKKZOnXpO35NUD5GRkeTkOKvQXXLJJfzhD3/gxhtvJCIigq1btxIYGEhhYSExMTHcdNNNRERE8NZbb51031ON/B48eJDw8HCio6PZuXMnEydOpG/fvjRr1oxt27axYMECOnfuTE5ODqGhoQwYMIDXXnuNvn37Hp/6GBMTQ1paGosWLWLQoEGMHTv2lN/LgQMHSElJwc/Pj7fffpuioiIABgwYwF/+8hduuOGGk6Y+hoSEcMkll3DPPffwxhtvVOyOlcpx9NCJIrZv48llLLfUWaQi6zrlq9ngEmXMMzIWpON/xT3VrqgZYxjZM40HP1rC9LW7uLBZotuRREROqzJfAJfUu3dvRowYweOPP461lnHjxvHuu++ybdu2Xzz2oUOHyMvLY/DgwXTr1o1GjRpV5i4QHxAbG0vPnj1p1aoVgwYN4oYbbqB79+4ARERE8N5777F+/XoeffRR/Pz8CAwM5NVXXwXgrrvuYtCgQdSpU6fMYynbtm1L+/btadmyJQ0aNKBnz54ABAUF8fHHH/PAAw9w+PBhQkND+e6777jjjjtYu3Ytbdq0ITAwkDvvvJP777+fP/3pT9x+++08/fTTdO3a9ZTfy7333suwYcP49NNP6dev3/HRtoEDB7JkyRI6depEUFAQgwcP5umnnwbgxhtv5PPPP2fAgAEVul/lPOTnlVq4Y+OJ6YqHdpy8bUSSU8CaDDi5jMWkQ1B42Y8v4jJzqndYK1unTp3swoULK+WxC4qKueDZaTRKiOC9O079h1pEBGD16tU0b+7uAkQ33HADy5YtY9CgQaSkpPD6668Dp38B3KlTJ/7zn//w8ssvn/IFMJy8PH9Zi4lMnjz5F4+dnJzMkCFDjk8/e+SRR7j11lvL9b2UtT+NMYustZ3OYxfVKGU9R3rD72lN9txzz3HgwAGeeuqpct9HP7MKUHDYOafYSSd9znA+ztl28rbhCSUW7mhw4rixmAYQHOFOfpEzON3zY7UsagCvTF/PPyb9zOSHetM0KbLSvo6I+D69mKpYKmrnT0XNuwwdOpQNGzYwderUszofoX5mZ+HgNtj20y/PM3Zw68nbhcWVKmMlzjUWEuVOdpHzcLrnx2o39fGY6zun8u/v1zFmdgbPXt3G7TgiIiICdO3alaNHj5503bvvvkvr1q1dSnRm48aNcztC9XQ4G1aNh+WfQuZswDN4EBbrFK+0C04s3nHs35BoNxOLVKlqW9RqhwdxVYcUPluUxf8b2JTYCC2TKiLVmy++AJaaZ968eW5HEDcVHIF138LyT2DtZCjKh9hG0O8JaNjfGSULre12ShGvUG2LGsDInml8MG8zH8zbzAP9G7sdR0S82KmW5fYl3vAC2K3p9DVFdfg9rSn0f6GE4mLYNAeWfQyrvoSjB5zjyTrfAa2vgbrtQb/XIr9QrYtao4RI+jSJ550fN3FXnwYEB/i7HUlEvFBISAh79+4lNjZWL4LPg7WWvXv3Hj8nlVQs/Z76Dv1f8NixwilnK8Y6x5oFRTjnI2t9DaT3Af9q/TJU5LxV+/8hI3ulc+uY+XyzbDtXdUhxO46IeKGUlBSysrLYvXu321F8XkhICCkp+ltbGfR76ltq7P+F7C3OMWfLP4Vdq8AvABpdBBf/BZoO1nnJRM5CtS9qvRvH0SghgjdmZzC0fbLehRSRXwgMDCQ9Pd3tGCKnpd9T8Vp5+04sCrJpjnNdva5w6fPQYiiEx7qbT8RHVfui5pwAO50nxi1nQeZ+uqTHuB1JRERExLcVHIG1k2DZJ87iIMUFENcELvy9M7WxdprbCUV8XrUvagBD2yfzj8lreGP2RhU1ERERkXNRXOQso7/sE1j9JRw9CBFJ0PVXTjmr01aLgohUoBpR1EKD/LmhSyqvztjA5r15pMZqfrSIiIjIGVkLO5afWBQkZzsERUKLKzyLgvQGPy3WJlIZakRRA7ilexqjZ27k7bmZ/OGyFm7HEREREfFe+zedWBRk9xrwC4TGF0Prp6HpIAgMdTuhSLVXY4paUnQIl7apw8cLtvDQRY2JDAl0O5KIiIiI98jbByvHOeVs81znutTucOkL0HIohOnwEZGqVGOKGsBtPdMZv2Qbny7MYmQvrZwlIiIiNVzBYfh5olPO1k1xFgWJbwYX/sGzKEh9txOK1Fg1qqi1q1eLjvVr89YPmdzaIw1/Px3wKiIiIjVMcRFkzPQsCvIV5OdAZB1nUZA210JSay0KIuIFalRRAxjZM537PljM96t3MqBlkttxRERERCqftbB9qVPOVoyFQzsgOApaDoHWwyGtlxYFEfEyNa6oXdIykeRaoYyZk6GiJiIiItXb/kxY9iks/wT2rHUWBWlyiTOtscklWhRExIvVuKIW4O/HrT3q8/SENazcdoCWdaPdjiQiIl7OGDMQeAnwB1631j5T6va+wHggw3PV59bav3huywRygCKg0FrbqWpSS42VuxdWfu4cd7ZlnnNd/Z7Q7V5oMUSLgoj4iBpX1ACu7ZTKi9+tY8zsTJ4f3tbtOCIi4sWMMf7Ay8DFQBawwBjzpbV2ValNZ1lrLzvFw/Sz1u6pzJxSw+Xnwc8TnHK2/jsoLoT45tD/T9D6aqiV6nZCETlLNbKoRYcFcnXHFD6av4XHBjUlITLE7UgiIuK9ugDrrbUbAYwxHwFDgNJFTaRqFRVCxgynnK3+CvIPQWRdZ+SszXBIbKVFQUR8WI0sauAs1f/O3E28/+NmfnNxE7fjiIiI90oGtpT4PAvoWsZ23Y0xS4FtwCPW2pWe6y3wrTHGAv+11o4u64sYY+4C7gJITdXoh5yCtbDtJ8/JqD+D3F0QHO2c56zNtc4URz8/t1OKSAWosUUtPS6c/s0SeO/HTdzTtyEhgVrpSEREylTWkIQt9flioL619pAxZjDwBdDYc1tPa+02Y0wCMMUYs8ZaO/MXD+gUuNEAnTp1Kv34UtPt23hiUZC968E/CBoPcMpZ4wEQqNlBItVNjS1qACN7pXPj6/P4cuk2hneq53YcERHxTllAySeJFJxRs+OstQdLfDzBGPOKMSbOWrvHWrvNc/0uY8w4nKmUvyhqIr+QuwdWfO6Us6wFznVpF0CPX0OLKyC0trv5RKRS1eii1qNhLM2SIhkzO4NrOqZgNI9bRER+aQHQ2BiTDmwFrgNuKLmBMSYJ2GmttcaYLoAfsNcYEw74WWtzPB8PAP5StfHFp+TnwpoJTjlb/z3YIudYs4uedBYFiU5xO6GIVJEaXdSMMYzsmc7/G7uMuRv30qNhnNuRRETEy1hrC40x9wOTcZbnH2OtXWmMudtz+2vA1cA9xphC4DBwnae0JQLjPG8EBgAfWGsnufKNiPcqKoSN051ytvprKMiFqBTo8YBnUZCWbicUERfU6KIGcEW7ujwzaQ1jZmeoqImISJmstROACaWue63Ex6OAUWXcbyOg88DIL1kLWxc75WzFWMjdDSHRzqhZm+GQ2kOLgojUcDW+qIUE+nNT11T+M209GXtySY8LdzuSiIiIVFd7NzgrNi77BPZtAP9gaHKJZ1GQiyEg2O2EIuIlanxRA7ipe31enbGBt3/I5M9XaHqBiIiIVKBDu04sCrJ1EWAgrRf0+g00vxxCa7mdUES8kIoakBAZwuVt6/LJwi385uImRIcGuh1JREREfNnRQ7DmG6ecbZjmLAqS1BoufgpaDYPoZLcTioiXU1HzGNkznc8Xb+WTBVu4s3cDt+OIiIiIrykqcErZ8k+cklaQB9Gp0PNB57izhOZuJxQRH6Ki5tEqOZou6TG89UMmt/VMI8BfB/CKiIjIGVgLWQs9i4J8Dnl7IKSWc8xZm+FQr5sWBRGRc6KiVsLtvdL51buLmLJqJ4Na13E7joiIiHirPeudcrbsE9ifAQEh0GSgU84aXQwBQW4nFBEfp6JWwkXNE6kXE8obszNU1ERERORk+Xmw+B1Y9hFs+wkwkN4bej/qLAoSEuV2QhGpRlTUSvD3M4zokc5TX69i6ZZs2tar5XYkERER8QY/T4KJj0L2ZkhqAwP+5iwKEqU3dkWkcmjSdCnDO6UQERzAm3My3I4iIiIibsveAh/dCB9eCwGhcOvXcPcs6HG/SpqIVCoVtVIiQwIZ3qkeXy/bzs6DR9yOIyIiIm4oKoA5L8HLXWD999D/T3D3bEi/wO1kIlJDqKiVYUSPNIqs5Z25mW5HERERkaq26Qd47QKY8kdo0BfumwcX/FYLhIhIlVJRK0NqbBgXN0/kg3mbOZxf5HYcERERqQq5e2DcPfDmIMg/BNd9CNd/CLXru51MRGogFbVTGNkrnf15BXyxZKvbUURERKQyFRfDwjfhPx2dJfd7/cYZRWs22O1kIlKDadXHU+iaHkPLulGMmZ3BdZ3rYYxxO5KIiIhUtO1L4evfwtaFUL8XXPo8JDRzO5WIyJlH1IwxIcaY+caYpcaYlcaYJ0+zbWdjTJEx5uqKjVn1jDGM7JnOul2HmLVuj9txREREpCIdOQgTH4fRfWF/Jgz9L4z4WiVNRLxGeaY+HgUutNa2BdoBA40x3UpvZIzxB54FJldoQhdd1rYOcRHBjNFS/SIiItWDtbBiLIzqDPNeg44j4IGF0PY60OwZEfEiZyxq1nHI82mg52LL2PQBYCywq+LiuSs4wJ+bu9Vn+s+7Wb/r0JnvICIiIt5r7wZ47yr4bCREJsId38Nl/4LQ2m4nExH5hXItJmKM8TfGLMEpYVOstfNK3Z4MDAVeO8Pj3GWMWWiMWbh79+5zjFy1buyWSlCAH2/9oFE1ERERn1RwBKY9Da90g6yFMOifcOc0SOnodjIRkVMqV1Gz1hZZa9sBKUAXY0yrUpu8CDxmrT3tWvbW2tHW2k7W2k7x8fHnkrfKxUUEc2W7uoxdtJXsvHy344iIiMjZWP+dU9BmPAvNr4D7F0DXu8DP3+1kIiKndVbL81trs4HpwMBSN3UCPjLGZAJXA68YY648/3jeYWSvdA4XFPHh/C1uRxEREZHyOLgNPrkF3hvmlLJbxsPVb0BkktvJRETKpTyrPsYbY2p5Pg4FLgLWlNzGWpturU2z1qYBnwH3Wmu/qPC0LmmWFEXPRrG8MzeTgqJit+OIiIjIqRQVwg+jnMVC1k6Gfr+He36ABn3dTiYiclbKM6JWB5hmjFkGLMA5Ru1rY8zdxpi7Kzee9xjZM53tB44wacUOt6OIiIhIWTbPg9F94NvfQf0ecO+P0OdRCAh2O5mIyFk74wmvrbXLgPZlXF/mwiHW2hHnH8v79GuaQFpsGG/MzuDytnXdjiMiIiLH5O2D7/4Ei9+BqGQY/i40v1zL7YuITzurY9RqMj8/w20901myJZvFm/e7HUdERESKi2Hxu/CfjvDT+9DjAbhvPrS4QiVNRCqVtZYjBaddR/G8nXFETU64umMKz337M2NmZ9DhBp1zRURExDU7V8LXv4UtP0K9bnDZC5DY0u1UIlLNWGvZlXOUtTtzWLvzEOt25rBu1yHW7sxhQIsknh/ettK+toraWQgPDuD6Lqm8MTuDbdmHqVsr1O1IIiIiNcvRHJj+DPz4KoREw5CXoe0N4KdJQiJy7qy17M45ytqdTglbt+tEMTt4pPD4drXDAmmcGMmQdnXp0TCuUjOpqJ2lW7rX5/VZG3l7bib/N6i523FERERqBmth9Zcw8XHI2QYdboWL/gxhMW4nExEfYq1l96GjrPMUspKjZAcOFxzfrlZYIE0SIrm8bV2aJEbSODGCxgmRxEUEYapoarWK2llKqR3GwFZJfDhvMw/2b0xYkHahiIhIpdqXARMehfVTILE1DH8b6nVxO5WIeLFjhWz9sUK2yylka3eeXMiiQwNpkhjBpW3q0CQhwlPKqraQnYpaxjm4vVc6E5bvYOzirdzcrb7bcURERKqnwqMw5yWY9Tz4BcAlf4cud4G/Xr6IiMNay55D+ScdO7Zu5yHW7sohO+9EIYsKCaBJYiSDW9ehSWLE8VGy+Ihg1wvZqegv3TnokFqbtinRvDk7gxu7pOLn550/XBEREZ+1YRp88zDs2wAtroSBf4conR5HpCbbc+jo8SJW8hiy/WUUskGtkmicEEmTxEiaJEYQH+m9hexUVNTOgTGGkb3SefCjJcxYu5t+zRLcjiQiIlI95OyAyU/AirFQOx1uGguNLnI7lYhUob2HnEU9nDJ2rJgdYl9u/vFtIj2FbGCrJBolRB4fJUvwwUJ2Kipq52hQqzo8HbWaMXMyVNRERETOV1EhLHwDpv7VmfLY9/+g50MQGOJ2MhGpJPty8z1FLOf4aovrdx1ib8lCFhxA48QIBrRIpHFiJI09x5ElRlWfQnYqKmrnKCjAj1u6p/HPyT+zdmcOTRIj3Y4kIiLim7IWwdcPwY5l0PBCGPwcxDZ0O5WIVJD9nkJ2YkEPp5DtOXSikEV4CtlFzRNpXOIYsqSokGpfyE5FRe083NAllX9/v44xszN4Zlgbt+OIiIj4lsP74bsnYdFbEJEIV78JLYdCDX1RJuLr9ufml1jQI+f49MXShaxRQgQXNks4vsJikxpeyE5FRe081A4P4qoOKYxdnMWjlzQlNiLY7UgiIiLez1pY+hF8+3s4vA+63eNMdQyJcjuZiJRDdl7+8RJW8nxkew4dPb5NeJA/jRIj6dc04fjoWJPESOpEq5CVl4raeRrZM40P52/mw/mbuf/Cxm7HERER8W67VjurOW6aAymd4dJxUEezUkS80YG8AtaetKCHU8h25/yykPVtGk+TxAjPCFkkdVXIzpuK2nlqnBhJ7ybxvDN3E3f1bkhQgJ/bkURERLxPfi7M+AfMHQVBEXD5S9D+FvDT86aI2w4cLvjFgh5rd+awq0QhCwvyp3FCBH2axB9f0KNxYgR1o0N1qqpKoqJWAUb2TGPEmwv4Zvk2hrZPcTuOiIiId1nzDUx8DA5sgXY3wcVPQnic26lEapwDhwtYv+tEITs2Srbz4IlCFhroT+PECC5ofGyELILGCZEk11Ihq2oqahWgd+N4GsaH88bsDK5sl6xhXhEREYD9m5yCtnYiJLSA2yZB/e5upxKpEay1LMjcz7crd/Czp5TtOHjk+O2hgf40SoigZ6O44yeFViHzLipqFcDPzzkB9u/GrWDhpv10TotxO5KIiIh7CvNh7n9gxj/B+MHFTzkLhvgHup1MpNrbvDePsYuz+PynLLbsO0xwgB+NEyPo0TD2+AqLjRMiSamtQubtVNQqyFXtU/jHpJ8ZMztDRU1ERGqujJnOYiF71kLzy2HgMxCtwwJEKtPBIwVMWLadsYuzWJC5H2OgR8NYfnNREwa2SiIsSC/5fZF+ahUkNMifG7qm8t8ZG9iyL496MWFuRxIREak6h3Y5y+0v+xhq1YcbPoUmA9xOJVJtFRVbZq3bzdjFW/l25Q6OFhbTID6cRy9pytD2ydStFep2RDlPKmoV6Jbu9fnfzI28/UMmv7+shdtxREREKl9xESwcA98/BQV5cMEjcMHDEKQ3LEUqw887cvh8cRbjftrKrpyjRIcGMrxTPa7qkEy7erW0VkI1oqJWgepEhzK4dR0+XrCFhy5uQkSwdq+IiFRj236Cr38L2xZDem+49AWI0zlFRSra3kNH+XLpNsYuzmLF1oME+Bn6Nk1gWIdkLmyeQHCAv9sRpRKoSVSwkb3S+XLpNj5buIURPdPdjiMiIlLxDmfD1L/CgtchIgGGvQGthoHeyRepMEcLi5i2ZhefLdrK9J93UVhsaVk3ij9e1oIr2tUlLiLY7YhSyVTUKli7erXokFqLN3/I5ObuafhrNR0REakurIXln8HkJyBvD3S5Ey78PYREu51MpFqw1rI06wCfL87iy6XbyM4rID4ymJG90rmqQzLNkqLcjihVSEWtEozslc79H/zE1DW7uLhFottxREREzt/utTDhYWdVx7od4MZPoG57t1OJVAvbDxxm3E9bGbsoiw27cwkO8GNAyySGdUimV6M4Avz93I4oLlBRqwQDWyZRNzqEMbMzVNRERMS35efBrOdgzr8hMAwufR463gZ+OiZG5Hzk5RcyeeUOxi7aypwNe7AWOtWvzd+vasClbeoQFaLzDtZ0KmqVIMDfj1t7pPH3iWtYte0gLepqmFpERHzQ2skw4RHI3gxtroMBTznHpInIOSkutszL2MfYxVlMXL6d3PwiUmqH8sCFjRnWIZn6seFuRxQvoqJWSa7rnMqL361jzJwMnrumrdtxREREyi97C0x6HNZ8DXFN4davIf0Ct1OJ+KzMPbmMXZzF54u3sjX7MBHBAVzapg7DOqTQOS0GP61pIGVQUask0WGBXN0xhY8XbOGxgc2Ij9TKPCIivsoYMxB4CfAHXrfWPlPq9r7AeCDDc9Xn1tq/lOe+XqWoAH58BaY/4ywc0v9P0P1+CAhyO5mIzzlwuIBvlm1n7OIsFm3ajzHQq1Ec/29gUwa0SCI0SNOH5fRU1CrRbT3TePfHTbw/bxMPXdTE7TgiInIOjDH+wMvAxUAWsMAY86W1dlWpTWdZay87x/u6b9MPzjnRdq+GJoNg0LNQu77bqUR8SmFRMbPW7eGzxVlMWbWT/MJiGiVE8NjAZgxtn0xSdIjbEcWHqKhVogbxEVzYLIH3ftzEPX0b6mSEIiK+qQuw3lq7EcAY8xEwBChP2Tqf+1aN3D0w5Y+w5H2IrgfXfQjNBrudSsSnrN5+kLGLsvhiyTb2HDpK7bBAru9cj2EdU2idHI3ROQblHKioVbKRPdO56Y15fLlkG9d0qud2HBEROXvJwJYSn2cBXcvYrrsxZimwDXjEWrvyLO6LMeYu4C6A1NTUCoh9BsXFsPht+O7PkH8Iev0Gej8KQVrMQKQ8duccZfySrXy+eCurth8k0N/Qr2kCwzqm0K9pAkEBWlJfzo+KWiXr2SiWpomRjJmTydUdU/SOioiI7ynrD7ct9flioL619pAxZjDwBdC4nPd1rrR2NDAaoFOnTmVuU2G2L4NvfgtZC6B+L2fJ/YRmlfolRaqDIwVFTF2zi7GLspi+djdFxZY2KdE8eUVLLm9bl5hwHc8pFUdFrZIZYxjZK43Hxi7nx4376N4w1u1IIiJydrKAklMiUnBGzY6z1h4s8fEEY8wrxpi48ty3Sh05CNOehvn/hdAYGPpfaHMt6E1EkVOy1vLTlmzGLsriq6XbOHikkMSoYO68oAHDOiTTODHS7YhSTamoVYEh7ZJ5dtLPvDE7Q0VNRMT3LAAaG2PSga3AdcANJTcwxiQBO6211hjTBfAD9gLZZ7pvlbAWVn4Ok56AQzuh023Q/48QWrvKo4j4iq3ZhxnnWVJ/455cQgL9uKRlEsM6pNCzURz+WlJfKpmKWhUICfTnxq6pjJq2nsw9uaTFaf6/iIivsNYWGmPuBybjLLE/xlq70hhzt+f214CrgXuMMYXAYeA6a60FyrxvlX4Dezc4J63eMBXqtIXrPoCUjlUaQcRX5B4tZNKKHYxdnMXcjXuxFrqkx3B3n4YMap1EZEig2xGlBlFRqyI3d6vPazM28NYPmfz5ipZuxxERkbNgrZ0ATCh13WslPh4FjCrvfatEwRGY/S/nEhAMg/4JnW8HP61ALFJScbHlx417+WxxFpNW7CAvv4jUmDAe6t+Eoe2TSY0Nczui1FAqalUkISqEy9vU5dOFW/jtgCZE6R0ZERGpLOu/g28egf0Z0OpquORvEJnkdioRr7Jh9yE+X5zFuMVb2XbgCJHBAQxpV5erOqTQqX5tLQAnrlNRq0K39Uzn85+28smCLdxxQQO344iISHU177/OyNnNX0DDfm6nEfEa2Xn5fLVsO2MXZbFkSzZ+Bi5oHM/jg5szoEUiIYEacRbvoaJWhVqnRNMlLYY352QyokcaAf46v4aIiFSCK1+F4EhnyqNIDVdQVMyMn3fz+U9ZfLdqF/lFxTRNjOSJwc24sl0yCVEhbkcUKZOKWhUb2Sudu99bxHerdzKwVR2344iISHUUHud2AhHXrdx2gLGLtvLl0q3sOZRPbHgQN3ZLZViHFFrWjdLURvF6KmpV7OIWiaTUDmXM7EwVNREREZEKtCvnCON/2sbYxVms2ZFDkL8f/ZsncFWHFPo2jSdQs5nEh6ioVTF/P8OIHmn89ZvVLM86QOuUaLcjiYiIiPisIwVFTFm1k88XZzFz3R6Kii3t6tXiqSEtubxtXWqFBbkdUeScnLGoGWNCgJlAsGf7z6y1fyq1zY3AY55PDwH3WGuXVnDWamN453r8a8paxszJ4F/XtnM7joiIiIhPsdayaNN+xi7eytfLtpFzpJA60SH8qncDruqQQqOECLcjipy38oyoHQUutNYeMsYEArONMROttT+W2CYD6GOt3W+MGQSMBrpWQt5qISokkOGd6/Hej5t4fFAzEnUQq4iIiMgZbdmXx7iftvL54iwy9+YRGujPoFZJDOuYQrcGsfj76bgzqT7OWNSstRZnlAwg0HOxpbb5ocSnPwIpFRWwuhrRI423fsjkvR838fCApm7HEREREfFKh44WMmG5s6T+vIx9AHRvEMt9/RoxqHUdIoJ1JI9UT+X6zTbG+AOLgEbAy9baeafZ/HZg4ike5y7gLoDU1NSzS1rN1I8N56Lmibw/bzP39Wuk83aIiIiIeBQVW37YsIexi7KYtHIHRwqKSY8L5+GLmzC0QzIptcPcjihS6cpV1Ky1RUA7Y0wtYJwxppW1dkXp7Ywx/XCKWq9TPM5onGmRdOrUyZa1TU0ysmc6U1bt5IuftnJdl5pdXEVERETW7zrE2MVZfPHTVrYfOEJUSABXdUhhWIcUOqTW0pL6UqOc1VixtTbbGDMdGAicVNSMMW2A14FB1tq9FZawGuvWIIYWdaIYMyeDazvX0x8fERERqXGKiy3jftrKO3MzWZp1AH8/Q58m8fz+0hb0b56gWUdSY5Vn1cd4oMBT0kKBi4BnS22TCnwO3GytXVspSashYwwje6XzyKdLmbN+L70a6wSlIiIiUnOs3ZnD78YtZ0HmfpomRvL7S5tzRbu6JERqoTWR8oyo1QHe9hyn5gd8Yq392hhzN4C19jXgj0As8IpnVKjQWtupkjJXK5e3rcMzE1fzxuyNKmoiIiJSIxzOL+LfU9fxv5kbiQgJ4B/D2nB1xxT8tGqjyHHlWfVxGdC+jOtfK/HxHcAdFRutZggO8OembvV58bt1bNh9iIbxOu+HiIiIVF/Tft7FH8evYMu+wwzrkMITg5sRGxHsdiwRr+PndgCBm7rVJ8jfj7fmZLodRURERKRS7Dx4hHvfX8Rtby4gyN+PD+/sxvPD26qkiZyCTjzhBeIighnSri6fLcrikQFNiQ4LdDuSiIiISIUoKra8OzeT575dS35RMQ9f3IS7+jQgOECLhIicjkbUvMRtPdM5XFDEhws2ux1FREREpEKs2HqAoa/M4c9fraJ9ai2+fag3D/RvrJImUg4aUfMSLepG0b1BLG//kMntvdIJ9FeHFhEREd+Uc6SA579dyztzM4kJD+bf17fn8jZ1dCoikbOgNuBFbu+VzvYDR5i8cofbUURERETOmrWWicu3c9ELM3h7biY3dq3P9w/34Yq2dVXSRM6SRtS8yIXNEqgfG8YbszO4rE1dt+OIiIiIlNuWfXn8cfwKpv28mxZ1onjtpo60T63tdiwRn6Wi5kX8/Ay39Ujjz1+tYvHm/XTQHzcRERHxcgVFxbw+K4OXvl+LnzH8/tLmjOiRRoAO4xA5L/of5GWu6VSPyJAA3tRS/SIiIuLlFmbu49J/z+LZSWvo3Tie737bhzsuaKCSJlIB9L/Iy4QHB3Bd53pMWL6d7QcOux1HRERE5Bey8/J5fOwyrn5tLoeOFPK/Wzox+pZO1K0V6nY0kWpDRc0L3dI9DWstb/+wye0oIiIiIsdZaxm7KIsLn5/Bp4uyuKt3A6b8tg8Xt0h0O5pItaNj1LxQvZgwLmmZxIfzN/Pr/o0IC9KPSURERNy1Yfchfj9uBXM37qV9ai3+dmVrWtSNcjuWSLWlETUvdXuvdA4cLuDzxVvdjiIiIiI12JGCIl749mcGvTiLldsO8LehrRh7dw+VNJFKpqEaL9Wxfm3apETz5pwMbuiSip+fzj0iIiIiVWvWut384YsVZO7NY0i7uvz+0hbERwa7HUukRtCImpcyxjCyZzobducyY91ut+OIiIhIDbIr5wi//vAnbn5jPgDv3d6Vl65rr5ImUoVU1LzY4NZ1SIgMZszsDLejiIiISA1QXGx578dN9H9+BpNW7ODX/Rsz6aHe9Goc53Y0kRpHUx+9WFCAH7f2SOOfk39m7c4cmiRGuh1JREREqqlV2w7yuy+W89PmbLo3iOWvQ1vRMD7C7VgiNZZG1Lzc9V1SCQ7w0wmwRUREpFLkHi3kb9+s4vJRs9m8N48Xhrflgzu7qqSJuEwjal4uJjyIqzok8/niLB69pCkx4UFuRxIREZFqYsqqnfxp/Aq2HTjC9V3q8djAZtQK02sNEW+gETUfcFvPdI4WFvPh/M1uRxEREZFqYFv2Ye58ZyF3vrOQyJBAPru7O3+/qo1KmogX0YiaD2iSGMkFjeN4Z24md17QgKAA9WsRERE5e4VFxbz1QyYvTFlLsbU8PqgZt/dKJ9Bfry1EvI3+V/qIkb3S2XnwKBNXbHc7ioiIiPignzbv5/JRc/jrN6vp1iCWKb/pw919GqqkiXgpjaj5iD6N42kQH84bszO4om1djNEJsEVEROTMDhwu4J+T1/D+vM0kRAbz6o0dGNgqSa8lRLycipqP8PMz3NYznT98sYJFm/bTKS3G7UgiIiLixay1fLl0G099vZp9uUcZ0SON317chMiQQLejiUg5aKzbhwzrkEx0aCBj5ugE2CIiInJqmXtyuWXMfB78aAl1a4Uw/r5e/OnylippIj5EI2o+JCwogOu7pDJ65gay9ueRUjvM7UgiIiLiRY4WFvHfGRsZNW09Qf5+PHlFS27qVh9/P01zFPE1GlHzMbd0r48xhrd/yHQ7ioiIiHiRuRv2MvilWbwwZS0XN0/k+4f7cGuPNJU0ER+lETUfU7dWKINb1+GjBVt48KImRATrRygiIlKT7T10lKcnrGHs4izqxYTy5m2d6dc0we1YInKeNKLmg0b2TCPnSCFjF2W5HUVERERcUlxs+XjBZvq/MIPxS7Zyb9+GfPtQH5U0kWpCwzE+qH1qbdqn1uLNORnc3K0+fprSICIiUqOs3ZnD78YtZ0HmfrqkxfDXoa1okhjpdiwRqUAaUfNRI3umk7k3j6lrdrkdRURERKrI4fwinp20hsEvzWLdrkP8Y1gbPrqrm0qaSDWkETUfNahVEnWjQxgzJ4OLWiS6HUdEREQq2bSfd/HH8SvYsu8wV3dM4YnBzYkJD3I7lohUEhU1HxXg78ctPdJ4ZuIaVm8/SPM6UW5HEhERkUqw8+ARnvxqJROW76BhfDgf3dWNbg1i3Y4lIpVMUx992HWd6xEa6M+Y2ToBtoiISHVTVGx5a04G/Z+fwferd/HIgCZMePAClTSRGkIjaj6sVlgQwzom88mCLB4b1Iy4iGC3I4mIiEgFWJ51gCfGLWf51gNc0DiOv17Zivqx4W7HEpEqpBE1H3dbz3Tyi4p5/8fNbkcRERGR85RzpIA/f7mSIS/PZvuBI/z7+va8M7KLSppIDaSi5uMaxkfQr2k87/64iaOFRW7HERGplowxA40xPxtj1htjHj/Ndp2NMUXGmKtLXJdpjFlujFlijFlYNYnF11hrmbB8Oxe9MIO352ZyY9f6fP9wH65oWxdjdBoekZpIRa0aGNkrnT2HjvLV0u1uRxERqXaMMf7Ay8AgoAVwvTGmxSm2exaYXMbD9LPWtrPWdqrUsOKTtuzLY+RbC7j3/cXEhgfz+T09eOrKVkSHBrodTURcpGPUqoFejeJokhjBmNkZDOuQrHfeREQqVhdgvbV2I4Ax5iNgCLCq1HYPAGOBzlUbT3xVQVExr8/K4KXv1+JnDL+/tDkjeqQR4K/30UVEI2rVgjGGkT3TWbX9IPMy9rkdR0SkukkGtpT4PMtz3XHGmGRgKPBaGfe3wLfGmEXGmLtO9UWMMXcZYxYaYxbu3r27AmKLN1uYuY9L/z2LZyetoXfjeL77bR/uuKCBSpqIHKe/BtXEle2TqR0WqKX6RUQqXlnTFGypz18EHrPWlnWwcE9rbQecqZP3GWN6l/VFrLWjrbWdrLWd4uPjzyuweK/svHweH7uMq1+bS+7RIv53SydG39KJurVC3Y4mIl5GUx+riZBAf27sWp+Xp69n095crQ4lIlJxsoB6JT5PAbaV2qYT8JFn6nkcMNgYU2it/cJauw3AWrvLGDMOZyrlzMqPLd7EWsvni7fytwmrOXC4gLt6N+DB/o0JD9ZLMREpm0bUqpGbu9cnwM/w1g+ZbkcREalOFgCNjTHpxpgg4Drgy5IbWGvTrbVp1to04DPgXmvtF8aYcGNMJIAxJhwYAKyo2vjitg27D3HD/+bx8KdLqR8bxtcP9OKJwc1V0kTktM74F8IYE4Lzzl+wZ/vPrLV/KrWNAV4CBgN5wAhr7eKKjyunkxgVwmVt6vLpwix+e3ETIkO0WpSIyPmy1hYaY+7HWc3RHxhjrV1pjLnbc3tZx6UdkwiM84y0BQAfWGsnVXZm8Q5HCop4Zdp6XpuxkZBAP/42tBXXd07Fz0+LfonImZXnrZyjwIXW2kPGmEBgtjFmorX2xxLbDAIaey5dgVc9/0oVG9kznXE/beWThVnc3ivd7TgiItWCtXYCMKHUdWUWNGvtiBIfbwTaVmo48Uqz1u3mD1+sIHNvHle2q8vvLm1BfGSw27FExIecsahZay1wyPNpoOdS+iDqIcA7nm1/NMbUMsbUsdbqxF5VrHVKNJ3TavPWDxmM6JGGv961ExERqTK7co7w169X8+XSbaTHhfPe7V3p1TjO7Vgi4oPKdYyaMcbfGLME2AVMsdbOK7XJGZcu9jyOlh6uAiN7prNl32GmrNrpdhQREZEaobjY8t6Pm+j//AwmrdjBg/0bM/HBC1TSROSclesoVs9yw+2MMbVw5tq3staWPBi6PEsXY60dDYwG6NSp0y9ul4oxoGUSKbVDGTMng4GtktyOIyIiUq2t2naQJ8YtZ8mWbLo3iOWvQ1vRMD7C7Vgi4uPOatVHa202MB0YWOqm8ixdLFXE388wokca8zP2sWLrAbfjiIiIVEu5Rwv52zeruHzUbLbsy+OF4W354M6uKmkiUiHOWNSMMfGekTSMMaHARcCaUpt9CdxiHN2AAzo+zV3DO9cjPMhfJ8AWERGpBFNW7eTiF2bwv1kZDO+UwvcP9+GqDil4VvgUETlv5Zn6WAd42xjjj1PsPrHWfl1qWeIJOEvzr8dZnv+2Ssor5RQVEsg1nerx/rxNPD6oGQlRIW5HEhER8Xnbsg/zpy9XMmXVTpomRvLZ9e3plBbjdiwRqYbKs+rjMqB9Gde/VuJjC9xXsdHkfI3okcbbczN578dN/HZAU7fjiIiI+LS1O3MY+vIciqzl8UHNuL1XOoH+Z3UUiYhIuemvSzWWFhdO/2aJvDdvM0cKityOIyIi4tNe+n4dxhi+fagPd/dpqJImIpVKf2GquZG90tiXm8/4JVvdjiIiIuKz1u86xITl27mle31SY8PcjiMiNYCKWjXXvUEszetEMWZ2Js4MVRERETlbr0xfT3CAH7f3Snc7iojUECpq1ZwxhpE90/h5Zw4/bNjrdhwRERGfs3lvHuOXbOPGrvWJjQh2O46I1BAqajXA5W3rEhcRxBtaql9EROSsvTZzA/7GcFfvBm5HEZEaREWtBggJ9OfGrvWZumYXG3cfcjuOiIiIz9h+4DCfLcxieOcUEnWqGxGpQipqNcRN3eoT5O/HWz9kuh1FRETEZ4yeuZFia/lV74ZuRxGRGkZFrYaIjwzminZ1+XRhFgfyCtyOIyIi4vV25xzlw/mbubJ9MvVitNKjiFQtFbUa5LaeaRwuKOKjBZvdjiIiIuL13pidwdHCYu7tq9E0Eal6Kmo1SMu60XRrEMPbP2RSWFTsdhwRERGvlZ2Xz7tzM7msTV0axEe4HUdEaiAVtRrm9l4N2HbgCJNX7nQ7ioiIiNd6c04muflF3NdPo2ki4g4VtRrmwmYJ1I8NY8wcLdUvIiJSlpwjBbw5J4MBLRJplhTldhwRqaFU1GoYfz/DiB5pLNq0nyVbst2OIyIi4nXe+3EzB48Ucv+FjdyOIiI1mIpaDXRNp3pEBgcwRifAFhEROcnh/CJen7WRPk3iaZNSy+04IlKDqajVQBHBAVzbuR4Tlm9n+4HDbscRERHxGh/O38ze3Hwe0GiaiLhMRa2GurVHGsXW8u7cTW5HERER8QpHC4v478wNdE2PoVNajNtxRKSGU1GroerFhDGgRRIfzN/M4fwit+OIiIi47rNFWew8eJQHLmzsdhQRERW1muz2C9LJzivg85+y3I4iIiLiqoKiYl6dvoF29WrRs1Gs23FERFTUarJO9WvTOjmaMbMzKC62bscRERFxzfgl28jaf5gHLmyEMcbtOCIiKmo1mTGGkb3S2LA7l1nr97gdR0RExBVFxZZXpq2neZ0oLmyW4HYcERFARa3Gu7R1XRIig3lDS/WLiEgNNWH5djbuydVomoh4FRW1Gi4owI9butdn5trdrNuZ43YcERGRKlVcbHl52noaJUQwsGWS23FERI5TUROu75JKcIAfb/6Q6XYUERGRKvX9ml2s2ZHDff0a4uen0TQR8R4qakJsRDBD2yfz+eIs9ufmux1HRESkSlhrGTV1HakxYVzepq7bcURETqKiJgDc1jOdIwXFfDB/s9tRREREqsSsdXtYmnWAe/o2JMBfL4lExLvor5IA0DQpkgsax/HO3EwKiordjiMiIlLpRk1dT53oEK7qkOx2FBGRX1BRk+NG9kxn58GjTFi+3e0oIiIilWrexr3Mz9zHr3o3IDjA3+04IiK/oKImx/VpEk+DuHDGzM7AWp0AW0REqq9R09YTFxHEdV1S3Y4iIlImFTU5zs/PcFvPNJZmHWDx5v1uxxEREakUS7ZkM2vdHu68oAEhgRpNExHvpKImJxnWMYWokAB+N24Fy7Ky3Y4jIiJS4UZNXU+tsEBu7Fbf7SgiIqekoiYnCQsK4F/XtmNvbj5DXp7D78YtJztPS/aLiEj1sGrbQb5bvZORPdOJCA5wO46IyCmpqMkv9G+eyNSH+zCyZzofLdhCv+em89H8zRQX67g1ERHxbS9PX09kcAC39khzO4qIyGmpqEmZIkMC+cNlLfjm171onBDJ458v56pXf2B51gG3o4mIiJyT9bsOMWH5dm7uXp/o0EC344iInJaKmpxWs6QoPv5VN/51bVuy9h/mipdn8/svNB1SRER8zyvT1xMc4MftvdLdjiIickYqanJGxhiGtk9h6iN9uK1HOh/O38KFz8/g4wWaDikiIr5h8948xi/Zxo1d6xMbEex2HBGRM1JRk3KLCgnkj5e34OsHetEwPpzHxjrTIVds1XRIERHxbq/O2IC/MdzVu4HbUUREykVFTc5a8zpRfPKr7rww3JkOefmo2fzhixUcyCtwO5qIiMgvbD9wmM8WbWF45xQSo0LcjiMiUi4qanJOjDFc1SGF7x/uw63d03h/3ib6PT+dTxZu0XRIERHxKv+dsRFr4Ve9G7odRUSk3FTU5LxEhwby5yta8vUDF9AgLpz/99kyrn5N0yFFRMQ77M45ykcLNjO0fTL1YsLcjiMiUm4qalIhWtR1pkM+d01bNu/L44pRs/njeE2HFBERd70xO4P8wmLu6avRNBHxLSpqUmH8/AxXd0zh+4f7ckv3NN77cRMXPj+dTzUdUkREXJCdl8+7czO5rE1dGsRHuB1HROSsqKhJhTs2HfKrB3qRFhfOo58t45r/zmXlNk2HFBGRqvPmnExy84u4r18jt6OIiJy1MxY1Y0w9Y8w0Y8xqY8xKY8yDZWwTbYz5yhiz1LPNbZUTV3xJy7rRfPqr7vzz6jZk7snl8v/M5k/jV3DgsKZDiohvMcYMNMb8bIxZb4x5/DTbdTbGFBljrj7b+0rFyjlSwJtzMhjQIpGmSZFuxxEROWvlGVErBB621jYHugH3GWNalNrmPmCVtbYt0Bd43hgTVKFJxSf5+Rmu6VSPqQ/35eZu9Xn3x030f346ny3K0nRIEfEJxhh/4GVgENACuL6M58Fj2z0LTD7b+0rFe/fHTRw8Usj9F2o0TUR80xmLmrV2u7V2sefjHGA1kFx6MyDSGGOACGAfTsETASA6LJAnh7Tiy/t7kRoTxiOfLmX4f+eyattBt6OJiJxJF2C9tXajtTYf+AgYUsZ2DwBjgV3ncF+pQHn5hbw+K4M+TeJpk1LL7TgiIufkrI5RM8akAe2BeaVuGgU0B7YBy4EHrbXFFRFQqpdWydF8dncP/nF1GzbuyeWy/8ziz1+u1HRIEfFmycCWEp9nUeoNS2NMMjAUeO1s7ysV78P5W9iXm88DGk0TER9W7qJmjInAeafwIWtt6WGQS4AlQF2gHTDKGBNVxmPcZYxZaIxZuHv37nMOLb7Nz88wvFM9pj3clxu71ueduZn0f346YxdlYa2mQ4qI1zFlXFf6j9WLwGPW2qJzuK+zoZ4jK8TRwiJGz9xAtwYxdEqLcTuOiMg5K1dRM8YE4pS09621n5exyW3A59axHsgAmpXeyFo72lrbyVrbKT4+/nxySzUQHRbIU1c60yHrxYTxsGc65Ortmg4pIl4lC6hX4vMUnBkkJXUCPjLGZAJXA68YY64s530BPUdWlM8WZbHz4FEeuLCx21FERM5LeVZ9NMAbwGpr7Qun2Gwz0N+zfSLQFNhYUSGlemuVHM3Yu3vwj2Ft2LA7l8v+M5snv1rJwSOaDikiXmEB0NgYk+5ZKOs64MuSG1hr0621adbaNOAz4F5r7Rflua9UnIKiYl6dvoH2qbXo0TDW7TgiIucloBzb9ARuBpYbY5Z4rnsCSAWw1r4GPAW8ZYxZjjPN4zFr7Z6KjyvVlZ+fYXjnegxomchz3/7MWz9k8tXS7TwxuBlD2yfjvF8gIlL1rLWFxpj7cVZz9AfGWGtXGmPu9txe+ri0M963KnLXROOXbCNr/2GevKKlnjdExOcZt44J6tSpk124cKErX1u83/KsA/xh/AqWbMmmS1oMf7myJc2SfnHYo4j4CGPMImttJ7dz+Ao9R569omLLxS/MIDjQnwm/7qWiJiI+4XTPj2e16qNIVWmdEs3n9/Tg2WGtWbcrh0v/PZu/fLVK0yFFRKRME5ZvZ+OeXB64sJFKmohUC75d1IpLL64l1Ymfn+HazqlMe6Qv13Wux5s/ZND/+Rl88dNWrQ4pIiLHFRdbRk1dT6OECAa2THI7johIhfDdorZrNbzSDbYtcTuJVLJaYUH8bWhrxt/Xk7rRITz08RKuHf0jP+/IcTuaiIh4ge9W7+TnnTnc168hfn4aTROR6sF3i5rxh4LD8NalsP57t9NIFWiTUotx9/bk71e1Zt3OHAb/exZPfb2KHE2HFBGpsay1jJq2ntSYMC5vU9ftOCIiFcZ3i1p8E7h9CtROgw+Gw9KP3U4kVcDPz3B9l1SmPtyXazvXY8ycDC58fgbjl2g6pIhITTRr3R6WZR3g3r4NCfD33Zc1IiKl+fZftKg6cNsESO0O4+6C2S+CXqzXCLXDg3h6aGu+uLcndaJDePCjJVw3+kfW7tR0SBGRmmTU1PXUiQ7hqg4pbkcREalQvl3UAEKi4aax0GoYfPcnmPiYFhmpQdrWc6ZDPj20NT/vzGHQS7P4q6ZDiojUCPM27mV+5j5+1bsBQQG+/5JGRKSk6vFXLSAYrnodut8P8/8Ln90GBUfcTiVVxN/PcEPXVKY93JfhnerxxhxndUhNhxQRqd5GTVtPXEQQ13VJdTuKiEiFqx5FDcDPDy75Gwz4G6waD+9dBYf3u51KqlDt8CD+flVrxt3bkyTPdMjr/6fpkCIi1dFPm/cza90e7rygASGB/m7HERGpcNWnqB3T434Y9gZsmQ9jBsGBrW4nkirWzjMd8m9DW7F6ew6DX5rF0xNWc+hoodvRRESkgrw8bT21wgK5sVt9t6OIiFSK6lfUAFpf7Ry3dnArvHEx7FzldiKpYv5+hhu71mfaI325umMKo2dupP/z0/ly6TZNhxQR8XErtx3gu9W7GNkznYjgALfjiIhUiupZ1AAa9HFWhCwugjcHQuYctxOJC2LCg3hmWBvG3duD+Mhgfv3hT9zwv3ms03RIERGf9cq0DUQGB3BrjzS3o4iIVJrqW9QAklrDHVMgIhHeHQorv3A7kbikfWptxt/Xi6eubMXKbQcY9NIs/q7pkCIiPmf9rhwmrNjOLT3qEx0a6HYcEZFKU72LGkCtVBg5Geq2g09HwLzRbicSl/j7GW7u5kyHHNYhhf/O3MhFz8/gK02HFBHxGa9M30BIgD8je6a7HUVEpFJV/6IGEBYDt4yHpoNh4qPw3Z91YuwaLDYimGevbsPYe3oQGxHEAx/+xI2vz2P9Lk2HFBHxZpv35jF+yTZu7JpKbESw23FERCpVzShqAIGhcO270GkkzP4XjLsbCvPdTiUu6li/Nl/e34unhrRkxdYDDHxxFn+fuJpcTYcUEfFKr87YgL8x3Nm7gdtRREQqXc0pagB+/nDpC9Dv97DsI/jwWjiqUZSazN/PcHP3NKY+0peh7ZP574yN9H9+Bt8s267pkCIiXmT7gcN8tmgLwzunkBgV4nYcEZFKV7OKGoAx0OdRGPIybJwBb10KOTvdTiUui4sI5p/XtGXsPT2ICQ/ivg8Wc/Mb81m/65Db0UREBPjvjI1YC7/q3dDtKCIiVaLmFbVj2t8E138Ee9Y551rbu8HtROIFOtavzVcP9OIvQ1qyNCubQS/N5JmJazQdUkTERbtzjvLh/M0MbZ9MvZgwt+OIiFSJmlvUAJoMgFu/hvxDTlnLWuR2IvEC/n6GW7qnMe2Rvgxpl8xrMzZw0QszmLBc0yFFRNzw+uyNFBQVc09fjaaJSM1Rs4saQEpHuH0KBEfC25fB2sluJxIvERcRzHPXtOWzu7tTKyyIe99fzC1j5rNht6ZDiohUley8fN6bu4nL2tSlQXyE23FERKqMihpAbEOnrMU1gQ+vh8XvuJ1IvEintBi+ur8nT17RkiVbshn44kyenbSGvHxNhxQRqWxvzskkN7+I+/o1cjuKiEiVUlE7JiIBRnwDDfrClw/A9Gd1rjU5LsDfj1t7pDH14b5c0TaZV6dv4KLnZzBR0yFFRCpNzpEC3pyTwSUtE2maFOl2HBGRKqWiVlJwBNzwMbS9HqY/DV8/BEUaNZET4iODeX54Wz69uztRoYHc45kOuVHTIUVEKty7P27i4JFC7u/X2O0oIiJVTkWtNP9AuPJVuOBhWPQWfHIz5Oe5nUq8TOe0GL5+oBd/urwFSzZnc8mLM/nnZE2HFBGpKHn5hbw+K4M+TeJpnRLtdhwRkSqnolYWY6D/H2Hwc/DzRHhnCOTtczuVeJkAfz9u65nO94/04fK2dXl5mjMdctIKTYcUETlfH87fwr7cfB64UMemiUjNpKJ2Ol3uhOHvwPal8MYA2L/J7UTihRIiQ3hheDs++ZUzHfLu9xZz65sLyNiT63Y0ERGfdKSgiNEzN9CtQQyd0mLcjiMi4goVtTNpcQXcMh5ydznnWtu+zO1E4qW6pDvTIf94WQt+2rSfS/41k+cm/8zh/CK3o4mI+JTPFmWx8+BRHrhQx6aJSM2lolYe9bvDyG/BLxDeHAwbp7udSLxUgL8fI3s50yEva1OHUdPWc9ELM5i0YoemQ4qIlENBUTGvTt9A+9Ra9GgY63YcERHXqKiVV0IzuP1bqFUP3rsaln3qdiLxYgmRIbxwbTs+vqsbEcEB3P3eIkZoOqSIyBl98dNWtmYf5oELG2GMcTuOiIhrVNTORnQy3DYR6nWFz++AOf/WudbktLo2iOXrX/fiD5e1YNGm/Vz8wgxufmMe78/bxO6co27HExHxKkXFllenb6BFnSj6NU1wO46IiKtU1M5WaC24aSy0uBKm/AEmPwHFxW6nEi8W6O/H7b3SmfpwH+64oAFb9uXxu3Er6PL0dwx/bS5jZmewLfuw2zFFRFw3Yfl2Nu7J1WiaiAgQ4HYAnxQYAle/CZPrwI+vQM52GPpfCAh2O5l4sYSoEB4f1IzHBjZlzY4cJq7YweQVO/jL16v4y9eraFuvFgNbJjGoVRJpceFuxxURqVLFxZZRU9fTKCGCS1omuR1HRMR1Kmrnys8PBv4dourAlD9C7h647n0I0Uk55fSMMTSvE0XzOlH89uImbNx9iIkrdjBpxQ6enbSGZyetoVlSJINa1WFgqySaJEbonWURqfa+W72Tn3fm8K9r2+Lnp795IiLGrZXoOnXqZBcuXOjK165wyz6BL+6FuCZw02cQVdftROKjsvbnMWnFDiav3MHCTfuxFhrEhTOwVRKDWtWhVXKUSpv4JGPMImttJ7dz+Ipq9RxZDtZahrw8h+y8AqY+3IcAfx2ZISI1w+meHzWiVhHaDIfwePj4Jnj9YucYtoRmbqcSH5RSO4w7LmjAHRc0YNfBI0xetZNJK7bz35kbeWX6BpJrhXpKWxIdUmvrXWcRqRZmrtvDsqwDPHNVa5U0EREPjahVpO1L4f1roPAoXP+Rc/41kQqwPzefKat3MmnFDmav20N+UTHxkcFc0jKRQa3q0DU9Ri9uxKtpRO3sVMvnyFOw1nLNa3PZmn2YGY/2IyhAf8tEpObQiFpVqdPWOdfae8Pg3Sth2OvQ/HK3U0k1UDs8iOGd6jG8Uz1yjhQwdc0uJq3YwdhFW3nvx83UCgvk4uaJDGqdRM9GcQQH+LsdWUSkXOZl7GPhpv08eUVLlTQRkRJU1Cpa7TQY+S18eC18fDMM/id0udPtVFKNRIYEMqRdMkPaJXM4v4gZa53SNmnFDj5dlEVkcAAXNk9gYMsk+jSNJyxI/81FxHu9PG09cRHBXNu5nttRRES8il7BVYbwWLjlS/hsJEx4xFm+/8I/gBaBkAoWGuTPwFZ1GNiqDkcLi/hh/V4mrtjOlFU7Gb9kGyGBfvRtksCg1kn0a5ZAVEig25FFRI77afN+Zq3bwxODmxESqJkAIiIlqahVlqAwuPY9+Oa3MOt5yNkBl78E/nqhLJUjOMCffs0S6NcsgcKiYuZn7HPO1bZyB5NW7iDI34+ejWIZ1KoOF7dIpHZ4kNuRRaSGe3naemqFBXJj1/puRxER8ToqapXJP8ApZ1HJMP1pOLQTrnkbgiPcTibVXIC/Hz0axdGjURxPXtGSn7bsZ+LyHUxcsYNpPy/Df5yha3oMg1olcUnLJBKiQtyOLCI1zMptB/hu9S5+e3ETwoP1ckREpDT9ZaxsxkDfxyAyCb5+CN6+DG74FCLi3U4mNYSfn6Fj/Rg61o/hd5c2Z8XWg0xauZ2JK3bwh/Er+eOXK+mYWpuBntJWLybM7cgiUgO8Mm0DkcEB3Nojze0oIiJe6YxFzRhTD3gHSAKKgdHW2pfK2K4v8CIQCOyx1vapyKA+r+OtEJEIn46ANzznWott6HYqqWGMMbROiaZ1SjSPDGjKul2HmLTCGWn76zer+es3q2mdHM3AVkkMbJVEw3iN/opIxVu/K4cJK7Zzb9+GRIfqkAARkbKc8Txqxpg6QB1r7WJjTCSwCLjSWruqxDa1gB+AgdbazcaYBGvtrtM9bk06R8xJshY651ozfnDjJ5Dc0e1EIgBk7sll0kpn9cglW7IBaJIY4SxW0jKJ5nUiMVoQR86RzqN2dqr7c+RvP17CxBU7mP1YP2Ijgt2OIyLimvM6j5q1djuw3fNxjjFmNZAMrCqx2Q3A59bazZ7tTlvSarSUTnD7FHhvKLx1GQx/Bxpf7HYqEdLiwrm7T0Pu7tOQbdmHmbzSGWn7z9R1/Pv7ddSPDXNG2lom0a5eLZU2ETknm/bmMn7pNm7rkaaSJiJyGmd1jJoxJg1oD8wrdVMTINAYMx2IBF6y1r5Txv3vAu4CSE1NPYe41URcI7j9O3j/avjgWrjiP9D+RrdTiRxXt1Yot/VM57ae6ezOOcqUVTuZuGI7b8zK4L8zNlInOoRLWiYxqFUSndJi8PdTaROR8nltxgb8/Qx39m7gdhQREa9W7qJmjIkAxgIPWWsPlvE4HYH+QCgw1xjzo7V2bcmNrLWjgdHgTOs4n+A+LzIRbpvgnBR7/L2Qsw0ueETnWhOvEx8ZzA1dU7mhayoH8gr4bvVOJq7YwQfzN/PWD5nERQRxcQuntHVvGEugv5/bkUXES20/cJjPFmVxXedUErXarIjIaZWrqBljAnFK2vvW2s/L2CQLZwGRXCDXGDMTaAusLWNbOSY4Em74BL68H6b+FQ5uh8H/BD+d9FO8U3RYIMM6pjCsYwqHjhYybc0uJq3cwfglW/lw/maiQgK4qEUig1rV4YLGcTqBrYic5L8zNmIt/KqPRtNERM6kPKs+GuANYLW19oVTbDYeGGWMCQCCgK7AvyosZXUWEARXvgaRdWDOi8651oa9DoGhbicTOa2I4AAub1uXy9vW5UhBETPX7mbSyh18t2onny/eSniQcwLuga2S6Nc0QedJEqnhducc5cP5mxnaPpmU2joNiIjImZTnlVNP4GZguTFmiee6J4BUAGvta9ba1caYScAynCX8X7fWrqiEvNWTnx9c/CRE1YWJj8E7V8L1H0JYjNvJRMolJNCfAS2TGNAyifzCYuZu3MukFdv5duVOvl62neAAP3o3iWdQqyT6N0skOkzLcYtvMcYMBF4C/HGe454pdfsQ4Cmc58BCnMMEZntuywRygCKgsKaufvn67I0UFBVzT1+dmkZEpDzOuDx/ZanuSw+fs5Xj4PO7oHa6c661WvXcTiRyzoqKLQsy9zFphbPs/46DRwjwM/RoFMegVkkMaJGoVd9qCF9ent8Y448zlf9inKn+C4DrS52mJgLItdZaY0wb4BNrbTPPbZlAJ2vtnvJ+zer2HLk/N59ez06lf/NE/n19e7fjiIh4jfNanl+qWMuhEB4PH97gnBj7xs8gqZXbqUTOib+foVuDWLo1iOWPl7VgaVb28RNs/9/ny/nduOV0TothUKskLmmVRJ1oTfkVr9QFWG+t3QhgjPkIGEKJ09RYaw+V2D4cqNkLZpXy5g+Z5OYXcV+/Rm5HERHxGVqezRul9YKRkwADbw6CjJluJxI5b35+hvaptfm/wc2Z8WhfJvz6Au7v14h9ufn8+atVdP/7VK58eQ7/nbGBzXvz3I4rUlIysKXE51me605ijBlqjFkDfAOMLHGTBb41xizynKamTMaYu4wxC40xC3fv3l1B0d138EgBb83J4JKWiTRNinQ7joiIz1BR81aJLeCOKc5xa+8NgxVj3U4kUmGMMbSoG8VvBzRlym/78N1v+/DoJU0pLC7m7xPX0Puf0xj80iz+/f061u3McTuuSFnnTfnFiJm1dpxnuuOVOMerHdPTWtsBGATcZ4zpXdYXsdaOttZ2stZ2io+Pr4DY3uHduZs4eKSQ+/s1djuKiIhP0dRHbxad4oysfXgDfDYScnZA9/vcTiVS4RolRNAooRH39WvEln15zjFtK3fwwpS1vDBlLQ3jwxnUqg4DWyXRsm4URucblKqVBZQ8YDgF2Haqja21M40xDY0xcdbaPdbabZ7rdxljxuFMpawRUyXy8gt5Y3YGfZvG0zol2u04IiI+RUXN24XWhpvHwed3wuQn4OA2uPgpZ6VIkWqoXkwYd/ZuwJ29G7Dz4BEmr9zBxOU7eGX6ekZNW0+9mFAGtkxiYKs6tK9XCz8/lTapdAuAxsaYdGArcB1wQ8kNjDGNgA2exUQ64JyqZq8xJhzws9bmeD4eAPylauO758P5W9iXm88DF+rYNBGRs6Wi5gsCQ+Cat2DS4zB3lDOyduUrEKDV8qR6S4wK4ZbuadzSPY19uflMWeUsRPLWD5n8b1YGiVHBXNIyiYGtkuhUP4agAL2BIRXPWltojLkfmIyzPP8Ya+1KY8zdnttfA4YBtxhjCoDDwLWe0pYIjPOMAgcAH1hrJ7nyjVSxIwVFjJ65gW4NYuhYX6ebERE5WypqvsLPHwb9wzlm7bs/Q+4uuPZ9CIlyO5lIlYgJD+Lazqlc2zmVA4cLmLZmFxNXbOeThVt4Z+4m/Awk1w4lLTac9LjwE//GhZNSO5RAf5U4OXfW2gnAhFLXvVbi42eBZ8u430agbaUH9EKfLcpi58GjvDC8ndtRRER8koqaLzEGev0GIuvA+PvgzcFw46cQVcftZCJVKjo0kCvbJ3Nl+2Ty8guZuXY3q7YdJGNvHhl7DvHT4mwOHS08vn2AnyGldihppQpcemw4ybVD8df0SZEKVVBUzKvTN9A+tRY9Gsa6HUdExCepqPmittdBeBx8fAu8McA5MXZ8E7dTibgiLCiAga3qMLDViTcsrLXsOZRP5t5cMvbkkrkn1/NxHvMz9pGXX3R820B/Q2pM2PFRuLS4E0WuTlSIjoETOQdf/LSVrdmHeerKllr8R0TkHKmo+apGF8Ft38D718CYAXD9x5Da1e1UIl7BGEN8ZDDxkcF0Tjv52BhrLbtyjh4vcBl7PUVuTx6z1u3haGHx8W2DA/yoHxt20ijcsY8To4L1AlSkDEXFllemb6BFnSj6NU1wO46IiM9SUfNlddvD7VPgvavgnSvg6jHQ7FK3U4l4NWMMiVEhJEaF0K3ByVOyiostOw4eOanAZezJY+OeXKb/vJv8ohMlLjTQn/qxYSdNo0yLCyctLoz4CJU4qbm+Wb6djD25vHpjB/0/EBE5Dypqvi4m3SlrHwyHj2+CS5+HTiPdTiXik/z8DHVrhVK3Vig9GsWddFtRsWVb9mEySxS4zL25/LwjhymrdlJYfOL8xxHBAc5IXIkClx7njMzFhAfpxatUW8XFlpenrqdRQgSXtExyO46IiE9TUasOwuPg1q/g0xHw9W/g4Hbo94Sz+IiIVAh/P0O9mDDqxYRxQeP4k24rLCpma/bhEsfD5ZGxJ5cVWw8wacUOikqUuMiQgFLHw52YWlkrLKiqvy2RCvXd6p38vDOHF69tp+M7RUTOk4padREUDtd9CF8/CDP/ATnb4LKXwF8/YpHKFuDvR/3YcOrHhkPTk2/LLywma3/e8cVMji1ssnjzfr5atg17osNRKyzwpNMLpMWdmFoZFRJYtd+UyFmy1jJq2npSY8K4rI1WIxYROV96FV+d+AfAFaMgKhlmPAuHdjknyg4KdzuZSI0VFOBHg/gIGsRH/OK2o4VFbNmXd7zAHTsubt7GvYz7aetJ28aGB5VYzCTspIVNwoP1p1zcN3PdHpZlHeCZq1oToPMWioicNz27VzfGONMeI5Pgm4fh7cvhhk+c6ZEi4lWCA/xplBBJo4TIX9x2pKCITZ4plCeOi8tl9vrdjF189KRt4yODPcfCnXxcXFpsOKFB/lX17UgNZq3lP9+vo050CFd1SHE7johItaCiVl11GgkRifDZyBPnWotJdzuViJRTSKA/TZMiaZr0yxKXl19I5p68X5wnbuqa3ew5lHXStklRIZ4plBEnHQ9XLyaMkECVOKkY8zL2sXDTfp68oiVBARpNExGpCCpq1VmzS+GWL+HDa+GNi+HGT50l/UXEp4UFBdCibhQt6kb94racIwUnRuJKTKecvHIH+3Lzj29nDNSNDvUcA3fyueLq1Q7Ti205K6OmricuIphrO9dzO4qISLWholbdpXaFkd/Ce8PgzUvh2neck2WLSLUUGRJIq+RoWiVH/+K2A3kFJc4Pd2JK5ZdLtnHwSOHx7fwMpNQ+No0yjAf6NyYuIrgqvw3xIYs372f2+j08MbiZRmlFRCqQilpNEN8Ebv8W3r8GPrjWWXCk3fVupxKRKhYdFki7sFq0q1frpOuttezPKzhpGuWxIrd4035+c3ETdwKLT3h56npqhQVyY9f6bkcREalWVNRqiqg6cNs3zkmxv7gbcrZDr9/oXGsigjGGmPAgYsKD6Fi/9km3WWt1gm45pZXbDvD9ml08fHETrT4qIlLBdBBCTRISDTeOhVZXw/dPwsT/B8VFbqcSES+mkian88q0DUQGB3BLjzS3o4iIVDt6+6umCQiCq/7nLN8/dxTk7HA+DwxxO5mIiPiQ9btymLBiO/f2bUh0qE7ILiJS0TSiVhP5+cElf4NLnobVX8K7Q+HwfrdTiYiID3ll2gZCAvwZ2VOnfhERqQwqajVZ9/vg6jGwdSGMGQgHss58HxERqfE27c1l/NJt3Ng1lVitCCoiUilU1Gq6VsOck2Ef3AavXww7V7mdSEREvNxrMzbg72e4s3cDt6OIiFRbKmoC6b3htomAdUbWMme7nUhERLzUtuzDfLYoi2s71SMxSsc3i4hUFhU1cSS1gtunOIuMvDsUfhgFOTvdTiUiIl5m9MyNWAu/6qPRNBGRyqSiJifUqgcjJ0G9rvDt7+D5pjBmEPz4GhzY6nY6ERFx2e6co3w4fzNXdUgmpXaY23FERKo1Lc8vJwuLgVu/gt1rYNV45zLpMeeS0gVaXAHNr4Da9d1OKiIiVez12RspKCrmnr6N3I4iIlLtqajJLxkDCc2dS9/HYfdaWD0eVn0J3/7eudRtDy2GOKUttqHbiUVEpJLtz83nvbmbuKxNXdLjwt2OIyJS7amoyZnFN4H4R6H3o7Bvo1PYVo2H7/7sXJJae0rbEGdbERGpdt78IZPc/CLu66fRNBGRqqCiJmcnpgH0esi5ZG8+Udqm/tW5xDd3SluLIc6InDFuJxYRkfN08EgBb83J4JKWiTRNinQ7johIjaCiJueuVir0uN+5HNgKa752StuMZ2HGMxDb2DmmrcUQSGqj0iYi4qPenbuJg0cKub9fY7ejiIjUGCpqUjGik6Hrr5xLzk5Y85Uz2jb7XzDreaiddmKkrW4HlTYRER+Rl1/IG7Mz6Ns0ntYp0W7HERGpMVTUpOJFJkLnO5xL7h5Y840z0jb3ZZjzEkTXcxYhaTEEUjqDn84SISLirT6Yt5l9ufk8cKGOTRMRqUoqalK5wuOg463OJW8f/DwRVn8JC/4HP74MkXVOlLbUbuDn73ZiERHxOFJQxOiZG+neIJaO9WPcjiMiUqOoqEnVCYuB9jc6lyMHYO1kZ6Rt8dsw/78QHg/NL3dKW/1e4K9fTxERN322KItdOUd58dp2bkcREalx9EpY3BESDW2GO5ejh2Ddt05pW/oRLBwDoTHQ/DJnyf/03hAQ5HZiEZEapaComFenb6B9ai26N4x1O46ISI2joibuC46AVlc5l/w8WP+dU9pWjIPF7zilrumlzkhbw34QEOx2YhGRau+Ln7ayNfswT13ZEqMFoEREqpyKmniXoDDPkv5XQMER2DjNKW1rvoGlH0BwFDQZ6JS2Rv0hMNTtxCIi1U5RseWV6RtoUSeKfk0T3I4jIlIjqaiJ9woMgaaDnEthPmTM8JS2r2H5JxAYDk0GOKWt8QAICnc7sYhItfDN8u1k7Mnl1Rs7aDRNRMQlZyxqxph6wDtAElAMjLbWvnSKbTsDPwLXWms/q8igUsMFBEHji53LZf+CzNlOaVv9FawcBwGh0Pgi55i2JpdASJTbiUVEfFJxseXlqetplBDBJS2T3I4jIlJjlWdErRB42Fq72BgTCSwyxkyx1q4quZExxh94FphcCTlFTvAPdI5Va9gPLn0eNs91StuqL53i5h8EDfs7I21NB0JobbcTi4j4jCmrd/LzzhxevLYdfn4aTRMRccsZi5q1djuw3fNxjjFmNZAMrCq16QPAWKBzRYcUOSU/f0jr5VwGPgtZ80+UtrUTwS8QGvTxlLZLIVwrl4mInIq1llFT11M/NozL2tRxO46ISI12VseoGWPSgPbAvFLXJwNDgQs5TVEzxtwF3AWQmpp6llFFzsDPzzlpdmo3uORp2LoYVn3hFLcvHwDzEKRf4JS2ZpdBhA6QFxEpacba3SzfeoBnh7UmwN/P7TgiIjVauYuaMSYCZ8TsIWvtwVI3vwg8Zq0tOt1Bx9ba0cBogE6dOtmzTitSXsZASkfncvFfYPtSWP0lrPwCvv4NfPMwpPZwSlvzyyFK7xyLSM12bDStbnQIQ9unuB1HRKTGK1dRM8YE4pS09621n5exSSfgI09JiwMGG2MKrbVfVFRQkXNmDNRt51wu/APsWuWZHjkeJj7qXOp1O1HaatVzO7GISJWbl7GPhZv28+QVLQkK0GiaiIjbyrPqowHeAFZba18oaxtrbXqJ7d8CvlZJE69kDCS2dC79noDdPzvHs60aD5P/z7kkd/SUtisgJv3MjykiUg2MmrqeuIhgru2sN6tERLxBeUbUegI3A8uNMUs81z0BpAJYa1+rnGgiVSC+KfR51Lns3XBipG3KH51Lnbae0jYE4hq5nVZEpFIs3ryf2ev38MTgZoQE+rsdR0REKN+qj7OBcq/Pa60dcT6BRFwT2xAu+K1z2Z/pLPW/ajx8/xfnktDSKW0thkBCM7fTiohUmJenrqdWWCA3dq3vdhQREfE4q1UfRWqM2mnQ4wHnciDLU9q+hOl/h+lPQ1xTaHGFU9oSWzlTKkVEfNCKrQf4fs0uHr64CeHBelkgIuIt9BdZ5EyiU6DbPc4lZ8eJkbZZz8PMf0JMgxMjbXXaqbSJiE95Zfp6IoMDuKVHmttRRESkBBU1kbMRmQRd7nQuh3bDz984pW3Ov2H2v6BWqrMISYsrnUVJ/LRymoh4r/W7cpi4Ygf39W1EdGig23FERKQEFTWRcxURDx1HOJe8ffDzBKe0zfsvzB0FUcme0nYF1OsKfjpAX0S8yyvTNhAS4M/IXlrhVkTE26ioiVSEsBhof5NzOZwNayc5x7QtHAPzXoWIROccbc0uhcTWEB6nKZIi4qpNe3MZv3Qbt/VIIyY8yO04IiJSioqaSEULrQVtr3MuR3Ng7WRnpO2n92HB6842IdEQ2whiGzv/xjVy/o1pCEFhrsYXkZrhtRkb8Pcz3Nm7gdtRRESkDCpqIpUpOBJaX+1c8nNh81zYsx72roM96yBzNiz76OT7RKWcKG6xjU98HF1P0ydFXGKMGQi8BPgDr1trnyl1+xDgKaAYKAQe8pze5oz3dcO27MN8tiiL6zqnkhgV4nYcEREpg4qaSFUJCodGFzmXkvJzYd9Gp7jt3XCixC37BI4ePLGdf7CzwmTJEhfbCOIaO1MvRaRSGGP8gZeBi4EsYIEx5ktr7aoSm30PfGmttcaYNsAnQLNy3rfKjZ65EWvhV300miYi4q1U1ETcFhQOSa2dS0nWQu5u2LveU+LWO5fdP8PPk6C44MS2oTEnSltswxMlLqYBBOrdcpHz1AVYb63dCGCM+QgYAhwvW9baQyW2Dwdsee9b1XblHOHD+Zu5qkMyKbU11VpExFupqIl4K2MgIsG51O9x8m1FhZC96ZclbsNUWPJ+yQeBWvU8Uyg95e3YJSpZpw8QKZ9kYEuJz7OArqU3MsYMBf4OJACXns19Pfe/C7gLIDU19bxDn8obszIoKCrmnr6NKu1riIjI+VNRE/FF/gGekbOG0OSSk287muOZQrm+RJFbBz/Ng/wSb/oHhHoeo1GJ0TjPx6G1qvTbEfFyZS3Ran9xhbXjgHHGmN44x6tdVN77eu4/GhgN0KlTpzK3OV/7c/N598dNXN62Lulx4ZXxJUREpIKoqIlUN8GRULedcynJWsjZ4SlwnuPh9qyDHctg9Vdgi05sGx5/8ujbsRJXOx0CtIy31DhZQL0Sn6cA2061sbV2pjGmoTEm7mzvW9nenJNBXn4R9/XTaJqIiLdTUROpKYyBqDrOJf2Ck28rzIf9mSVK3Hpndcq1kyH33RKP4Qe16nuKm+d4uGMlLrKOzg0n1dUCoLExJh3YClwH3FByA2NMI2CDZzGRDkAQsBfIPtN9q8rBIwW89UMmA1sm0SQx0o0IIiJyFlTURMQZJYtv4lxKO5xdYipliRKXMQsKD5/YLjD85OJW8tQCwXpRKL7LWltojLkfmIyzxP4Ya+1KY8zdnttfA4YBtxhjCoDDwLXWWguUeV83vo93527i4JFCjaaJiPgIFTUROb3QWpDS0bmUVFwMOdtKHAfnObVA1kJY8TknHYYTkXTyib2PrUpZuz74B1bldyNyTqy1E4AJpa57rcTHzwLPlve+VS0vv5A3ZmfQt2k8rVOi3YwiIiLlpKImIufGzw+iU5xLg74n31ZwBPZn/LLErfoSDu8r8RgBznFvZZW4iARNpRSpIB/M28y+3HweuFCjaSIivkJFTUQqXmAIJDR3LqXl7Su1ImWJUwsUHT2xXXDUiXPCnXR+uIbOuedEpFyOFBQxeuZGujeIpWP9GLfjiIhIOamoiUjVCouBsC5Qr8vJ1xcXwYGsk1ek3LseNs+F5Z+cvG1U8skn9o5rDFF1IaQWhNaGwFCNxol4fLooi105R3nx2nZuRxERkbOgoiYi3sHP3zlmrXZ9aHTRybfl58G+jScWNNnjGYVb8RkcOfDLx/IPdo6tC63tXEJKfFzm9Z5/Q6KdHCLVREFRMa9N30CH1Fp0bxjrdhwRETkLKmoi4v2CwiCplXMpyVrI2+uMvh3aCUey4fD+EhfP5weyYOcK5+OSJ/0uS0h0qWJ3qnJX6vrA0Mr4zkXOy7iftrI1+zB/vbIVRqPMIiI+RUVNRHyXMRAe51zKqzDfGYU7VuZOKnfZv7z+wJYT15c8KXhp/sHlG7U7PnpXS6N4UqmKii2vTt9Ay7pR9G0a73YcERE5SypqIlKzBARBRLxzORvWwtGcMxe7Y9dnb4Hty5zrTzuKZyAk6iymaZa4XqN4chrfLN9Oxp5cXr2xg0bTRER8kIqaiEh5GE+hComCWqlnd9/CfE+Ryz5FsStV+g5sOXHd6UbxAkJOM02z1qlLX3C0c3oFqbaKiy0vT11Po4QILmmZ5HYcERE5BypqIiKVLSDIOS9cRMLZ3e/YKF65pmlmQ/Ym2L7Uua4g9zQPbJwpl+U9/q5uB+eUC+Izpqzeyc87c3jx2nb4+Wk0TUTEF6moiYh4q5KjeLXrn919j4/ilWOa5uH9sH/Tiett8cmP9ZuVzonNxWeMnrmR+rFhXNamjttRRETkHKmoiYhUR+c6ildcDPk5Jxe78LN8DHHdyzd0YGv2YQL8NcVVRMRXqaiJiMgJfn6eUxREn/0onniNpOgQkqI1XVVExJfprTYREREREREvo6ImIiIiIiLiZVTUREREREREvIyKmoiIiIiIiJdRURMREREREfEyKmoiIiIiIiJeRkVNRERERETEy6ioiYiIiIiIeBkVNRERERERES+joiYiIiIiIuJlVNRERERERES8jIqaiIiIiIiIl1FRExERERER8TIqaiIiIiIiIl5GRU1ERERERMTLGGutO1/YmN3ApvN8mDhgTwXEqSq+lFdZK4cvZQXfyquslaOista31sZXwOPUCDXwOdKXsoJv5VXWyqGslceX8lZE1lM+P7pW1CqCMWahtbaT2znKy5fyKmvl8KWs4Ft5lbVy+FJWOZkv/ex8KSv4Vl5lrRzKWnl8KW9lZ9XURxERERERES+joiYiIiIiIuJlfL2ojXY7wFnypbzKWjl8KSv4Vl5lrRy+lFVO5ks/O1/KCr6VV1krh7JWHl/KW6lZffoYNRERERERkerI10fUREREREREqh0VNRERERERES/jE0XNGDPQGPOzMWa9MebxMm43xph/e25fZozp4EZOT5YzZe1rjDlgjFniufzRjZyeLGOMMbuMMStOcbs37dczZfWm/VrPGDPNGLPaGLPSGPNgGdt4xb4tZ1Zv2rchxpj5xpilnrxPlrGNt+zb8mT1mn3ryeNvjPnJGPN1Gbd5xX6VX9JzZOXQc2Tl0HNkpWXV82Mlcu350Vrr1RfAH9gANACCgKVAi1LbDAYmAgboBszz4qx9ga/d3q+eLL2BDsCKU9zuFfu1nFm9ab/WATp4Po4E1nrx72x5snrTvjVAhOfjQGAe0M1L9215snrNvvXk+S3wQVmZvGW/6vKLn4ueIysvr54jKyerniMrJ6ueHys3syvPj74wotYFWG+t3WitzQc+AoaU2mYI8I51/AjUMsbUqeqglC+r17DWzgT2nWYTb9mv5cnqNay12621iz0f5wCrgeRSm3nFvi1nVq/h2V+HPJ8Gei6lV0Tyln1bnqxewxiTAlwKvH6KTbxiv8ov6Dmykug5snLoObJy6Pmx8rj5/OgLRS0Z2FLi8yx++Z+kPNtUhfLm6O4Z7p1ojGlZNdHOibfs1/Lyuv1qjEkD2uO8W1SS1+3b02QFL9q3nukHS4BdwBRrrdfu23JkBe/Zty8C/w8oPsXtXrNf5SR6jnSPt+zX8vK6/arnyIql58dK8yIuPT/6QlEzZVxXunWXZ5uqUJ4ci4H61tq2wH+ALyo71Hnwlv1aHl63X40xEcBY4CFr7cHSN5dxF9f27RmyetW+tdYWWWvbASlAF2NMq1KbeM2+LUdWr9i3xpjLgF3W2kWn26yM67z170FNoudI93jLfi0Pr9uveo6seHp+rHhuPz/6QlHLAuqV+DwF2HYO21SFM+aw1h48NtxrrZ0ABBpj4qou4lnxlv16Rt62X40xgTh/1N+31n5exiZes2/PlNXb9u0x1tpsYDowsNRNXrNvjzlVVi/atz2BK4wxmTjT0S40xrxXahuv268C6DnSTd6yX8/I2/arniMrl54fK5Srz4++UNQWAI2NMenGmCDgOuDLUtt8CdziWXWlG3DAWru9qoNSjqzGmCRjjPF83AXnZ7C3ypOWj7fs1zPypv3qyfEGsNpa+8IpNvOKfVuerF62b+ONMbU8H4cCFwFrSm3mLfv2jFm9Zd9aa//PWptirU3D+bs11Vp7U6nNvGK/yi/oOdI93rJfz8ib9queIyuHnh8rh9vPjwEV8SCVyVpbaIy5H5iMs2LUGGvtSmPM3Z7bXwMm4Ky4sh7IA27z4qxXA/cYYwqBw8B11lpXhp2NMR/irKoTZ4zJAv6Ec0CnV+1XKFdWr9mvOO++3AwsN878a4AngFTwun1bnqzetG/rAG8bY/xx/mh/Yq392hv/HpQzqzft21/w0v0qJeg5svLoObLS6Dmycuj5sQpV1X41XvQ9i4iIiIiICL4x9VFERERERKRGUVETERERERHxMipqIiIiIiIiXkZFTURERERExMuoqImIiIiIiHgZFTWRs2CMKTLGLClxebwCHzvNGLOioh5PRESkquj5UaTief151ES8zGFrbTu3Q4iIiHgZPT+KVDCNqIlUAGNMpjHmWWPMfM+lkef6+saY740xyzz/pnquTzTGjDPGLPVcengeyt8Y8z9jzEpjzLfGmFDP9v+/nXtnrSKKwjD8LkOQgKigjaBgk0pQvOAPsLW0iGIlNqaJlZcfYK+EpLGwEAXLlAEREcRgIdhoKXYRkiJImiDyWWSLB80Bc5iQCbxPc/asGfaZXS3WvsxMVX1u/bzYpWFKkrQt5kdpdBZq0vZM/LW1Y2rg3vckF4E54FGLzQFPk5wGngOzLT4LvElyBjgHfGrxSWA+ySlgDbjS4veBs62fWzszNEmSRmZ+lDpWSXb7HaQ9o6rWkxzYIv4VuJTkS1WNA9+SHKmqVeBYkh8tvpzkaFWtAMeTbAz0cRJ4mWSyXd8DxpM8qKpFYB1YABaSrO/wUCVJ+m/mR6l7rqhJ3cmQ9rBntrIx0P7Jn3Okl4F54Dzwoao8XypJ2ivMj9IILNSk7kwN/C619jvgamtfB9629itgGqCqxqrq4LBOq2ofcCLJa+AucBj4Z9ZSkqSeMj9KI3DWQdqeiar6OHC9mOT3J4j3V9V7NidArrXYDPCkqu4AK8CNFr8NPK6qm2zODE4Dy0P+cwx4VlWHgAIeJlnraDySJHXB/Ch1zDNqUgfaHvwLSVZ3+10kSeoL86M0Orc+SpIkSVLPuKImSZIkST3jipokSZIk9YyFmiRJkiT1jIWaJEmSJPWMhZokSZIk9YyFmiRJkiT1zC832Hlh0bWpSAAAAABJRU5ErkJggg=="
class="
jp-needs-light-background
"
>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Nice!!!</p>
<p>It looks like our regularization techniques (data augmentation and label smoothing) helped prevent our model from overfitting (the training loss is still higher than the test loss) this indicates our model has a bit more capacity to learn and could improve with further training.</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="107-saving-and-loading-foodvision-big">10.7 Saving and loading FoodVision Big<a class="anchor-link" href="#107-saving-and-loading-foodvision-big">&#182;</a></h3><p>Now we've trained our biggest model yet, let's save it so we can load it back in later.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[74]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-74">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="c1"># Create a model path</span>
<span class="n">effnetb2_food101_model_path</span> <span class="o">=</span> <span class="s2">&quot;09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth&quot;</span> 

<span class="c1"># Save FoodVision Big model</span>
<span class="n">utils</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2_food101</span><span class="p">,</span>
                 <span class="n">target_dir</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
                 <span class="n">model_name</span><span class="o">=</span><span class="n">effnetb2_food101_model_path</span><span class="p">)</span>
</pre></div>
<div id="cell-74" class="clipboard-copy-txt">from going_modular.going_modular import utils

# Create a model path
effnetb2_food101_model_path = "09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth" 

# Save FoodVision Big model
utils.save_model(model=effnetb2_food101,
                 target_dir="models",
                 model_name=effnetb2_food101_model_path)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Saving model to: models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Model saved!</p>
<p>Before we move on, let's make sure we can load it back in.</p>
<p>We'll do so by creating a model instance first with <code>create_effnetb2_model(num_classes=101)</code> (101 classes for all Food101 classes).</p>
<p>And then loading the saved <code>state_dict()</code> with <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict#torch.nn.Module.load_state_dict"><code>torch.nn.Module.load_state_dict()</code></a> and <a href="https://pytorch.org/docs/stable/generated/torch.load.html"><code>torch.load()</code></a>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[75]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-75">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create Food101 compatible EffNetB2 instance</span>
<span class="n">loaded_effnetb2_food101</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>

<span class="c1"># Load the saved model&#39;s state_dict()</span>
<span class="n">loaded_effnetb2_food101</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth&quot;</span><span class="p">))</span>
</pre></div>
<div id="cell-75" class="clipboard-copy-txt"># Create Food101 compatible EffNetB2 instance
loaded_effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101)

# Load the saved model's state_dict()
loaded_effnetb2_food101.load_state_dict(torch.load("models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"))</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[75]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>&lt;All keys matched successfully&gt;</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="108-checking-foodvision-big-model-size">10.8 Checking FoodVision Big model size<a class="anchor-link" href="#108-checking-foodvision-big-model-size">&#182;</a></h3><p>Our FoodVision Big model is capable of classifying 101 classes versus FoodVision Mini's 3 classes, a 33.6x increase!</p>
<p>How does this effect the model size?</p>
<p>Let's find out.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[76]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-76">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Get the model size in bytes then convert to megabytes</span>
<span class="n">pretrained_effnetb2_food101_model_size</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;models&quot;</span><span class="p">,</span> <span class="n">effnetb2_food101_model_path</span><span class="p">)</span><span class="o">.</span><span class="n">stat</span><span class="p">()</span><span class="o">.</span><span class="n">st_size</span> <span class="o">//</span> <span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> <span class="c1"># division converts bytes to megabytes (roughly) </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pretrained EffNetB2 feature extractor Food101 model size: </span><span class="si">{</span><span class="n">pretrained_effnetb2_food101_model_size</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-76" class="clipboard-copy-txt">from pathlib import Path

# Get the model size in bytes then convert to megabytes
pretrained_effnetb2_food101_model_size = Path("models", effnetb2_food101_model_path).stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) 
print(f"Pretrained EffNetB2 feature extractor Food101 model size: {pretrained_effnetb2_food101_model_size} MB")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Pretrained EffNetB2 feature extractor Food101 model size: 30 MB
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Hmm, it looks like the model size stayed largely the same (30 MB for FoodVision Big and 29 MB for FoodVision Mini) despite the large increase in the number of classes.</p>
<p>This is because all the extra parameters for FoodVision Big are <em>only</em> in the last layer (the classifier head).</p>
<p>All of the base layers are the same between FoodVision Big and FoodVision Mini.</p>
<p>Going back up and comparing the model summaries will give more details.</p>
<table>
<thead>
<tr>
  <th><strong>Model</strong></th>
  <th><strong>Output shape (num classes)</strong></th>
  <th><strong>Trainable parameters</strong></th>
  <th><strong>Total parameters</strong></th>
  <th><strong>Model size (MB)</strong></th>
</tr>
</thead>
<tbody>
<tr>
  <td>FoodVision Mini (EffNetB2 feature extractor)</td>
  <td>3</td>
  <td>4,227</td>
  <td>7,705,221</td>
  <td>29</td>
</tr>
<tr>
  <td>FoodVision Big (EffNetB2 feature extractor)</td>
  <td>101</td>
  <td>142,309</td>
  <td>7,843,303</td>
  <td>30</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="11-turning-our-foodvision-big-model-into-a-deployable-app">11. Turning our FoodVision Big model into a deployable app<a class="anchor-link" href="#11-turning-our-foodvision-big-model-into-a-deployable-app">&#182;</a></h2><p>We've got a trained and saved EffNetB2 model on 20% of the Food101 dataset.</p>
<p>And instead of letting our model live in a folder all its life, let's deploy it!</p>
<p>We'll deploy our FoodVision Big model in the same way we deployed our FoodVision Mini model, as a Gradio demo on Hugging Face Spaces.</p>
<p>To begin, let's create a <code>demos/foodvision_big/</code> directory to store our FoodVision Big demo files as well as a <code>demos/foodvision_big/examples</code> directory to hold an example image to test the demo with.</p>
<p>When we're finished we'll have the following file structure:</p>
<pre><code>demos/
  foodvision_big/
    09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth
    app.py
    class_names.txt
    examples/
      example_1.jpg
    model.py
    requirements.txt
</code></pre>
<p>Where:</p>
<ul>
<li><code>09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth</code> is our trained PyTorch model file.</li>
<li><code>app.py</code> contains our FoodVision Big Gradio app.</li>
<li><code>class_names.txt</code> contains all of the class names for FoodVision Big.</li>
<li><code>examples/</code> contains example images to use with our Gradio app.</li>
<li><code>model.py</code> contains the model defintion as well as any transforms assosciated with the model.</li>
<li><code>requirements.txt</code> contains the dependencies to run our app such as <code>torch</code>, <code>torchvision</code> and <code>gradio</code>.</li>
</ul>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[77]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-77">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Create FoodVision Big demo path</span>
<span class="n">foodvision_big_demo_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;demos/foodvision_big/&quot;</span><span class="p">)</span>

<span class="c1"># Make FoodVision Big demo directory</span>
<span class="n">foodvision_big_demo_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Make FoodVision Big demo examples directory</span>
<span class="p">(</span><span class="n">foodvision_big_demo_path</span> <span class="o">/</span> <span class="s2">&quot;examples&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<div id="cell-77" class="clipboard-copy-txt">from pathlib import Path

# Create FoodVision Big demo path
foodvision_big_demo_path = Path("demos/foodvision_big/")

# Make FoodVision Big demo directory
foodvision_big_demo_path.mkdir(parents=True, exist_ok=True)

# Make FoodVision Big demo examples directory
(foodvision_big_demo_path / "examples").mkdir(parents=True, exist_ok=True)</div>
        
        </div>
    </div>

</div>
</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="111-downloading-an-example-image-and-moving-it-to-the-examples-directory">11.1 Downloading an example image and moving it to the <code>examples</code> directory<a class="anchor-link" href="#111-downloading-an-example-image-and-moving-it-to-the-examples-directory">&#182;</a></h3><p>For our example image, we're going to use the faithful <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg"><code>pizza-dad</code> image</a> (a photo of my dad eating pizza).</p>
<p>So let's download it from the course GitHub via the <code>!wget</code> command and then we can move it to <code>demos/foodvision_big/examples</code> with the <code>!mv</code> command (short for &quot;move&quot;).</p>
<p>While we're here we'll move our trained Food101 EffNetB2 model from <code>models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth</code> to <code>demos/foodvision_big</code> as well.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[78]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-78">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Download and move an example image</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">mrdbourke</span><span class="o">/</span><span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">images</span><span class="o">/</span><span class="mi">04</span><span class="o">-</span><span class="n">pizza</span><span class="o">-</span><span class="n">dad</span><span class="o">.</span><span class="n">jpeg</span> 
<span class="err">!</span><span class="n">mv</span> <span class="mi">04</span><span class="o">-</span><span class="n">pizza</span><span class="o">-</span><span class="n">dad</span><span class="o">.</span><span class="n">jpeg</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="mi">04</span><span class="o">-</span><span class="n">pizza</span><span class="o">-</span><span class="n">dad</span><span class="o">.</span><span class="n">jpg</span>

<span class="c1"># Move trained model to FoodVision Big demo folder (will error if model is already moved)</span>
<span class="err">!</span><span class="n">mv</span> <span class="n">models</span><span class="o">/</span><span class="mi">09</span><span class="n">_pretrained_effnetb2_feature_extractor_food101_20_percent</span><span class="o">.</span><span class="n">pth</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span>
</pre></div>
<div id="cell-78" class="clipboard-copy-txt"># Download and move an example image
!wget https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg 
!mv 04-pizza-dad.jpeg demos/foodvision_big/examples/04-pizza-dad.jpg

# Move trained model to FoodVision Big demo folder (will error if model is already moved)
!mv models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth demos/foodvision_big</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>--2022-08-25 14:24:41--  https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 2874848 (2.7M) [image/jpeg]
Saving to: &#39;04-pizza-dad.jpeg

04-pizza-dad.jpeg   100%[===================&gt;]   2.74M  7.85MB/s    in 0.3s    

2022-08-25 14:24:43 (7.85 MB/s) - &#39;04-pizza-dad.jpeg saved [2874848/2874848]

</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="112-saving-food101-class-names-to-file-class_namestxt">11.2 Saving Food101 class names to file (<code>class_names.txt</code>)<a class="anchor-link" href="#112-saving-food101-class-names-to-file-class_namestxt">&#182;</a></h3><p>Because there are so many classes in the Food101 dataset, instead of storing them as a list in our <code>app.py</code> file, let's saved them to a <code>.txt</code> file and read them in when necessary instead.</p>
<p>We'll just remind ourselves what they look like first by checking out <code>food101_class_names</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[79]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-79">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Check out the first 10 Food101 class names</span>
<span class="n">food101_class_names</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
<div id="cell-79" class="clipboard-copy-txt"># Check out the first 10 Food101 class names
food101_class_names[:10]</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[79]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[&#39;apple_pie&#39;,
 &#39;baby_back_ribs&#39;,
 &#39;baklava&#39;,
 &#39;beef_carpaccio&#39;,
 &#39;beef_tartare&#39;,
 &#39;beet_salad&#39;,
 &#39;beignets&#39;,
 &#39;bibimbap&#39;,
 &#39;bread_pudding&#39;,
 &#39;breakfast_burrito&#39;]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Wonderful, now we can write these to a text file by first creating a path to <code>demos/foodvision_big/class_names.txt</code> and then opening a file with Python's <code>open()</code> and then writing to it leaving a new line for each class.</p>
<p>Ideally, we want our class names to be saved like:</p>
<pre><code>apple_pie
baby_back_ribs
baklava
beef_carpaccio
beef_tartare
...
</code></pre>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[80]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-80">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Create path to Food101 class names</span>
<span class="n">foodvision_big_class_names_path</span> <span class="o">=</span> <span class="n">foodvision_big_demo_path</span> <span class="o">/</span> <span class="s2">&quot;class_names.txt&quot;</span>

<span class="c1"># Write Food101 class names list to file</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">foodvision_big_class_names_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Saving Food101 class names to </span><span class="si">{</span><span class="n">foodvision_big_class_names_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">food101_class_names</span><span class="p">))</span> <span class="c1"># leave a new line between each class</span>
</pre></div>
<div id="cell-80" class="clipboard-copy-txt"># Create path to Food101 class names
foodvision_big_class_names_path = foodvision_big_demo_path / "class_names.txt"

# Write Food101 class names list to file
with open(foodvision_big_class_names_path, "w") as f:
    print(f"[INFO] Saving Food101 class names to {foodvision_big_class_names_path}")
    f.write("\n".join(food101_class_names)) # leave a new line between each class</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>[INFO] Saving Food101 class names to demos/foodvision_big/class_names.txt
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>Excellent, now let's make sure we can read them in.</p>
<p>To do so we'll use Python's <a href="https://www.w3schools.com/python/ref_func_open.asp"><code>open()</code></a> in read mode (<code>&quot;r&quot;</code>) and then use the <a href="https://www.w3schools.com/python/ref_file_readlines.asp"><code>readlines()</code></a> method to read each line of our <code>class_names.txt</code> file.</p>
<p>And we can save the class names to a list by stripping the newline value of each of them with a list comprehension and <a href="https://www.w3schools.com/python/ref_string_strip.asp"><code>strip()</code></a>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[81]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-81">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Open Food101 class names file and read each line into a list</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">foodvision_big_class_names_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">food101_class_names_loaded</span> <span class="o">=</span> <span class="p">[</span><span class="n">food</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">food</span> <span class="ow">in</span>  <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
    
<span class="c1"># View the first 5 class names loaded back in</span>
<span class="n">food101_class_names_loaded</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
<div id="cell-81" class="clipboard-copy-txt"># Open Food101 class names file and read each line into a list
with open(foodvision_big_class_names_path, "r") as f:
    food101_class_names_loaded = [food.strip() for food in  f.readlines()]
    
# View the first 5 class names loaded back in
food101_class_names_loaded[:5]</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[81]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>[&#39;apple_pie&#39;, &#39;baby_back_ribs&#39;, &#39;baklava&#39;, &#39;beef_carpaccio&#39;, &#39;beef_tartare&#39;]</pre>
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="113-turning-our-foodvision-big-model-into-a-python-script-modelpy">11.3 Turning our FoodVision Big model into a Python script (<code>model.py</code>)<a class="anchor-link" href="#113-turning-our-foodvision-big-model-into-a-python-script-modelpy">&#182;</a></h3><p>Just like the FoodVision Mini demo, let's create a script that's capable of instantiating an EffNetB2 feature extractor model along with its necessary transforms.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[82]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-82">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">py</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">def</span> <span class="nf">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                          <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Creates an EfficientNetB2 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of classes in the classifier head. </span>
<span class="sd">            Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): EffNetB2 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): EffNetB2 image transforms.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create EffNetB2 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Freeze all layers in base model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Change classifier head with random seed for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div id="cell-82" class="clipboard-copy-txt">%%writefile demos/foodvision_big/model.py
import torch
import torchvision

from torch import nn


def create_effnetb2_model(num_classes:int=3, 
                          seed:int=42):
    """Creates an EfficientNetB2 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of classes in the classifier head. 
            Defaults to 3.
        seed (int, optional): random seed value. Defaults to 42.

    Returns:
        model (torch.nn.Module): EffNetB2 feature extractor model. 
        transforms (torchvision.transforms): EffNetB2 image transforms.
    """
    # Create EffNetB2 pretrained weights, transforms and model
    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.efficientnet_b2(weights=weights)

    # Freeze all layers in base model
    for param in model.parameters():
        param.requires_grad = False

    # Change classifier head with random seed for reproducibility
    torch.manual_seed(seed)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.3, inplace=True),
        nn.Linear(in_features=1408, out_features=num_classes),
    )
    
    return model, transforms</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Overwriting demos/foodvision_big/model.py
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="114-turning-our-foodvision-big-gradio-app-into-a-python-script-apppy">11.4 Turning our FoodVision Big Gradio app into a Python script (<code>app.py</code>)<a class="anchor-link" href="#114-turning-our-foodvision-big-gradio-app-into-a-python-script-apppy">&#182;</a></h3><p>We've got a FoodVision Big <code>model.py</code> script, now let's create a FoodVision Big <code>app.py</code> script.</p>
<p>This will again mostly be the same as the FoodVision Mini <code>app.py</code> script except we'll change:</p>
<ol>
<li><strong>Imports and class names setup</strong> - The <code>class_names</code> variable will be a list for all of the Food101 classes rather than pizza, steak, sushi. We can access these via <code>demos/foodvision_big/class_names.txt</code>.</li>
<li><strong>Model and transforms preparation</strong> - The <code>model</code> will have <code>num_classes=101</code> rather than <code>num_classes=3</code>. We'll also be sure to load the weights from <code>&quot;09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth&quot;</code> (our FoodVision Big model path).</li>
<li><strong>Predict function</strong> - This will stay the same as FoodVision Mini's <code>app.py</code>.</li>
<li><strong>Gradio app</strong> - The Gradio interace will have different <code>title</code>, <code>description</code> and <code>article</code> parameters to reflect the details of FoodVision Big.</li>
</ol>
<p>We'll also make sure to save it to <code>demos/foodvision_big/app.py</code> using the <code>%%writefile</code> magic command.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[83]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-83">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">app</span><span class="o">.</span><span class="n">py</span>
<span class="c1">### 1. Imports and class names setup ### </span>
<span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">create_effnetb2_model</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>

<span class="c1"># Setup class names</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;class_names.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># reading them in from class_names.txt</span>
    <span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">food_name</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">food_name</span> <span class="ow">in</span>  <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
    
<span class="c1">### 2. Model and transforms preparation ###    </span>

<span class="c1"># Create model</span>
<span class="n">effnetb2</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="c1"># could also use len(class_names)</span>
<span class="p">)</span>

<span class="c1"># Load saved weights</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">f</span><span class="o">=</span><span class="s2">&quot;09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth&quot;</span><span class="p">,</span>
        <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>  <span class="c1"># load to CPU</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1">### 3. Predict function ###</span>

<span class="c1"># Create predict function</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Transforms and performs a prediction on img and returns prediction and time taken.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Start the timer</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    
    <span class="c1"># Transform the target image and add a batch dimension</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">effnetb2_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Put model into evaluation mode and turn on inference mode</span>
    <span class="n">effnetb2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
        <span class="c1"># Pass the transformed image through the model and turn the prediction logits into prediction probabilities</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">effnetb2</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio&#39;s output parameter)</span>
    <span class="n">pred_labels_and_probs</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))}</span>
    
    <span class="c1"># Calculate the prediction time</span>
    <span class="n">pred_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># Return the prediction dictionary and prediction time </span>
    <span class="k">return</span> <span class="n">pred_labels_and_probs</span><span class="p">,</span> <span class="n">pred_time</span>

<span class="c1">### 4. Gradio app ###</span>

<span class="c1"># Create title, description and article strings</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;FoodVision Big &quot;</span>
<span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;An EfficientNetB2 feature extractor computer vision model to classify images of food into [101 different classes](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names.txt).&quot;</span>
<span class="n">article</span> <span class="o">=</span> <span class="s2">&quot;Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/).&quot;</span>

<span class="c1"># Create examples list from &quot;examples/&quot; directory</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;examples/&quot;</span> <span class="o">+</span> <span class="n">example</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;examples&quot;</span><span class="p">)]</span>

<span class="c1"># Create Gradio interface </span>
<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span>
    <span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;pil&quot;</span><span class="p">),</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">gr</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">num_top_classes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predictions&quot;</span><span class="p">),</span>
        <span class="n">gr</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prediction time (s)&quot;</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">examples</span><span class="o">=</span><span class="n">example_list</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Launch the app!</span>
<span class="n">demo</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</pre></div>
<div id="cell-83" class="clipboard-copy-txt">%%writefile demos/foodvision_big/app.py
### 1. Imports and class names setup ### 
import gradio as gr
import os
import torch

from model import create_effnetb2_model
from timeit import default_timer as timer
from typing import Tuple, Dict

# Setup class names
with open("class_names.txt", "r") as f: # reading them in from class_names.txt
    class_names = [food_name.strip() for food_name in  f.readlines()]
    
### 2. Model and transforms preparation ###    

# Create model
effnetb2, effnetb2_transforms = create_effnetb2_model(
    num_classes=101, # could also use len(class_names)
)

# Load saved weights
effnetb2.load_state_dict(
    torch.load(
        f="09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth",
        map_location=torch.device("cpu"),  # load to CPU
    )
)

### 3. Predict function ###

# Create predict function
def predict(img) -> Tuple[Dict, float]:
    """Transforms and performs a prediction on img and returns prediction and time taken.
    """
    # Start the timer
    start_time = timer()
    
    # Transform the target image and add a batch dimension
    img = effnetb2_transforms(img).unsqueeze(0)
    
    # Put model into evaluation mode and turn on inference mode
    effnetb2.eval()
    with torch.inference_mode():
        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities
        pred_probs = torch.softmax(effnetb2(img), dim=1)
    
    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)
    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}
    
    # Calculate the prediction time
    pred_time = round(timer() - start_time, 5)
    
    # Return the prediction dictionary and prediction time 
    return pred_labels_and_probs, pred_time

### 4. Gradio app ###

# Create title, description and article strings
title = "FoodVision Big "
description = "An EfficientNetB2 feature extractor computer vision model to classify images of food into [101 different classes](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names.txt)."
article = "Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."

# Create examples list from "examples/" directory
example_list = [["examples/" + example] for example in os.listdir("examples")]

# Create Gradio interface 
demo = gr.Interface(
    fn=predict,
    inputs=gr.Image(type="pil"),
    outputs=[
        gr.Label(num_top_classes=5, label="Predictions"),
        gr.Number(label="Prediction time (s)"),
    ],
    examples=example_list,
    title=title,
    description=description,
    article=article,
)

# Launch the app!
demo.launch()</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Overwriting demos/foodvision_big/app.py
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="115-creating-a-requirements-file-for-foodvision-big-requirementstxt">11.5 Creating a requirements file for FoodVision Big (<code>requirements.txt</code>)<a class="anchor-link" href="#115-creating-a-requirements-file-for-foodvision-big-requirementstxt">&#182;</a></h3><p>Now all we need is a <code>requirements.txt</code> file to tell our Hugging Face Space what dependencies our FoodVision Big app requires.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[84]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-84">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">torch</span><span class="o">==</span><span class="mf">1.12.0</span>
<span class="n">torchvision</span><span class="o">==</span><span class="mf">0.13.0</span>
<span class="n">gradio</span><span class="o">==</span><span class="mf">3.1.4</span>
</pre></div>
<div id="cell-84" class="clipboard-copy-txt">%%writefile demos/foodvision_big/requirements.txt
torch==1.12.0
torchvision==0.13.0
gradio==3.1.4</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Overwriting demos/foodvision_big/requirements.txt
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="116-downloading-our-foodvision-big-app-files">11.6 Downloading our FoodVision Big app files<a class="anchor-link" href="#116-downloading-our-foodvision-big-app-files">&#182;</a></h3><p>We've got all the files we need to deploy our FoodVision Big app on Hugging Face, let's now zip them together and download them.</p>
<p>We'll use the same process we used for the FoodVision Mini app above in <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#91-downloading-our-foodvision-mini-app-files">section 9.1: <em>Downloading our Foodvision Mini app files</em></a>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[85]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-85">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># Zip foodvision_big folder but exclude certain files</span>
<span class="err">!</span><span class="n">cd</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span> <span class="o">&amp;&amp;</span> <span class="nb">zip</span> <span class="o">-</span><span class="n">r</span> <span class="o">../</span><span class="n">foodvision_big</span><span class="o">.</span><span class="n">zip</span> <span class="o">*</span> <span class="o">-</span><span class="n">x</span> <span class="s2">&quot;*.pyc&quot;</span> <span class="s2">&quot;*.ipynb&quot;</span> <span class="s2">&quot;*__pycache__*&quot;</span> <span class="s2">&quot;*ipynb_checkpoints*&quot;</span>

<span class="c1"># Download the zipped FoodVision Big app (if running in Google Colab)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;demos/foodvision_big.zip&quot;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Not running in Google Colab, can&#39;t use google.colab.files.download()&quot;</span><span class="p">)</span>
</pre></div>
<div id="cell-85" class="clipboard-copy-txt"># Zip foodvision_big folder but exclude certain files
!cd demos/foodvision_big && zip -r ../foodvision_big.zip * -x "*.pyc" "*.ipynb" "*__pycache__*" "*ipynb_checkpoints*"

# Download the zipped FoodVision Big app (if running in Google Colab)
try:
    from google.colab import files
    files.download("demos/foodvision_big.zip")
except:
    print("Not running in Google Colab, can't use google.colab.files.download()")</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>updating: 09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth (deflated 8%)
updating: app.py (deflated 54%)
updating: class_names.txt (deflated 48%)
updating: examples/ (stored 0%)
updating: flagged/ (stored 0%)
updating: model.py (deflated 56%)
updating: requirements.txt (deflated 4%)
updating: examples/04-pizza-dad.jpg (deflated 0%)
Not running in Google Colab, can&#39;t use google.colab.files.download()
</pre>
</div>
</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h3 id="117-deploying-our-foodvision-big-app-to-huggingface-spaces">11.7 Deploying our FoodVision Big app to HuggingFace Spaces<a class="anchor-link" href="#117-deploying-our-foodvision-big-app-to-huggingface-spaces">&#182;</a></h3><p>B, E, A, Utiful!</p>
<p>Time to bring our biggest model of the whole course to life!</p>
<p>Let's deploy our FoodVision Big Gradio demo to Hugging Face Spaces so we can test it interactively and let others experience the magic of our machine learning efforts!</p>
<blockquote>
<p><strong>Note:</strong> There are <a href="https://huggingface.co/docs/hub/repositories-getting-started#getting-started-with-repositories">several ways to upload files to Hugging Face Spaces</a>. The following steps treat Hugging Face as a git repository to track files. However, you can also upload directly to Hugging Face Spaces via the <a href="https://huggingface.co/docs/hub/repositories-getting-started#adding-files-to-a-repository-web-ui">web interface</a> or by the <a href="https://huggingface.co/docs/huggingface_hub/index"><code>huggingface_hub</code> library</a>.</p>
</blockquote>
<p>The good news is, we've already done the steps to do so with FoodVision Mini, so now all we have to do is customize them to suit FoodVision Big:</p>
<ol>
<li><a href="https://huggingface.co/join">Sign up</a> for a Hugging Face account.</li>
<li>Start a new Hugging Face Space by going to your profile and then <a href="https://huggingface.co/new-space">clicking &quot;New Space&quot;</a>.<ul>
<li><strong>Note:</strong> A Space in Hugging Face is also known as a &quot;code repository&quot; (a place to store your code/files) or &quot;repo&quot; for short.</li>
</ul>
</li>
<li>Give the Space a name, for example, mine is called <code>mrdbourke/foodvision_big</code>, you can see it here: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_big">https://huggingface.co/spaces/mrdbourke/foodvision_big</a></li>
<li>Select a license (I used <a href="https://opensource.org/licenses/MIT">MIT</a>).</li>
<li>Select Gradio as the Space SDK (software development kit).<ul>
<li><strong>Note:</strong> You can use other options such as Streamlit but since our app is built with Gradio, we'll stick with that.</li>
</ul>
</li>
<li>Choose whether your Space is it's public or private (I selected public since I'd like my Space to be available to others).</li>
<li>Click &quot;Create Space&quot;.</li>
<li>Clone the repo locally by running: <code>git clone https://huggingface.co/spaces/[YOUR_USERNAME]/[YOUR_SPACE_NAME]</code> in terminal or command prompt.<ul>
<li><strong>Note:</strong> You can also add files via uploading them under the &quot;Files and versions&quot; tab.</li>
</ul>
</li>
<li>Copy/move the contents of the downloaded <code>foodvision_big</code> folder to the cloned repo folder.</li>
<li>To upload and track larger files (e.g. files over 10MB or in our case, our PyTorch model file) you'll need to <a href="https://git-lfs.github.com/">install Git LFS</a> (which stands for &quot;git large file storage&quot;).</li>
<li>After you've installed Git LFS, you can activate it by running <code>git lfs install</code>.</li>
<li>In the <code>foodvision_big</code> directory, track the files over 10MB with Git LFS with <code>git lfs track &quot;*.file_extension&quot;</code>.<ul>
<li>Track EffNetB2 PyTorch model file with <code>git lfs track &quot;09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth&quot;</code>.</li>
<li><strong>Note:</strong> If you get any errors uploading images, you may have to track them with <code>git lfs</code> too, for example <code>git lfs track &quot;examples/04-pizza-dad.jpg&quot;</code></li>
</ul>
</li>
<li>Track <code>.gitattributes</code> (automatically created when cloning from HuggingFace, this file will help ensure our larger files are tracked with Git LFS). You can see an example <code>.gitattributes</code> file on the <a href="https://huggingface.co/spaces/mrdbourke/foodvision_big/blob/main/.gitattributes">FoodVision Big Hugging Face Space</a>.<ul>
<li><code>git add .gitattributes</code></li>
</ul>
</li>
<li>Add the rest of the <code>foodvision_big</code> app files and commit them with:<ul>
<li><code>git add *</code></li>
<li><code>git commit -m &quot;first commit&quot;</code></li>
</ul>
</li>
<li>Push (upload) the files to Hugging Face:<ul>
<li><code>git push</code></li>
</ul>
</li>
<li>Wait 3-5 minutes for the build to happen (future builds are faster) and your app to become live!</li>
</ol>
<p>If everything worked correctly, our FoodVision Big Gradio demo should be ready to classify!</p>
<p>You can see my version here: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_big/">https://huggingface.co/spaces/mrdbourke/foodvision_big/</a></p>
<p>Or we can even embed our FoodVision Big Gradio demo right within our notebook as an <a href="https://gradio.app/sharing_your_app/#embedding-with-iframes">iframe</a> with <a href="https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.IFrame"><code>IPython.display.IFrame</code></a> and a link to our space in the format <code>https://hf.space/embed/[YOUR_USERNAME]/[YOUR_SPACE_NAME]/+</code>.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div  class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[86]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
        
        
        <div class="CodeMirror cm-s-jupyter">
            <div class="zeroclipboard-container">
                <clipboard-copy for="cell-86">
                <div>
                    <span class="notice" hidden>Copied!</span>
                    <svg aria-hidden="true" width="20" height="20" viewBox="0 0 16 16" version="1.1"  data-view-component="true" class="clipboard-copy-icon">
                        <path fill="currentColor" fill-rule="evenodd" d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z"></path>
                        <path fill="currentColor" fill-rule="evenodd" d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z"></path>
                    </svg>
                    </div>
                </clipboard-copy>
            </div>
            <div class="highlight-ipynb hl-python "><pre><span></span><span class="c1"># IPython is a library to help work with Python iteractively </span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>

<span class="c1"># Embed FoodVision Big Gradio demo as an iFrame</span>
<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">&quot;https://hf.space/embed/mrdbourke/foodvision_big/+&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">)</span>
</pre></div>
<div id="cell-86" class="clipboard-copy-txt"># IPython is a library to help work with Python iteractively 
from IPython.display import IFrame

# Embed FoodVision Big Gradio demo as an iFrame
IFrame(src="https://hf.space/embed/mrdbourke/foodvision_big/+", width=900, height=750)</div>
        
        </div>
    </div>

</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[86]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">

        <iframe
            width="900"
            height="750"
            src="https://hf.space/embed/mrdbourke/foodvision_big/+"
            frameborder="0"
            allowfullscreen
            
        ></iframe>
        
</div>

</div>

</div>

</div>

</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<p>How cool is that!?!</p>
<p>We've come a long way from building PyTorch models to predict a straight line... now we're building computer vision models accessible to people all around the world!</p>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="main-takeaways">Main takeaways<a class="anchor-link" href="#main-takeaways">&#182;</a></h2><ul>
<li><strong>Deployment is as important as training.</strong> Once youve got a good working model, your first question should be: how can I deploy this and make it accessible to others? Deployment allows you to test your model in the real world rather than on private training and test sets.</li>
<li><strong>Three questions for machine learning model deployment:</strong><ol>
<li>Whats the most ideal use case for the model (how well and how fast does it perform)?</li>
<li>Wheres the model going to go (is it on-device or on the cloud)?</li>
<li>Hows the model going to function (are predictions online or offline)?</li>
</ol>
</li>
<li><strong>Deployment options are a plenty.</strong> But best to start simple. One of the best current ways (I say current because these things are always changing) is to use Gradio to create a demo and host it on Hugging Face Spaces. Start simple and scale up when needed.</li>
<li><strong>Never stop experimenting.</strong> Your machine learning model needs will likely change overtime so deploying a single model is not the last step. You might find the dataset changes, so youll have to update your model. Or new research gets released and theres a better architecture to use.<ul>
<li>So deploying one model is an excellent step, but you'll likely want to update it over time.</li>
</ul>
</li>
<li><strong>Machine learning model deployment is part of the engineering practice of MLOps (machine learning operations).</strong> MLOps is an extension of DevOps (development operations) and involves all the engineering parts around training a model: data collection and storage, data preprocessing, model deployment, model monitoring, versioning and more. Its a rapidly evolving field but there are some solid resources out there to learn more, many of which are in <a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and-deep-learning-engineering">PyTorch Extra Resources</a>.</li>
</ul>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="exercises">Exercises<a class="anchor-link" href="#exercises">&#182;</a></h2><p>All of the exercises are focused on practicing the code above.</p>
<p>You should be able to complete them by referencing each section or by following the resource(s) linked.</p>
<p><strong>Resources:</strong></p>
<ul>
<li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/09_pytorch_model_deployment_exercises.ipynb">Exercise template notebook for 09</a>.</li>
<li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/09_pytorch_model_deployment_exercise_solutions.ipynb">Example solutions notebook for 09</a> try the exercises <em>before</em> looking at this.<ul>
<li>See a live <a href="https://youtu.be/jOX5ZCkWO-0">video walkthrough of the solutions on YouTube</a> (errors and all).</li>
</ul>
</li>
</ul>
<ol>
<li>Make and time predictions with both feature extractor models on the test dataset using the GPU (<code>device=&quot;cuda&quot;</code>). Compare the model's prediction times on GPU vs CPU - does this close the gap between them? As in, does making predictions on the GPU make the ViT feature extractor prediction times closer to the EffNetB2 feature extractor prediction times?<ul>
<li>You'll find code to do these steps in <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#5-making-predictions-with-our-trained-models-and-timing-them">section 5. Making predictions with our trained models and timing them</a> and <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#6-comparing-model-results-prediction-times-and-size">section 6. Comparing model results, prediction times and size</a>.</li>
</ul>
</li>
<li>The ViT feature extractor seems to have more learning capacity (due to more parameters) than EffNetB2, how does it go on the larger 20% split of the entire Food101 dataset?<ul>
<li>Train a ViT feature extractor on the 20% Food101 dataset for 5 epochs, just like we did with EffNetB2 in section <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#10-creating-foodvision-big">10. Creating FoodVision Big</a>.</li>
</ul>
</li>
<li>Make predictions across the 20% Food101 test dataset with the ViT feature extractor from exercise 2 and find the &quot;most wrong&quot; predictions.<ul>
<li>The predictions will be the ones with the highest prediction probability but with the wrong predicted label.</li>
<li>Write a sentence or two about why you think the model got these predictions wrong.</li>
</ul>
</li>
<li>Evaluate the ViT feature extractor across the whole Food101 test dataset rather than just the 20% version, how does it perform?<ul>
<li>Does it beat the original Food101 paper's best result of 56.4% accuracy?</li>
</ul>
</li>
<li>Head to <a href="https://paperswithcode.com/">Paperswithcode.com</a> and find the current best performing model on the Food101 dataset.<ul>
<li>What model architecture does it use?</li>
</ul>
</li>
<li>Write down 1-3 potential failure points of our deployed FoodVision models and what some potential solutions might be.<ul>
<li>For example, what happens if someone was to upload a photo that wasn't of food to our FoodVision Mini model?</li>
</ul>
</li>
<li>Pick any dataset from <a href="https://pytorch.org/vision/stable/datasets.html"><code>torchvision.datasets</code></a> and train a feature extractor model on it using a model from <a href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a> (you could use one of the model's we've already created, e.g. EffNetB2 or ViT) for 5 epochs and then deploy your model as a Gradio app to Hugging Face Spaces.<ul>
<li>You may want to pick smaller dataset/make a smaller split of it so training doesn't take too long.</li>
<li>I'd love to see your deployed models! So be sure to share them in Discord or on the <a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">course GitHub Discussions page</a>.</li>
</ul>
</li>
</ol>

</div>
</div>
</div>
</div>
<div  class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="extra-curriculum">Extra-curriculum<a class="anchor-link" href="#extra-curriculum">&#182;</a></h2><ul>
<li>Machine learning model deployment is generally an engineering challenge rather than a pure machine learning challenge, see the <a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and-deep-learning-engineering">PyTorch Extra Resources machine learning engineering section</a> for resources on learning more.<ul>
<li>Inside you'll find recommendations for resources such as Chip Huyen's book <a href="https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969"><em>Designing Machine Learning Systems</em></a> (especially chapter 7 on model deployment) and Goku Mohandas's <a href="https://madewithml.com/#mlops">Made with ML MLOps course</a>.</li>
</ul>
</li>
<li>As you start to build more and more of your own projects, you'll likely start using Git (and potentially GitHub) quite frequently. To learn more about both, I'd recommend the <a href="https://youtu.be/RGOj5yH7evk"><em>Git and GitHub for Beginners - Crash Course</em></a> video on the freeCodeCamp YouTube channel.</li>
<li>We've only scratched the surface with what's possible with Gradio. For more, I'd recommend checking out the <a href="https://gradio.app/docs/">full documentation</a>, especially:<ul>
<li>All of the different kinds of <a href="https://gradio.app/docs/#components">input and output components</a>.</li>
<li>The <a href="https://gradio.app/docs/#blocks">Gradio Blocks API</a> for more advanced workflows.</li>
<li>The Hugging Face Course chapter on <a href="https://huggingface.co/course/chapter9/1">how to use Gradio with Hugging Face</a>.</li>
</ul>
</li>
<li>Edge devices aren't limited to mobile phones, they include small computers like the Raspberry Pi and the PyTorch team have a <a href="https://pytorch.org/tutorials/intermediate/realtime_rpi.html">fantastic blog post tutorial</a> on deploying a PyTorch model to one.</li>
<li>For a fanstastic guide on developing AI and ML-powered applications, see <a href="https://pair.withgoogle.com/guidebook">Google's People + AI Guidebook</a>. One of my favourites is the section on <a href="https://pair.withgoogle.com/guidebook/patterns#set-the-right-expectations">setting the right expectations</a>.<ul>
<li>I covered more of these kinds of resources, including guides from Apple, Microsoft and more in the <a href="https://zerotomastery.io/blog/machine-learning-monthly-april-2021/">April 2021 edition of Machine Learning Monthly</a> (a monthly newsletter I send out with the latest and greatest of the ML field).</li>
</ul>
</li>
<li>If you'd like to speed up your model's runtime on CPU, you should be aware of <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">TorchScript</a>, <a href="https://pytorch.org/docs/stable/onnx.html">ONNX</a> (Open Neural Network Exchange) and <a href="https://docs.openvino.ai/latest/notebooks/102-pytorch-onnx-to-openvino-with-output.html">OpenVINO</a>. Going from pure PyTorch to ONNX/OpenVINO models I've seen a ~2x+ increase in performance.</li>
<li>For turning models into a deployable and scalable API, see the <a href="https://pytorch.org/serve/">TorchServe library</a>.</li>
<li>For a terrific example and rationale as to why deploying a machine learning model in the browser (a form of edge deployment) offers several benefits (no network transfer latency delay), see Jo Kristian Bergum's article on <a href="https://bergum.medium.com/moving-ml-inference-from-the-cloud-to-the-edge-d6f98dbdb2e3"><em>Moving ML Inference from the Cloud to the Edge</em></a>.</li>
</ul>

</div>
</div>
</div>
</div>
</div>








                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs Insiders
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/mrdbourke" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mrdbourke/pytorch-deep-learning" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.youtube.com/channel/UCr8O8l5cCX85Oem1d18EezQ" target="_blank" rel="noopener" title="www.youtube.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.top"], "search": "../assets/javascripts/workers/search.6c7302c4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.10c6cd24.min.js"></script>
      
    
  </body>
</html>